{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Clapping?\n",
    "Clapping is a way readers can show appreciation for a Medium story and recommend it to their followers. The more you like something, the more you can clap. You can clap up to 50 times per post, and you can clap for as many posts as you want. Clapping plays a role in determining how much you can earn per story.\n",
    "https://medium.com/blogging-guide/how-do-claps-work-on-medium-b2897784ce6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "\n",
    "import pandas as pd\n",
    "import requests \n",
    "import numpy as np\n",
    "from time import sleep \n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save url as a variable\n",
    "url = 'https://towardsdatascience.com/archive/2021/3/3'\n",
    "\n",
    "#check status\n",
    "res = requests.get(url)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_data = []\n",
    "\n",
    "for month in range(1, 5):\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        n_days = 31\n",
    "    elif month in [4, 6, 9, 11]:\n",
    "        n_days = 30\n",
    "    else:\n",
    "        n_days = 28\n",
    "\n",
    "    for day in range(1, n_days + 1):\n",
    "\n",
    "        month, day = str(month), str(day)\n",
    "\n",
    "        if len(month) == 1:\n",
    "            month = f'0{month}'\n",
    "        if len(day) == 1:\n",
    "            day = f'0{day}'\n",
    "\n",
    "        date = f'{month}/{day}/2021'\n",
    "        url = f'https://towardsdatascience.com/archive/2021/{month}/{day}'\n",
    "\n",
    "        page  = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        stories = soup.find_all('div', class_='streamItem streamItem--postPreview js-streamItem')\n",
    "        \n",
    "        sleep(np.random.randint(1, 15))\n",
    "        \n",
    "        for story in stories:\n",
    "            each_story = []\n",
    "\n",
    "            author_box = story.find('div', class_='postMetaInline u-floatLeft u-sm-maxWidthFullWidth')\n",
    "            author_url = author_box.find('a')['href']\n",
    "\n",
    "            try:\n",
    "                reading_time = author_box.find('span', class_='readingTime')['title']\n",
    "                reading_time = reading_time.split()[0]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            title = story.find('h3').text if story.find('h3') else '-'\n",
    "            subtitle = story.find('h4').text if story.find('h4') else '-'\n",
    "            \n",
    "            sleep(np.random.randint(1, 15))\n",
    "\n",
    "            if story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                           ' js-multirecommendCountButton u-disablePointerEvents'):\n",
    "\n",
    "                claps = story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                                    ' js-multirecommendCountButton u-disablePointerEvents').text\n",
    "            else:\n",
    "                claps = 0\n",
    "\n",
    "            if story.find('a', class_='button button--chromeless u-baseColor--buttonNormal'):\n",
    "                responses = story.find('a', class_='button button--chromeless u-baseColor--buttonNormal').text\n",
    "                responses = responses.split()[0]\n",
    "            else:\n",
    "                responses = '0 responses'\n",
    "\n",
    "            story_url = story.find('a', class_='button button--smaller button--chromeless u-baseColor--buttonNormal')[\n",
    "                'href']\n",
    "            \n",
    "            story_page = requests.get(story_url)\n",
    "            story_soup = BeautifulSoup(story_page.text, 'html.parser')\n",
    "\n",
    "            sections = story_soup.find_all('section')\n",
    "            story_paragraphs = []\n",
    "            section_titles = []\n",
    "            \n",
    "            for section in sections:\n",
    "                paragraphs = section.find_all('p')\n",
    "                for paragraph in paragraphs:\n",
    "                    story_paragraphs.append(paragraph.text)\n",
    "\n",
    "                subs = section.find_all('h1')\n",
    "                for sub in subs:\n",
    "                    section_titles.append(sub.text)\n",
    "\n",
    "            number_sections = len(section_titles)\n",
    "            number_paragraphs = len(story_paragraphs)\n",
    "            \n",
    "            each_story.append(date)\n",
    "            each_story.append(title)\n",
    "            each_story.append(subtitle)\n",
    "            each_story.append(claps)\n",
    "            each_story.append(responses)\n",
    "            each_story.append(author_url)\n",
    "            each_story.append(story_url)\n",
    "            each_story.append(reading_time)\n",
    "            each_story.append(number_sections)\n",
    "            each_story.append(section_titles)\n",
    "            each_story.append(number_paragraphs)\n",
    "            each_story.append(story_paragraphs)\n",
    "            stories_data.append(each_story)\n",
    "            \n",
    "    columns = ['date', 'title', 'subtitle', 'claps', 'responses', \n",
    "           'author_url', 'story_url', 'reading_time (mins)', \n",
    "           'number_sections', 'section_titles', 'number_paragraphs', 'paragraphs']\n",
    "\n",
    "    df = pd.DataFrame(stories_data, columns=columns)\n",
    "    df.to_csv(f'2021_{month}.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some 2020 stories\n",
    "stories_data = []\n",
    "\n",
    "for month in range(10, 13):\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        n_days = 31\n",
    "    elif month in [4, 6, 9, 11]:\n",
    "        n_days = 30\n",
    "    else:\n",
    "        n_days = 28\n",
    "\n",
    "    for day in range(1, n_days + 1):\n",
    "\n",
    "        month, day = str(month), str(day)\n",
    "\n",
    "        if len(month) == 1:\n",
    "            month = f'0{month}'\n",
    "        if len(day) == 1:\n",
    "            day = f'0{day}'\n",
    "\n",
    "        date = f'{month}/{day}/2020'\n",
    "        url = f'https://towardsdatascience.com/archive/2020/{month}/{day}'\n",
    "\n",
    "        page  = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        stories = soup.find_all('div', class_='streamItem streamItem--postPreview js-streamItem')\n",
    "        \n",
    "        sleep(np.random.randint(1, 15))\n",
    "        \n",
    "        for story in stories:\n",
    "            each_story = []\n",
    "\n",
    "            author_box = story.find('div', class_='postMetaInline u-floatLeft u-sm-maxWidthFullWidth')\n",
    "            author_url = author_box.find('a')['href']\n",
    "\n",
    "            try:\n",
    "                reading_time = author_box.find('span', class_='readingTime')['title']\n",
    "                reading_time = reading_time.split()[0]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            title = story.find('h3').text if story.find('h3') else '-'\n",
    "            subtitle = story.find('h4').text if story.find('h4') else '-'\n",
    "            \n",
    "            sleep(np.random.randint(1, 15))\n",
    "\n",
    "            if story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                           ' js-multirecommendCountButton u-disablePointerEvents'):\n",
    "\n",
    "                claps = story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                                    ' js-multirecommendCountButton u-disablePointerEvents').text\n",
    "            else:\n",
    "                claps = 0\n",
    "\n",
    "            if story.find('a', class_='button button--chromeless u-baseColor--buttonNormal'):\n",
    "                responses = story.find('a', class_='button button--chromeless u-baseColor--buttonNormal').text\n",
    "                responses = responses.split()[0]\n",
    "            else:\n",
    "                responses = '0 responses'\n",
    "\n",
    "            story_url = story.find('a', class_='button button--smaller button--chromeless u-baseColor--buttonNormal')[\n",
    "                'href']\n",
    "            \n",
    "            story_page = requests.get(story_url)\n",
    "            story_soup = BeautifulSoup(story_page.text, 'html.parser')\n",
    "\n",
    "            sections = story_soup.find_all('section')\n",
    "            story_paragraphs = []\n",
    "            section_titles = []\n",
    "            \n",
    "            for section in sections:\n",
    "                paragraphs = section.find_all('p')\n",
    "                for paragraph in paragraphs:\n",
    "                    story_paragraphs.append(paragraph.text)\n",
    "\n",
    "                subs = section.find_all('h1')\n",
    "                for sub in subs:\n",
    "                    section_titles.append(sub.text)\n",
    "\n",
    "            number_sections = len(section_titles)\n",
    "            number_paragraphs = len(story_paragraphs)\n",
    "            \n",
    "            each_story.append(date)\n",
    "            each_story.append(title)\n",
    "            each_story.append(subtitle)\n",
    "            each_story.append(claps)\n",
    "            each_story.append(responses)\n",
    "            each_story.append(author_url)\n",
    "            each_story.append(story_url)\n",
    "            each_story.append(reading_time)\n",
    "            each_story.append(number_sections)\n",
    "            each_story.append(section_titles)\n",
    "            each_story.append(number_paragraphs)\n",
    "            each_story.append(story_paragraphs)\n",
    "            stories_data.append(each_story)\n",
    "            \n",
    "    columns = ['date', 'title', 'subtitle', 'claps', 'responses', \n",
    "           'author_url', 'story_url', 'reading_time (mins)', \n",
    "           'number_sections', 'section_titles', 'number_paragraphs', 'paragraphs']\n",
    "\n",
    "    df = pd.DataFrame(stories_data, columns=columns)\n",
    "    df.to_csv(f'2020_{month}.csv', sep='\\t', index=False)\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
