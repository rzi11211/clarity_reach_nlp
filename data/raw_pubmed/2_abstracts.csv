pmid,citations,title,date,text
33340009,2.0,Systems biology in cardiovascular disease: a multiomics approach,2021 May;18(5):313-330.,"Omics techniques generate large, multidimensional data that are amenable to analysis by new informatics approaches alongside conventional statistical methods. Systems theories, including network analysis and machine learning, are well placed for analysing these data but must be applied with an understanding of the relevant biological and computational theories. Through applying these techniques to omics data, systems biology addresses the problems posed by the complex organization of biological processes. In this Review, we describe the techniques and sources of omics data, outline network theory, and highlight exemplars of novel approaches that combine gene regulatory and co-expression networks, proteomics, metabolomics, lipidomics and phenomics with informatics techniques to provide new insights into cardiovascular disease. The use of systems approaches will become necessary to integrate data from more than one omic technique. Although understanding the interactions between different omics data requires increasingly complex concepts and methods, we argue that hypothesis-driven investigations and independent validation must still accompany these novel systems biology approaches to realize their full potential."
33337337,,Technical Aspects of Developing Chatbots for Medical Applications: Scoping Review,2020 Dec 18;22(12):e19127.,"Background:                    Chatbots are applications that can conduct natural language conversations with users. In the medical field, chatbots have been developed and used to serve different purposes. They provide patients with timely information that can be critical in some scenarios, such as access to mental health resources. Since the development of the first chatbot, ELIZA, in the late 1960s, much effort has followed to produce chatbots for various health purposes developed in different ways.              Objective:                    This study aimed to explore the technical aspects and development methodologies associated with chatbots used in the medical field to explain the best methods of development and support chatbot development researchers on their future work.              Methods:                    We searched for relevant articles in 8 literature databases (IEEE, ACM, Springer, ScienceDirect, Embase, MEDLINE, PsycINFO, and Google Scholar). We also performed forward and backward reference checking of the selected articles. Study selection was performed by one reviewer, and 50% of the selected studies were randomly checked by a second reviewer. A narrative approach was used for result synthesis. Chatbots were classified based on the different technical aspects of their development. The main chatbot components were identified in addition to the different techniques for implementing each module.              Results:                    The original search returned 2481 publications, of which we identified 45 studies that matched our inclusion and exclusion criteria. The most common language of communication between users and chatbots was English (n=23). We identified 4 main modules: text understanding module, dialog management module, database layer, and text generation module. The most common technique for developing text understanding and dialogue management is the pattern matching method (n=18 and n=25, respectively). The most common text generation is fixed output (n=36). Very few studies relied on generating original output. Most studies kept a medical knowledge base to be used by the chatbot for different purposes throughout the conversations. A few studies kept conversation scripts and collected user data and previous conversations.              Conclusions:                    Many chatbots have been developed for medical use, at an increasing rate. There is a recent, apparent shift in adopting machine learning-based approaches for developing chatbot systems. Further research can be conducted to link clinical outcomes to different chatbot development techniques and technical characteristics."
33333829,1.0,A Systematic Review of Statistical and Machine Learning Methods for Electrical Power Forecasting with Reported MAPE Score,2020 Dec 15;22(12):1412.,"Electric power forecasting plays a substantial role in the administration and balance of current power systems. For this reason, accurate predictions of service demands are needed to develop better programming for the generation and distribution of power and to reduce the risk of vulnerabilities in the integration of an electric power system. For the purposes of the current study, a systematic literature review was applied to identify the type of model that has the highest propensity to show precision in the context of electric power forecasting. The state-of-the-art model in accurate electric power forecasting was determined from the results reported in 257 accuracy tests from five geographic regions. Two classes of forecasting models were compared: classical statistical or mathematical (MSC) and machine learning (ML) models. Furthermore, the use of hybrid models that have made significant contributions to electric power forecasting is identified, and a case of study is applied to demonstrate its good performance when compared with traditional models. Among our main findings, we conclude that forecasting errors are minimized by reducing the time horizon, that ML models that consider various sources of exogenous variability tend to have better forecast accuracy, and finally, that the accuracy of the forecasting models has significantly increased over the last five years."
33330127,,Mini Review: Clinical Routine Microbiology in the Era of Automation and Digital Health,2020 Nov 30;10:582028.,"Clinical microbiology laboratories are the first line to combat and handle infectious diseases and antibiotic resistance, including newly emerging ones. Although most clinical laboratories still rely on conventional methods, a cascade of technological changes, driven by digital imaging and high-throughput sequencing, will revolutionize the management of clinical diagnostics for direct detection of bacteria and swift antimicrobial susceptibility testing. Importantly, such technological advancements occur in the golden age of machine learning where computers are no longer acting passively in data mining, but once trained, can also help physicians in making decisions for diagnostics and optimal treatment administration. The further potential of physically integrating new technologies in an automation chain, combined to machine-learning-based software for data analyses, is seducing and would indeed lead to a faster management in infectious diseases. However, if, from one side, technological advancement would achieve a better performance than conventional methods, on the other side, this evolution challenges clinicians in terms of data interpretation and impacts the entire hospital personnel organization and management. In this mini review, we discuss such technological achievements offering practical examples of their operability but also their limitations and potential issues that their implementation could rise in clinical microbiology laboratories."
33329090,,Reviewing a Decade of Research Into Suicide and Related Behaviour Using the South London and Maudsley NHS Foundation Trust Clinical Record Interactive Search (CRIS) System,2020 Nov 27;11:553463.,"Suicide is a serious public health issue worldwide, yet current clinical methods for assessing a person's risk of taking their own life remain unreliable and new methods for assessing suicide risk are being explored. The widespread adoption of electronic health records (EHRs) has opened up new possibilities for epidemiological studies of suicide and related behaviour amongst those receiving healthcare. These types of records capture valuable information entered by healthcare practitioners at the point of care. However, much recent work has relied heavily on the structured data of EHRs, whilst much of the important information about a patient's care pathway is recorded in the unstructured text of clinical notes. Accessing and structuring text data for use in clinical research, and particularly for suicide and self-harm research, is a significant challenge that is increasingly being addressed using methods from the fields of natural language processing (NLP) and machine learning (ML). In this review, we provide an overview of the range of suicide-related studies that have been carried out using the Clinical Records Interactive Search (CRIS): a database for epidemiological and clinical research that contains de-identified EHRs from the South London and Maudsley NHS Foundation Trust. We highlight the variety of clinical research questions, cohorts and techniques that have been explored for suicide and related behaviour research using CRIS, including the development of NLP and ML approaches. We demonstrate how EHR data provides comprehensive material to study prevalence of suicide and self-harm in clinical populations. Structured data alone is insufficient and NLP methods are needed to more accurately identify relevant information from EHR data. We also show how the text in clinical notes provide signals for ML approaches to suicide risk assessment. We envision increased progress in the decades to come, particularly in externally validating findings across multiple sites and countries, both in terms of clinical evidence and in terms of NLP and machine learning method transferability."
33328300,1.0,Soft sensors that can feel it all,2020 Dec 16;5(49):eabf0894.,"Soft materials and machine learning combine to enable a sensor that distinguishes bending, stretching, and compression."
33327400,1.0,Bird Eye View of Protein Subcellular Localization Prediction,2020 Dec 14;10(12):347.,"Proteins are made up of long chain of amino acids that perform a variety of functions in different organisms. The activity of the proteins is determined by the nucleotide sequence of their genes and by its 3D structure. In addition, it is essential for proteins to be destined to their specific locations or compartments to perform their structure and functions. The challenge of computational prediction of subcellular localization of proteins is addressed in various in silico methods. In this review, we reviewed the progress in this field and offered a bird eye view consisting of a comprehensive listing of tools, types of input features explored, machine learning approaches employed, and evaluation matrices applied. We hope the review will be useful for the researchers working in the field of protein localization predictions."
33326953,,Artificial Intelligence in Thyroid Fine Needle Aspiration Biopsies,2020 Dec 16;1-6.,"Background:                    From cell phones to aerospace, artificial intelligence (AI) has wide-reaching influence in the modern age. In this review, we discuss the application of AI solutions to an equally ubiquitous problem in cytopathology - thyroid fine needle aspiration biopsy (FNAB). Thyroid nodules are common in the general population, and FNAB is the sampling modality of choice. The resulting prevalence in the practicing pathologist's daily workload makes thyroid FNAB an appealing target for the application of AI solutions.              Summary:                    This review summarizes all available literature on the application of AI to thyroid cytopathology. We follow the evolution from morphometric analysis to convolutional neural networks. We explore the application of AI technology to different questions in thyroid cytopathology, including distinguishing papillary carcinoma from benign, distinguishing follicular adenoma from carcinoma and identifying non-invasive follicular thyroid neoplasm with papillary-like nuclear features by key words and phrases. Key Messages: The current literature shows promise towards the application of AI technology to thyroid fine needle aspiration biopsy. Much work is needed to define how this powerful technology will be of best use to the future of cytopathology practice."
33325829,,Paradigm Shift Toward Digital Neuropsychology and High-Dimensional Neuropsychological Assessments: Review,2020 Dec 16;22(12):e23777.,"Neuropsychologists in the digital age have increasing access to emerging technologies. The National Institutes of Health (NIH) initiatives for behavioral and social sciences have emphasized these developing scientific and technological potentials (eg, novel sensors) for augmented characterization of neurocognitive, behavioral, affective, and social processes. Perhaps these innovative technologies will lead to a paradigm shift from disintegrated and data-poor behavioral science to cohesive and data-rich science that permits improved translation from bench to bedside. The 4 main advances influencing the scientific priorities of a recent NIH Office of Behavioral and Social Sciences Research strategic plan include the following: integration of neuroscience into behavioral and social sciences, transformational advances in measurement science, digital intervention platforms, and large-scale population cohorts and data integration. This paper reviews these opportunities for novel brain-behavior characterizations. Emphasis is placed on the increasing concern of neuropsychology with these topics and the need for development in these areas to maintain relevance as a scientific discipline and advance scientific developments. Furthermore, the effects of such advancements necessitate discussion and modification of training as well as ethical and legal mandates for neuropsychological research and praxes."
33323492,,Machine Learning for Child and Adolescent Health: A Systematic Review,2021 Jan;147(1):e2020011833.,"Context:                    In the last few decades, data acquisition and processing has seen tremendous amount of growth, thus sparking interest in machine learning (ML) within the health care system.              Objective:                    Our aim for this review is to provide an evidence map of the current available evidence on ML in pediatrics and adolescent medicine and provide insight for future research.              Data sources:                    A literature search was conducted by using Medline, the Cochrane Library, the Cumulative Index to Nursing and Allied Health Literature Plus, Web of Science Library, and EBSCO Dentistry & Oral Science Source.              Study selection:                    Articles in which an ML model was assessed for the diagnosis, prediction, or management of any condition in children and adolescents (0-18 years) were included.              Data extraction:                    Data were extracted for year of publication, geographical location, age range, number of participants, disease or condition under investigation, study methodology, reference standard, type, category, and performance of ML algorithms.              Results:                    The review included 363 studies, with subspecialties such as psychiatry, neonatology, and neurology having the most literature. A majority of the studies were from high-income (82%; n = 296) and upper middle-income countries (15%; n = 56), whereas only 3% (n = 11) were from low middle-income countries. Neural networks and ensemble methods were most commonly tested in the 1990s, whereas deep learning and clustering emerged rapidly in the current decade.              Limitations:                    Only studies conducted in the English language could be used in this review.              Conclusions:                    The interest in ML has been growing across various subspecialties and countries, suggesting a potential role in health service delivery for children and adolescents in the years to come."
33319174,,Emerging Materials for Neuromorphic Devices and Systems,2020 Nov 24;23(12):101846.,"Neuromorphic devices and systems have attracted attention as next-generation computing due to their high efficiency in processing complex data. So far, they have been demonstrated using both machine-learning software and complementary metal-oxide-semiconductor-based hardware. However, these approaches have drawbacks in power consumption and learning speed. An energy-efficient neuromorphic computing system requires hardware that can mimic the functions of a brain. Therefore, various materials have been introduced for the development of neuromorphic devices. Here, recent advances in neuromorphic devices are reviewed. First, the functions of biological synapses and neurons are discussed. Also, deep neural networks and spiking neural networks are described. Then, the operation mechanism and the neuromorphic functions of emerging devices are reviewed. Finally, the challenges and prospects for developing neuromorphic devices that use emerging materials are discussed."
33317961,,Next-Generation Liquid Biopsies: Embracing Data Science in Oncology,2021 Apr;7(4):283-292.,"Deeper and broader sequencing of circulating tumor DNA (ctDNA) has identified a wealth of cancer markers in the circulation, resulting in a paradigm shift towards data science-driven liquid biopsies in oncology. Although panel sequencing for actionable mutations in plasma is moving towards the clinic, the next generation of liquid biopsies is increasingly shifting from analyzing digital mutation signals towards analog signals, requiring a greater role for machine learning. Concomitantly, there is an increasing acceptance that these cancer signals do not have to arise from the tumor itself. In this Opinion, we discuss the opportunities and challenges arising from increasingly complex cancer liquid biopsy data."
33316137,,Machine learning for predictive data analytics in medicine: A review illustrated by cardiovascular and nuclear medicine examples,2021 Mar;41(2):113-127.,"The evidence-based medicine allows the physician to evaluate the risk-benefit ratio of a treatment through setting and data. Risk-based choices can be done by the doctor using different information. With the emergence of new technologies, a large amount of data is recorded offering interesting perspectives with machine learning for predictive data analytics. Machine learning is an ensemble of methods that process data to model a learning problem. Supervised machine learning algorithms consist in using annotated data to construct the model. This category allows to solve prediction data analytics problems. In this paper, we detail the use of supervised machine learning algorithms for predictive data analytics problems in medicine. In the medical field, data can be split into two categories: medical images and other data. For brevity, our review deals with any kind of medical data excluding images. In this article, we offer a discussion around four supervised machine learning approaches: information-based, similarity-based, probability-based and error-based approaches. Each method is illustrated with detailed cardiovascular and nuclear medicine examples. Our review shows that model ensemble (ME) and support vector machine (SVM) methods are the most popular. SVM, ME and artificial neural networks often lead to better results than those given by other algorithms. In the coming years, more studies, more data, more tools and more methods will, for sure, be proposed."
33313059,,Leveraging Data Science for a Personalized Haemodialysis,2020 Nov;6(6):385-394.,"Background:                    The 2019 Science for Dialysis Meeting at Bellvitge University Hospital was devoted to the challenges and opportunities posed by the use of data science to facilitate precision and personalized medicine in nephrology, and to describe new approaches and technologies. The meeting included separate sections for issues in data collection and data analysis. As part of data collection, we presented the institutional ARGOS e-health project, which provides a common model for the standardization of clinical practice. We also pay specific attention to the way in which randomized controlled trials offer data that may be critical to decision-making in the real world. The opportunities of open source software (OSS) for data science in clinical practice were also discussed.              Summary:                    Precision medicine aims to provide the right treatment for the right patients at the right time and is deeply connected to data science. Dialysis patients are highly dependent on technology to live, and their treatment generates a huge volume of data that has to be analysed. Data science has emerged as a tool to provide an integrated approach to data collection, storage, cleaning, processing, analysis, and interpretation from potentially large volumes of information. This is meant to be a perspective article about data science based on the experience of the experts invited to the Science for Dialysis Meeting and provides an up-to-date perspective of the potential of data science in kidney disease and dialysis.              Key messages:                    Healthcare is quickly becoming data-dependent, and data science is a discipline that holds the promise of contributing to the development of personalized medicine, although nephrology still lags behind in this process. The key idea is to ensure that data will guide medical decisions based on individual patient characteristics rather than on averages over a whole population usually based on randomized controlled trials that excluded kidney disease patients. Furthermore, there is increasing interest in obtaining data about the effectiveness of available treatments in current patient care based on pragmatic clinical trials. The use of data science in this context is becoming increasingly feasible in part thanks to the swift developments in OSS."
33311940,1.0,Emerging use of artificial intelligence in inflammatory bowel disease,2020 Nov 28;26(44):6923-6928.,"Inflammatory bowel disease (IBD) is a complex, immune-mediated gastrointestinal disorder with ill-defined etiology, multifaceted diagnostic criteria, and unpredictable treatment response. Innovations in IBD diagnostics, including developments in genomic sequencing and molecular analytics, have generated tremendous interest in leveraging these large data platforms into clinically meaningful tools. Artificial intelligence, through machine learning facilitates the interpretation of large arrays of data, and may provide insight to improving IBD outcomes. While potential applications of machine learning models are vast, further research is needed to generate standardized models that can be adapted to target IBD populations."
33309305,,Current Application of Digital Diagnosing Systems for Retinopathy of Prematurity,2021 Mar;200:105871.,"Background and objective:                    Retinopathy of prematurity (ROP), a proliferative vascular eye disease, is one of the leading causes of blindness in childhood and prevails in premature infants with low-birth-weight. The recent progress in digital image analysis offers novel strategies for ROP diagnosis. This paper provides a comprehensive review on the development of digital diagnosing systems for ROP to software researchers. It may also be adopted as a guide to ophthalmologists for selecting the most suitable diagnostic software in the clinical setting, particularly for the remote ophthalmic support.              Methods:                    We review the latest literatures concerning the application of digital diagnosing systems for ROP. The diagnosing systems are analyzed and categorized. Articles published between 1998 and 2020 were screened with the two searching engines Pubmed and Google Scholar.              Results:                    Telemedicine is a method of remote image interpretation that can provide medical service to remote regions, and yet requires training to local operators. On the basis of image collection in telemedicine, computer-based image analytical systems for ROP were later developed. So far, the aforementioned systems have been mainly developed by virtue of classic machine learning, deep learning (DL) and multiple machine learning. During the past two decades, various computer-aided systems for ROP based on classic machine learning (e.g. RISA, ROPtool, CAIER) became available and have achieved satisfactory performance. Further, automated systems for ROP diagnosis based on DL are developed for clinical applications and exhibit high accuracy. Moreover, multiple instance learning is another method to establish an automated system for ROP detection besides DL, which, however, warrants further investigation in future.              Conclusion:                    At present, the incorporation of computer-based image analysis with telemedicine potentially enables the detection, supervision and in-time treatment of ROP for the preterm babies."
33307463,,ArtiÔ¨Åcial intelligence applications for oncological positron emission tomography imaging,2021 Jan;134:109448.,"Positron emission tomography (PET), a functional and dynamic molecular imaging technique, is generally used to reveal tumors' biological behavior. Radiomics allows a high-throughput extraction of multiple features from images with artificial intelligence (AI) approaches and develops rapidly worldwide. Quantitative and objective features of medical images have been explored to recognize reliable biomarkers, with the development of PET radiomics. This paper will review the current clinical exploration of PET-based classical machine learning and deep learning methods, including disease diagnosis, the prediction of histological subtype, gene mutation status, tumor metastasis, tumor relapse, therapeutic side effects, therapeutic intervention and evaluation of prognosis. The applications of AI in oncology will be mainly discussed. The image-guided biopsy or surgery assisted by PET-based AI will be introduced as well. This paper aims to present the applications and methods of AI for PET imaging, which may offer important details for further clinical studies. Relevant precautions are put forward and future research directions are suggested."
33307283,,Artificial intelligence (AI) impacting diagnosis of glaucoma and understanding the regulatory aspects of AI-based software as medical device,2021 Jan;87:101818.,"Glaucoma, the group of eye diseases is characterized by increased intraocular pressure, optic neuropathy and visual field defect patterns. Early and correct diagnosis of glaucoma can prevent irreversible vision loss and glaucomatous structural damages to the eye. However, greater chances of misdiagnosis by the currently used conventional methods for diagnosis open up ways for more advanced techniques like the use of artificial intelligence (AI). Artificial intelligence coupled with optical coherence tomography imaging creates an algorithm that can be effectively used to make a model of complex data for detection as well as diagnosis of glaucoma. The present review is an attempt to provide state-of-the-art information on various AI techniques used in the diagnosis and assessment of glaucoma. The second part of the review is focused on understanding how the AI along with machine learning (ML) can be potentially used to be subjected for software as a medical device (SaMD) in precise diagnosis or early detection of disease conditions."
33307272,,Changing the landscape of tumor immunology: novel tools to examine T cell specificity,2020 Dec 8;69:1-9.,"Immunotherapy has established itself as a stalwart arm in patient care and with precision medicine forms the new paradigm in cancer treatment. T cells are an important group of immune cells capable of potent cancer immune surveillance and immunity. The advent of bioinformatics, particularly more recent advances incorporating algorithms employing machine learning, provide a seemingly limitless ability for T cell analysis and hypothesis generation. Such endeavors have become indispensable to research efforts accelerating and evolving to such an extent that there exists an appreciable gap between knowledge and proof of function and application. Exciting new technologies such as DNA barcoding, cytometry by time-of-flight (CyTOF), and peptide-exchangeable pHLA multimers inclusive of rare and difficult HLA alleles offer high-throughput cell-by-cell analytical capabilities. These outstanding recent contributions to T cell research will help close this gap and potentially bring practical benefit to patients."
33304463,2.0,The computational approaches of lncRNA identification based on coding potential: Status quo and challenges,2020 Nov 19;18:3666-3677.,"Long noncoding RNAs (lncRNAs) make up a large proportion of transcriptome in eukaryotes, and have been revealed with many regulatory functions in various biological processes. When studying lncRNAs, the first step is to accurately and specifically distinguish them from the colossal transcriptome data with complicated composition, which contains mRNAs, lncRNAs, small RNAs and their primary transcripts. In the face of such a huge and progressively expanding transcriptome data, the in-silico approaches provide a practicable scheme for effectively and rapidly filtering out lncRNA targets, using machine learning and probability statistics. In this review, we mainly discussed the characteristics of algorithms and features on currently developed approaches. We also outlined the traits of some state-of-the-art tools for ease of operation. Finally, we pointed out the underlying challenges in lncRNA identification with the advent of new experimental data."
33304450,1.0,Homology modeling in the time of collective and artificial intelligence,2020 Nov 14;18:3494-3506.,"Homology modeling is a method for building protein 3D structures using protein primary sequence and utilizing prior knowledge gained from structural similarities with other proteins. The homology modeling process is done in sequential steps where sequence/structure alignment is optimized, then a backbone is built and later, side-chains are added. Once the low-homology loops are modeled, the whole 3D structure is optimized and validated. In the past three decades, a few collective and collaborative initiatives allowed for continuous progress in both homology and ab initio modeling. Critical Assessment of protein Structure Prediction (CASP) is a worldwide community experiment that has historically recorded the progress in this field. Folding@Home and Rosetta@Home are examples of crowd-sourcing initiatives where the community is sharing computational resources, whereas RosettaCommons is an example of an initiative where a community is sharing a codebase for the development of computational algorithms. Foldit is another initiative where participants compete with each other in a protein folding video game to predict 3D structure. In the past few years, contact maps deep machine learning was introduced to the 3D structure prediction process, adding more information and increasing the accuracy of models significantly. In this review, we will take the reader in a journey of exploration from the beginnings to the most recent turnabouts, which have revolutionized the field of homology modeling. Moreover, we discuss the new trends emerging in this rapidly growing field."
33303419,,Applications of deep learning in dentistry,2020 Nov 18;S2212-4403(20)31321-3.,"Over the last few years, translational applications of so-called artificial intelligence in the field of medicine have garnered a significant amount of interest. The present article aims to review existing dental literature that has examined deep learning, a subset of machine learning that has demonstrated the highest performance when applied to image processing and that has been tested as a formidable diagnostic support tool through its automated analysis of radiographic/photographic images. Furthermore, the article will critically evaluate the literature to describe potential methodological weaknesses of the studies and the need for further development. This review includes 28 studies that have described the applications of deep learning in various fields of dentistry. Research into the applications of deep learning in dentistry contains claims of its high accuracy. Nonetheless, many of these studies have substantial limitations and methodological issues (e.g., examiner reliability, the number of images used for training/testing, the methods used for validation) that have significantly limited the external validity of their results. Therefore, future studies that acknowledge the methodological limitations of existing literature will help to establish a better understanding of the usefulness of applying deep learning in dentistry."
33302517,,A Comprehensive Survey on Local Differential Privacy toward Data Statistics and Analysis,2020 Dec 8;20(24):7030.,"Collecting and analyzing massive data generated from smart devices have become increasingly pervasive in crowdsensing, which are the building blocks for data-driven decision-making. However, extensive statistics and analysis of such data will seriously threaten the privacy of participating users. Local differential privacy (LDP) was proposed as an excellent and prevalent privacy model with distributed architecture, which can provide strong privacy guarantees for each user while collecting and analyzing data. LDP ensures that each user's data is locally perturbed first in the client-side and then sent to the server-side, thereby protecting data from privacy leaks on both the client-side and server-side. This survey presents a comprehensive and systematic overview of LDP with respect to privacy models, research tasks, enabling mechanisms, and various applications. Specifically, we first provide a theoretical summarization of LDP, including the LDP model, the variants of LDP, and the basic framework of LDP algorithms. Then, we investigate and compare the diverse LDP mechanisms for various data statistics and analysis tasks from the perspectives of frequency estimation, mean estimation, and machine learning. Furthermore, we also summarize practical LDP-based application scenarios. Finally, we outline several future research directions under LDP."
33299440,4.0,Artificial intelligence (AI) and interventional radiotherapy (brachytherapy): state of art and future perspectives,2020 Oct;12(5):497-500.,"Purpose:                    Artificial intelligence (AI) plays a central role in building decision supporting systems (DSS), and its application in healthcare is rapidly increasing. The aim of this study was to define the role of AI in healthcare, with main focus on radiation oncology (RO) and interventional radiotherapy (IRT, brachytherapy).              Artificial intelligence in interventional radiation therapy:                    AI in RO has a large impact in providing clinical decision support, data mining and advanced imaging analysis, automating repetitive tasks, optimizing time, and modelling patients and physicians' behaviors in heterogeneous contexts. Implementing AI and automation in RO and IRT can successfully facilitate all the steps of treatment workflow, such as patient consultation, target volume delineation, treatment planning, and treatment delivery.              Conclusions:                    AI may contribute to improve clinical outcomes through the application of predictive models and DSS optimization. This approach could lead to reducing time-consuming repetitive tasks, healthcare costs, and improving treatment quality assurance and patient's assistance in IRT."
33299275,,Machine Learning and Artificial Intelligence in Surgical Fields,2020 Dec;11(4):573-577.,"Artificial intelligence (AI) and machine learning (ML) have the potential to improve multiple facets of medical practice, including diagnosis of disease, surgical training, clinical outcomes, and access to healthcare. There have been various applications of this technology to surgical fields. AI and ML have been used to evaluate a surgeon's technical skill. These technologies can detect instrument motion, recognize patterns in video recordings, and track the physical motion, eye movements, and cognitive function of the surgeon. These modalities also aid in the advancement of robotic surgical training. The da Vinci Standard Surgical System developed a recording and playback system to help trainees receive tactical feedback to acquire more precision when operating. ML has shown promise in recognizing and classifying complex patterns on diagnostic images and within pathologic tissue analysis. This allows for more accurate and efficient diagnosis and treatment. Artificial neural networks are able to analyze sets of symptoms in conjunction with labs, imaging, and exam findings to determine the likelihood of a diagnosis or outcome. Telemedicine is another use of ML and AI that uses technology such as voice recognition to deliver health care remotely. Limitations include the need for large data sets to program computers to create the algorithms. There is also the potential for misclassification of data points that do not follow the typical patterns learned by the machine. As more applications of AI and ML are developed for the surgical field, further studies are needed to determine feasibility, efficacy, and cost."
33297436,1.0,A Review of Machine Learning Methods of Feature Selection and Classification for Autism Spectrum Disorder,2020 Dec 7;10(12):949.,"Autism Spectrum Disorder (ASD), according to DSM-5 in the American Psychiatric Association, is a neurodevelopmental disorder that includes deficits of social communication and social interaction with the presence of restricted and repetitive behaviors. Children with ASD have difficulties in joint attention and social reciprocity, using non-verbal and verbal behavior for communication. Due to these deficits, children with autism are often socially isolated. Researchers have emphasized the importance of early identification and early intervention to improve the level of functioning in language, communication, and well-being of children with autism. However, due to limited local assessment tools to diagnose these children, limited speech-language therapy services in rural areas, etc., these children do not get the rehabilitation they need until they get into compulsory schooling at the age of seven years old. Hence, efficient approaches towards early identification and intervention through speedy diagnostic procedures for ASD are required. In recent years, advanced technologies like machine learning have been used to analyze and investigate ASD to improve diagnostic accuracy, time, and quality without complexity. These machine learning methods include artificial neural networks, support vector machines, a priori algorithms, and decision trees, most of which have been applied to datasets connected with autism to construct predictive models. Meanwhile, the selection of features remains an essential task before developing a predictive model for ASD classification. This review mainly investigates and analyzes up-to-date studies on machine learning methods for feature selection and classification of ASD. We recommend methods to enhance machine learning's speedy execution for processing complex data for conceptualization and implementation in ASD diagnostic research. This study can significantly benefit future research in autism using a machine learning approach for feature selection, classification, and processing imbalanced data."
33295676,1.0,Artificial intelligence and machine learning-aided drug discovery in central nervous system diseases: State-of-the-arts and future directions,2021 May;41(3):1427-1473.,"Neurological disorders significantly outnumber diseases in other therapeutic areas. However, developing drugs for central nervous system (CNS) disorders remains the most challenging area in drug discovery, accompanied with the long timelines and high attrition rates. With the rapid growth of biomedical data enabled by advanced experimental technologies, artificial intelligence (AI) and machine learning (ML) have emerged as an indispensable tool to draw meaningful insights and improve decision making in drug discovery. Thanks to the advancements in AI and ML algorithms, now the AI/ML-driven solutions have an unprecedented potential to accelerate the process of CNS drug discovery with better success rate. In this review, we comprehensively summarize AI/ML-powered pharmaceutical discovery efforts and their implementations in the CNS area. After introducing the AI/ML models as well as the conceptualization and data preparation, we outline the applications of AI/ML technologies to several key procedures in drug discovery, including target identification, compound screening, hit/lead generation and optimization, drug response and synergy prediction, de novo drug design, and drug repurposing. We review the current state-of-the-art of AI/ML-guided CNS drug discovery, focusing on blood-brain barrier permeability prediction and implementation into therapeutic discovery for neurological diseases. Finally, we discuss the major challenges and limitations of current approaches and possible future directions that may provide resolutions to these difficulties."
33294870,,Extensions of the External Validation for Checking Learned Model Interpretability and Generalizability,2020 Nov 13;1(8):100129.,"We discuss the validation of machine learning models, which is standard practice in determining model efficacy and generalizability. We argue that internal validation approaches, such as cross-validation and bootstrap, cannot guarantee the quality of a machine learning model due to potentially biased training data and the complexity of the validation procedure itself. For better evaluating the generalization ability of a learned model, we suggest leveraging on external data sources from elsewhere as validation datasets, namely external validation. Due to the lack of research attractions on external validation, especially a well-structured and comprehensive study, we discuss the necessity for external validation and propose two extensions of the external validation approach that may help reveal the true domain-relevant model from a candidate set. Moreover, we also suggest a procedure to check whether a set of validation datasets is valid and introduce statistical reference points for detecting external data problems."
33294867,,Model-Driven Decision Making in Multiple Sclerosis Research: Existing Works and Latest Trends,2020 Nov 13;1(8):100121.,"Multiple sclerosis (MS) is a neurological disorder that strikes the central nervous system. Due to the complexity of this disease, healthcare sectors are increasingly in need of shared clinical decision-making tools to provide practitioners with insightful knowledge and information about MS. These tools ought to be comprehensible by both technical and non-technical healthcare audiences. To aid this cause, this literature review analyzes the state-of-the-art decision support systems (DSSs) in MS research with a special focus on model-driven decision-making processes. The review clusters common methodologies used to support the decision-making process in classifying, diagnosing, predicting, and treating MS. This work observes that the majority of the investigated DSSs rely on knowledge-based and machine learning (ML) approaches, so the utilization of ontology and ML in the MS domain is observed to extend the scope of this review. Finally, this review summarizes the state-of-the-art DSSs, discusses the methods that have commonalities, and addresses the future work of applying DSS technologies in the MS field."
33294256,,Application of artificial intelligence to the diagnosis and therapy of colorectal cancer,2020 Nov 1;10(11):3575-3598.,"Artificial intelligence (AI) is a relatively new branch of computer science involving many disciplines and technologies, including robotics, speech recognition, natural language and image recognition or processing, and machine learning. Recently, AI has been widely applied in the medical field. The effective combination of AI and big data can provide convenient and efficient medical services for patients. Colorectal cancer (CRC) is a common type of gastrointestinal cancer. The early diagnosis and treatment of CRC are key factors affecting its prognosis. This review summarizes the research progress and clinical application value of AI in the investigation, early diagnosis, treatment, and prognosis of CRC, to provide a comprehensive theoretical basis for AI as a promising diagnostic and treatment tool for CRC."
33294134,1.0,Combining structure and genomics to understand antimicrobial resistance,2020 Oct 29;18:3377-3394.,"Antimicrobials against bacterial, viral and parasitic pathogens have transformed human and animal health. Nevertheless, their widespread use (and misuse) has led to the emergence of antimicrobial resistance (AMR) which poses a potentially catastrophic threat to public health and animal husbandry. There are several routes, both intrinsic and acquired, by which AMR can develop. One major route is through non-synonymous single nucleotide polymorphisms (nsSNPs) in coding regions. Large scale genomic studies using high-throughput sequencing data have provided powerful new ways to rapidly detect and respond to such genetic mutations linked to AMR. However, these studies are limited in their mechanistic insight. Computational tools can rapidly and inexpensively evaluate the effect of mutations on protein function and evolution. Subsequent insights can then inform experimental studies, and direct existing or new computational methods. Here we review a range of sequence and structure-based computational tools, focussing on tools successfully used to investigate mutational effect on drug targets in clinically important pathogens, particularly Mycobacterium tuberculosis. Combining genomic results with the biophysical effects of mutations can help reveal the molecular basis and consequences of resistance development. Furthermore, we summarise how the application of such a mechanistic understanding of drug resistance can be applied to limit the impact of AMR."
33293292,1.0,Neuronal differentiation strategies: insights from single-cell sequencing and machine learning,2020 Dec 8;147(23):dev193631.,"Neuronal replacement therapies rely on the in vitro differentiation of specific cell types from embryonic or induced pluripotent stem cells, or on the direct reprogramming of differentiated adult cells via the expression of transcription factors or signaling molecules. The factors used to induce differentiation or reprogramming are often identified by informed guesses based on differential gene expression or known roles for these factors during development. Moreover, differentiation protocols usually result in partly differentiated cells or the production of a mix of cell types. In this Hypothesis article, we suggest that, to overcome these inefficiencies and improve neuronal differentiation protocols, we need to take into account the developmental history of the desired cell types. Specifically, we present a strategy that uses single-cell sequencing techniques combined with machine learning as a principled method to select a sequence of programming factors that are important not only in adult neurons but also during differentiation."
33291859,,A Review and a Framework of Variables for Defining and Characterizing Tinnitus Subphenotypes,2020 Dec 4;10(12):938.,"Tinnitus patients can present with various characteristics, such as those related to the tinnitus perception, symptom severity, and pattern of comorbidities. It is speculated that this phenotypic heterogeneity is associated with differences in the underlying pathophysiology and personal reaction to the condition. However, there is as yet no established protocol for tinnitus profiling or subtyping, hindering progress in treatment development. This review summarizes data on variables that have been used in studies investigating phenotypic differences in subgroups of tinnitus, including variables used to both define and compare subgroups. A PubMed search led to the identification of 64 eligible articles. In most studies, variables for subgrouping were chosen by the researchers (hypothesis-driven approach). Other approaches included application of unsupervised machine-learning techniques for the definition of subgroups (data-driven), and subgroup definition based on the response to a tinnitus treatment (treatment response). A framework of 94 variable concepts was created to summarize variables used across all studies. Frequency statistics for the use of each variable concept are presented, demonstrating those most and least commonly assessed. This review highlights the high dimensionality of tinnitus heterogeneity. The framework of variables can contribute to the design of future studies, helping to decide on tinnitus assessment and subgrouping."
33291844,,From Ethnomedicine to Plant Biotechnology and Machine Learning: The Valorization of the Medicinal Plant Bryophyllum sp,2020 Dec 4;13(12):444.,"The subgenus Bryophyllum includes about 25 plant species native to Madagascar, and is widely used in traditional medicine worldwide. Different formulations from Bryophyllum have been employed for the treatment of several ailments, including infections, gynecological disorders, and chronic diseases, such as diabetes, neurological and neoplastic diseases. Two major families of secondary metabolites have been reported as responsible for these bioactivities: phenolic compounds and bufadienolides. These compounds are found in limited amounts in plants because they are biosynthesized in response to different biotic and abiotic stresses. Therefore, novel approaches should be undertaken with the aim of achieving the phytochemical valorization of Bryophyllum sp., allowing a sustainable production that prevents from a massive exploitation of wild plant resources. This review focuses on the study of phytoconstituents reported on Bryophyllum sp.; the application of plant tissue culture methodology as a reliable tool for the valorization of bioactive compounds; and the application of machine learning technology to model and optimize the full phytochemical potential of Bryophyllum sp. As a result, Bryophyllum species can be considered as a promising source of plant bioactive compounds, with enormous antioxidant and anticancer potential, which could be used for their large-scale biotechnological exploitation in cosmetic, food, and pharmaceutical industries."
33291301,1.0,Diagnostic Utility of Genome-Wide DNA Methylation Analysis in Mendelian Neurodevelopmental Disorders,2020 Dec 6;21(23):9303.,"Mendelian neurodevelopmental disorders customarily present with complex and overlapping symptoms, complicating the clinical diagnosis. Individuals with a growing number of the so-called rare disorders exhibit unique, disorder-specific DNA methylation patterns, consequent to the underlying gene defects. Besides providing insights to the pathophysiology and molecular biology of these disorders, we can use these epigenetic patterns as functional biomarkers for the screening and diagnosis of these conditions. This review summarizes our current understanding of DNA methylation episignatures in rare disorders and describes the underlying technology and analytical approaches. We discuss the computational parameters, including statistical and machine learning methods, used for the screening and classification of genetic variants of uncertain clinical significance. Describing the rationale and principles applied to the specific computational models that are used to develop and adapt the DNA methylation episignatures for the diagnosis of rare disorders, we highlight the opportunities and challenges in this emerging branch of diagnostic medicine."
33291266,,The Utility of Deep Learning in Breast Ultrasonic Imaging: A Review,2020 Dec 6;10(12):1055.,"Breast cancer is the most frequently diagnosed cancer in women; it poses a serious threat to women's health. Thus, early detection and proper treatment can improve patient prognosis. Breast ultrasound is one of the most commonly used modalities for diagnosing and detecting breast cancer in clinical practice. Deep learning technology has made significant progress in data extraction and analysis for medical images in recent years. Therefore, the use of deep learning for breast ultrasonic imaging in clinical practice is extremely important, as it saves time, reduces radiologist fatigue, and compensates for a lack of experience and skills in some cases. This review article discusses the basic technical knowledge and algorithms of deep learning for breast ultrasound and the application of deep learning technology in image classification, object detection, segmentation, and image synthesis. Finally, we discuss the current issues and future perspectives of deep learning technology in breast ultrasound."
33290820,1.0,Advanced machine-learning techniques in drug discovery,2021 Mar;26(3):769-777.,"The popularity of machine learning (ML) across drug discovery continues to grow, yielding impressive results. As their use increases, so do their limitations become apparent. Such limitations include their need for big data, sparsity in data, and their lack of interpretability. It has also become apparent that the techniques are not truly autonomous, requiring retraining even post deployment. In this review, we detail the use of advanced techniques to circumvent these challenges, with examples drawn from drug discovery and allied disciplines. In addition, we present emerging techniques and their potential role in drug discovery. The techniques presented herein are anticipated to expand the applicability of ML in drug discovery."
33290771,,Computer-aided diagnosis of esophageal cancer and neoplasms in endoscopic images: a systematic review and meta-analysis of diagnostic test accuracy,2021 May;93(5):1006-1015.e13.,"Background and aims:                    Diagnosis of esophageal cancer or precursor lesions by endoscopic imaging depends on endoscopist expertise and is inevitably subject to interobserver variability. Studies on computer-aided diagnosis (CAD) using deep learning or machine learning are on the increase. However, studies with small sample sizes are limited by inadequate statistical strength. Here, we used a meta-analysis to evaluate the diagnostic test accuracy (DTA) of CAD algorithms of esophageal cancers or neoplasms using endoscopic images.              Methods:                    Core databases were searched for studies based on endoscopic imaging using CAD algorithms for the diagnosis of esophageal cancer or neoplasms and presenting data on diagnostic performance, and a systematic review and DTA meta-analysis were performed.              Results:                    Overall, 21 and 19 studies were included in the systematic review and DTA meta-analysis, respectively. The pooled area under the curve, sensitivity, specificity, and diagnostic odds ratio of CAD algorithms for the diagnosis of esophageal cancer or neoplasms in the image-based analysis were 0.97 (95% confidence interval [CI], 0.95-0.99), 0.94 (95% CI, 0.89-0.96), 0.88 (95% CI, 0.76-0.94), and 108 (95% CI, 43-273), respectively. Meta-regression showed no heterogeneity, and no publication bias was detected. The pooled area under the curve, sensitivity, specificity, and diagnostic odds ratio of CAD algorithms for the diagnosis of esophageal cancer invasion depth were 0.96 (95% CI, 0.86-0.99), 0.90 (95% CI, 0.88-0.92), 0.88 (95% CI, 0.83-0.91), and 138 (95% CI, 12-1569), respectively.              Conclusions:                    CAD algorithms showed high accuracy for the automatic endoscopic diagnosis of esophageal cancer and neoplasms. The limitation of a lack in performance in external validation and clinical applications should be overcome."
33290527,1.0,Deep learning and generative methods in cheminformatics and chemical biology: navigating small molecule space intelligently,2020 Dec 11;477(23):4559-4580.,"The number of 'small' molecules that may be of interest to chemical biologists - chemical space - is enormous, but the fraction that have ever been made is tiny. Most strategies are discriminative, i.e. have involved 'forward' problems (have molecule, establish properties). However, we normally wish to solve the much harder generative or inverse problem (describe desired properties, find molecule). 'Deep' (machine) learning based on large-scale neural networks underpins technologies such as computer vision, natural language processing, driverless cars, and world-leading performance in games such as Go; it can also be applied to the solution of inverse problems in chemical biology. In particular, recent developments in deep learning admit the in silico generation of candidate molecular structures and the prediction of their properties, thereby allowing one to navigate (bio)chemical space intelligently. These methods are revolutionary but require an understanding of both (bio)chemistry and computer science to be exploited to best advantage. We give a high-level (non-mathematical) background to the deep learning revolution, and set out the crucial issue for chemical biology and informatics as a two-way mapping from the discrete nature of individual molecules to the continuous but high-dimensional latent representation that may best reflect chemical space. A variety of architectures can do this; we focus on a particular type known as variational autoencoders. We then provide some examples of recent successes of these kinds of approach, and a look towards the future."
33288953,2.0,Tools for experimental and computational analyses of off-target editing by programmable nucleases,2021 Jan;16(1):10-26.,"Genome editing using programmable nucleases is revolutionizing life science and medicine. Off-target editing by these nucleases remains a considerable concern, especially in therapeutic applications. Here we review tools developed for identifying potential off-target editing sites and compare the ability of these tools to properly analyze off-target effects. Recent advances in both in silico and experimental tools for off-target analysis have generated remarkably concordant results for sites with high off-target editing activity. However, no single tool is able to accurately predict low-frequency off-target editing, presenting a bottleneck in therapeutic genome editing, because even a small number of cells with off-target editing can be detrimental. Therefore, we recommend that at least one in silico tool and one experimental tool should be used together to identify potential off-target sites, and amplicon-based next-generation sequencing (NGS) should be used as the gold standard assay for assessing the true off-target effects at these candidate sites. Future work to improve off-target analysis includes expanding the true off-target editing dataset to evaluate new experimental techniques and to train machine learning algorithms; performing analysis using the particular genome of the cells in question rather than the reference genome; and applying novel NGS techniques to improve the sensitivity of amplicon-based off-target editing quantification."
33286958,,An Appraisal of Incremental Learning Methods,2020 Oct 22;22(11):1190.,"As a special case of machine learning, incremental learning can acquire useful knowledge from incoming data continuously while it does not need to access the original data. It is expected to have the ability of memorization and it is regarded as one of the ultimate goals of artificial intelligence technology. However, incremental learning remains a long term challenge. Modern deep neural network models achieve outstanding performance on stationary data distributions with batch training. This restriction leads to catastrophic forgetting for incremental learning scenarios since the distribution of incoming data is unknown and has a highly different probability from the old data. Therefore, a model must be both plastic to acquire new knowledge and stable to consolidate existing knowledge. This review aims to draw a systematic review of the state of the art of incremental learning methods. Published reports are selected from Web of Science, IEEEXplore, and DBLP databases up to May 2020. Each paper is reviewed according to the types: architectural strategy, regularization strategy and rehearsal and pseudo-rehearsal strategy. We compare and discuss different methods. Moreover, the development trend and research focus are given. It is concluded that incremental learning is still a hot research area and will be for a long period. More attention should be paid to the exploration of both biological systems and computational models."
33285855,1.0,High-Dimensional Brain in a High-Dimensional World: Blessing of Dimensionality,2020 Jan 9;22(1):82.,"High-dimensional data and high-dimensional representations of reality are inherent features of modern Artificial Intelligence systems and applications of machine learning. The well-known phenomenon of the ""curse of dimensionality"" states: many problems become exponentially difficult in high dimensions. Recently, the other side of the coin, the ""blessing of dimensionality"", has attracted much attention. It turns out that generic high-dimensional datasets exhibit fairly simple geometric properties. Thus, there is a fundamental tradeoff between complexity and simplicity in high dimensional spaces. Here we present a brief explanatory review of recent ideas, results and hypotheses about the blessing of dimensionality and related simplifying effects relevant to machine learning and neuroscience."
33284779,1.0,Artificial Intelligence in the Fight Against COVID-19: Scoping Review,2020 Dec 15;22(12):e20756.,"Background:                    In December 2019, COVID-19 broke out in Wuhan, China, leading to national and international disruptions in health care, business, education, transportation, and nearly every aspect of our daily lives. Artificial intelligence (AI) has been leveraged amid the COVID-19 pandemic; however, little is known about its use for supporting public health efforts.              Objective:                    This scoping review aims to explore how AI technology is being used during the COVID-19 pandemic, as reported in the literature. Thus, it is the first review that describes and summarizes features of the identified AI techniques and data sets used for their development and validation.              Methods:                    A scoping review was conducted following the guidelines of PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews). We searched the most commonly used electronic databases (eg, MEDLINE, EMBASE, and PsycInfo) between April 10 and 12, 2020. These terms were selected based on the target intervention (ie, AI) and the target disease (ie, COVID-19). Two reviewers independently conducted study selection and data extraction. A narrative approach was used to synthesize the extracted data.              Results:                    We considered 82 studies out of the 435 retrieved studies. The most common use of AI was diagnosing COVID-19 cases based on various indicators. AI was also employed in drug and vaccine discovery or repurposing and for assessing their safety. Further, the included studies used AI for forecasting the epidemic development of COVID-19 and predicting its potential hosts and reservoirs. Researchers used AI for patient outcome-related tasks such as assessing the severity of COVID-19, predicting mortality risk, its associated factors, and the length of hospital stay. AI was used for infodemiology to raise awareness to use water, sanitation, and hygiene. The most prominent AI technique used was convolutional neural network, followed by support vector machine.              Conclusions:                    The included studies showed that AI has the potential to fight against COVID-19. However, many of the proposed methods are not yet clinically accepted. Thus, the most rewarding research will be on methods promising value beyond COVID-19. More efforts are needed for developing standardized reporting protocols or guidelines for studies on AI."
33282401,,Putting artificial intelligence (AI) on the spot: machine learning evaluation of pulmonary nodules,2020 Nov;12(11):6954-6965.,"Lung cancer remains the leading cause of cancer related death world-wide despite advances in treatment. This largely relates to the fact that many of these patients already have advanced diseases at the time of initial diagnosis. As most lung cancers present as nodules initially, an accurate classification of pulmonary nodules as early lung cancers is critical to reducing lung cancer morbidity and mortality. There have been significant recent advances in artificial intelligence (AI) for lung nodule evaluation. Deep learning (DL) and convolutional neural networks (CNNs) have shown promising results in pulmonary nodule detection and have also excelled in segmentation and classification of pulmonary nodules. This review aims to provide an overview of progress that has been made in AI recently for pulmonary nodule detection and characterization with the ultimate goal of lung cancer prediction and classification while outlining some of the pitfalls and challenges that remain to bring such advancements to routine clinical use."
33278409,,Prediction Machines: Applied Machine Learning for Therapeutic Protein Design and Development,2021 Feb;110(2):665-681.,"The rapid growth in technological advances and quantity of scientific data over the past decade has led to several challenges including data storage and analysis. Accurate models of complex datasets were previously difficult to develop and interpret. However, improvements in machine learning algorithms have since enabled unparalleled classification and prediction capabilities. The application of machine learning can be seen throughout diverse industries due to their ease of use and interpretability. In this review, we describe popular machine learning algorithms and highlight their application in pharmaceutical protein development. Machine learning models have now been applied to better understand the nonlinear concentration dependent viscosity of protein solutions, predict protein oxidation and deamidation rates, classify sub-visible particles and compare the physical stability of proteins. We also applied several machine learning algorithms using previously published data and describe models with improved predictions and classification. The authors hope that this review can be used as a resource to others and encourage continued application of machine learning algorithms to problems in pharmaceutical protein development."
33271399,,"Precision health data: Requirements, challenges and existing techniques for data security and privacy",2021 Feb;129:104130.,"Precision health leverages information from various sources, including omics, lifestyle, environment, social media, medical records, and medical insurance claims to enable personalized care, prevent and predict illness, and precise treatments. It extensively uses sensing technologies (e.g., electronic health monitoring devices), computations (e.g., machine learning), and communication (e.g., interaction between the health data centers). As health data contain sensitive private information, including the identity of patient and carer and medical conditions of the patient, proper care is required at all times. Leakage of these private information affects the personal life, including bullying, high insurance premium, and loss of job due to the medical history. Thus, the security, privacy of and trust on the information are of utmost importance. Moreover, government legislation and ethics committees demand the security and privacy of healthcare data. Besides, the public, who is the data source, always expects the security, privacy, and trust of their data. Otherwise, they can avoid contributing their data to the precision health system. Consequently, as the public is the targeted beneficiary of the system, the effectiveness of precision health diminishes. Herein, in the light of precision health data security, privacy, ethical and regulatory requirements, finding the best methods and techniques for the utilization of the health data, and thus precision health is essential. In this regard, firstly, this paper explores the regulations, ethical guidelines around the world, and domain-specific needs. Then it presents the requirements and investigates the associated challenges. Secondly, this paper investigates secure and privacy-preserving machine learning methods suitable for the computation of precision health data along with their usage in relevant health projects. Finally, it illustrates the best available techniques for precision health data security and privacy with a conceptual system model that enables compliance, ethics clearance, consent management, medical innovations, and developments in the health domain."
33270183,,Use of Machine Learning Approaches in Clinical Epidemiological Research of Diabetes,2020 Dec 3;20(12):80.,"Purpose of review:                    Machine learning approaches-which seek to predict outcomes or classify patient features by recognizing patterns in large datasets-are increasingly applied to clinical epidemiology research on diabetes. Given its novelty and emergence in fields outside of biomedical research, machine learning terminology, techniques, and research findings may be unfamiliar to diabetes researchers. Our aim was to present the use of machine learning approaches in an approachable way, drawing from clinical epidemiological research in diabetes published from 1 Jan 2017 to 1 June 2020.              Recent findings:                    Machine learning approaches using tree-based learners-which produce decision trees to help guide clinical interventions-frequently have higher sensitivity and specificity than traditional regression models for risk prediction. Machine learning approaches using neural networking and ""deep learning"" can be applied to medical image data, particularly for the identification and staging of diabetic retinopathy and skin ulcers. Among the machine learning approaches reviewed, researchers identified new strategies to develop standard datasets for rigorous comparisons across older and newer approaches, methods to illustrate how a machine learner was treating underlying data, and approaches to improve the transparency of the machine learning process. Machine learning approaches have the potential to improve risk stratification and outcome prediction for clinical epidemiology applications. Achieving this potential would be facilitated by use of universal open-source datasets for fair comparisons. More work remains in the application of strategies to communicate how the machine learners are generating their predictions."
33270029,,Visual Analytic Tools and Techniques in Population Health and Health Services Research: Scoping Review,2020 Dec 3;22(12):e17892.,"Background:                    Visual analytics (VA) promotes the understanding of data with visual, interactive techniques, using analytic and visual engines. The analytic engine includes automated techniques, whereas common visual outputs include flow maps and spatiotemporal hot spots.              Objective:                    This scoping review aims to address a gap in the literature, with the specific objective to synthesize literature on the use of VA tools, techniques, and frameworks in interrelated health care areas of population health and health services research (HSR).              Methods:                    Using the 2018 PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews) guidelines, the review focuses on peer-reviewed journal articles and full conference papers from 2005 to March 2019. Two researchers were involved at each step, and another researcher arbitrated disagreements. A comprehensive abstraction platform captured data from diverse bodies of the literature, primarily from the computer and health sciences.              Results:                    After screening 11,310 articles, findings from 55 articles were synthesized under the major headings of visual and analytic engines, visual presentation characteristics, tools used and their capabilities, application to health care areas, data types and sources, VA frameworks, frameworks used for VA applications, availability and innovation, and co-design initiatives. We found extensive application of VA methods used in areas of epidemiology, surveillance and modeling, health services access, use, and cost analyses. All articles included a distinct analytic and visualization engine, with varying levels of detail provided. Most tools were prototypes, with 5 in use at the time of publication. Seven articles presented methodological frameworks. Toward consistent reporting, we present a checklist, with an expanded definition for VA applications in health care, to assist researchers in sharing research for greater replicability. We summarized the results in a Tableau dashboard.              Conclusions:                    With the increasing availability and generation of big health care data, VA is a fast-growing method applied to complex health care data. What makes VA innovative is its capability to process multiple, varied data sources to demonstrate trends and patterns for exploratory analysis, leading to knowledge generation and decision support. This is the first review to bridge a critical gap in the literature on VA methods applied to the areas of population health and HSR, which further indicates possible avenues for the adoption of these methods in the future. This review is especially important in the wake of COVID-19 surveillance and response initiatives, where many VA products have taken center stage.              International registered report identifier (irrid):                    RR2-10.2196/14019."
33269107,,The Application of Artificial Intelligence in the Genetic Study of Alzheimer's Disease,2020 Dec 1;11(6):1567-1584.,"Alzheimer's disease (AD) is a neurodegenerative disease in which genetic factors contribute approximately 70% of etiological effects. Studies have found many significant genetic and environmental factors, but the pathogenesis of AD is still unclear. With the application of microarray and next-generation sequencing technologies, research using genetic data has shown explosive growth. In addition to conventional statistical methods for the processing of these data, artificial intelligence (AI) technology shows obvious advantages in analyzing such complex projects. This article first briefly reviews the application of AI technology in medicine and the current status of genetic research in AD. Then, a comprehensive review is focused on the application of AI in the genetic research of AD, including the diagnosis and prognosis of AD based on genetic data, the analysis of genetic variation, gene expression profile, gene-gene interaction in AD, and genetic analysis of AD based on a knowledge base. Although many studies have yielded some meaningful results, they are still in a preliminary stage. The main shortcomings include the limitations of the databases, failing to take advantage of AI to conduct a systematic biology analysis of multilevel databases, and lack of a theoretical framework for the analysis results. Finally, we outlook the direction of future development. It is crucial to develop high quality, comprehensive, large sample size, data sharing resources; a multi-level system biology AI analysis strategy is one of the development directions, and computational creativity may play a role in theory model building, verification, and designing new intervention protocols for AD."
33266128,1.0,"Deep Learning in LncRNAome: Contribution, Challenges, and Perspectives",2020 Nov 30;6(4):47.,"Long non-coding RNAs (lncRNA), the pervasively transcribed part of the mammalian genome, have played a significant role in changing our protein-centric view of genomes. The abundance of lncRNAs and their diverse roles across cell types have opened numerous avenues for the research community regarding lncRNAome. To discover and understand lncRNAome, many sophisticated computational techniques have been leveraged. Recently, deep learning (DL)-based modeling techniques have been successfully used in genomics due to their capacity to handle large amounts of data and produce relatively better results than traditional machine learning (ML) models. DL-based modeling techniques have now become a choice for many modeling tasks in the field of lncRNAome as well. In this review article, we summarized the contribution of DL-based methods in nine different lncRNAome research areas. We also outlined DL-based techniques leveraged in lncRNAome, highlighting the challenges computational scientists face while developing DL-based models for lncRNAome. To the best of our knowledge, this is the first review article that summarizes the role of DL-based techniques in multiple areas of lncRNAome."
33260881,,A Customizable Analysis Flow in Integrative Multi-Omics,2020 Nov 27;10(12):1606.,"The number of researchers using multi-omics is growing. Though still expensive, every year it is cheaper to perform multi-omic studies, often exponentially so. In addition to its increasing accessibility, multi-omics reveals a view of systems biology to an unprecedented depth. Thus, multi-omics can be used to answer a broad range of biological questions in finer resolution than previous methods. We used six omic measurements-four nucleic acid (i.e., genomic, epigenomic, transcriptomics, and metagenomic) and two mass spectrometry (proteomics and metabolomics) based-to highlight an analysis workflow on this type of data, which is often vast. This workflow is not exhaustive of all the omic measurements or analysis methods, but it will provide an experienced or even a novice multi-omic researcher with the tools necessary to analyze their data. This review begins with analyzing a single ome and study design, and then synthesizes best practices in data integration techniques that include machine learning. Furthermore, we delineate methods to validate findings from multi-omic integration. Ultimately, multi-omic integration offers a window into the complexity of molecular interactions and a comprehensive view of systems biology."
33260412,,Proximal Methods for Plant Stress Detection Using Optical Sensors and Machine Learning,2020 Nov 29;10(12):193.,"Plant stresses have been monitored using the imaging or spectrometry of plant leaves in the visible (red-green-blue or RGB), near-infrared (NIR), infrared (IR), and ultraviolet (UV) wavebands, often augmented by fluorescence imaging or fluorescence spectrometry. Imaging at multiple specific wavelengths (multi-spectral imaging) or across a wide range of wavelengths (hyperspectral imaging) can provide exceptional information on plant stress and subsequent diseases. Digital cameras, thermal cameras, and optical filters have become available at a low cost in recent years, while hyperspectral cameras have become increasingly more compact and portable. Furthermore, smartphone cameras have dramatically improved in quality, making them a viable option for rapid, on-site stress detection. Due to these developments in imaging technology, plant stresses can be monitored more easily using handheld and field-deployable methods. Recent advances in machine learning algorithms have allowed for images and spectra to be analyzed and classified in a fully automated and reproducible manner, without the need for complicated image or spectrum analysis methods. This review will highlight recent advances in portable (including smartphone-based) detection methods for biotic and abiotic stresses, discuss data processing and machine learning techniques that can produce results for stress identification and classification, and suggest future directions towards the successful translation of these methods into practical use."
33260343,,Autonomous Corrosion Assessment of Reinforced Concrete Structures: Feasibility Study,2020 Nov 29;20(23):6825.,"In this work, technological feasibility of autonomous corrosion assessment of reinforced concrete structures is studied. Corrosion of reinforcement bars (rebar), induced by carbonation or chloride penetration, is one of the leading causes for deterioration of concrete structures throughout the globe. Continuous nondestructive in-service monitoring of carbonation through pH and chloride ion (Cl-) concentration in concrete is indispensable for early detection of corrosion and making appropriate decisions, which ultimately make the lifecycle management of RC structures optimal from resources and safety perspectives. Critical state-of-the-art review of pH and Cl- sensors revealed that the majority of the sensors have high sensitivity, reliability, and stability in concrete environment, though the experiments were carried out for relatively short periods. Among the reviewed works, only three attempted to monitor Cl- wirelessly, albeit over a very short range. As part of the feasibility study, this work recommends the use of internet of things (IoT) and machine learning for autonomous corrosion condition assessment of RC structures."
33259944,1.0,"A review on deep learning approaches in healthcare systems: Taxonomies, challenges, and open issues",2021 Jan;113:103627.,"In the last few years, the application of Machine Learning approaches like Deep Neural Network (DNN) models have become more attractive in the healthcare system given the rising complexity of the healthcare data. Machine Learning (ML) algorithms provide efficient and effective data analysis models to uncover hidden patterns and other meaningful information from the considerable amount of health data that conventional analytics are not able to discover in a reasonable time. In particular, Deep Learning (DL) techniques have been shown as promising methods in pattern recognition in the healthcare systems. Motivated by this consideration, the contribution of this paper is to investigate the deep learning approaches applied to healthcare systems by reviewing the cutting-edge network architectures, applications, and industrial trends. The goal is first to provide extensive insight into the application of deep learning models in healthcare solutions to bridge deep learning techniques and human healthcare interpretability. And then, to present the existing open challenges and future directions."
33256133,2.0,What Can Machine Learning Approaches in Genomics Tell Us about the Molecular Basis of Amyotrophic Lateral Sclerosis?,2020 Nov 26;10(4):247.,"Amyotrophic Lateral Sclerosis (ALS) is the most common late-onset motor neuron disorder, but our current knowledge of the molecular mechanisms and pathways underlying this disease remain elusive. This review (1) systematically identifies machine learning studies aimed at the understanding of the genetic architecture of ALS, (2) outlines the main challenges faced and compares the different approaches that have been used to confront them, and (3) compares the experimental designs and results produced by those approaches and describes their reproducibility in terms of biological results and the performances of the machine learning models. The majority of the collected studies incorporated prior knowledge of ALS into their feature selection approaches, and trained their machine learning models using genomic data combined with other types of mined knowledge including functional associations, protein-protein interactions, disease/tissue-specific information, epigenetic data, and known ALS phenotype-genotype associations. The importance of incorporating gene-gene interactions and cis-regulatory elements into the experimental design of future ALS machine learning studies is highlighted. Lastly, it is suggested that future advances in the genomic and machine learning fields will bring about a better understanding of ALS genetic architecture, and enable improved personalized approaches to this and other devastating and complex diseases."
33256107,7.0,Application of Artificial Intelligence Technology in Oncology: Towards the Establishment of Precision Medicine,2020 Nov 26;12(12):3532.,"In recent years, advances in artificial intelligence (AI) technology have led to the rapid clinical implementation of devices with AI technology in the medical field. More than 60 AI-equipped medical devices have already been approved by the Food and Drug Administration (FDA) in the United States, and the active introduction of AI technology is considered to be an inevitable trend in the future of medicine. In the field of oncology, clinical applications of medical devices using AI technology are already underway, mainly in radiology, and AI technology is expected to be positioned as an important core technology. In particular, ""precision medicine,"" a medical treatment that selects the most appropriate treatment for each patient based on a vast amount of medical data such as genome information, has become a worldwide trend; AI technology is expected to be utilized in the process of extracting truly useful information from a large amount of medical data and applying it to diagnosis and treatment. In this review, we would like to introduce the history of AI technology and the current state of medical AI, especially in the oncology field, as well as discuss the possibilities and challenges of AI technology in the medical field."
33255705,3.0,"Augmented Realities, Artificial Intelligence, and Machine Learning: Clinical Implications and How Technology Is Shaping the Future of Medicine",2020 Nov 25;9(12):3811.,"Technology has been integrated into every facet of human life, and whether it is completely advantageous remains unknown, but one thing is for sure; we are dependent on technology. Medical advances from the integration of artificial intelligence, machine learning, and augmented realities are widespread and have helped countless patients. Much of the advanced technology utilized by medical providers today has been borrowed and extrapolated from other industries. There remains no great collaboration between providers and engineers, which may be why medicine is only in its infancy of innovation with regards to advanced technologic integration. The purpose of this narrative review is to highlight the different technologies currently being utilized in a variety of medical specialties. Furthermore, we hope that by bringing attention to one shortcoming of the medical community, we may inspire future innovators to seek collaboration outside of the purely medical community for the betterment of all patients seeking care."
33255668,,From Early Morphometrics to Machine Learning-What Future for Cardiovascular Imaging of the Pulmonary Circulation?,2020 Nov 25;10(12):1004.,"Imaging plays a cardinal role in the diagnosis and management of diseases of the pulmonary circulation. Behind the picture itself, every digital image contains a wealth of quantitative data, which are hardly analysed in current routine clinical practice and this is now being transformed by radiomics. Mathematical analyses of these data using novel techniques, such as vascular morphometry (including vascular tortuosity and vascular volumes), blood flow imaging (including quantitative lung perfusion and computational flow dynamics), and artificial intelligence, are opening a window on the complex pathophysiology and structure-function relationships of pulmonary vascular diseases. They have the potential to make dramatic alterations to how clinicians investigate the pulmonary circulation, with the consequences of more rapid diagnosis and a reduction in the need for invasive procedures in the future. Applied to multimodality imaging, they can provide new information to improve disease characterization and increase diagnostic accuracy. These new technologies may be used as sophisticated biomarkers for risk prediction modelling of prognosis and for optimising the long-term management of pulmonary circulatory diseases. These innovative techniques will require evaluation in clinical trials and may in themselves serve as successful surrogate end points in trials in the years to come."
33255489,,A Synthetic Literature Review on the Management of Emerging Treatment Resistance in First Episode Psychosis: Can We Move towards Precision Intervention and Individualised Care?,2020 Nov 24;56(12):638.,"Treatment resistance is prevalent in early intervention in psychosis services, and causes a significant burden for the individual. A wide range of variables are shown to contribute to treatment resistance in first episode psychosis (FEP). Heterogeneity in illness course and the complex, multidimensional nature of the concept of recovery calls for an evidence base to better inform practice at an individual level. Current gold standard treatments, adopting a 'one-size fits all' approach, may not be addressing the needs of many individuals. This following review will provide an update and critical appraisal of current clinical practices and methodological approaches for understanding, identifying, and managing early treatment resistance in early psychosis. Potential new treatments along with new avenues for research will be discussed. Finally, we will discuss and critique the application and translation of machine learning approaches to aid progression in this area. The move towards 'big data' and machine learning holds some prospect for stratifying intervention-based subgroups of individuals. Moving forward, better recognition of early treatment resistance is needed, along with greater sophistication and precision in predicting outcomes, so that effective evidence-based treatments can be appropriately tailored to the individual. Understanding the antecedents and the early trajectory of one's illness may also be key to understanding the factors that drive illness course."
33254082,1.0,The impact of pre- and post-image processing techniques on deep learning frameworks: A comprehensive review for digital pathology image analysis,2021 Jan;128:104129.,"Recently, deep learning frameworks have rapidly become the main methodology for analyzing medical images. Due to their powerful learning ability and advantages in dealing with complex patterns, deep learning algorithms are ideal for image analysis challenges, particularly in the field of digital pathology. The variety of image analysis tasks in the context of deep learning includes classification (e.g., healthy vs. cancerous tissue), detection (e.g., lymphocytes and mitosis counting), and segmentation (e.g., nuclei and glands segmentation). The majority of recent machine learning methods in digital pathology have a pre- and/or post-processing stage which is integrated with a deep neural network. These stages, based on traditional image processing methods, are employed to make the subsequent classification, detection, or segmentation problem easier to solve. Several studies have shown how the integration of pre- and post-processing methods within a deep learning pipeline can further increase the model's performance when compared to the network by itself. The aim of this review is to provide an overview on the types of methods that are used within deep learning frameworks either to optimally prepare the input (pre-processing) or to improve the results of the network output (post-processing), focusing on digital pathology image analysis. Many of the techniques presented here, especially the post-processing methods, are not limited to digital pathology but can be extended to almost any image analysis field."
33253918,,Uncertainty quantification in drug design,2021 Feb;26(2):474-489.,"Machine learning and artificial intelligence are increasingly being applied to the drug-design process as a result of the development of novel algorithms, growing access, the falling cost of computation and the development of novel technologies for generating chemically and biologically relevant data. There has been recent progress in fields such as molecular de novo generation, synthetic route prediction and, to some extent, property predictions. Despite this, most research in these fields has focused on improving the accuracy of the technologies, rather than on quantifying the uncertainty in the predictions. Uncertainty quantification will become a key component in autonomous decision making and will be crucial for integrating machine learning and chemistry automation to create an autonomous design-make-test-analyse cycle. This review covers the empirical, frequentist and Bayesian approaches to uncertainty quantification, and outlines how they can be used for drug design. We also outline the impact of uncertainty quantification on decision making."
33253326,,Transcriptional insights into pathogenesis of cutaneous systemic sclerosis using pathway driven meta-analysis assisted by machine learning methods,2020 Nov 30;15(11):e0242863.,"Pathophysiology of systemic sclerosis (SSc, Scleroderma), an autoimmune rheumatic disease, comprises of mechanisms that drive vasculopathy, inflammation and fibrosis. Understanding of the disease and associated clinical heterogeneity has advanced considerably in the past decade, highlighting the necessity of more specific targeted therapy. While many of the recent trials in SSc failed to meet the primary end points that predominantly relied on changes in modified Rodnan skin scores (MRSS), sub-group analysis, especially those focused on the basal skin transcriptomic data have provided insights into patient subsets that respond to therapies. These findings suggest that deeper understanding of the molecular changes in pathways is very important to define disease drivers in various patient subgroups. In view of these challenges, we performed meta-analysis on 9 public available SSc microarray studies using a novel pathway pivoted approach combining consensus clustering and machine learning assisted feature selection. Selected pathway modules were further explored through cluster specific topological network analysis in search of novel therapeutic concepts. In addition, we went beyond previously described SSc class divisions of 3 clusters (e.g. inflammation, fibro-proliferative, normal-like) and expanded into a much finer stratification in order to profile SSc patients more accurately. Our analysis unveiled an important 80 pathway signatures that differentiated SSc patients into 8 unique subtypes. The 5 pathway modules derived from such signature successfully defined the 8 SSc subsets and were validated by in-silico cellular deconvolution analysis. Myeloid cells and fibroblasts involvement in different clusters were confirmed and linked to corresponding pathway activities. Collectively, our findings revealed more complex disease subtypes in SSc; Key gene mediators such as IL6, FGFR1, TLR7, PLCG2, IRK2 identified by network analysis underscored the scientific rationale for exploring additional targets in treatment of SSc."
33252345,,Social Media as a Research Tool (SMaaRT) for Risky Behavior Analytics: Methodological Review,2020 Nov 30;6(4):e21660.,"Background:                    Modifiable risky health behaviors, such as tobacco use, excessive alcohol use, being overweight, lack of physical activity, and unhealthy eating habits, are some of the major factors for developing chronic health conditions. Social media platforms have become indispensable means of communication in the digital era. They provide an opportunity for individuals to express themselves, as well as share their health-related concerns with peers and health care providers, with respect to risky behaviors. Such peer interactions can be utilized as valuable data sources to better understand inter-and intrapersonal psychosocial mediators and the mechanisms of social influence that drive behavior change.              Objective:                    The objective of this review is to summarize computational and quantitative techniques facilitating the analysis of data generated through peer interactions pertaining to risky health behaviors on social media platforms.              Methods:                    We performed a systematic review of the literature in September 2020 by searching three databases-PubMed, Web of Science, and Scopus-using relevant keywords, such as ""social media,"" ""online health communities,"" ""machine learning,"" ""data mining,"" etc. The reporting of the studies was directed by the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Two reviewers independently assessed the eligibility of studies based on the inclusion and exclusion criteria. We extracted the required information from the selected studies.              Results:                    The initial search returned a total of 1554 studies, and after careful analysis of titles, abstracts, and full texts, a total of 64 studies were included in this review. We extracted the following key characteristics from all of the studies: social media platform used for conducting the study, risky health behavior studied, the number of posts analyzed, study focus, key methodological functions and tools used for data analysis, evaluation metrics used, and summary of the key findings. The most commonly used social media platform was Twitter, followed by Facebook, QuitNet, and Reddit. The most commonly studied risky health behavior was nicotine use, followed by drug or substance abuse and alcohol use. Various supervised and unsupervised machine learning approaches were used for analyzing textual data generated from online peer interactions. Few studies utilized deep learning methods for analyzing textual data as well as image or video data. Social network analysis was also performed, as reported in some studies.              Conclusions:                    Our review consolidates the methodological underpinnings for analyzing risky health behaviors and has enhanced our understanding of how social media can be leveraged for nuanced behavioral modeling and representation. The knowledge gained from our review can serve as a foundational component for the development of persuasive health communication and effective behavior modification technologies aimed at the individual and population levels."
33248809,,Deep learning for the prediction of treatment response in depression,2021 Feb 15;281:618-622.,"Background:                    Mood disorders are characterized by heterogeneity in severity, symptoms and treatment response. The possibility of selecting the correct therapy on the basis of patient-specific biomarker may be a considerable step towards personalized psychiatry. Machine learning methods are gaining increasing popularity in the medical field. Once trained, the possibility to consider single patients in the analyses instead of whole groups makes them particularly appealing to investigate treatment response. Deep learning, a branch of machine learning, lately gained attention, due to its effectiveness in dealing with large neuroimaging data and to integrate them with clinical, molecular or -omics biomarkers.              Methods:                    In this mini-review, we summarize studies that use deep learning methods to predict response to treatment in depression. We performed a bibliographic search on PUBMED, Google Scholar and Web of Science using the terms ""psychiatry"", ""mood disorder"", ""depression"", ""treatment"", ""deep learning"", ""neural networks"". Only studies considering patients' datasets are considered.              Results:                    Eight studies met the inclusion criteria. Accuracies in prediction of response to therapy were considerably high in all studies, but results may be not easy to interpret.              Limitations:                    The major limitation for the current studies is the small sample size, which constitutes an issue for machine learning methods.              Conclusions:                    Deep learning shows promising results in terms of prediction of treatment response, often outperforming regression methods and reaching accuracies of around 80%. This could be of great help towards personalized medicine. However, more efforts are needed in terms of increasing datasets size and improved interpretability of results."
33247802,4.0,"Magnetic resonance imaging for chronic pain: diagnosis, manipulation, and biomarkers",2020 Nov 23.,"Pain is a multidimensional subjective experience with biological, psychological, and social factors. Whereas acute pain can be a warning signal for the body to avoid excessive injury, long-term and ongoing pain may be developed as chronic pain. There are more than 100 million people in China living with chronic pain, which has raised a huge socioeconomic burden. Studying the mechanisms of pain and developing effective analgesia approaches are important for basic and clinical research. Recently, with the development of brain imaging and data analytical approaches, the neural mechanisms of chronic pain have been widely studied. In the first part of this review, we briefly introduced the magnetic resonance imaging and conventional analytical approaches for brain imaging data. Then, we reviewed brain alterations caused by several chronic pain disorders, including localized and widespread primary pain, primary headaches and orofacial pain, musculoskeletal pain, and neuropathic pain, and present meta-analytical results to show brain regions associated with the pathophysiology of chronic pain. Next, we reviewed brain changes induced by pain interventions, such as pharmacotherapy, neuromodulation, and acupuncture. Lastly, we reviewed emerging studies that combined advanced machine learning and neuroimaging techniques to identify diagnostic, prognostic, and predictive biomarkers in chronic pain patients."
33246838,,Emerging use of machine learning and advanced technologies to assess red cell quality,2020 Dec;59(6):103020.,"Improving blood product quality and patient outcomes is an accepted goal in transfusion medicine research. Thus, there is an urgent need to understand the potential adverse effects on red blood cells (RBCs) during pre-transfusion storage. Current assessment techniques of these degradation events, termed ""storage lesions"", are subjective, labor-intensive, and complex. Here we describe emerging technologies that assess the biochemical, biophysical, and morphological characteristics of RBC storage lesions. Of these emerging techniques, machine learning (ML) has shown potential to overcome the limitations of conventional RBC assessment methods. Our previous work has shown that neural networks can extract chronological progressions of morphological changes in RBCs during storage without human input. We hypothesize that, with broader training and testing of multivariate data (e.g., varying donor factors and manufacturing methods), ML can further our understanding of clinical transfusion outcomes in multiple patient groups."
33245914,1.0,"Challenges in the Development, Deployment, and Regulation of Artificial Intelligence in Anatomic Pathology",2020 Nov 24;S0002-9440(20)30508-3.,"Significant advances in artificial intelligence (AI), deep learning, and other machine-learning approaches have been made in recent years, with applications found in almost every industry, including health care. AI has proved to be capable of completing a spectrum of mundane to complex medically oriented tasks previously performed only by boarded physicians, most recently assisting with the detection of cancers difficult to find on histopathology slides. Although computers will not replace pathologists any time soon, properly designed AI-based tools hold great potential for increasing workflow efficiency and diagnostic accuracy in the practice of pathology. Recent trends, such as data augmentation, crowdsourcing for generating annotated data sets, and unsupervised learning with molecular and/or clinical outcomes versus human diagnoses as a source of ground truth, are eliminating the direct role of pathologists in algorithm development. Proper integration of AI-based systems into anatomic-pathology practice will necessarily require fully digital imaging platforms, an overhaul of legacy information-technology infrastructures, modification of laboratory/pathologist workflows, appropriate reimbursement/cost-offsetting models, and ultimately, the active participation of pathologists to encourage buy-in and oversight. Regulations tailored to the nature and limitations of AI are currently in development and, when instituted, are expected to promote safe and effective use. This review addresses the challenges in AI development, deployment, and regulation to be overcome prior to its widespread adoption in anatomic pathology."
33245088,,"The application potential of machine learning and genomics for understanding natural product diversity, chemistry, and therapeutic translatability",2020 Nov 27.,"Covering: up to the end of 2020. The machine learning field can be defined as the study and application of algorithms that perform classification and prediction tasks through pattern recognition instead of explicitly defined rules. Among other areas, machine learning has excelled in natural language processing. As such methods have excelled at understanding written languages (e.g. English), they are also being applied to biological problems to better understand the ""genomic language"". In this review we focus on recent advances in applying machine learning to natural products and genomics, and how those advances are improving our understanding of natural product biology, chemistry, and drug discovery. We discuss machine learning applications in genome mining (identifying biosynthetic signatures in genomic data), predictions of what structures will be created from those genomic signatures, and the types of activity we might expect from those molecules. We further explore the application of these approaches to data derived from complex microbiomes, with a focus on the human microbiome. We also review challenges in leveraging machine learning approaches in the field, and how the availability of other ""omics"" data layers provides value. Finally, we provide insights into the challenges associated with interpreting machine learning models and the underlying biology and promises of applying machine learning to natural product drug discovery. We believe that the application of machine learning methods to natural product research is poised to accelerate the identification of new molecular entities that may be used to treat a variety of disease indications."
33243455,,Machine Learning and Improved Quality Metrics in Acute Intracranial Hemorrhage by Noncontrast Computed Tomography,2020 Nov 15;S0363-0188(20)30208-5.,"Objective:                    The timely reporting of critical results in radiology is paramount to improved patient outcomes. Artificial intelligence has the ability to improve quality by optimizing clinical radiology workflows. We sought to determine the impact of a United States Food and Drug Administration-approved machine learning (ML) algorithm, meant to mark computed tomography (CT) head examinations pending interpretation as higher probability for intracranial hemorrhage (ICH), on metrics across our healthcare system. We hypothesized that ML is associated with a reduction in report turnaround time (RTAT) and length of stay (LOS) in emergency department (ED) and inpatient populations.              Materials and methods:                    An ML algorithm was incorporated across CT scanners at imaging sites in January 2018. RTAT and LOS were derived for reports and patients between July 2017 and December 2017 prior to implementation of ML and compared to those between January 2018 and June 2018 after implementation of ML. A total of 25,658 and 24,996 ED and inpatient cases were evaluated across the entire healthcare system before and after ML, respectively.              Results:                    RTAT decreased from 75 to 69 minutes (P <0.001) at all facilities in the healthcare system. At the level 1 trauma center specifically, RTAT decreased from 67 to 59 minutes (P <0.001). ED LOS decreased from 471 to 425 minutes (P <0.001) for patients without ICH, and from 527 to 491 minutes for those with ICH (P = 0.456). Inpatient LOS decreased from 18.4 to 15.8 days for those without ICH (P = 0.001) and 18.1 to 15.8 days for those with ICH (P = 0.02).              Conclusion:                    We demonstrated that utilization of ML was associated with a statistically significant decrease in RTAT. There was also a significant decrease in LOS for ED patients without ICH, but not for ED patients with ICH. Further evaluation of the impact of such tools on patient care and outcomes is needed."
33242721,,"Towards precise resting-state fMRI biomarkers in psychiatry: synthesizing developments in transdiagnostic research, dimensional models of psychopathology, and normative neurodevelopment",2020 Dec;65:120-128.,"Searching for biomarkers has been a chief pursuit of the field of psychiatry. Toward this end, studies have catalogued candidate resting-state biomarkers in nearly all forms of mental disorder. However, it is becoming increasingly clear that these biomarkers lack specificity, limiting their capacity to yield clinical impact. We discuss three avenues of research that are overcoming this limitation: (i) the adoption of transdiagnostic research designs, which involve studying and explicitly comparing multiple disorders from distinct diagnostic axes of psychiatry; (ii) dimensional models of psychopathology that map the full spectrum of symptomatology and that cut across traditional disorder boundaries; and (iii) modeling individuals' unique functional connectomes throughout development. We provide a framework for tying these subfields together that draws on tools from machine learning and network science."
33242635,1.0,Artificial intelligence in cardiology,2020 Nov 23;S1050-1738(20)30151-1.,"This review examines the current state and application of artificial intelligence (AI) and machine learning (ML) in cardiovascular medicine. AI is changing the clinical practice of medicine in other specialties. With progress continuing in this emerging technology, the impact for cardiovascular medicine is highlighted to provide insight for the practicing clinician and to identify potential patient benefits."
33242563,,"Rodent and fly models in behavioral neuroscience: An evaluation of methodological advances, comparative research, and future perspectives",2021 Jan;120:1-12.,"The assessment of behavioral outcomes is a central component of neuroscientific research, which has required continuous technological innovations to produce more detailed and reliable findings. In this article, we provide an in-depth review on the progress and future implications for three model organisms (mouse, rat, and Drosophila) essential to our current understanding of behavior. By compiling a comprehensive catalog of popular assays, we are able to compare the diversity of tasks and usage of these animal models in behavioral research. This compilation also allows for the evaluation of existing state-of-the-art methods and experimental applications, including optogenetics, machine learning, and high-throughput behavioral assays. We go on to discuss novel apparatuses and inter-species analyses for centrophobism, feeding behavior, aggression and mating paradigms, with the goal of providing a unique view on comparative behavioral research. The challenges and recent advances are evaluated in terms of their translational value, ethical procedures, and trustworthiness for behavioral research."
33242537,,Automation and data-driven design of polymer therapeutics,2020 Nov 24;171:1-28.,"Polymers are uniquely suited for drug delivery and biomaterial applications due to tunable structural parameters such as length, composition, architecture, and valency. To facilitate designs, researchers may explore combinatorial libraries in a high throughput fashion to correlate structure to function. However, traditional polymerization reactions including controlled living radical polymerization (CLRP) and ring-opening polymerization (ROP) require inert reaction conditions and extensive expertise to implement. With the advent of air-tolerance and automation, several polymerization techniques are now compatible with well plates and can be carried out at the benchtop, making high throughput synthesis and high throughput screening (HTS) possible. To avoid HTS pitfalls often described as ""fishing expeditions,"" it is crucial to employ intelligent and big data approaches to maximize experimental efficiency. This is where the disruptive technologies of machine learning (ML) and artificial intelligence (AI) will likely play a role. In fact, ML and AI are already impacting small molecule drug discovery and showing signs of emerging in drug delivery. In this review, we present state-of-the-art research in drug delivery, gene delivery, antimicrobial polymers, and bioactive polymers alongside data-driven developments in drug design and organic synthesis. From this insight, important lessons are revealed for the polymer therapeutics community including the value of a closed loop design-build-test-learn workflow. This is an exciting time as researchers will gain the ability to fully explore the polymer structural landscape and establish quantitative structure-property relationships (QSPRs) with biological significance."
33240726,,Is Artificial Intelligence the New Friend for Radiologists? A Review Article,2020 Oct 24;12(10):e11137.,"Artificial intelligence (AI) is a path-breaking advancement for many industries, including the health care sector. The expeditious development of information technology and data processing has led to the formation of recent tools known as artificial intelligence. Radiology has been a portal for medical technological advancements, and AI will likely be no dissimilar. Radiology is the platform for many technological advances in the medical field; AI can undoubtedly impact every step of a radiologist's workflow. AI can simplify every activity like ordering and scheduling, protocoling and acquisition, image interpretation, reporting, communication, and billing. AI has eminent potential to augment efficiency and accuracy throughout radiology, but it also possesses inherent drawbacks and biases. We collected studies that were published in the past five years using PubMed as our database. We chose studies that were relevant to artificial intelligence in radiology. We mainly focused on the overview of AI in radiology, components included in the functioning of AI, AI assisting in the radiologists' workflow, ethical aspects of AI, challenges, and biases that AI experiencing together with some clinical applications of AI. Of all 33 studies, we found 15 articles discussed the overview and components of AI, five articles about AI affecting radiologist's workflow, five articles related to challenges and biases in AI, two articles discussed ethical aspects of AI, and six articles about practical implications of AI. We found out that the application of AI could make time-dependent tasks that can be performed effortlessly, permitting radiologists more time and opportunities to engage in patient care via increased time for consultation and development in imaging and extracting useful data from those images. AI could only be an aid to radiologists but will not replace a radiologist. Radiologists who use AI to their benefit, rather than to avoid it out of fear, might supersede those radiologists who do not. Substantial research should be done regarding the practical implications of AI algorithms for residents curriculum and the benefits of AI in radiology."
33240470,1.0,The era of big data: Genome-scale modelling meets machine learning,2020 Oct 16;18:3287-3300.,"With omics data being generated at an unprecedented rate, genome-scale modelling has become pivotal in its organisation and analysis. However, machine learning methods have been gaining ground in cases where knowledge is insufficient to represent the mechanisms underlying such data or as a means for data curation prior to attempting mechanistic modelling. We discuss the latest advances in genome-scale modelling and the development of optimisation algorithms for network and error reduction, intracellular constraining and applications to strain design. We further review applications of supervised and unsupervised machine learning methods to omics datasets from microbial and mammalian cell systems and present efforts to harness the potential of both modelling approaches through hybrid modelling."
33240317,,Current Trends in Experimental and Computational Approaches to Combat Antimicrobial Resistance,2020 Nov 6;11:563975.,"A multitude of factors, such as drug misuse, lack of strong regulatory measures, improper sewage disposal, and low-quality medicine and medications, have been attributed to the emergence of drug resistant microbes. The emergence and outbreaks of multidrug resistance to last-line antibiotics has become quite common. This is further fueled by the slow rate of drug development and the lack of effective resistome surveillance systems. In this review, we provide insights into the recent advances made in computational approaches for the surveillance of antibiotic resistomes, as well as experimental formulation of combinatorial drugs. We explore the multiple roles of antibiotics in nature and the current status of combinatorial and adjuvant-based antibiotic treatments with nanoparticles, phytochemical, and other non-antibiotics based on synergetic effects. Furthermore, advancements in machine learning algorithms could also be applied to combat the spread of antibiotic resistance. Development of resistance to new antibiotics is quite rapid. Hence, we review the recent literature on discoveries of novel antibiotic resistant genes though shotgun and expression-based metagenomics. To decelerate the spread of antibiotic resistant genes, surveillance of the resistome is of utmost importance. Therefore, we discuss integrative applications of whole-genome sequencing and metagenomics together with machine learning models as a means for state-of-the-art surveillance of the antibiotic resistome. We further explore the interactions and negative effects between antibiotics and microbiomes upon drug administration."
33237824,,"Multimodality cardiac imaging in the 21st century: evolution, advances and future opportunities for innovation",2021 Jan 1;94(1117):20200780.,"Cardiovascular imaging has significantly evolved since the turn of the century. Progress in the last two decades has been marked by advances in every modality used to image the heart, including echocardiography, cardiac magnetic resonance, cardiac CT and nuclear cardiology. There has also been a dramatic increase in hybrid and fusion modalities that leverage the unique capabilities of two imaging techniques simultaneously, as well as the incorporation of artificial intelligence and machine learning into the clinical workflow. These advances in non-invasive cardiac imaging have guided patient management and improved clinical outcomes. The technological developments of the past 20 years have also given rise to new imaging subspecialities and increased the demand for dedicated cardiac imagers who are cross-trained in multiple modalities. This state-of-the-art review summarizes the evolution of multimodality cardiac imaging in the 21st century and highlights opportunities for future innovation."
33235943,,Risk-stratified and stepped models of care for back pain and osteoarthritis: are we heading towards a common model?,2020 Sep 23;5(5):e843.,"The overall quality of care for musculoskeletal pain conditions is suboptimal, partly due to a considerable evidence-practice gap. In osteoarthritis and low back pain, structured models of care exist to help overcome that challenge. In osteoarthritis, focus is on stepped care models, where treatment decisions are guided by response to treatment, and increasingly comprehensive interventions are only offered to people with inadequate response to more simple care. In low back pain, the most widely known approach is based on risk stratification, where patients with higher predicted risk of poor outcome are offered more comprehensive care. For both conditions, the recommended interventions and models of care share many commonalities and there is no evidence that one model of care is more effective than the other. Limitations of existing models of care include a lack of integrated information on social factors, comorbid conditions, and previous treatment experience, and they do not support an interplay between health care, self-management, and community-based activities. Moving forwards, a common model across musculoskeletal conditions seems realistic, which points to an opportunity for reducing the complexity of implementation. We foresee this development will use big data sources and machine-learning methods to combine stepped and risk-stratified care and to integrate self-management support and patient-centred care to a greater extent in future models of care."
33232845,,Fermented food products in the era of globalization: tradition meets biotechnology innovations,2020 Nov 21;70:36-41.,"Omics tools offer the opportunity to characterize and trace traditional and industrial fermented foods. Bioinformatics, through machine learning, and other advanced statistical approaches, are able to disentangle fermentation processes and to predict the evolution and metabolic outcomes of a food microbial ecosystem. By assembling microbial artificial consortia, the biotechnological advances will also be able to enhance the nutritional value and organoleptics characteristics of fermented food, preserving, at the same time, the potential of autochthonous microbial consortia and metabolic pathways, which are difficult to reproduce. Preserving the traditional methods contributes to protecting the hidden value of local biodiversity, and exploits its potential in industrial processes with the final aim of guaranteeing food security and safety, even in developing countries."
33230875,2.0,A Review of Piezoelectric and Magnetostrictive Biosensor Materials for Detection of COVID-19 and Other Viruses,2021 Jan;33(1):e2005448.,"The spread of the severe acute respiratory syndrome coronavirus has changed the lives of people around the world with a huge impact on economies and societies. The development of wearable sensors that can continuously monitor the environment for viruses may become an important research area. Here, the state of the art of research on biosensor materials for virus detection is reviewed. A general description of the principles for virus detection is included, along with a critique of the experimental work dedicated to various virus sensors, and a summary of their detection limitations. The piezoelectric sensors used for the detection of human papilloma, vaccinia, dengue, Ebola, influenza A, human immunodeficiency, and hepatitis B viruses are examined in the first section; then the second part deals with magnetostrictive sensors for the detection of bacterial spores, proteins, and classical swine fever. In addition, progress related to early detection of COVID-19 (coronavirus disease 2019) is discussed in the final section, where remaining challenges in the field are also identified. It is believed that this review will guide material researchers in their future work of developing smart biosensors, which can further improve detection sensitivity in monitoring currently known and future virus threats."
33227439,,"Osteoarthritis year in review: genetics, genomics, epigenetics",2021 Feb;29(2):151-160.,"Objective:                    In this review, we have highlighted advances in genetics, genomics and epigenetics in the field of osteoarthritis (OA) over the past year.              Methods:                    A literature search was performed using PubMed and the criteria: ""osteoarthritis"" and one of the following terms ""genetic(s), genomic(s), epigenetic(s), epigenomic(s), noncoding RNA, microRNA, long noncoding RNA, lncRNA, circular RNA, RNA sequencing, single cell sequencing, or DNA methylation between April 1, 2019 and April 30, 2020.              Results:                    We identified 653 unique publications, many studies spanned multiple search terms. We summarized advances relating to evolutionary genetics, pain, ethnicity specific risk factors, functional studies of gene variants, and interactions between coding and non-coding RNAs in OA pathogenesis.              Conclusions:                    Studies have identified variants contributing to OA susceptibility, candidate biomarkers for diagnosis and prognosis, as well as promising therapeutic candidates. Validation in multiple cohorts, multi-omics strategies, and machine learning aided computational analyses have all contributed to the strength of published literature. Open access data-sets, greater sample sizes to capture broader populations and understanding disease mechanisms by investigating the interactions between multiple tissue types will further aid in progress towards understanding and curing OA."
33224516,1.0,"Suicidal thoughts, suicidal behaviours and self-harm in daily life: A systematic review of ecological momentary assessment studies",2020 Nov 3;6:2055207620963958.,"Background:                    Ecological Momentary Assessments (EMA) offer an approach to understand the daily risk factors of suicide and self-harm of individuals through the use of self-monitoring techniques using mobile technologies.              Objectives:                    This systematic review aimed to examine the results of studies on suicidality risk factors and self-harm that used Ecological Momentary Assessments.              Methods:                    Pubmed and PsycINFO databases were searched up to April 2020. Bibliographies of eligible studies were hand-searched, and 744 abstracts were screened and double-coded for inclusion.              Results:                    The 49 studies using EMA included in the review found associations between daily affect, rumination and interpersonal interactions and daily non-suicidal self-injury (NSSI). Studies also found associations between daily negative affect and positive affect, social support, sleep, and emotions and a person's history of suicide and self-harm. Associations between daily suicide thoughts and self-harm, and psychopathology factors measured at baseline were also observed.              Conclusions:                    Research using EMA has the potential to offer clinicians the ability to understand the daily predictors, or risk factors, of suicide and self-harm. However, there are no clear reporting standards for EMA studies on risk factors for suicide. Further research should utilise longitudinal study designs, harmonise datasets and use machine learning techniques to identify patterns of proximal risk factors for suicide behaviours."
33222226,,Real-time biomechanics using the finite element method and machine learning: Review and perspective,2021 Jan;48(1):7-18.,"Purpose:                    The finite element method (FEM) is the preferred method to simulate phenomena in anatomical structures. However, purely FEM-based mechanical simulations require considerable time, limiting their use in clinical applications that require real-time responses, such as haptics simulators. Machine learning (ML) approaches have been proposed to help with the reduction of the required time. The present paper reviews cases where ML could help to generate faster simulations, without considerably affecting the performance results.              Methods:                    This review details the ML approaches used, considering the anatomical structures involved, the data collection strategies, the selected ML algorithms, with corresponding features, the metrics used for validation, and the resulting time gains.              Results:                    A total of 41 references were found. ML algorithms are mainly trained with FEM-based simulations in 32 publications. The preferred ML approach is neural networks, including deep learning in 35 publications. Tissue deformation is simulated in 18 applications, but other features are also considered. The average distance error and mean squared error are the most frequently used performance metrics, in 14 and 17 publications, respectively. The time gains were considerable, going from hours or minutes for purely FEM-based simulations to milliseconds, when using ML.              Conclusions:                    ML algorithms can be used to accelerate FEM-based biomechanical simulations of anatomical structures, possibly reaching real-time responses. Fast and real-time simulations of anatomical structures, generated with ML algorithms, can help to reduce the time required by FEM-based simulations and accelerate their adoption in the clinical practice."
33222032,1.0,Modeling of dynamical systems through deep learning,2020 Nov 22;12(6):1311-1320.,"This review presents a modern perspective on dynamical systems in the context of current goals and open challenges. In particular, our review focuses on the key challenges of discovering dynamics from data and finding data-driven representations that make nonlinear systems amenable to linear analysis. We explore various challenges in modern dynamical systems, along with emerging techniques in data science and machine learning to tackle them. The two chief challenges are (1) nonlinear dynamics and (2) unknown or partially known dynamics. Machine learning is providing new and powerful techniques for both challenges. Dimensionality reduction methods are used for projecting dynamical methods in reduced form, and these methods perform computational efficiency on real-world data. Data-driven models drive to discover the governing equations and give laws of physics. The identification of dynamical systems through deep learning techniques succeeds in inferring physical systems. Machine learning provides advanced new and powerful algorithms for nonlinear dynamics. Advanced deep learning methods like autoencoders, recurrent neural networks, convolutional neural networks, and reinforcement learning are used in modeling of dynamical systems."
33221420,1.0,Machine learning for metabolic engineering: A review,2021 Jan;63:34-60.,"Machine learning provides researchers a unique opportunity to make metabolic engineering more predictable. In this review, we offer an introduction to this discipline in terms that are relatable to metabolic engineers, as well as providing in-depth illustrative examples leveraging omics data and improving production. We also include practical advice for the practitioner in terms of data management, algorithm libraries, computational resources, and important non-technical issues. A variety of applications ranging from pathway construction and optimization, to genetic editing optimization, cell factory testing, and production scale-up are discussed. Moreover, the promising relationship between machine learning and mechanistic models is thoroughly reviewed. Finally, the future perspectives and most promising directions for this combination of disciplines are examined."
33220532,,Methodological uncertainties in drug-receptor binding free energy predictions based on classical molecular dynamics,2021 Apr;67:127-134.,"Computational approaches are becoming an essential tool in modern drug design and discovery, with fast compound triaging using a combination of machine learning and docking techniques followed by molecular dynamics binding free energies assessment using alchemical techniques. The traditional MD-based alchemical free energy perturbation (FEP) method faces severe sampling issues that may limits its reliability in automated workflows. Here we review the major sources of uncertainty in FEP protocols for drug discovery, showing how the sampling problem can be effectively tackled by switching to nonequilibrium alchemical techniques."
33220267,1.0,The potential for complex computational models of aging,2021 Jan;193:111403.,"The gradual accumulation of damage and dysregulation during the aging of living organisms can be quantified. Even so, the aging process is complex and has multiple interacting physiological scales - from the molecular to cellular to whole tissues. In the face of this complexity, we can significantly advance our understanding of aging with the use of computational models that simulate realistic individual trajectories of health as well as mortality. To do so, they must be systems-level models that incorporate interactions between measurable aspects of age-associated changes. To incorporate individual variability in the aging process, models must be stochastic. To be useful they should also be predictive, and so must be fit or parameterized by data from large populations of aging individuals. In this perspective, we outline where we have been, where we are, and where we hope to go with such computational models of aging. Our focus is on data-driven systems-level models, and on their great potential in aging research."
33217963,1.0,"Digital Pathology: Advantages, Limitations and Emerging Perspectives",2020 Nov 18;9(11):3697.,"Digital pathology is on the verge of becoming a mainstream option for routine diagnostics. Faster whole slide image scanning has paved the way for this development, but implementation on a large scale is challenging on technical, logistical, and financial levels. Comparative studies have published reassuring data on safety and feasibility, but implementation experiences highlight the need for training and the knowledge of pitfalls. Up to half of the pathologists are reluctant to sign out reports on only digital slides and are concerned about reporting without the tool that has represented their profession since its beginning. Guidelines by international pathology organizations aim to safeguard histology in the digital realm, from image acquisition over the setup of work-stations to long-term image archiving, but must be considered a starting point only. Cost-efficiency analyses and occupational health issues need to be addressed comprehensively. Image analysis is blended into the traditional work-flow, and the approval of artificial intelligence for routine diagnostics starts to challenge human evaluation as the gold standard. Here we discuss experiences from past digital pathology implementations, future possibilities through the addition of artificial intelligence, technical and occupational health challenges, and possible changes to the pathologist's profession."
33217660,2.0,"Coronary artery disease detection using artificial intelligence techniques: A survey of trends, geographical differences and diagnostic features 1991-2020",2021 Jan;128:104095.,"While coronary angiography is the gold standard diagnostic tool for coronary artery disease (CAD), but it is associated with procedural risk, it is an invasive technique requiring arterial puncture, and it subjects the patient to radiation and iodinated contrast exposure. Artificial intelligence (AI) can provide a pretest probability of disease that can be used to triage patients for angiography. This review comprehensively investigates published papers in the domain of CAD detection using different AI techniques from 1991 to 2020, in order to discern broad trends and geographical differences. Moreover, key decision factors affecting CAD diagnosis are identified for different parts of the world by aggregating the results from different studies. In this study, all datasets that have been used for the studies for CAD detection, their properties, and achieved performances using various AI techniques, are presented, compared, and analyzed. In particular, the effectiveness of machine learning (ML) and deep learning (DL) techniques to diagnose and predict CAD are reviewed. From PubMed, Scopus, Ovid MEDLINE, and Google Scholar search, 500 papers were selected to be investigated. Among these selected papers, 256 papers met our criteria and hence were included in this study. Our findings demonstrate that AI-based techniques have been increasingly applied for the detection of CAD since 2008. AI-based techniques that utilized electrocardiography (ECG), demographic characteristics, symptoms, physical examination findings, and heart rate signals, reported high accuracy for the detection of CAD. In these papers, the authors ranked the features based on their assessed clinical importance with ML techniques. The results demonstrate that the attribution of the relative importance of ML features for CAD diagnosis is different among countries. More recently, DL methods have yielded high CAD detection performance using ECG signals, which drives its burgeoning adoption."
33215079,1.0,Use of machine learning in geriatric clinical care for chronic diseases: a systematic literature review,2020 Oct 8;3(3):459-471.,"Objectives:                    Geriatric clinical care is a multidisciplinary assessment designed to evaluate older patients' (age 65 years and above) functional ability, physical health, and cognitive well-being. The majority of these patients suffer from multiple chronic conditions and require special attention. Recently, hospitals utilize various artificial intelligence (AI) systems to improve care for elderly patients. The purpose of this systematic literature review is to understand the current use of AI systems, particularly machine learning (ML), in geriatric clinical care for chronic diseases.              Materials and methods:                    We restricted our search to eight databases, namely PubMed, WorldCat, MEDLINE, ProQuest, ScienceDirect, SpringerLink, Wiley, and ERIC, to analyze research articles published in English between January 2010 and June 2019. We focused on studies that used ML algorithms in the care of geriatrics patients with chronic conditions.              Results:                    We identified 35 eligible studies and classified in three groups: psychological disorder (n = 22), eye diseases (n = 6), and others (n = 7). This review identified the lack of standardized ML evaluation metrics and the need for data governance specific to health care applications.              Conclusion:                    More studies and ML standardization tailored to health care applications are required to confirm whether ML could aid in improving geriatric clinical care."
33211357,,Artificial intelligence and deep learning for small bowel capsule endoscopy,2021 Jan;33(2):290-297.,"Capsule endoscopy is ideally suited to artificial intelligence-based interpretation given its reliance on pattern recognition in still images. Time saving viewing modes and lesion detection features currently available rely on machine learning algorithms, a form of artificial intelligence. Current software necessitates close human supervision given poor sensitivity relative to an expert reader. However, with the advent of deep learning, artificial intelligence is becoming increasingly reliable and will be increasingly relied upon. We review the major advances in artificial intelligence for capsule endoscopy in recent publications and briefly review artificial intelligence development for historical understanding. Importantly, recent advancements in artificial intelligence have not yet been incorporated into practice and it is immature to judge the potential of this technology based on current platforms. Remaining regulatory and standardization hurdles are being overcome and artificial intelligence-based clinical applications are likely to proliferate rapidly."
33210822,1.0,"Worldwide occurrence of haemoplasmas in wildlife: Insights into the patterns of infection, transmission, pathology and zoonotic potential",2020 Nov 19.,"Haemotropic mycoplasmas (haemoplasmas) have increasingly attracted the attention of wildlife disease researchers due to a combination of wide host range, high prevalence and genetic diversity. A systematic review identified 75 articles that investigated haemoplasma infection in wildlife by molecular methods (chiefly targeting partial 16S rRNA gene sequences), which included 131 host genera across six orders. Studies were less common in the Eastern Hemisphere (especially Africa and Asia) and more frequent in the Artiodactyla and Carnivora. Meta-analysis showed that infection prevalence did not vary by geographic region nor host order, but wild hosts showed significantly higher prevalence than captive hosts. Using a taxonomically flexible machine learning algorithm, we also found vampire bats and cervids to have greater prevalence, whereas mink, a subclade of vesper bats, and true foxes all had lower prevalence compared to the remaining sampled mammal phylogeny. Haemoplasma genotype and nucleotide diversity varied little among wild mammals but were marginally lower in primates and bats. Coinfection with more than one haemoplasma species or genotype was always confirmed when assessed. Risk factors of infection identified were sociality, age, males and high trophic levels, and both prevalence and diversity were often higher in undisturbed environments. Haemoplasmas likely use different and concurrent transmission routes and typically display enzootic dynamics when wild populations are studied longitudinally. Haemoplasma pathology is poorly known in wildlife but appears subclinical. Candidatus Mycoplasma haematohominis, which causes disease in humans, probably has it natural host in bats. Haemoplasmas can serve as a model system in ecological and evolutionary studies, and future research on these pathogens in wildlife must focus on increasing the geographic range and taxa of studies and elucidating pathology, transmission and zoonotic potential. To facilitate such work, we recommend using universal PCR primers or NGS protocols to detect novel haemoplasmas and other genetic markers to differentiate among species and infer cross-species transmission."
33207552,,Nonlinear Optical Characterization of 2D Materials,2020 Nov 16;10(11):2263.,"Characterizing the physical and chemical properties of two-dimensional (2D) materials is of great significance for performance analysis and functional device applications. As a powerful characterization method, nonlinear optics (NLO) spectroscopy has been widely used in the characterization of 2D materials. Here, we summarize the research progress of NLO in 2D materials characterization. First, we introduce the principles of NLO and common detection methods. Second, we introduce the recent research progress on the NLO characterization of several important properties of 2D materials, including the number of layers, crystal orientation, crystal phase, defects, chemical specificity, strain, chemical dynamics, and ultrafast dynamics of excitons and phonons, aiming to provide a comprehensive review on laser-based characterization for exploring 2D material properties. Finally, the future development trends, challenges of advanced equipment construction, and issues of signal modulation are discussed. In particular, we also discuss the machine learning and stimulated Raman scattering (SRS) technologies which are expected to provide promising opportunities for 2D material characterization."
33207461,3.0,"Autopsy, thanatopraxy, cemeteries and crematoria as hotspots of toxic organic contaminants in the funeral industry continuum",2021 Jan 20;753:141819.,"The occurrence and health risks of toxic organic contaminants (TOCs) in the funeral industry are relatively under-studied compared to other industries. An increasing body of literature reports TOCs including emerging contaminants in the funeral industry, but comprehensive reviews of the evidence are still lacking. Hence, evidence was analysed to address the proposition that, the funeral industry constitutes several hotspot reservoirs of a wide spectrum of TOCs posing ecological and human health risks. TOCs detected include embalming products, persistent organic pollutants, synthetic pesticides, pharmaceuticals, personal care products and illicit drugs. Human cadavers, solid wastes, wastewaters and air-borne particulates from autopsy, thanatopraxy care facilities (mortuaries, funeral homes), cemeteries and crematoria are hotspots of TOCs. Ingestion of contaminated water, and aquatic and marine foods constitutes non-occupational human exposure, while occupational exposure occurs via inhalation and dermal intake. Risk factors promoting exposure to TOCs include unhygienic burial practices, poor solid waste and wastewater disposal, and weak and poorly enforced regulations. The generic health risks of TOCs are quite diverse, and include; (1) genotoxicity, endocrine disruption, teratogenicity and neurodevelopmental disorders, (2) development of antimicrobial resistance, (3) info-disruption via biomimicry, and (4) disruption of ecosystem functions and trophic interactions. Barring formaldehyde and inferential evidence, the epidemiological studies linking TOCs in the funeral industry to specific health outcomes are scarce. The reasons for the lack of evidence, and limitations of current health risk assessment protocols are discussed. A comprehensive framework for hazard identification, risk assessment and mitigation (HIRAM) in the funeral industry is proposed. The HIRAM includes regulatory, surveillance and control systems such as prevention and removal of TOCs. Future directions on the ecotoxicology of mixtures, behaviour, and health risks of TOCs are highlighted. The opportunities presented by emerging tools, including isotopic labelling, genomics, big data analytics (e.g., machine learning), and in silico techniques in toxicokinetic modelling are highlighted."
33205139,,Artificial Intelligence Meets Citizen Science to Supercharge Ecological Monitoring,2020 Oct 9;1(7):100109.,"The development and uptake of citizen science and artificial intelligence (AI) techniques for ecological monitoring is increasing rapidly. Citizen science and AI allow scientists to create and process larger volumes of data than possible with conventional methods. However, managers of large ecological monitoring projects have little guidance on whether citizen science, AI, or both, best suit their resource capacity and objectives. To highlight the benefits of integrating the two techniques and guide future implementation by managers, we explore the opportunities, challenges, and complementarities of using citizen science and AI for ecological monitoring. We identify project attributes to consider when implementing these techniques and suggest that financial resources, engagement, participant training, technical expertise, and subject charisma and identification are important project considerations. Ultimately, we highlight that integration can supercharge outcomes for ecological monitoring, enhancing cost-efficiency, accuracy, and multi-sector engagement."
33205132,,Generative Adversarial Networks in Digital Pathology: A Survey on Trends and Future Potential,2020 Sep 11;1(6):100089.,"Image analysis in the field of digital pathology has recently gained increased popularity. The use of high-quality whole-slide scanners enables the fast acquisition of large amounts of image data, showing extensive context and microscopic detail at the same time. Simultaneously, novel machine-learning algorithms have boosted the performance of image analysis approaches. In this paper, we focus on a particularly powerful class of architectures, the so-called generative adversarial networks (GANs) applied to histological image data. Besides improving performance, GANs also enable previously intractable application scenarios in this field. However, GANs could exhibit a potential for introducing bias. Hereby, we summarize the recent state-of-the-art developments in a generalizing notation, present the main applications of GANs, and give an outlook of some chosen promising approaches and their possible future applications. In addition, we identify currently unavailable methods with potential for future applications."
33205106,10.0,A Review of Super-Resolution Single-Molecule Localization Microscopy Cluster Analysis and Quantification Methods,2020 Jun 12;1(3):100038.,"Single-molecule localization microscopy (SMLM) is a relatively new imaging modality, winning the 2014 Nobel Prize in Chemistry, and considered as one of the key super-resolution techniques. SMLM resolution goes beyond the diffraction limit of light microscopy and achieves resolution on the order of 10-20 nm. SMLM thus enables imaging single molecules and study of the low-level molecular interactions at the subcellular level. In contrast to standard microscopy imaging that produces 2D pixel or 3D voxel grid data, SMLM generates big data of 2D or 3D point clouds with millions of localizations and associated uncertainties. This unprecedented breakthrough in imaging helps researchers employ SMLM in many fields within biology and medicine, such as studying cancerous cells and cell-mediated immunity and accelerating drug discovery. However, SMLM data quantification and interpretation methods have yet to keep pace with the rapid advancement of SMLM imaging. Researchers have been actively exploring new computational methods for SMLM data analysis to extract biosignatures of various biological structures and functions. In this survey, we describe the state-of-the-art clustering methods adopted to analyze and quantify SMLM data and examine the capabilities and shortcomings of the surveyed methods. We classify the methods according to (1) the biological application (i.e., the imaged molecules/structures), (2) the data acquisition (such as imaging modality, dimension, resolution, and number of localizations), and (3) the analysis details (2D versus 3D, field of view versus region of interest, use of machine-learning and multi-scale analysis, biosignature extraction, etc.). We observe that the majority of methods that are based on second-order statistics are sensitive to noise and imaging artifacts, have not been applied to 3D data, do not leverage machine-learning formulations, and are not scalable for big-data analysis. Finally, we summarize state-of-the-art methodology, discuss some key open challenges, and identify future opportunities for better modeling and design of an integrated computational pipeline to address the key challenges."
33205097,2.0,Avoid Oversimplifications in Machine Learning: Going beyond the Class-Prediction Accuracy,2020 May 8;1(2):100025.,"Class-prediction accuracy provides a quick but superficial way of determining classifier performance. It does not inform on the reproducibility of the findings or whether the selected or constructed features used are meaningful and specific. Furthermore, the class-prediction accuracy oversummarizes and does not inform on how training and learning have been accomplished: two classifiers providing the same performance in one validation can disagree on many future validations. It does not provide explainability in its decision-making process and is not objective, as its value is also affected by class proportions in the validation set. Despite these issues, this does not mean we should omit the class-prediction accuracy. Instead, it needs to be enriched with accompanying evidence and tests that supplement and contextualize the reported accuracy. This additional evidence serves as augmentations and can help us perform machine learning better while avoiding naive reliance on oversimplified metrics."
33204501,,Artificial intelligence in orthopaedics: false hope or not? A narrative review along the line of Gartner's hype cycle,2020 Oct 26;5(10):593-603.,"Artificial Intelligence (AI) in general, and Machine Learning (ML)-based applications in particular, have the potential to change the scope of healthcare, including orthopaedic surgery.The greatest benefit of ML is in its ability to learn from real-world clinical use and experience, and thereby its capability to improve its own performance.Many successful applications are known in orthopaedics, but have yet to be adopted and evaluated for accuracy and efficacy in patients' care and doctors' workflows.The recent hype around AI triggered hope for development of better risk stratification tools to personalize orthopaedics in all subsequent steps of care, from diagnosis to treatment.Computer vision applications for fracture recognition show promising results to support decision-making, overcome bias, process high-volume workloads without fatigue, and hold the promise of even outperforming doctors in certain tasks.In the near future, AI-derived applications are very likely to assist orthopaedic surgeons rather than replace us. 'If the computer takes over the simple stuff, doctors will have more time again to practice the art of medicine'.76 Cite this article: EFORT Open Rev 2020;5:593-603. DOI: 10.1302/2058-5241.5.190092."
33202354,,Unlocking the next generation of phage therapy: the key is in the receptors,2020 Nov 14;68:115-123.,"Phage therapy, the clinical use of viruses that kill bacteria, is a promising strategy in the fight against antimicrobial resistance. Before administration, phages undergo a careful examination of their safety and interactions with target bacteria. This characterization seldom includes identifying the receptor on the bacterial surface involved in phage adsorption. In this perspective article, we propose that understanding the function and location of these phage receptors can open the door to improved and innovative ways to use phage therapy. With knowledge of phage receptors, we can design intelligent phage cocktails, discover new phage-derived antimicrobials, and steer the evolution of phage-resistance towards clinically exploitable phenotypes. In an effort to jump-start this initiative, we recommend priority groups of hosts and phages. Finally, we review modern approaches for the identification of phage receptors, including molecular platforms for high-throughput mutagenesis, synthetic biology, and machine learning."
