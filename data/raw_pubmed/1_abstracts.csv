pmid,title,date,text,citations
33948244,Lessons and tips for designing a machine learning study using EHR data,2020 Jul 24;5(1):e21.,"Machine learning (ML) provides the ability to examine massive datasets and uncover patterns within data without relying on a priori assumptions such as specific variable associations, linearity in relationships, or prespecified statistical interactions. However, the application of ML to healthcare data has been met with mixed results, especially when using administrative datasets such as the electronic health record. The black box nature of many ML algorithms contributes to an erroneous assumption that these algorithms can overcome major data issues inherent in large administrative healthcare data. As with other research endeavors, good data and analytic design is crucial to ML-based studies. In this paper, we will provide an overview of common misconceptions for ML, the corresponding truths, and suggestions for incorporating these methods into healthcare research while maintaining a sound study design.",
33937813,Computer-aided Assessment of Catheters and Tubes on Radiographs: How Good Is Artificial Intelligence for Assessment?,2020 Jan 29;2(1):e190082.,"Catheters are the second most common abnormal finding on radiographs. The position of catheters must be assessed on all radiographs because serious complications can arise if catheters are malpositioned. However, due to the large number of radiographs obtained each day, there can be substantial delays between the time a radiograph is obtained and when it is interpreted by a radiologist. Computer-aided approaches hold the potential to assist in prioritizing radiographs with potentially malpositioned catheters for interpretation and automatically insert text indicating the placement of catheters in radiology reports, thereby improving radiologists' efficiency. After 50 years of research in computer-aided diagnosis, there is still a paucity of study in this area. With the development of deep learning approaches, the problem of catheter assessment is far more solvable. This review provides an overview of current algorithms and identifies key challenges in building a reliable computer-aided diagnosis system for assessment of catheters on radiographs. This review may serve to further the development of machine learning approaches for this important use case. Supplemental material is available for this article. © RSNA, 2020.",
33785181,The prediction of preeclampsia: the way forward,2020 Nov 19;S0002-9378(20)31277-1.,"Despite intensive investigation, we still cannot adequately predict, treat, or prevent preeclampsia. We have gained awareness that preeclampsia is a syndrome not a disease and is heterogeneous in its presentation and pathophysiology, which may indicate differing underlying phenotypes, and that the impact extends beyond pregnancy per se. Effects on the fetus and mother extend many years after pregnancy, as evidenced by fetal programming of adult disease and increased risk of the development of maternal cardiovascular disease. The increased occurrence of preeclampsia in women with preexisting risk factors suggests that the stress of pregnancy may expose subclinical vascular disease as opposed to preeclampsia damaging the vasculature. The heterogeneity of preeclampsia has blighted efforts to predict preeclampsia early in gestation and has thwarted success in attempts at therapy with treatments, such as low-dose aspirin or global antioxidants. There is a critical need to identify the phenotypes to enable their specific prediction and treatment. Such studies require considerably larger collections of patients than employed in past and current studies. This does not necessarily imply much larger patient numbers in single studies but can be facilitated by the ability to easily combine many smaller studies. This can be accomplished by agreeing on a priori standardized and harmonized clinical data and biospecimen collection across new studies. Such standards are being established by international groups of investigators. Leadership by international organizations, perhaps adopting a carrot and stick approach, to overcome investigator, institutional and funder reticence toward data sharing is required to ensure adoption of such standards. Future studies should include women in both low- and high-resource settings and employ social media and novel methods for data collection and analysis, including machine learning and artificial intelligence. The goal is to identify the pathophysiology underlying differing preeclampsia phenotypes, their successful prediction with the design, and the implementation of phenotype-specific therapies.",
33778721,Precision Digital Oncology: Emerging Role of Radiomics-based Biomarkers and Artificial Intelligence for Advanced Imaging and Characterization of Brain Tumors,2020 Jul 31;2(4):e190047.,"Advances in computerized image analysis and the use of artificial intelligence-based approaches for image-based analysis and construction of prediction algorithms represent a new era for noninvasive biomarker discovery. In recent literature, it has become apparent that radiologic images can serve as mineable databases that contain large amounts of quantitative features with potential clinical significance. Extraction and analysis of these quantitative features is commonly referred to as texture or radiomic analysis. Numerous studies have demonstrated applications for texture and radiomic characterization methods for assessing brain tumors to improve noninvasive predictions of tumor histologic characteristics, molecular profile, distinction of treatment-related changes, and prediction of patient survival. In this review, the current use and future potential of texture or radiomic-based approaches with machine learning for brain tumor image analysis and prediction algorithm construction will be discussed. This technology has the potential to advance the value of diagnostic imaging by extracting currently unused information on medical scans that enables more precise, personalized therapy; however, significant barriers must be overcome if this technology is to be successfully implemented on a wide scale for routine use in the clinical setting. Keywords: Adults and Pediatrics, Brain/Brain Stem, CNS, Computer Aided Diagnosis (CAD), Computer Applications-General (Informatics), Image Postprocessing, Informatics, Neural Networks, Neuro-Oncology, Oncology, Treatment Effects, Tumor Response Supplemental material is available for this article. © RSNA, 2020.",
33735069,"A global review of publicly available datasets for ophthalmological imaging: barriers to access, usability, and generalisability",2021 Jan;3(1):e51-e66.,"Health data that are publicly available are valuable resources for digital health research. Several public datasets containing ophthalmological imaging have been frequently used in machine learning research; however, the total number of datasets containing ophthalmological health information and their respective content is unclear. This Review aimed to identify all publicly available ophthalmological imaging datasets, detail their accessibility, describe which diseases and populations are represented, and report on the completeness of the associated metadata. With the use of MEDLINE, Google's search engine, and Google Dataset Search, we identified 94 open access datasets containing 507 724 images and 125 videos from 122 364 patients. Most datasets originated from Asia, North America, and Europe. Disease populations were unevenly represented, with glaucoma, diabetic retinopathy, and age-related macular degeneration disproportionately overrepresented in comparison with other eye diseases. The reporting of basic demographic characteristics such as age, sex, and ethnicity was poor, even at the aggregate level. This Review provides greater visibility for ophthalmological datasets that are publicly available as powerful resources for research. Our paper also exposes an increasing divide in the representation of different population and disease groups in health data repositories. The improved reporting of metadata would enable researchers to access the most appropriate datasets for their needs and maximise the potential of such resources.",
33733218,Prognostics and Health Management of Industrial Assets: Current Progress and Road Ahead,2020 Nov 9;3:578613.,"Prognostic and Health Management (PHM) systems are some of the main protagonists of the Industry 4.0 revolution. Efficiently detecting whether an industrial component has deviated from its normal operating condition or predicting when a fault will occur are the main challenges these systems aim at addressing. Efficient PHM methods promise to decrease the probability of extreme failure events, thus improving the safety level of industrial machines. Furthermore, they could potentially drastically reduce the often conspicuous costs associated with scheduled maintenance operations. The increasing availability of data and the stunning progress of Machine Learning (ML) and Deep Learning (DL) techniques over the last decade represent two strong motivating factors for the development of data-driven PHM systems. On the other hand, the black-box nature of DL models significantly hinders their level of interpretability, de facto limiting their application to real-world scenarios. In this work, we explore the intersection of Artificial Intelligence (AI) methods and PHM applications. We present a thorough review of existing works both in the contexts of fault diagnosis and fault prognosis, highlighting the benefits and the drawbacks introduced by the adoption of AI techniques. Our goal is to highlight potentially fruitful research directions along with characterizing the main challenges that need to be addressed in order to realize the promises of AI-based PHM systems.",
33733216,Integration of AI and Machine Learning in Radiotherapy QA,2020 Sep 29;3:577620.,"The use of machine learning and other sophisticated models to aid in prediction and decision making has become widely popular across a breadth of disciplines. Within the greater diagnostic radiology, radiation oncology, and medical physics communities promising work is being performed in tissue classification and cancer staging, outcome prediction, automated segmentation, treatment planning, and quality assurance as well as other areas. In this article, machine learning approaches are explored, highlighting specific applications in machine and patient-specific quality assurance (QA). Machine learning can analyze multiple elements of a delivery system on its performance over time including the multileaf collimator (MLC), imaging system, mechanical and dosimetric parameters. Virtual Intensity-Modulated Radiation Therapy (IMRT) QA can predict passing rates using different measurement techniques, different treatment planning systems, and different treatment delivery machines across multiple institutions. Prediction of QA passing rates and other metrics can have profound implications on the current IMRT process. Here we cover general concepts of machine learning in dosimetry and various methods used in virtual IMRT QA, as well as their clinical applications.",
33733202,"Artificial Intelligence, Big Data, and mHealth: The Frontiers of the Prevention of Violence Against Children",2020 Oct 22;3:543305.,"Violence against children is a global public health threat of considerable concern. At least half of all children worldwide experience violence every year; globally, the total number of children between the ages of 2 and 17 years who have experienced violence in any given year is one billion. Based on a review of the literature, we argue that there is substantial potential for AI (and associated machine learning and big data), and mHealth approaches to be utilized to prevent and address violence at a large scale. This potential is particularly marked in low- and middle-income countries (LMIC), although whether it could translate into effective solutions at scale remains unclear. We discuss possible entry points for Artificial Intelligence (AI), big data, and mHealth approaches to violence prevention, linking these to the World Health Organization's seven INSPIRE strategies. However, such work should be approached with caution. We highlight clear directions for future work in technology-based and technology-enabled violence prevention. We argue that there is a need for good agent-based models at the level of entire cities where and when violence can occur, where local response systems are. Yet, there is a need to develop common, reliable, and valid population- and individual/family-level data on predictors of violence. These indicators could be integrated into routine health or other information systems and become the basis of Al algorithms for violence prevention and response systems. Further, data on individual help-seeking behavior, risk factors for child maltreatment, and other information which could help us to identify the parameters required to understand what happens to cause, and in response to violence, are needed. To respond to ethical issues engendered by these kinds of interventions, there must be concerted, meaningful efforts to develop participatory and user-led work in the AI space, to ensure that the privacy and profiling concerns outlined above are addressed explicitly going forward. Finally, we make the case that developing AI and other technological infrastructure will require substantial investment, particularly in LMIC.",
33733193,The Next Generation of Medical Decision Support: A Roadmap Toward Transparent Expert Companions,2020 Sep 24;3:507973.,"Increasing quality and performance of artificial intelligence (AI) in general and machine learning (ML) in particular is followed by a wider use of these approaches in everyday life. As part of this development, ML classifiers have also gained more importance for diagnosing diseases within biomedical engineering and medical sciences. However, many of those ubiquitous high-performing ML algorithms reveal a black-box-nature, leading to opaque and incomprehensible systems that complicate human interpretations of single predictions or the whole prediction process. This puts up a serious challenge on human decision makers to develop trust, which is much needed in life-changing decision tasks. This paper is designed to answer the question how expert companion systems for decision support can be designed to be interpretable and therefore transparent and comprehensible for humans. On the other hand, an approach for interactive ML as well as human-in-the-loop-learning is demonstrated in order to integrate human expert knowledge into ML models so that humans and machines act as companions within a critical decision task. We especially address the problem of Semantic Alignment between ML classifiers and its human users as a prerequisite for semantically relevant and useful explanations as well as interactions. Our roadmap paper presents and discusses an interdisciplinary yet integrated Comprehensible Artificial Intelligence (cAI)-transition-framework with regard to the task of medical diagnosis. We explain and integrate relevant concepts and research areas to provide the reader with a hands-on-cookbook for achieving the transition from opaque black-box models to interactive, transparent, comprehensible and trustworthy systems. To make our approach tangible, we present suitable state of the art methods with regard to the medical domain and include a realization concept of our framework. The emphasis is on the concept of Mutual Explanations (ME) that we introduce as a dialog-based, incremental process in order to provide human ML users with trust, but also with stronger participation within the learning process.",
33733182,Artificial Intelligence for COVID-19 Drug Discovery and Vaccine Development,2020 Aug 18;3:65.,"SARS-COV-2 has roused the scientific community with a call to action to combat the growing pandemic. At the time of this writing, there are as yet no novel antiviral agents or approved vaccines available for deployment as a frontline defense. Understanding the pathobiology of COVID-19 could aid scientists in their discovery of potent antivirals by elucidating unexplored viral pathways. One method for accomplishing this is the leveraging of computational methods to discover new candidate drugs and vaccines in silico. In the last decade, machine learning-based models, trained on specific biomolecules, have offered inexpensive and rapid implementation methods for the discovery of effective viral therapies. Given a target biomolecule, these models are capable of predicting inhibitor candidates in a structural-based manner. If enough data are presented to a model, it can aid the search for a drug or vaccine candidate by identifying patterns within the data. In this review, we focus on the recent advances of COVID-19 drug and vaccine development using artificial intelligence and the potential of intelligent training for the discovery of COVID-19 therapeutics. To facilitate applications of deep learning for SARS-COV-2, we highlight multiple molecular targets of COVID-19, inhibition of which may increase patient survival. Moreover, we present CoronaDB-AI, a dataset of compounds, peptides, and epitopes discovered either in silico or in vitro that can be potentially used for training models in order to extract COVID-19 treatment. The information and datasets provided in this review can be used to train deep learning-based models and accelerate the discovery of effective viral therapies.",3
33733152,On Consequentialism and Fairness,2020 May 8;3:34.,"Recent work on fairness in machine learning has primarily emphasized how to define, quantify, and encourage ""fair"" outcomes. Less attention has been paid, however, to the ethical foundations which underlie such efforts. Among the ethical perspectives that should be taken into consideration is consequentialism, the position that, roughly speaking, outcomes are all that matter. Although consequentialism is not free from difficulties, and although it does not necessarily provide a tractable way of choosing actions (because of the combined problems of uncertainty, subjectivity, and aggregation), it nevertheless provides a powerful foundation from which to critique the existing literature on machine learning fairness. Moreover, it brings to the fore some of the tradeoffs involved, including the problem of who counts, the pros and cons of using a policy, and the relative value of the distant future. In this paper we provide a consequentialist critique of common definitions of fairness within machine learning, as well as a machine learning perspective on consequentialism. We conclude with a broader discussion of the issues of learning and randomization, which have important implications for the ethics of automated decision making systems.",
33733124,An Introductory Review of Deep Learning for Prediction Models With Big Data,2020 Feb 28;3:4.,"Deep learning models stand for a new learning paradigm in artificial intelligence (AI) and machine learning. Recent breakthrough results in image analysis and speech recognition have generated a massive interest in this field because also applications in many other domains providing big data seem possible. On a downside, the mathematical and computational methodology underlying deep learning models is very challenging, especially for interdisciplinary scientists. For this reason, we present in this paper an introductory review of deep learning approaches including Deep Feedforward Neural Networks (D-FFNN), Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), Autoencoders (AEs), and Long Short-Term Memory (LSTM) networks. These models form the major core architectures of deep learning models currently used and should belong in any data scientist's toolbox. Importantly, those core architectural building blocks can be composed flexibly-in an almost Lego-like manner-to build new application-specific network architectures. Hence, a basic understanding of these network architectures is important to be prepared for future developments in AI.",2
33693420,Securing Machine Learning in the Cloud: A Systematic Review of Cloud Machine Learning Security,2020 Nov 12;3:587139.,"With the advances in machine learning (ML) and deep learning (DL) techniques, and the potency of cloud computing in offering services efficiently and cost-effectively, Machine Learning as a Service (MLaaS) cloud platforms have become popular. In addition, there is increasing adoption of third-party cloud services for outsourcing training of DL models, which requires substantial costly computational resources (e.g., high-performance graphics processing units (GPUs)). Such widespread usage of cloud-hosted ML/DL services opens a wide range of attack surfaces for adversaries to exploit the ML/DL system to achieve malicious goals. In this article, we conduct a systematic evaluation of literature of cloud-hosted ML/DL models along both the important dimensions-attacks and defenses-related to their security. Our systematic review identified a total of 31 related articles out of which 19 focused on attack, six focused on defense, and six focused on both attack and defense. Our evaluation reveals that there is an increasing interest from the research community on the perspective of attacking and defending different attacks on Machine Learning as a Service platforms. In addition, we identify the limitations and pitfalls of the analyzed articles and highlight open research issues that require further investigation.",
33693419,Machine Learning Methods to Predict Acute Respiratory Failure and Acute Respiratory Distress Syndrome,2020 Nov 23;3:579774.,"Acute respiratory failure (ARF) is a common problem in medicine that utilizes significant healthcare resources and is associated with high morbidity and mortality. Classification of acute respiratory failure is complicated, and it is often determined by the level of mechanical support that is required, or the discrepancy between oxygen supply and uptake. These phenotypes make acute respiratory failure a continuum of syndromes, rather than one homogenous disease process. Early recognition of the risk factors for new or worsening acute respiratory failure may prevent that process from occurring. Predictive analytical methods using machine learning leverage clinical data to provide an early warning for impending acute respiratory failure or its sequelae. The aims of this review are to summarize the current literature on ARF prediction, to describe accepted procedures and common machine learning tools for predictive tasks through the lens of ARF prediction, and to demonstrate the challenges and potential solutions for ARF prediction that can improve patient outcomes.",
33693398,Considerations for a More Ethical Approach to Data in AI: On Data Representation and Infrastructure,2020 Sep 2;3:25.,"Data shapes the development of Artificial Intelligence (AI) as we currently know it, and for many years centralized networking infrastructures have dominated both the sourcing and subsequent use of such data. Research suggests that centralized approaches result in poor representation, and as AI is now integrated more in daily life, there is a need for efforts to improve on this. The AI research community has begun to explore managing data infrastructures more democratically, finding that decentralized networking allows for more transparency which can alleviate core ethical concerns, such as selection-bias. With this in mind, herein, we present a mini-survey framed around data representation and data infrastructures in AI. We outline four key considerations (auditing, benchmarking, confidence and trust, explainability and interpretability) as they pertain to data-driven AI, and propose that reflection of them, along with improved interdisciplinary discussion may aid the mitigation of data-based AI ethical concerns, and ultimately improve individual wellbeing when interacting with AI.",
33679715,Immune Deregulation in Sepsis and Septic Shock: Reversing Immune Paralysis by Targeting PD-1/PD-L1 Pathway,2021 Feb 17;11:624279.,"Sepsis remains a major problem for human health worldwide, thereby manifesting high rates of morbidity and mortality. Sepsis, once understood as a monophasic sustained hyperinflammation, is currently recognized as a dysregulated host response to infection, with both hyperinflammation and immunoparalysis occurring simultaneously from the earliest stages of sepsis, involving multiple organ dysfunctions. Despite the recent progress in the understanding of the pathophysiology underlying sepsis, no specific treatment to restore immune dysregulation in sepsis has been validated in clinical trials. In recent years, treatment for immune checkpoints such as the programmed cell death protein 1/programmed death ligand (PD-1/PD-L) pathway in tumor-infiltrating T-lymphocytes has been successful in the field of cancer immune therapy. As immune-paralysis in sepsis involves exhausted T-lymphocytes, future clinical applications of checkpoint inhibitors for sepsis are expected. In addition, the functions of PD-1/PD-L on innate lymphoid cells and the role of exosomal forms of PD-L1 warrant further research. Looking back on the history of repeatedly failed clinical trials of immune modulatory therapies for sepsis, sepsis must be recognized as a difficult disease entity for performing clinical trials. A major obstacle that could prevent effective clinical trials of drug candidates is the disease complexity and heterogeneities; clinically diagnosed sepsis could contain multiple sepsis subgroups that suffer different levels of hyper-inflammation and immune-suppression in distinct organs. Thus, the selection of appropriate more homogenous sepsis subgroup is the key for testing the clinical efficacy of experimental therapies targeting specific pathways in either hyperinflammation and/or immunoparalysis. An emerging technology such as artificial intelligence (AI) may help to identify an immune paralysis subgroup who would best be treated by PD-1/PD-L1 pathway inhibitors.",
33659949,New techniques for studying neurodevelopment,2020 Nov 25;9:17.,"The extraordinary diversity, variability, and complexity of cell types in the vertebrate brain is overwhelming and far exceeds that of any other organ. This complexity is the result of multiple cell divisions and intricate gene regulation and cell movements that take place during embryonic development. Understanding the cellular and molecular mechanisms underlying these complicated developmental processes requires the ability to obtain a complete registry of interconnected events often taking place far apart from each other. To assist with this challenging task, developmental neuroscientists take advantage of a broad set of methods and technologies, often adopted from other fields of research. Here, we review some of the methods developed in recent years whose use has rapidly spread for application in the field of developmental neuroscience. We also provide several considerations regarding the promise that these techniques hold for the near future and share some ideas on how existing methods from other research fields could help with the analysis of how neural circuits emerge.",
33632415,Cardiac magnetic resonance fingerprinting: Trends in technical development and potential clinical applications,2021 Feb;122:11-22.,"Quantitative cardiac magnetic resonance has emerged in recent years as an approach for evaluating a range of cardiovascular conditions, with T1 and T2 mapping at the forefront of these developments. Cardiac Magnetic Resonance Fingerprinting (cMRF) provides a rapid and robust framework for simultaneous quantification of myocardial T1 and T2 in addition to other tissue properties. Since the advent of cMRF, a number of technical developments and clinical validation studies have been reported. This review provides an overview of cMRF, recent technical developments, healthy subject and patient studies, anticipated technical improvements, and potential clinical applications. Recent technical developments include slice profile and pulse efficiency corrections, improvements in image reconstruction, simultaneous multislice imaging, 3D whole-ventricle imaging, motion-resolved imaging, fat-water separation, and machine learning for rapid dictionary generation. Future technical developments in cMRF, such as B0 and B1 field mapping, acceleration of acquisition and reconstruction, imaging of patients with implanted devices, and quantification of additional tissue properties are also described. Potential clinical applications include characterization of infiltrative, inflammatory, and ischemic cardiomyopathies, tissue characterization in the left atrium and right ventricle, post-cardiac transplantation assessment, reduction of contrast material, pre-procedural planning for electrophysiology interventions, and imaging of patients with implanted devices.",
33627972,Future of Health Services: The Role of Physicians in the Disruptive Era,Oct-Dec 2020;13(4):250-256.,"This article aimed to address the role of physicians in future health in the disruptive era. Physicians in this disruptive era must increase their capability and knowledge to compensate for this development. Advances in technology increase the impact on health care and the significance of disruption. Disruptive innovation encompasses several fields, such as physics, digital, and biology. Big data as one of the most important parts in clinical aspects encompass high-throughput cellular and protein-binding assays toward chemoinformatic-driven databases. Health status can be modified by changing epigenetic factor, such as lifestyle and environment. As a result, they affect human genetics and provide the insight of pathophysiology of disease, clinical treatment, and early preventive action. Disruptive innovations in health-care align with the development of artificial intelligence, machine learning, robotics, Internet of things, digitalization, and genomics. New paradigm shifting in physician-patient relationships is relevant to consumer health informatics.",
33623737,Artificial Intelligence in COVID-19 Ultrastructure,2020 Dec 10;8(4):146-147.,"Artificial intelligence has found its way into numerous fields of medicine in the past decade, spurred by the availability of big data and powerful processors. For the COVID-19 pandemic, aside from predicting its onset, artificial intelligence has been used to track disease spread, detect pulmonary involvement in computed tomography scans, risk-stratify patients, and model virtual protein structure and potential therapeutic agents. This mini-review briefly discusses the potential applications of artificial intelligence in COVID-19 microscopy.",
33585563,Artificial Intelligence for the Future Radiology Diagnostic Service,2021 Jan 28;7:614258.,"Radiology historically has been a leader of digital transformation in healthcare. The introduction of digital imaging systems, picture archiving and communication systems (PACS), and teleradiology transformed radiology services over the past 30 years. Radiology is again at the crossroad for the next generation of transformation, possibly evolving as a one-stop integrated diagnostic service. Artificial intelligence and machine learning promise to offer radiology new powerful new digital tools to facilitate the next transformation. The radiology community has been developing computer-aided diagnosis (CAD) tools based on machine learning (ML) over the past 20 years. Among various AI techniques, deep-learning convolutional neural networks (CNN) and its variants have been widely used in medical image pattern recognition. Since the 1990s, many CAD tools and products have been developed. However, clinical adoption has been slow due to a lack of substantial clinical advantages, difficulties integrating into existing workflow, and uncertain business models. This paper proposes three pathways for AI's role in radiology beyond current CNN based capabilities 1) improve the performance of CAD, 2) improve the productivity of radiology service by AI-assisted workflow, and 3) develop radiomics that integrate the data from radiology, pathology, and genomics to facilitate the emergence of a new integrated diagnostic service.",
33584660,IgE-Mediated Peanut Allergy: Current and Novel Predictive Biomarkers for Clinical Phenotypes Using Multi-Omics Approaches,2021 Jan 28;11:594350.,"Food allergy is a collective term for several immune-mediated responses to food. IgE-mediated food allergy is the best-known subtype. The patients present with a marked diversity of clinical profiles including symptomatic manifestations, threshold reactivity and reaction kinetics. In-vitro predictors of these clinical phenotypes are evasive and considered as knowledge gaps in food allergy diagnosis and risk management. Peanut allergy is a relevant disease model where pioneer discoveries were made in diagnosis, immunotherapy and prevention. This review provides an overview on the immune basis for phenotype variations in peanut-allergic individuals, in the light of future patient stratification along emerging omic-areas. Beyond specific IgE-signatures and basophil reactivity profiles with established correlation to clinical outcome, allergenomics, mass spectrometric resolution of peripheral allergen tracing, might be a fundamental approach to understand disease pathophysiology underlying biomarker discovery. Deep immune phenotyping is thought to reveal differential cell responses but also, gene expression and gene methylation profiles (eg, peanut severity genes) are promising areas for biomarker research. Finally, the study of microbiome-host interactions with a focus on the immune system modulation might hold the key to understand tissue-specific responses and symptoms. The immune mechanism underlying acute food-allergic events remains elusive until today. Deciphering this immunological response shall enable to identify novel biomarker for stratification of patients into reaction endotypes. The availability of powerful multi-omics technologies, together with integrated data analysis, network-based approaches and unbiased machine learning holds out the prospect of providing clinically useful biomarkers or biomarker signatures being predictive for reaction phenotypes.",
33569373,Opportunities at the Interface of Network Science and Metabolic Modeling,2021 Jan 25;8:591049.,"Metabolism plays a central role in cell physiology because it provides the molecular machinery for growth. At the genome-scale, metabolism is made up of thousands of reactions interacting with one another. Untangling this complexity is key to understand how cells respond to genetic, environmental, or therapeutic perturbations. Here we discuss the roles of two complementary strategies for the analysis of genome-scale metabolic models: Flux Balance Analysis (FBA) and network science. While FBA estimates metabolic flux on the basis of an optimization principle, network approaches reveal emergent properties of the global metabolic connectivity. We highlight how the integration of both approaches promises to deliver insights on the structure and function of metabolic systems with wide-ranging implications in discovery science, precision medicine and industrial biotechnology.",
33568979,Analysis of Human Gait Using Hybrid EEG-fNIRS-Based BCI System: A Review,2021 Jan 25;14:613254.,"Human gait is a complex activity that requires high coordination between the central nervous system, the limb, and the musculoskeletal system. More research is needed to understand the latter coordination's complexity in designing better and more effective rehabilitation strategies for gait disorders. Electroencephalogram (EEG) and functional near-infrared spectroscopy (fNIRS) are among the most used technologies for monitoring brain activities due to portability, non-invasiveness, and relatively low cost compared to others. Fusing EEG and fNIRS is a well-known and established methodology proven to enhance brain-computer interface (BCI) performance in terms of classification accuracy, number of control commands, and response time. Although there has been significant research exploring hybrid BCI (hBCI) involving both EEG and fNIRS for different types of tasks and human activities, human gait remains still underinvestigated. In this article, we aim to shed light on the recent development in the analysis of human gait using a hybrid EEG-fNIRS-based BCI system. The current review has followed guidelines of preferred reporting items for systematic reviews and meta-Analyses (PRISMA) during the data collection and selection phase. In this review, we put a particular focus on the commonly used signal processing and machine learning algorithms, as well as survey the potential applications of gait analysis. We distill some of the critical findings of this survey as follows. First, hardware specifications and experimental paradigms should be carefully considered because of their direct impact on the quality of gait assessment. Second, since both modalities, EEG and fNIRS, are sensitive to motion artifacts, instrumental, and physiological noises, there is a quest for more robust and sophisticated signal processing algorithms. Third, hybrid temporal and spatial features, obtained by virtue of fusing EEG and fNIRS and associated with cortical activation, can help better identify the correlation between brain activation and gait. In conclusion, hBCI (EEG + fNIRS) system is not yet much explored for the lower limb due to its complexity compared to the higher limb. Existing BCI systems for gait monitoring tend to only focus on one modality. We foresee a vast potential in adopting hBCI in gait analysis. Imminent technical breakthroughs are expected using hybrid EEG-fNIRS-based BCI for gait to control assistive devices and Monitor neuro-plasticity in neuro-rehabilitation. However, although those hybrid systems perform well in a controlled experimental environment when it comes to adopting them as a certified medical device in real-life clinical applications, there is still a long way to go.",
33554111,Wearable Technology and Analytics as a Complementary Toolkit to Optimize Workload and to Reduce Injury Burden,2021 Jan 21;2:630576.,"Wearable sensors enable the real-time and non-invasive monitoring of biomechanical, physiological, or biochemical parameters pertinent to the performance of athletes. Sports medicine researchers compile datasets involving a multitude of parameters that can often be time consuming to analyze in order to create value in an expeditious and accurate manner. Machine learning and artificial intelligence models may aid in the clinical decision-making process for sports scientists, team physicians, and athletic trainers in translating the data acquired from wearable sensors to accurately and efficiently make decisions regarding the health, safety, and performance of athletes. This narrative review discusses the application of commercial sensors utilized by sports teams today and the emergence of descriptive analytics to monitor the internal and external workload, hydration status, sleep, cardiovascular health, and return-to-sport status of athletes. This review is written for those who are interested in the application of wearable sensor data and data science to enhance performance and reduce injury burden in athletes of all ages.",1
33552135,Predicting Genome Architecture: Challenges and Solutions,2021 Jan 22;11:617202.,"Genome architecture plays a pivotal role in gene regulation. The use of high-throughput methods for chromatin profiling and 3-D interaction mapping provide rich experimental data sets describing genome organization and dynamics. These data challenge development of new models and algorithms connecting genome architecture with epigenetic marks. In this review, we describe how chromatin architecture could be reconstructed from epigenetic data using biophysical or statistical approaches. We discuss the applicability and limitations of these methods for understanding the mechanisms of chromatin organization. We also highlight the emergence of new predictive approaches for scoring effects of structural variations in human cells.",
33551784,Machine Learning Methods for Diagnosing Autism Spectrum Disorder and Attention- Deficit/Hyperactivity Disorder Using Functional and Structural MRI: A Survey,2021 Jan 20;14:575999.,"Here we summarize recent progress in machine learning model for diagnosis of Autism Spectrum Disorder (ASD) and Attention-deficit/Hyperactivity Disorder (ADHD). We outline and describe the machine-learning, especially deep-learning, techniques that are suitable for addressing research questions in this domain, pitfalls of the available methods, as well as future directions for the field. We envision a future where the diagnosis of ASD, ADHD, and other mental disorders is accomplished, and quantified using imaging techniques, such as MRI, and machine-learning models.",
33521637,Feature-based PET/MRI radiomics in patients with brain tumors,2021 Jan 23;2(Suppl 4):iv15-iv21.,"Radiomics allows the extraction of quantitative features from medical images such as CT, MRI, or PET, thereby providing additional, potentially relevant diagnostic information for clinical decision-making. Because the computation of these features is performed highly automated on medical images acquired during routine follow-up, radiomics offers this information at low cost. Further, the radiomics features can be used alone or combined with other clinical or histomolecular parameters to generate predictive or prognostic mathematical models. These models can then be applied for various important diagnostic indications in neuro-oncology, for example, to noninvasively predict relevant biomarkers in glioma patients, to differentiate between treatment-related changes and local brain tumor relapse, or to predict treatment response. In recent years, amino acid PET has become an important diagnostic tool in patients with brain tumors. Therefore, the number of studies in patients with brain tumors investigating the potential of PET radiomics or combined PET/MRI radiomics is steadily increasing. This review summarizes current research regarding feature-based PET as well as combined PET/MRI radiomics in neuro-oncology.",
33519600,Detection of Genuine and Posed Facial Expressions of Emotion: Databases and Methods,2021 Jan 15;11:580287.,"Facial expressions of emotion play an important role in human social interactions. However, posed expressions of emotion are not always the same as genuine feelings. Recent research has found that facial expressions are increasingly used as a tool for understanding social interactions instead of personal emotions. Therefore, the credibility assessment of facial expressions, namely, the discrimination of genuine (spontaneous) expressions from posed (deliberate/volitional/deceptive) ones, is a crucial yet challenging task in facial expression understanding. With recent advances in computer vision and machine learning techniques, rapid progress has been made in recent years for automatic detection of genuine and posed facial expressions. This paper presents a general review of the relevant research, including several spontaneous vs. posed (SVP) facial expression databases and various computer vision based detection methods. In addition, a variety of factors that will influence the performance of SVP detection methods are discussed along with open issues and technical challenges in this nascent field.",
33511330,Biomarkers of COVID-19 and technologies to combat SARS-CoV-2,2020;2:1-23.,"Due to the unprecedented public health crisis caused by COVID-19, our first contribution to the newly launching journal, Advances in Biomarker Sciences and Technology, has abruptly diverted to focus on the current pandemic. As the number of new COVID-19 cases and deaths continue to rise steadily around the world, the common goal of healthcare providers, scientists, and government officials worldwide has been to identify the best way to detect the novel coronavirus, named SARS-CoV-2, and to treat the viral infection - COVID-19. Accurate detection, timely diagnosis, effective treatment, and future prevention are the vital keys to management of COVID-19, and can help curb the viral spread. Traditionally, biomarkers play a pivotal role in the early detection of disease etiology, diagnosis, treatment and prognosis. To assist myriad ongoing investigations and innovations, we developed this current article to overview known and emerging biomarkers for SARS-CoV-2 detection, COVID-19 diagnostics, treatment and prognosis, and ongoing work to identify and develop more biomarkers for new drugs and vaccines. Moreover, biomarkers of socio-psychological stress, the high-technology quest for new virtual drug screening, and digital applications are described.",3
33510640,Selective Serotonin Reuptake Inhibitor Pharmaco-Omics: Mechanisms and Prediction,2021 Jan 11;11:614048.,"Selective serotonin reuptake inhibitors (SSRIs) are a standard of care for the pharmacotherapy of patients suffering from Major Depressive Disorder (MDD). However, only one-half to two-thirds of MDD patients respond to SSRI therapy. Recently, a ""multiple omics"" research strategy was applied to identify genetic differences between patients who did and did not respond to SSRI therapy. As a first step, plasma metabolites were assayed using samples from the 803 patients in the PGRN-AMPS SSRI MDD trial. The metabolomics data were then used to ""inform"" genomics by performing a genome-wide association study (GWAS) for plasma concentrations of the metabolite most highly associated with clinical response, serotonin (5-HT). Two genome-wide or near genome-wide significant single nucleotide polymorphism (SNP) signals were identified, one that mapped near the TSPAN5 gene and another across the ERICH3 gene, both genes that are highly expressed in the brain. Knocking down TSPAN5 and ERICH3 resulted in decreased 5-HT concentrations in neuroblastoma cell culture media and decreased expression of enzymes involved in 5-HT biosynthesis and metabolism. Functional genomic studies demonstrated that ERICH3 was involved in clathrin-mediated vesicle formation and TSPAN5 was an ethanol-responsive gene that may be a marker for response to acamprosate pharmacotherapy of alcohol use disorder (AUD), a neuropsychiatric disorder highly co-morbid with MDD. In parallel studies, kynurenine was the plasma metabolite most highly associated with MDD symptom severity and application of a metabolomics-informed pharmacogenomics approach identified DEFB1 and AHR as genes associated with variation in plasma kynurenine levels. Both genes also contributed to kynurenine-related inflammatory pathways. Finally, a multiply replicated predictive algorithm for SSRI clinical response with a balanced predictive accuracy of 76% (compared with 56% for clinical data alone) was developed by including the SNPs in TSPAN5, ERICH3, DEFB1 and AHR. In summary, application of a multiple omics research strategy that used metabolomics to inform genomics, followed by functional genomic studies, identified novel genes that influenced monoamine biology and made it possible to develop a predictive algorithm for SSRI clinical outcomes in MDD. A similar pharmaco-omic research strategy might be broadly applicable for the study of other neuropsychiatric diseases and their drug therapy.",
33509373,Artificial Intelligence and Machine Learning in Nuclear Medicine: Future Perspectives,2021 Mar;51(2):170-177.,"Artificial intelligence and machine learning based approaches are increasingly finding their way into various areas of nuclear medicine imaging. With the technical development of new methods and the expansion to new fields of application, this trend is likely to become even more pronounced in future. Possible means of application range from automated image reading and classification to correlation with clinical outcomes and to technological applications in image processing and reconstruction. In the context of tumor imaging, that is, predominantly FDG or PSMA PET imaging but also bone scintigraphy, artificial intelligence approaches can be used to quantify the whole-body tumor volume, for the segmentation and classification of pathological foci or to facilitate the diagnosis of micro-metastases. More advanced applications aim at the correlation of image features that are derived by artificial intelligence with clinical endpoints, for example, whole-body tumor volume with overall survival. In nuclear medicine imaging of benign diseases, artificial intelligence methods are predominantly used for automated and/or facilitated image classification and clinical decision making. Automated feature selection, segmentation and classification of myocardial perfusion scintigraphy can help in identifying patients that would benefit from intervention and to forecast clinical prognosis. Automated reporting of neurodegenerative diseases such as Alzheimer's disease might be extended to early diagnosis-being of special interest, if targeted treatment options might become available. Technological approaches include artificial intelligence-based attenuation correction of PET images, image reconstruction or anatomical landmarking. Attenuation correction is of special interest for avoiding the need of a coregistered CT scan, in the process of image reconstruction artefacts might be reduced, or ultra low-dose PET images might be denoised. The development of accurate ultra low-dose PET imaging might broaden the method's applicability, for example, toward oncologic PET screening. Most artificial intelligence approaches in nuclear medicine imaging are still in early stages of development, further improvements are necessary for broad clinical applications. In this review, we describe the current trends in the context fields of body oncology, cardiac imaging, and neuroimaging while an additional section puts emphasis on technological trends. Our aim is not only to describe currently available methods, but also to place a special focus on the description of possible future developments.",
33509372,Artificial Intelligence for Response Evaluation With PET/CT,2021 Mar;51(2):157-169.,"Positron emission tomography (PET)/computed tomography (CT) are nuclear diagnostic imaging modalities that are routinely deployed for cancer staging and monitoring. They hold the advantage of detecting disease related biochemical and physiologic abnormalities in advance of anatomical changes, thus widely used for staging of disease progression, identification of the treatment gross tumor volume, monitoring of disease, as well as prediction of outcomes and personalization of treatment regimens. Among the arsenal of different functional imaging modalities, nuclear imaging has benefited from early adoption of quantitative image analysis starting from simple standard uptake value normalization to more advanced extraction of complex imaging uptake patterns; thanks to application of sophisticated image processing and machine learning algorithms. In this review, we discuss the application of image processing and machine/deep learning techniques to PET/CT imaging with special focus on the oncological radiotherapy domain as a case study and draw examples from our work and others to highlight current status and future potentials.",
33509371,"Artificial Intelligence for the Characterization of Pulmonary Nodules, Lung Tumors and Mediastinal Nodes on PET/CT",2021 Mar;51(2):143-156.,"Lung cancer is the leading cause of cancer related death around the world although early diagnosis remains vital to enabling access to curative treatment options. This article briefly describes the current role of imaging, in particular 2-deoxy-2-[18F]fluoro-D-glucose (FDG) PET/CT, in lung cancer and specifically the role of artificial intelligence with CT followed by a detailed review of the published studies applying artificial intelligence (ie, machine learning and deep learning), on FDG PET or combined PET/CT images with the purpose of early detection and diagnosis of pulmonary nodules, and characterization of lung tumors and mediastinal lymph nodes. A comprehensive search was performed on Pubmed, Embase, and clinical trial databases. The studies were analyzed with a modified version of the Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD) and Prediction model Risk Of Bias Assessment Tool (PROBAST) statement. The search resulted in 361 studies; of these 29 were included; all retrospective; none were clinical trials. Twenty-two records evaluated standard machine learning (ML) methods on imaging features (ie, support vector machine), and 7 studies evaluated new ML methods (ie, deep learning) applied directly on PET or PET/CT images. The studies mainly reported positive results regarding the use of ML methods for diagnosing pulmonary nodules, characterizing lung tumors and mediastinal lymph nodes. However, 22 of the 29 studies were lacking a relevant comparator and/or lacking independent testing of the model. Application of ML methods with feature and image input from PET/CT for diagnosing and characterizing lung cancer is a relatively young area of research with great promise. Nevertheless, current published studies are often under-powered and lacking a clinically relevant comparator and/or independent testing.",
33509368,Ethical and Legal Challenges of Artificial Intelligence in Nuclear Medicine,2021 Mar;51(2):120-125.,"Artificial intelligence (AI) in nuclear medicine has gained significant traction and promises to be a disruptive, but innovative, technology. Recent developments in artificial neural networks, machine learning, and deep learning have ignited debate with respect to ethical and legal challenges associated with the use of AI in healthcare and medicine. While AI in nuclear medicine has the potential to improve workflow and productivity, and enhance clinical and research capabilities, there remains a professional responsibility to the profession and to patients: ethical, social, and legal. Enthusiasm to embrace new technology should not displace responsibilities for the ethical, social, and legal application of technology. This is especially true in relation to data usage, the algorithms applied, and how algorithms are used in practice. Governance of software and algorithms used for detection (segmentation) and/or diagnosis (classification) of disease using medical images requires rigorous evidence-based regulation. A number of frameworks have been developed for ethical application of AI generally in society and in radiology. For nuclear medicine, consideration needs to be given to beneficence, nonmaleficence, fairness and justice, safety, reliability, data security, privacy and confidentiality, mitigation of bias, transparency, explainability, and autonomy. AI is merely a tool, how it is utilised is a human choice. There is potential for AI applications to enhance clinical and research practice in nuclear medicine and concurrently produce deeper, more meaningful interactions between the physicians and the patient. Nonetheless ethical, legal, and social challenges demand careful attention and formulation of standards/guidelines for nuclear medicine.",
33509366,"Intelligent Imaging in Nuclear Medicine: the Principles of Artificial Intelligence, Machine Learning and Deep Learning",2021 Mar;51(2):102-111.,"The emergence of artificial intelligence (AI) in nuclear medicine has occurred over the last 50 years but more recent developments in machine learning (ML) and deep learning (DL) have driven new capabilities of AI in nuclear medicine. In nuclear medicine, the artificial neural network (ANN) is the backbone of ML and DL. The inputs may be radiomic features that have been extracted from the image files or, if using a convolutional neural network (CNN), may be the images themselves. AI in nuclear medicine re-engineers and re-imagines clinical and research capabilities. An understanding of the principles of AI, ML and DL contextualised to nuclear medicine allows richer engagement in clinical and research applications, and capacity for problem solving where required. Simple applications of ML include quality assurance, risk assessment, business analytics and rudimentary classifications. More complex applications of DL for detection, localisation, classification, segmentation, quantitation and radiomic feature extraction using CNNs can be applied to general nuclear medicine, SPECT, PET, CT and MRI. There are also applications of ANNs and ML that allow small datasets (and larger ones) to be analysed in parallel to conventional statistical analysis. AI has assimilated into the clinical and research practice of nuclear medicine with little disruption. The emergence of ML and DL applications, however, has produced a seismic significant shift in the clinical and research landscape that demands at least rudimentary understanding of the principles of AI, ANNs and CNNs among nuclear medicine professionals.",
33501338,A Brief Survey of Telerobotic Time Delay Mitigation,2020 Dec 15;7:578805.,"There is a substantial number of telerobotics and teleoperation applications ranging from space operations, ground/aerial robotics, drive-by-wire systems to medical interventions. Major obstacles for such applications include latency, channel corruptions, and bandwidth which limit teleoperation efficacy. This survey reviews the time delay problem in teleoperation systems. We briefly review different solutions from early approaches which consist of control-theory-based models and user interface designs and focus on newer approaches developed since 2014. Future solutions to the time delay problem will likely be hybrid solutions which include modeling of user intent, prediction of robot movements, and time delay prediction all potentially using time series prediction methods. Hence, we examine methods that are primarily based on time series prediction. Recent prediction approaches take advantage of advances in nonlinear statistical models as well as machine learning and neural network techniques. We review Recurrent Neural Networks, Long Short-Term Memory, Sequence to Sequence, and Generative Adversarial Network models and examine each of these approaches for addressing time delay. As time delay is still an unsolved problem, we suggest some possible future research directions from information-theory-based modeling, which may lead to promising new approaches to advancing the field.",
33501307,Emotion Recognition for Human-Robot Interaction: Recent Advances and Future Perspectives,2020 Dec 21;7:532279.,"A fascinating challenge in the field of human-robot interaction is the possibility to endow robots with emotional intelligence in order to make the interaction more intuitive, genuine, and natural. To achieve this, a critical point is the capability of the robot to infer and interpret human emotions. Emotion recognition has been widely explored in the broader fields of human-machine interaction and affective computing. Here, we report recent advances in emotion recognition, with particular regard to the human-robot interaction context. Our aim is to review the state of the art of currently adopted emotional models, interaction modalities, and classification strategies and offer our point of view on future developments and critical issues. We focus on facial expressions, body poses and kinematics, voice, brain activity, and peripheral physiological responses, also providing a list of available datasets containing data from these modalities.",
33501168,"Symbolic, Distributed, and Distributional Representations for Natural Language Processing in the Era of Deep Learning: A Survey",2020 Jan 21;6:153.,"Natural language is inherently a discrete symbolic representation of human knowledge. Recent advances in machine learning (ML) and in natural language processing (NLP) seem to contradict the above intuition: discrete symbols are fading away, erased by vectors or tensors called distributed and distributional representations. However, there is a strict link between distributed/distributional representations and discrete symbols, being the first an approximation of the second. A clearer understanding of the strict link between distributed/distributional representations and symbols may certainly lead to radically new deep learning networks. In this paper we make a survey that aims to renew the link between symbolic representations and distributed/distributional representations. This is the right time to revitalize the area of interpreting how discrete symbols are represented inside neural networks.",
33500754,Artificial Intelligence and Machine Learning in Cardiovascular Imaging,Oct-Dec 2020;16(4):263-271.,"Cardiovascular disease is the leading cause of mortality in Western countries and leads to a spectrum of complications that can complicate patient management. The emergence of artificial intelligence (AI) has garnered significant interest in many industries, and the field of cardiovascular imaging is no exception. Machine learning (ML) especially is showing significant promise in various diagnostic imaging modalities. As conventional statistics are reaching their apex in computational capabilities, ML can explore new possibilities and unravel hidden relationships. This will have a positive impact on diagnosis and prognosis for cardiovascular imaging. In this in-depth review, we highlight the role of AI and ML for various cardiovascular imaging modalities.",
33490920,Reaction prediction via atomistic simulation: from quantum mechanics to machine learning,2020 Dec 30;24(1):102013.,"It is an ultimate goal in chemistry to predict reaction without recourse to experiment. Reaction prediction is not just the reaction rate determination of known reactions but, more broadly, the reaction exploration to identify new reaction routes. This review briefly overviews the theory on chemical reaction and the current methods for computing/estimating reaction rate and exploring reaction space. We particularly focus on the atomistic simulation methods for reaction exploration, which are benefited significantly by recently emerged machine learning potentials. We elaborate the stochastic surface walking global pathway sampling based on the global neural network (SSW-NN) potential, developed in our group since 2013, which can explore complex reactions systems unbiasedly and automatedly. Two examples, molecular reaction and heterogeneous catalytic reactions, are presented to illustrate the current status for reaction prediction using SSW-NN.",
33485296,Machine learning as the new approach in understanding biomarkers of suicidal behavior,2020 Dec 31.,"In psychiatry, compared to other medical fields, the identification of biological markers that would complement current clinical interview, and enable more objective and faster clinical diagnosis, implement accurate monitoring of treatment response and remission, is grave. Current technological development enables analyses of various biological marks in high throughput scale at reasonable costs, and therefore 'omic' studies are entering the psychiatry research. However, big data demands a whole new plethora of skills in data processing, before clinically useful information can be extracted. So far the classical approach to data analysis did not really contribute to identification of biomarkers in psychiatry, but the extensive amounts of data might get to a higher level, if artificial intelligence in the shape of machine learning algorithms would be applied. Not many studies on machine learning in psychiatry have been published, but we can already see from that handful of studies that the potential to build a screening portfolio of biomarkers for different psychopathologies, including suicide, exists.",
33476063,How artificial intelligence may help the Covid-19 pandemic: Pitfalls and lessons for the future,2020 Dec 19;e2205.,"The clinical severity, rapid transmission and human losses due to coronavirus disease 2019 (Covid-19) have led the World Health Organization to declare it a pandemic. Traditional epidemiological tools are being significantly complemented by recent innovations especially using artificial intelligence (AI) and machine learning. AI-based model systems could improve pattern recognition of disease spread in populations and predictions of outbreaks in different geographical locations. A variable and a minimal amount of data are available for the signs and symptoms of Covid-19, allowing a composite of maximum likelihood algorithms to be employed to enhance the accuracy of disease diagnosis and to identify potential drugs. AI-based forecasting and predictions are expected to complement traditional approaches by helping public health officials to select better response and preparedness measures against Covid-19 cases. AI-based approaches have helped address the key issues but a significant impact on the global healthcare industry is yet to be achieved. The capability of AI to address the challenges may make it a key player in the operation of healthcare systems in future. Here, we present an overview of the prospective applications of the AI model systems in healthcare settings during the ongoing Covid-19 pandemic.",
33468305,Heart rate variability analysis in horses for the diagnosis of arrhythmias,2021 Feb;268:105590.,"Heart rate variability (HRV) analysis has been performed on ECG-derived data sets for more than 170 years but is currently undergoing a rapid evolution, thanks to the expansion of the human and veterinary medical technology sector. Traditional HRV analysis was initially performed to identify changes in vago-sympathetic balance, while the most recent focus has expanded to include the use of complex computer algorithms, neural networks and machine learning technology to identify cardiac arrhythmias, particularly atrial fibrillation (AF). Some of these techniques have recently been translated for use in the field of equine cardiology, with particular focus on improving the diagnosis of arrhythmias both at rest and during exercise. This review focuses on understanding the basic HRV variables and important factors to consider when collecting data for use in HRV analysis. In addition, the use of HRV analysis for the diagnosis of arrhythmias is discussed from human, small animal and equine perspectives. Finally, the future of HRV analysis is briefly introduced, including an overview of future developments in this rapidly expanding and exciting field.",
33458608,Machine learning toward advanced energy storage devices and systems,2020 Dec 13;24(1):101936.,"Technology advancement demands energy storage devices (ESD) and systems (ESS) with better performance, longer life, higher reliability, and smarter management strategy. Designing such systems involve a trade-off among a large set of parameters, whereas advanced control strategies need to rely on the instantaneous status of many indicators. Machine learning can dramatically accelerate calculations, capture complex mechanisms to improve the prediction accuracy, and make optimized decisions based on comprehensive status information. The computational efficiency makes it applicable for real-time management. This paper reviews recent progresses in this emerging area, especially new concepts, approaches, and applications of machine learning technologies for commonly used energy storage devices (including batteries, capacitors/supercapacitors, fuel cells, other ESDs) and systems (including battery ESS, hybrid ESS, grid and microgrid-containing energy storage units, pumped-storage system, thermal ESS). The perspective on future directions is also discussed.",
33447598,"Artificial Intelligence-Based Polyp Detection in Colonoscopy: Where Have We Been, Where Do We Stand, and Where Are We Headed?",2020 Dec;36(6):428-438.,"Background:                    In the past, image-based computer-assisted diagnosis and detection systems have been driven mainly from the field of radiology, and more specifically mammography. Nevertheless, with the availability of large image data collections (known as the ""Big Data"" phenomenon) in correlation with developments from the domain of artificial intelligence (AI) and particularly so-called deep convolutional neural networks, computer-assisted detection of adenomas and polyps in real-time during screening colonoscopy has become feasible.              Summary:                    With respect to these developments, the scope of this contribution is to provide a brief overview about the evolution of AI-based detection of adenomas and polyps during colonoscopy of the past 35 years, starting with the age of ""handcrafted geometrical features"" together with simple classification schemes, over the development and use of ""texture-based features"" and machine learning approaches, and ending with current developments in the field of deep learning using convolutional neural networks. In parallel, the need and necessity of large-scale clinical data will be discussed in order to develop such methods, up to commercially available AI products for automated detection of polyps (adenoma and benign neoplastic lesions). Finally, a short view into the future is made regarding further possibilities of AI methods within colonoscopy.              Key messages:                    Research of image-based lesion detection in colonoscopy data has a 35-year-old history. Milestones such as the Paris nomenclature, texture features, big data, and deep learning were essential for the development and availability of commercial AI-based systems for polyp detection.",
33443081,Systems Neuroscience of Natural Behaviors in Rodents,2021 Feb 3;41(5):911-919.,"Animals evolved in complex environments, producing a wide range of behaviors, including navigation, foraging, prey capture, and conspecific interactions, which vary over timescales ranging from milliseconds to days. Historically, these behaviors have been the focus of study for ecology and ethology, while systems neuroscience has largely focused on short timescale behaviors that can be repeated thousands of times and occur in highly artificial environments. Thanks to recent advances in machine learning, miniaturization, and computation, it is newly possible to study freely moving animals in more natural conditions while applying systems techniques: performing temporally specific perturbations, modeling behavioral strategies, and recording from large numbers of neurons while animals are freely moving. The authors of this review are a group of scientists with deep appreciation for the common aims of systems neuroscience, ecology, and ethology. We believe it is an extremely exciting time to be a neuroscientist, as we have an opportunity to grow as a field, to embrace interdisciplinary, open, collaborative research to provide new insights and allow researchers to link knowledge across disciplines, species, and scales. Here we discuss the origins of ethology, ecology, and systems neuroscience in the context of our own work and highlight how combining approaches across these fields has provided fresh insights into our research. We hope this review facilitates some of these interactions and alliances and helps us all do even better science, together.",
33442551,Artificial Intelligence in Medicine: Chances and Challenges for Wide Clinical Adoption,2020 Dec;36(6):443-449.,"Background:                    Artificial intelligence (AI) applications that utilize machine learning are on the rise in clinical research and provide highly promising applications in specific use cases. However, wide clinical adoption remains far off. This review reflects on common barriers and current solution approaches.              Summary:                    Key challenges are abbreviated as the RISE criteria: Regulatory aspects, Interpretability, interoperability, and the need for Structured data and Evidence. As reoccurring barriers of AI adoption, these concepts are delineated and complemented by points to consider and possible solutions for effective and safe use of AI applications.              Key messages:                    There is a fraction of AI applications with proven clinical benefits and regulatory approval. Many new promising systems are the subject of current research but share common issues for wide clinical adoption. The RISE criteria can support preparation for challenges and pitfalls when designing or introducing AI applications into clinical practice.",
33437151,Artificial Intelligence in Drug Discovery: A Comprehensive Review of Data-driven and Machine Learning Approaches,2020;25(6):895-930.,"As expenditure on drug development increases exponentially, the overall drug discovery process requires a sustainable revolution. Since artificial intelligence (AI) is leading the fourth industrial revolution, AI can be considered as a viable solution for unstable drug research and development. Generally, AI is applied to fields with sufficient data such as computer vision and natural language processing, but there are many efforts to revolutionize the existing drug discovery process by applying AI. This review provides a comprehensive, organized summary of the recent research trends in AI-guided drug discovery process including target identification, hit identification, ADMET prediction, lead optimization, and drug repositioning. The main data sources in each field are also summarized in this review. In addition, an in-depth analysis of the remaining challenges and limitations will be provided, and proposals for promising future directions in each of the aforementioned areas.",
33431041,The C++ programming language in cheminformatics and computational chemistry,2020 Feb 7;12(1):10.,"This paper describes salient features of the C++ programming language and its programming ecosystem, with emphasis on how the language affects scientific software development. Brief history of C++ and its predecessor the C language is provided. Most important aspects of the language that define models of programming are described in greater detail and illustrated with code examples. Special attention is paid to the interoperability between C++ and other high-level languages commonly used in cheminformatics, machine learning, data processing and statistical computing.",
33431024,"A review of computational drug repositioning: strategies, approaches, opportunities, challenges, and directions",2020 Jul 22;12(1):46.,"Drug repositioning is the process of identifying novel therapeutic potentials for existing drugs and discovering therapies for untreated diseases. Drug repositioning, therefore, plays an important role in optimizing the pre-clinical process of developing novel drugs by saving time and cost compared to the traditional de novo drug discovery processes. Since drug repositioning relies on data for existing drugs and diseases the enormous growth of publicly available large-scale biological, biomedical, and electronic health-related data along with the high-performance computing capabilities have accelerated the development of computational drug repositioning approaches. Multidisciplinary researchers and scientists have carried out numerous attempts, with different degrees of efficiency and success, to computationally study the potential of repositioning drugs to identify alternative drug indications. This study reviews recent advancements in the field of computational drug repositioning. First, we highlight different drug repositioning strategies and provide an overview of frequently used resources. Second, we summarize computational approaches that are extensively used in drug repositioning studies. Third, we present different computing and experimental models to validate computational methods. Fourth, we address prospective opportunities, including a few target areas. Finally, we discuss challenges and limitations encountered in computational drug repositioning and conclude with an outline of further research directions.",4
33426010,The Role of Artificial Intelligence in Cardiovascular Imaging: State of the Art Review,2020 Dec 23;7:618849.,"In this current digital landscape, artificial intelligence (AI) has established itself as a powerful tool in the commercial industry and is an evolving technology in healthcare. Cutting-edge imaging modalities outputting multi-dimensional data are becoming increasingly complex. In this era of data explosion, the field of cardiovascular imaging is undergoing a paradigm shift toward machine learning (ML) driven platforms. These diverse algorithms can seamlessly analyze information and automate a range of tasks. In this review article, we explore the role of ML in the field of cardiovascular imaging.",2
33425679,Review of deep learning for photoacoustic imaging,2020 Dec 29;21:100215.,"Machine learning has been developed dramatically and witnessed a lot of applications in various fields over the past few years. This boom originated in 2009, when a new model emerged, that is, the deep artificial neural network, which began to surpass other established mature models on some important benchmarks. Later, it was widely used in academia and industry. Ranging from image analysis to natural language processing, it fully exerted its magic and now become the state-of-the-art machine learning models. Deep neural networks have great potential in medical imaging technology, medical data analysis, medical diagnosis and other healthcare issues, and is promoted in both pre-clinical and even clinical stages. In this review, we performed an overview of some new developments and challenges in the application of machine learning to medical image analysis, with a special focus on deep learning in photoacoustic imaging. The aim of this review is threefold: (i) introducing deep learning with some important basics, (ii) reviewing recent works that apply deep learning in the entire ecological chain of photoacoustic imaging, from image reconstruction to disease diagnosis, (iii) providing some open source materials and other resources for researchers interested in applying deep learning to photoacoustic imaging.",1
33425253,Advances in integrative structural biology: Towards understanding protein complexes in their cellular context,2020 Dec 3;19:214-225.,"Microorganisms rely on protein interactions to transmit signals, react to stimuli, and grow. One of the best ways to understand these protein interactions is through structural characterization. However, in the past, structural knowledge was limited to stable, high-affinity complexes that could be crystallized. Recent developments in structural biology have revolutionized how protein interactions are characterized. The combination of multiple techniques, known as integrative structural biology, has provided insight into how large protein complexes interact in their native environment. In this mini-review, we describe the past, present, and potential future of integrative structural biology as a tool for characterizing protein interactions in their cellular context.",
33418514,Application of machine learning to improve dairy farm management: A systematic literature review,2021 Feb;187:105237.,"In recent years, several researchers and practitioners applied machine learning algorithms in the dairy farm context and discussed several solutions to predict various variables of interest, most of which were related to incipient diseases. The objective of this article is to identify, assess, and synthesize the papers that discuss the application of machine learning in the dairy farm management context. Using a systematic literature review (SLR) protocol, we retrieved 427 papers, of which 38 papers were determined as primary studies and thus were analysed in detail. More than half of the papers (55 %) addressed disease detection. The other two categories of problems addressed were milk production and milk quality. Seventy-one independent variables were identified and grouped into seven categories. The two prominent categories that were used in more than half of the papers were milking parameters and milk properties. The other categories of independent variables were milk content, pregnancy/calving information, cow characteristics, lactation, and farm characteristics. Twenty-three algorithms were identified, which we grouped into four categories. Decision tree-based algorithms are by far the most used followed by artificial neural network-based algorithms. Regression-based algorithms and other algorithms that do not belong to the previous categories were used in 13 papers. Twenty-three evaluation parameters were identified of which 7 were used 3 or more times. The three evaluation parameters that were used by more than half of the papers are sensitivity, specificity, RMSE. The challenges most encountered were feature selection and unbalanced data and together with problem size, overfitting/estimating, and parameter tuning account for three-quarters of the challenges identified. To the best of our knowledge, this is the first SLR study on the use of machine learning to improve dairy farm management, and to this end, this study will be valuable not only for researchers but also practitioners in dairy farms.",
33412425,Genomic resources in plant breeding for sustainable agriculture,2021 Feb;257:153351.,"Climate change during the last 40 years has had a serious impact on agriculture and threatens global food and nutritional security. From over half a million plant species, cereals and legumes are the most important for food and nutritional security. Although systematic plant breeding has a relatively short history, conventional breeding coupled with advances in technology and crop management strategies has increased crop yields by 56 % globally between 1965-85, referred to as the Green Revolution. Nevertheless, increased demand for food, feed, fiber, and fuel necessitates the need to break existing yield barriers in many crop plants. In the first decade of the 21st century we witnessed rapid discovery, transformative technological development and declining costs of genomics technologies. In the second decade, the field turned towards making sense of the vast amount of genomic information and subsequently moved towards accurately predicting gene-to-phenotype associations and tailoring plants for climate resilience and global food security. In this review we focus on genomic resources, genome and germplasm sequencing, sequencing-based trait mapping, and genomics-assisted breeding approaches aimed at developing biotic stress resistant, abiotic stress tolerant and high nutrition varieties in six major cereals (rice, maize, wheat, barley, sorghum and pearl millet), and six major legumes (soybean, groundnut, cowpea, common bean, chickpea and pigeonpea). We further provide a perspective and way forward to use genomic breeding approaches including marker-assisted selection, marker-assisted backcrossing, haplotype based breeding and genomic prediction approaches coupled with machine learning and artificial intelligence, to speed breeding approaches. The overall goal is to accelerate genetic gains and deliver climate resilient and high nutrition crop varieties for sustainable agriculture.",
33410425,"COVID-19: Advances in diagnostic tools, treatment strategies, and vaccine development",2020;45(1):148.,"An unprecedented worldwide spread of the SARS-CoV-2 has imposed severe challenges on healthcare facilities and medical infrastructure. The global research community faces urgent calls for the development of rapid diagnostic tools, effective treatment protocols, and most importantly, vaccines against the pathogen. Pooling together expertise across broad domains to innovate effective solutions is the need of the hour. With these requirements in mind, in this review, we provide detailed critical accounts on the leading efforts at developing diagnostics tools, therapeutic agents, and vaccine candidates. Importantly, we furnish the reader with a multidisciplinary perspective on how conventional methods like serology and RT-PCR, as well as cutting-edge technologies like CRISPR/Cas and artificial intelligence/machine learning, are being employed to inform and guide such investigations. We expect this narrative to serve a broad audience of both active and aspiring researchers in the field of biomedical sciences and engineering and help inspire radical new approaches towards effective detection, treatment, and prevention of this global pandemic.",2
33409270,Streamlining Natural Products Biomanufacturing With Omics and Machine Learning Driven Microbial Engineering,2020 Dec 21;8:608918.,"Increasing demands for the supply of biopharmaceuticals have propelled the advancement of metabolic engineering and synthetic biology strategies for biomanufacturing of bioactive natural products. Using metabolically engineered microbes as the bioproduction hosts, a variety of natural products including terpenes, flavonoids, alkaloids, and cannabinoids have been synthesized through the construction and expression of known and newly found biosynthetic genes primarily from model and non-model plants. The employment of omics technology and machine learning (ML) platforms as high throughput analytical tools has been increasingly leveraged in promoting data-guided optimization of targeted biosynthetic pathways and enhancement of the microbial production capacity, thereby representing a critical debottlenecking approach in improving and streamlining natural products biomanufacturing. To this end, this mini review summarizes recent efforts that utilize omics platforms and ML tools in strain optimization and prototyping and discusses the beneficial uses of omics-enabled discovery of plant biosynthetic genes in the production of complex plant-based natural products by bioengineered microbes.",
33408594,Artificial Intelligence and its future potential in lung cancer screening,2020 Dec 11;19:1552-1562.,"Artificial intelligence (AI) simulates intelligent behavior as well as critical thinking comparable to a human being and can be used to analyze and interpret complex medical data. The application of AI in imaging diagnostics reduces the burden of radiologists and increases the sensitivity of lung cancer screening so that the morbidity and mortality associated with lung cancer can be decreased. In this article, we have tried to evaluate the role of artificial intelligence in lung cancer screening, as well as the future potential and efficiency of AI in the classification of nodules. The relevant studies between 2010-2020 were selected from the PubMed database after excluding animal studies and were analyzed for the contribution of AI. Techniques such as deep learning and machine learning allow automatic characterization and classification of nodules with high precision and promise an advanced lung cancer screening method in the future. Even though several combination models with high performance have been proposed, an effectively validated model for routine use still needs to be improvised. Combining the performance of artificial intelligence with a radiologist's expertise offers a successful outcome with higher accuracy. Thus, we can conclude that higher sensitivity, specificity, and accuracy of lung cancer screening and classification of nodules is possible through the integration of artificial intelligence and radiology. The validation of models and further research is to be carried out to determine the feasibility of this integration.",
33396754,Peptide-Based Nanomaterials for Tumor Immunotherapy,2020 Dec 30;26(1):132.,"With the increasing understanding of tumor immune circulation mechanisms, tumor immunotherapy including immune checkpoint blockade has become a research hotspot, which requires the development of more accurate and more efficient drugs with fewer side effects. In line with this requirement, peptides with good biocompatibility, targeting, and specificity become favorable theranostic reagents, and a series of promising candidates for tumor immunotherapy based on peptides have been developed. Additionally, the advantages of nanomaterials as drug carriers such as higher affinity have been demonstrated, providing possibilities of combination therapy. In this review, we summarize the development of peptide-based nanomaterials in tumor immunotherapy from the two aspects of functionalization and self-assembly. Furthermore, new methods for peptide screening, especially machine-learning-related strategies, is also a topic we were interested in, as this forms the basis for the construction of peptide-based platforms. Peptides provide broad prospects for tumor immunotherapy and we hope that this summary can provide insight into possible avenues for future exploration.",1
33396740,Structural Aspects and Prediction of Calmodulin-Binding Proteins,2020 Dec 30;22(1):308.,"Calmodulin (CaM) is an important intracellular protein that binds Ca2+ and functions as a critical second messenger involved in numerous biological activities through extensive interactions with proteins and peptides. CaM's ability to adapt to binding targets with different structures is related to the flexible central helix separating the N- and C-terminal lobes, which allows for conformational changes between extended and collapsed forms of the protein. CaM-binding targets are most often identified using prediction algorithms that utilize sequence and structural data to predict regions of peptides and proteins that can interact with CaM. In this review, we provide an overview of different CaM-binding proteins, the motifs through which they interact with CaM, and shared properties that make them good binding partners for CaM. Additionally, we discuss the historical and current methods for predicting CaM binding, and the similarities and differences between these methods and their relative success at prediction. As new CaM-binding proteins are identified and classified, we will gain a broader understanding of the biological processes regulated through changes in Ca2+ concentration through interactions with CaM.",
33396434,Artificial Neural Network Algorithms for 3D Printing,2020 Dec 31;14(1):163.,"Additive manufacturing with an emphasis on 3D printing has recently become popular due to its exceptional advantages over conventional manufacturing processes. However, 3D printing process parameters are challenging to optimize, as they influence the properties and usage time of printed parts. Therefore, it is a complex task to develop a correlation between process parameters and printed parts' properties via traditional optimization methods. A machine-learning technique was recently validated to carry out intricate pattern identification and develop a deterministic relationship, eliminating the need to develop and solve physical models. In machine learning, artificial neural network (ANN) is the most widely utilized model, owing to its capability to solve large datasets and strong computational supremacy. This study compiles the advancement of ANN in several aspects of 3D printing. Challenges while applying ANN in 3D printing and their potential solutions are indicated. Finally, upcoming trends for the application of ANN in 3D printing are projected.",
33392139,Internet of Things and Artificial Intelligence in Healthcare During COVID-19 Pandemic-A South American Perspective,2020 Dec 16;8:600213.,"The shudders of the COVID-19 pandemic have projected newer challenges in the healthcare domain across the world. In South American scenario, severe issues and difficulties have been noticed in areas like patient consultations, remote monitoring, medical resources, healthcare personnel etc. This work is aimed at providing a holistic view to the digital healthcare during the times of COVID-19 pandemic in South America. It includes different initiatives like mobile apps, web-platforms and intelligent analyses toward early detection and overall healthcare management. In addition to discussing briefly the key issues toward extensive implementation of eHealth paradigms, this work also sheds light on some key aspects of Artificial Intelligence and the Internet of Things along their potential applications like clinical decision support systems and predictive risk modeling, especially in the direction of combating the emergent challenges due to the COVID-19 pandemic.",
33385700,A review of machine learning methods for retinal blood vessel segmentation and artery/vein classification,2021 Feb;68:101905.,"The eye affords a unique opportunity to inspect a rich part of the human microvasculature non-invasively via retinal imaging. Retinal blood vessel segmentation and classification are prime steps for the diagnosis and risk assessment of microvascular and systemic diseases. A high volume of techniques based on deep learning have been published in recent years. In this context, we review 158 papers published between 2012 and 2020, focussing on methods based on machine and deep learning (DL) for automatic vessel segmentation and classification for fundus camera images. We divide the methods into various classes by task (segmentation or artery-vein classification), technique (supervised or unsupervised, deep and non-deep learning, hand-crafted methods) and more specific algorithms (e.g. multiscale, morphology). We discuss advantages and limitations, and include tables summarising results at-a-glance. Finally, we attempt to assess the quantitative merit of DL methods in terms of accuracy improvement compared to other methods. The results allow us to offer our views on the outlook for vessel segmentation and classification for fundus camera images.",
33385619,Machine learning approaches for crop improvement: Leveraging phenotypic and genotypic big data,2021 Feb;257:153354.,"Highly efficient and accurate selection of elite genotypes can lead to dramatic shortening of the breeding cycle in major crops relevant for sustaining present demands for food, feed, and fuel. In contrast to classical approaches that emphasize the need for resource-intensive phenotyping at all stages of artificial selection, genomic selection dramatically reduces the need for phenotyping. Genomic selection relies on advances in machine learning and the availability of genotyping data to predict agronomically relevant phenotypic traits. Here we provide a systematic review of machine learning approaches applied for genomic selection of single and multiple traits in major crops in the past decade. We emphasize the need to gather data on intermediate phenotypes, e.g. metabolite, protein, and gene expression levels, along with developments of modeling techniques that can lead to further improvements of genomic selection. In addition, we provide a critical view of factors that affect genomic selection, with attention to transferability of models between different environments. Finally, we highlight the future aspects of integrating high-throughput molecular phenotypic data from omics technologies with biological networks for crop improvement.",1
33384840,"Developments, application, and performance of artificial intelligence in dentistry - A systematic review",2021 Jan;16(1):508-522.,"Background/purpose:                    Artificial intelligence (AI) has made deep inroads into dentistry in the last few years. The aim of this systematic review was to identify the development of AI applications that are widely employed in dentistry and evaluate their performance in terms of diagnosis, clinical decision-making, and predicting the prognosis of the treatment.              Materials and methods:                    The literature for this paper was identified and selected by performing a thorough search in the electronic data bases like PubMed, Medline, Embase, Cochrane, Google scholar, Scopus, Web of science, and Saudi digital library published over the past two decades (January 2000-March 15, 2020).After applying inclusion and exclusion criteria, 43 articles were read in full and critically analyzed. Quality analysis was performed using QUADAS-2.              Results:                    AI technologies are widely implemented in a wide range of dentistry specialties. Most of the documented work is focused on AI models that rely on convolutional neural networks (CNNs) and artificial neural networks (ANNs). These AI models have been used in detection and diagnosis of dental caries, vertical root fractures, apical lesions, salivary gland diseases, maxillary sinusitis, maxillofacial cysts, cervical lymph nodes metastasis, osteoporosis, cancerous lesions, alveolar bone loss, predicting orthodontic extractions, need for orthodontic treatments, cephalometric analysis, age and gender determination.              Conclusion:                    These studies indicate that the performance of an AI based automated system is excellent. They mimic the precision and accuracy of trained specialists, in some studies it was found that these systems were even able to outmatch dental specialists in terms of performance and accuracy.",
33384838,"Scope and performance of artificial intelligence technology in orthodontic diagnosis, treatment planning, and clinical decision-making - A systematic review",2021 Jan;16(1):482-492.,"Background/purpose:                    In the recent years artificial intelligence (AI) has revolutionized in the field of dentistry. The aim of this systematic review was to document the scope and performance of the artificial intelligence based models that have been widely used in orthodontic diagnosis, treatment planning, and predicting the prognosis.              Materials and methods:                    The literature for this paper was identified and selected by performing a thorough search for articles in the electronic data bases like Pubmed, Medline, Embase, Cochrane, and Google scholar, Scopus and Web of science, Saudi digital library published over the past two decades (January 2000-February 2020). After applying the inclusion and exclusion criteria, 16 articles were read in full and critically analyzed. QUADAS-2 were adapted for quality analysis of the studies included.              Results:                    AI technology has been widely applied for identifying cephalometric landmarks, determining need for orthodontic extractions, determining the degree of maturation of the cervical vertebra, predicting the facial attractiveness after orthognathic surgery, predicting the need for orthodontic treatment, and orthodontic treatment planning. Most of these artificial intelligence models are based on either artificial neural networks (ANNs) or convolutional neural networks (CNNs).              Conclusion:                    The results from these reported studies are suggesting that these automated systems have performed exceptionally well, with an accuracy and precision similar to the trained examiners. These systems can simplify the tasks and provide results in quick time which can save the dentist time and help the dentist to perform his duties more efficiently. These systems can be of great value in orthodontics.",
33383867,"Public Health Impact of Using Biosimilars, Is Automated Follow up Relevant?",2020 Dec 29;18(1):186.,"Biologic reference drugs and their copies, biosimilars, have a complex structure. Biosimilars need to demonstrate their biosimilarity during development but unpredictable variations can remain, such as micro-heterogeneity. The healthcare community may raise questions regarding the clinical outcomes induced by this micro-heterogeneity. Indeed, unwanted immune reactions may be induced for numerous reasons, including product variations. However, it is challenging to assess these unwanted immune reactions because of the multiplicity of causes and potential delays before any reaction. Moreover, safety assessments as part of preclinical studies and clinical trials may be of limited value with respect to immunogenicity assessments because they are performed on a standardised population during a limited period. Real-life data could therefore supplement the assessments of clinical trials by including data on the real-life use of biosimilars, such as switches. Furthermore, real-life data also include any economic incentives to prescribe or use biosimilars. This article raises the question of relevance of automating real life data processing regarding Biosimilars. The objective is to initiate a discussion about different approaches involving Machine Learning. So, the discussion is established regarding implementation of Neural Network model to ensure safety of biosimilars subject to economic incentives. Nevertheless, the application of Machine Learning in the healthcare field raises ethical, legal and technical issues that require further discussion.",
33383831,Active and Passive Electro-Optical Sensors for Health Assessment in Food Crops,2020 Dec 29;21(1):171.,"In agriculture, early detection of plant stresses is advantageous in preventing crop yield losses. Remote sensors are increasingly being utilized for crop health monitoring, offering non-destructive, spatialized detection and the quantification of plant diseases at various levels of measurement. Advances in sensor technologies have promoted the development of novel techniques for precision agriculture. As in situ techniques are surpassed by multispectral imaging, refinement of hyperspectral imaging and the promising emergence of light detection and ranging (LIDAR), remote sensing will define the future of biotic and abiotic plant stress detection, crop yield estimation and product quality. The added value of LIDAR-based systems stems from their greater flexibility in capturing data, high rate of data delivery and suitability for a high level of automation while overcoming the shortcomings of passive systems limited by atmospheric conditions, changes in light, viewing angle and canopy structure. In particular, a multi-sensor systems approach and associated data fusion techniques (i.e., blending LIDAR with existing electro-optical sensors) offer increased accuracy in plant disease detection by focusing on traditional optimal estimation and the adoption of artificial intelligence techniques for spatially and temporally distributed big data. When applied across different platforms (handheld, ground-based, airborne, ground/aerial robotic vehicles or satellites), these electro-optical sensors offer new avenues to predict and react to plant stress and disease. This review examines the key sensor characteristics, platform integration options and data analysis techniques recently proposed in the field of precision agriculture and highlights the key challenges and benefits of each concept towards informing future research in this very important and rapidly growing field.",
33383423,"Water quality prospective in Twenty First Century: Status of water quality in major river basins, contemporary strategies and impediments: A review",2021 Feb 15;271:116332.,"Water quality improvement is one of the top priorities in the global agenda endorsed by United Nation. In this review manuscript, a holistic view of water quality degradation such as concerned pollutants, source of pollution, and its consequences in major river basins around the globe (at least 1 from each continent and a total of 16 basins) is presented. Additionally, nine contemporary techniques such as field scale evaluation, watershed scale evaluation, strategies to identify critical source areas, optimization strategies for placement of best management practices (BMPs), social component in watershed modeling, machine learning algorithms to address water quality problems in complex natural systems concomitant with spatial heterogeneity, establishing a total maximum daily loads (TMDLs), remote sensing in monitoring water quality, and developing water quality index are discussed. Next, the existing barriers to improve water quality are classified into primary and secondary impediments. A detail discussion of three primary impediments (climate change, urbanization and industrial activities, and agriculture) and ten secondary impediments (availability of water quality data, complexity of system, lack of skilled person, environmental legislation, fragmented mandate, limitation in resources, environmental awareness, resistance to change, alteration of nutrient ratio by river damming, and emerging pollutants) are illustrated. Finally, considering all the existing knowledge gaps pertaining to contemporary strategies, a future direction of water quality research is outlined to significantly improve the water quality around the globe.",
33383297,Omics-based strategies to discover novel classes of RiPP natural products,2020 Dec 28;69:60-67.,"Ribosomally synthesized and post-translationally modified peptides (RiPPs) form a highly diverse class of natural products, with various biotechnologically and clinically relevant activities. A recent increase in discoveries of novel RiPP classes suggests that currently known RiPPs constitute just the tip of the iceberg. Genome mining has been a driving force behind these discoveries, but remains challenging due to a lack of universal genetic markers for RiPP detection. In this review, we discuss how various genome mining methodologies contribute towards the discovery of novel RiPP classes. Some methods prioritize novel biosynthetic gene clusters (BGCs) based on shared modifications between RiPP classes. Other methods identify RiPP precursors using machine-learning classifiers. The integration of such methods as well as integration with other types of omics data in more comprehensive pipelines could help these tools reach their potential, and keep pushing the boundaries of the chemical diversity of this important class of molecules.",
33383256,5D superresolution imaging for a live cell nucleus,2021 Apr;67:77-83.,"With a spatial resolution breaking the diffraction limit of light, superresolution imaging allows the visualization of detailed structures of organelles such as mitochondria, cytoskeleton, nucleus, and so on. With multi-dimensional imaging (x, y, z, t, λ), namely, multi-color 3D live imaging enables us fully understand the function of the cell. It is necessary to analyze structural changes or molecular interactions across a large volume in 3D with different labelled targets. To achieve this goal, scientists recently have expanded the original 2D superresolution microscopic tools into 3D imaging techniques. In this review, we will discuss recent development in superresolution microscopy for live imaging with minimal phototoxicity. We will focus our discussion on the cell nucleus where the genetic materials are stored and processed. Machine learning algorism will be introduced to improve the axial resolution of superresolution imaging.",1
33382986,Resolving heterogeneity in transcranial electrical stimulation efficacy for attention deficit hyperactivity disorder,2021 Mar;337:113586.,"While the treatment of Attention Deficit Hyperactivity Disorder (ADHD) is dominated by pharmacological agents, transcranial electrical stimulation (tES) is gaining attention as an alternative method for treatment. Most current meta-analyses have suggested that tES can improve cognitive functions that are otherwise impaired in ADHD, such as inhibition and working memory, as well as alleviated clinical symptoms. Here we review some of the promising findings in the field of tES. At the same time, we highlight two factors, which hinder the effective application of tES in treating ADHD: 1) the heterogeneity of tES protocols used in different studies; 2) patient profiles influencing responses to tES. We highlight potential solutions for overcoming such limitations, including the use of active machine learning, and provide simulated data to demonstrate how these solutions could also improve the understanding, diagnosis, and treatment of ADHD.",
33381570,Artificial Intelligence in Coronary Computed Tomography Angiography: From Anatomy to Prognosis,2020 Dec 16;2020:6649410.,"Cardiac computed tomography angiography (CCTA) is widely used as a diagnostic tool for evaluation of coronary artery disease (CAD). Despite the excellent capability to rule-out CAD, CCTA may overestimate the degree of stenosis; furthermore, CCTA analysis can be time consuming, often requiring advanced postprocessing techniques. In consideration of the most recent ESC guidelines on CAD management, which will likely increase CCTA volume over the next years, new tools are necessary to shorten reporting time and improve the accuracy for the detection of ischemia-inducing coronary lesions. The application of artificial intelligence (AI) may provide a helpful tool in CCTA, improving the evaluation and quantification of coronary stenosis, plaque characterization, and assessment of myocardial ischemia. Furthermore, in comparison with existing risk scores, machine-learning algorithms can better predict the outcome utilizing both imaging findings and clinical parameters. Medical AI is moving from the research field to daily clinical practice, and with the increasing number of CCTA examinations, AI will be extensively utilized in cardiac imaging. This review is aimed at illustrating the state of the art in AI-based CCTA applications and future clinical scenarios.",1
33381440,Cardiac computed tomography radiomics: an emerging tool for the non-invasive assessment of coronary atherosclerosis,2020 Dec;10(6):2005-2017.,"In the last decades, significant advances have been made in the preventive approaches to cardiovascular disease. Even so, coronary artery disease remains one of the main causes of morbidity and mortality worldwide. Invasive imaging modalities, such as intravascular ultrasound or optical coherence tomography, have played a key role in the comprehension of the pathological processes underlying myocardial infarction and cerebrovascular disease. These imaging techniques have contributed greatly to the identification and phenotyping of the culprit lesion, the so-called vulnerable plaque. Coronary computed tomographic angiography (CCTA) has emerged in more recent years as the non-invasive modality of choice in the study of coronary atherosclerosis, showing in many studies a diagnostic yield comparable to invasive approaches. Moreover, being able to describe extra-luminal characteristics of the affected vessel, CCTA has greatly contributed towards shifting the attention of researchers from the mere quantification of luminal stenosis to the identification of adverse plaque features, which appear to have a stronger prognostic value. However, the identification of some of the hallmarks of vulnerable plaques is qualitative in nature and, therefore, subject to some degree of inter-reader variability. Moreover, CCTA is still unable to identify some fine markers of plaque vulnerability which can be detected by invasive techniques, such as neovascularization and plaque erosion, among others. Nonetheless, radiological images can be viewed as vast 3-D datasets which, via the use of recent technology, allow for the extraction of numerous quantitative features that may be used to accurately phenotype a given lesion. Radiomics is the process of extrapolating innumerable parameters from a given region of interest, with the goal of establishing correlations between quantitative variables and clinical data. These datasets can then be manipulated to create predictive models via the use of automated algorithms in a process called machine learning. As a result of these approaches, radiological images may offer information regarding the characterization of a plaque which can go much beyond the boundaries of what can be qualitatively asserted by the human eye, contributing to expanding the knowledge of the disease and ultimately assist clinical decisions. Thus far, radiomics has found its more consistent area of application in the field of oncology; to present date, the amount of clinical data regarding coronary artery disease is still relatively small, partly due to the technical difficulties associated with the implementation of such techniques to the study of a small and geometrically complex lesion such as the coronary plaque. The present review, after a summary of the imaging modalities most commonly used nowadays in the study of coronary plaques, will provide a perspective on the application of radiomic analysis to coronary artery disease.",
33375710,Privacy-Preserving Sensor-Based Continuous Authentication and User Profiling: A Review,2020 Dec 25;21(1):92.,"Ensuring the confidentiality of private data stored in our technological devices is a fundamental aspect for protecting our personal and professional information. Authentication procedures are among the main methods used to achieve this protection and, typically, are implemented only when accessing the device. Nevertheless, in many occasions it is necessary to carry out user authentication in a continuous manner to guarantee an allowed use of the device while protecting authentication data. In this work, we first review the state of the art of Continuous Authentication (CA), User Profiling (UP), and related biometric databases. Secondly, we summarize the privacy-preserving methods employed to protect the security of sensor-based data used to conduct user authentication, and some practical examples of their utilization. The analysis of the literature of these topics reveals the importance of sensor-based data to protect personal and professional information, as well as the need for exploring a combination of more biometric features with privacy-preserving approaches.",
33375658,Explainable AI: A Review of Machine Learning Interpretability Methods,2020 Dec 25;23(1):18.,"Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into ""black box"" approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.",1
33375609,Learning-Based Methods of Perception and Navigation for Ground Vehicles in Unstructured Environments: A Review,2020 Dec 25;21(1):73.,"The problem of autonomous navigation of a ground vehicle in unstructured environments is both challenging and crucial for the deployment of this type of vehicle in real-world applications. Several well-established communities in robotics research deal with these scenarios such as search and rescue robotics, planetary exploration, and agricultural robotics. Perception plays a crucial role in this context, since it provides the necessary information to make the vehicle aware of its own status and its surrounding environment. We present a review on the recent contributions in the robotics literature adopting learning-based methods to solve the problem of environment perception and interpretation with the final aim of the autonomous context-aware navigation of ground vehicles in unstructured environments. To the best of our knowledge, this is the first work providing such a review in this context.",
33374969,Application of Biological Domain Knowledge Based Feature Selection on Gene Expression Data,2020 Dec 22;23(1):2.,"In the last two decades, there have been massive advancements in high throughput technologies, which resulted in the exponential growth of public repositories of gene expression datasets for various phenotypes. It is possible to unravel biomarkers by comparing the gene expression levels under different conditions, such as disease vs. control, treated vs. not treated, drug A vs. drug B, etc. This problem refers to a well-studied problem in the machine learning domain, i.e., the feature selection problem. In biological data analysis, most of the computational feature selection methodologies were taken from other fields, without considering the nature of the biological data. Thus, integrative approaches that utilize the biological knowledge while performing feature selection are necessary for this kind of data. The main idea behind the integrative gene selection process is to generate a ranked list of genes considering both the statistical metrics that are applied to the gene expression data, and the biological background information which is provided as external datasets. One of the main goals of this review is to explore the existing methods that integrate different types of information in order to improve the identification of the biomolecular signatures of diseases and the discovery of new potential targets for treatment. These integrative approaches are expected to aid the prediction, diagnosis, and treatment of diseases, as well as to enlighten us on disease state dynamics, mechanisms of their onset and progression. The integration of various types of biological information will necessitate the development of novel techniques for integration and data analysis. Another aim of this review is to boost the bioinformatics community to develop new approaches for searching and determining significant groups/clusters of features based on one or more biological grouping functions.",
33374478,miRNA Targets: From Prediction Tools to Experimental Validation,2020 Dec 24;4(1):1.,"MicroRNAs (miRNAs) are post-transcriptional regulators of gene expression in both animals and plants. By pairing to microRNA responsive elements (mREs) on target mRNAs, miRNAs play gene-regulatory roles, producing remarkable changes in several physiological and pathological processes. Thus, the identification of miRNA-mRNA target interactions is fundamental for discovering the regulatory network governed by miRNAs. The best way to achieve this goal is usually by computational prediction followed by experimental validation of these miRNA-mRNA interactions. This review summarizes the key strategies for miRNA target identification. Several tools for computational analysis exist, each with different approaches to predict miRNA targets, and their number is constantly increasing. The major algorithms available for this aim, including Machine Learning methods, are discussed, to provide practical tips for familiarizing with their assumptions and understanding how to interpret the results. Then, all the experimental procedures for verifying the authenticity of the identified miRNA-mRNA target pairs are described, including High-Throughput technologies, in order to find the best approach for miRNA validation. For each strategy, strengths and weaknesses are discussed, to enable users to evaluate and select the right approach for their interests.",
33374270,"Driver Fatigue Detection Systems Using Multi-Sensors, Smartphone, and Cloud-Based Computing Platforms: A Comparative Analysis",2020 Dec 24;21(1):56.,"Internet of things (IoT) cloud-based applications deliver advanced solutions for smart cities to decrease traffic accidents caused by driver fatigue while driving on the road. Environmental conditions or driver behavior can ultimately lead to serious roadside accidents. In recent years, the authors have developed many low-cost, computerized, driver fatigue detection systems (DFDs) to help drivers, by using multi-sensors, and mobile and cloud-based computing architecture. To promote safe driving, these are the most current emerging platforms that were introduced in the past. In this paper, we reviewed state-of-the-art approaches for predicting unsafe driving styles using three common IoT-based architectures. The novelty of this article is to show major differences among multi-sensors, smartphone-based, and cloud-based architectures in multimodal feature processing. We discussed all of the problems that machine learning techniques faced in recent years, particularly the deep learning (DL) model, to predict driver hypovigilance, especially in terms of these three IoT-based architectures. Moreover, we performed state-of-the-art comparisons by using driving simulators to incorporate multimodal features of the driver. We also mention online data sources in this article to test and train network architecture in the field of DFDs on public available multimodal datasets. These comparisons assist other authors to continue future research in this domain. To evaluate the performance, we mention the major problems in these three architectures to help researchers use the best IoT-based architecture for detecting DFDs in a real-time environment. Moreover, the important factors of Multi-Access Edge Computing (MEC) and 5th generation (5G) networks are analyzed in the context of deep learning architecture to improve the response time of DFD systems. Lastly, it is concluded that there is a research gap when it comes to implementing the DFD systems on MEC and 5G technologies by using multimodal features and DL architecture.",
33374181,The Role of Artificial Intelligence in Endoscopic Ultrasound for Pancreatic Disorders,2020 Dec 24;11(1):18.,"The use of artificial intelligence (AI) in various medical imaging applications has expanded remarkably, and several reports have focused on endoscopic ultrasound (EUS) images of the pancreas. This review briefly summarizes each report in order to help endoscopists better understand and utilize the potential of this rapidly developing AI, after a description of the fundamentals of the AI involved, as is necessary for understanding each study. At first, conventional computer-aided diagnosis (CAD) was used, which extracts and selects features from imaging data using various methods and introduces them into machine learning algorithms as inputs. Deep learning-based CAD utilizing convolutional neural networks has been used; in these approaches, the images themselves are used as inputs, and more information can be analyzed in less time and with higher accuracy. In the field of EUS imaging, although AI is still in its infancy, further research and development of AI applications is expected to contribute to the role of optical biopsy as an alternative to EUS-guided tissue sampling while also improving diagnostic accuracy through double reading with humans and contributing to EUS education.",
33372625,A review of optical chemical structure recognition tools,2020 Oct 7;12(1):60.,"Structural information about chemical compounds is typically conveyed as 2D images of molecular structures in scientific documents. Unfortunately, these depictions are not a machine-readable representation of the molecules. With a backlog of decades of chemical literature in printed form not properly represented in open-access databases, there is a high demand for the translation of graphical molecular depictions into machine-readable formats. This translation process is known as Optical Chemical Structure Recognition (OCSR). Today, we are looking back on nearly three decades of development in this demanding research field. Most OCSR methods follow a rule-based approach where the key step of vectorization of the depiction is followed by the interpretation of vectors and nodes as bonds and atoms. Opposed to that, some of the latest approaches are based on deep neural networks (DNN). This review provides an overview of all methods and tools that have been published in the field of OCSR. Additionally, a small benchmark study was performed with the available open-source OCSR tools in order to examine their performance.",1
33371386,The Expanding Computational Toolbox for Engineering Microbial Phenotypes at the Genome Scale,2020 Dec 21;8(12):2050.,"Microbial strains are being engineered for an increasingly diverse array of applications, from chemical production to human health. While traditional engineering disciplines are driven by predictive design tools, these tools have been difficult to build for biological design due to the complexity of biological systems and many unknowns of their quantitative behavior. However, due to many recent advances, the gap between design in biology and other engineering fields is closing. In this work, we discuss promising areas of development of computational tools for engineering microbial strains. We define five frontiers of active research: (1) Constraint-based modeling and metabolic network reconstruction, (2) Kinetics and thermodynamic modeling, (3) Protein structure analysis, (4) Genome sequence analysis, and (5) Regulatory network analysis. Experimental and machine learning drivers have enabled these methods to improve by leaps and bounds in both scope and accuracy. Modern strain design projects will require these tools to be comprehensively applied to the entire cell and efficiently integrated within a single workflow. We expect that these frontiers, enabled by the ongoing revolution of big data science, will drive forward more advanced and powerful strain engineering strategies.",
33364579,Machine learning in plant science and plant breeding,2020 Dec 5;24(1):101890.,"Technological developments have revolutionized measurements on plant genotypes and phenotypes, leading to routine production of large, complex data sets. This has led to increased efforts to extract meaning from these measurements and to integrate various data sets. Concurrently, machine learning has rapidly evolved and is now widely applied in science in general and in plant genotyping and phenotyping in particular. Here, we review the application of machine learning in the context of plant science and plant breeding. We focus on analyses at different phenotype levels, from biochemical to yield, and in connecting genotypes to these. In this way, we illustrate how machine learning offers a suite of methods that enable researchers to find meaningful patterns in relevant plant data.",1
33362867,State of the Field in Multi-Omics Research: From Computational Needs to Data Mining and Sharing,2020 Dec 10;11:610798.,"Multi-omics, variously called integrated omics, pan-omics, and trans-omics, aims to combine two or more omics data sets to aid in data analysis, visualization and interpretation to determine the mechanism of a biological process. Multi-omics efforts have taken center stage in biomedical research leading to the development of new insights into biological events and processes. However, the mushrooming of a myriad of tools, datasets, and approaches tends to inundate the literature and overwhelm researchers new to the field. The aims of this review are to provide an overview of the current state of the field, inform on available reliable resources, discuss the application of statistics and machine/deep learning in multi-omics analyses, discuss findable, accessible, interoperable, reusable (FAIR) research, and point to best practices in benchmarking. Thus, we provide guidance to interested users of the domain by addressing challenges of the underlying biology, giving an overview of the available toolset, addressing common pitfalls, and acknowledging current methods' limitations. We conclude with practical advice and recommendations on software engineering and reproducibility practices to share a comprehensive awareness with new researchers in multi-omics for end-to-end workflow.",3
33362861,"Machine Learning Based Computational Gene Selection Models: A Survey, Performance Evaluation, Open Issues, and Future Research Directions",2020 Dec 10;11:603808.,"Gene Expression is the process of determining the physical characteristics of living beings by generating the necessary proteins. Gene Expression takes place in two steps, translation and transcription. It is the flow of information from DNA to RNA with enzymes' help, and the end product is proteins and other biochemical molecules. Many technologies can capture Gene Expression from the DNA or RNA. One such technique is Microarray DNA. Other than being expensive, the main issue with Microarray DNA is that it generates high-dimensional data with minimal sample size. The issue in handling such a heavyweight dataset is that the learning model will be over-fitted. This problem should be addressed by reducing the dimension of the data source to a considerable amount. In recent years, Machine Learning has gained popularity in the field of genomic studies. In the literature, many Machine Learning-based Gene Selection approaches have been discussed, which were proposed to improve dimensionality reduction precision. This paper does an extensive review of the various works done on Machine Learning-based gene selection in recent years, along with its performance analysis. The study categorizes various feature selection algorithms under Supervised, Unsupervised, and Semi-supervised learning. The works done in recent years to reduce the features for diagnosing tumors are discussed in detail. Furthermore, the performance of several discussed methods in the literature is analyzed. This study also lists out and briefly discusses the open issues in handling the high-dimension and less sample size data.",
33362384,Evolving role of artificial intelligence in gastrointestinal endoscopy,2020 Dec 14;26(46):7287-7298.,"Artificial intelligence (AI) is a combination of different technologies that enable machines to sense, comprehend, and learn with human-like levels of intelligence. AI technology will eventually enhance human capability, provide machines genuine autonomy, and reduce errors, and increase productivity and efficiency. AI seems promising, and the field is full of invention, novel applications; however, the limitation of machine learning suggests a cautious optimism as the right strategy. AI is also becoming incorporated into medicine to improve patient care by speeding up processes and achieving greater accuracy for optimal patient care. AI using deep learning technology has been used to identify, differentiate catalog images in several medical fields including gastrointestinal endoscopy. The gastrointestinal endoscopy field involves endoscopic diagnoses and prognostication of various digestive diseases using image analysis with the help of various gastrointestinal endoscopic device systems. AI-based endoscopic systems can reliably detect and provide crucial information on gastrointestinal pathology based on their training and validation. These systems can make gastroenterology practice easier, faster, more reliable, and reduce inter-observer variability in the coming years. However, the thought that these systems will replace human decision making replace gastrointestinal endoscopists does not seem plausible in the near future. In this review, we discuss AI and associated various technological terminologies, evolving role in gastrointestinal endoscopy, and future possibilities.",
33360622,Natural and engineered transglycosylases: Green tools for the enzyme-based synthesis of glycoproducts,2021 Apr;61:96-106.,"An increasing number of transglycosylase-based processes provide access to oligosaccharides or glycoconjugates, some of them reaching performance levels compatible with industrial developments. Nevertheless, the full potential of transglycosylases has not been explored because of the challenges in transforming a glycoside hydrolase into an efficient transglycosylase. Advances in studying enzyme structure/function relationships, screening enzyme activity, and generating synthetic libraries guided by computational protein design or machine learning methods should considerably accelerate the development of these catalysts. The time has now come for researchers to uncover their possibilities and learn how to design and precisely refine their activity to respond more rapidly to the growing demand for well-defined glycosidic structures.",
33360497,Advances to tackle backbone flexibility in protein docking,2021 Apr;67:178-186.,"Computational docking methods can provide structural models of protein-protein complexes, but protein backbone flexibility upon association often thwarts accurate predictions. In recent blind challenges, medium or high accuracy models were submitted in less than 20% of the 'difficult' targets (with significant backbone change or uncertainty). Here, we describe recent developments in protein-protein docking and highlight advances that tackle backbone flexibility. In molecular dynamics and Monte Carlo approaches, enhanced sampling techniques have reduced time-scale limitations. Internal coordinate formulations can now capture realistic motions of monomers and complexes using harmonic dynamics. And machine learning approaches adaptively guide docking trajectories or generate novel binding site predictions from deep neural networks trained on protein interfaces. These tools poise the field to break through the longstanding challenge of correctly predicting complex structures with significant conformational change.",
33358195,Artificial intelligence in radiology: relevance of collaborative work between radiologists and engineers for building a multidisciplinary team,2021 May;76(5):317-324.,"The use of artificial intelligence (AI) algorithms in the field of radiology is becoming more common. Several studies have demonstrated the potential utility of machine learning (ML) and deep learning (DL) techniques as aids for radiologists to solve specific radiological challenges. The decision-making process, the establishment of specific clinical or radiological targets, the profile of the different professionals involved in the development of AI solutions, and the relation with partnerships and stakeholders are only some of the main issues that have to be faced and solved prior to starting the development of radiological AI solutions. Among all the players in this multidisciplinary team, the communication between radiologists and data scientists is essential for a successful collaborative work. There are specific skills that are inherent to radiological and medical training that are critical for identifying anatomical or clinical targets as well as for segmenting or labelling lesions. These skills would then have to be transferred, explained, and taught to the data science experts to facilitate their comprehension and integration into ML or DL algorithms. On the other hand, there is a wide range of complex software packages, deep neural-network architectures, and data transfer processes for which radiologists need the expertise of software engineers and data scientists in order to select the optimal manner to analyse and post-process this amount of data. This paper offers a summary of the top five challenges faced by radiologists and data scientists including tips and tricks to build a successful AI team.",
33358138,Ethical issues in using ambient intelligence in health-care settings,2021 Feb;3(2):e115-e123.,"Ambient intelligence is increasingly finding applications in health-care settings, such as helping to ensure clinician and patient safety by monitoring staff compliance with clinical best practices or relieving staff of burdensome documentation tasks. Ambient intelligence involves using contactless sensors and contact-based wearable devices embedded in health-care settings to collect data (eg, imaging data of physical spaces, audio data, or body temperature), coupled with machine learning algorithms to efficiently and effectively interpret these data. Despite the promise of ambient intelligence to improve quality of care, the continuous collection of large amounts of sensor data in health-care settings presents ethical challenges, particularly in terms of privacy, data management, bias and fairness, and informed consent. Navigating these ethical issues is crucial not only for the success of individual uses, but for acceptance of the field as a whole.",1
33353986,Image-based profiling for drug discovery: due for a machine-learning upgrade?,2021 Feb;20(2):145-159.,"Image-based profiling is a maturing strategy by which the rich information present in biological images is reduced to a multidimensional profile, a collection of extracted image-based features. These profiles can be mined for relevant patterns, revealing unexpected biological activity that is useful for many steps in the drug discovery process. Such applications include identifying disease-associated screenable phenotypes, understanding disease mechanisms and predicting a drug's activity, toxicity or mechanism of action. Several of these applications have been recently validated and have moved into production mode within academia and the pharmaceutical industry. Some of these have yielded disappointing results in practice but are now of renewed interest due to improved machine-learning strategies that better leverage image-based information. Although challenges remain, novel computational technologies such as deep learning and single-cell methods that better capture the biological information in images hold promise for accelerating drug discovery.",4
33347838,Artificial intelligence in the early stages of drug discovery,2021 Feb 15;698:108730.,"Although the use of computational methods within the pharmaceutical industry is well established, there is an urgent need for new approaches that can improve and optimize the pipeline of drug discovery and development. In spite of the fact that there is no unique solution for this need for innovation, there has recently been a strong interest in the use of Artificial Intelligence for this purpose. As a matter of fact, not only there have been major contributions from the scientific community in this respect, but there has also been a growing partnership between the pharmaceutical industry and Artificial Intelligence companies. Beyond these contributions and efforts there is an underlying question, which we intend to discuss in this review: can the intrinsic difficulties within the drug discovery process be overcome with the implementation of Artificial Intelligence? While this is an open question, in this work we will focus on the advantages that these algorithms provide over the traditional methods in the context of early drug discovery.",2
33344334,Artificial Intelligence in Dermatology: A Practical Introduction to a Paradigm Shift,2020 Nov 8;11(6):881-889.,"Artificial Intelligence (AI) has surpassed dermatologists in skin cancer detection, but dermatology still lags behind radiology in its broader adoption. Building and using AI applications are becoming increasingly accessible. However, complex use cases may still require specialized expertise for design and deployment. AI has many applications in dermatology ranging from fundamental research, diagnostics, therapeutics, and cosmetic dermatology. The lack of standardization of images and privacy concerns are the foremost challenges stifling AI adoption. Dermatologists have a significant role to play in standardized data collection, curating data for machine learning, clinically validating AI solutions, and ultimately adopting this paradigm shift that is changing the way we practice.",
33343782,Machine learning-enabled multiplexed microfluidic sensors,2020 Dec 11;14(6):061506.,"High-throughput, cost-effective, and portable devices can enhance the performance of point-of-care tests. Such devices are able to acquire images from samples at a high rate in combination with microfluidic chips in point-of-care applications. However, interpreting and analyzing the large amount of acquired data is not only a labor-intensive and time-consuming process, but also prone to the bias of the user and low accuracy. Integrating machine learning (ML) with the image acquisition capability of smartphones as well as increasing computing power could address the need for high-throughput, accurate, and automatized detection, data processing, and quantification of results. Here, ML-supported diagnostic technologies are presented. These technologies include quantification of colorimetric tests, classification of biological samples (cells and sperms), soft sensors, assay type detection, and recognition of the fluid properties. Challenges regarding the implementation of ML methods, including the required number of data points, image acquisition prerequisites, and execution of data-limited experiments are also discussed.",1
33341601,Application and performance of artificial intelligence technology in forensic odontology - A systematic review,2021 Feb;48:101826.,"Forensic odontology (FO) mainly deals with the identification of the individual through the remains, which mainly includes teeth and jawbones. Artificial intelligence (AI) technology has proven to be a breakthrough in providing reliable information in decision making in forensic sciences. This systematic review aimed to report on the application and performance of AI technology in FO. The data was gathered through searching for the articles in the renowned search engines, which have been published between January 2000 - June 2020. QUADAS-2 was adopted for the risk of bias analysis of the included studies. AI technology has been widely applied in FO for identifying bite-marks, predicting mandibular morphology, gender determination, and age estimation. Most of these AI models are based on either artificial neural networks (ANNs) or convolutional neural networks (CNNs). The results of the studies are promising. Studies have reported that these models display accuracy and precision equivalent to that of the trained examiners. These models can be promising tools when identifying victims of mass disasters and as an additive aid in medico-legal situations.",
33340690,Using Interactome Big Data to Crack Genetic Mysteries and Enhance Future Crop Breeding,2021 Jan 4;14(1):77-94.,"The functional genes underlying phenotypic variation and their interactions represent ""genetic mysteries"". Understanding and utilizing these genetic mysteries are key solutions for mitigating the current threats to agriculture posed by population growth and individual food preferences. Due to advances in high-throughput multi-omics technologies, we are stepping into an Interactome Big Data era that is certain to revolutionize genetic research. In this article, we provide a brief overview of current strategies to explore genetic mysteries. We then introduce the methods for constructing and analyzing the Interactome Big Data and summarize currently available interactome resources. Next, we discuss how Interactome Big Data can be used as a versatile tool to dissect genetic mysteries. We propose an integrated strategy that could revolutionize genetic research by combining Interactome Big Data with machine learning, which involves mining information hidden in Big Data to identify the genetic models or networks that control various traits, and also provide a detailed procedure for systematic dissection of genetic mysteries,. Finally, we discuss three promising future breeding strategies utilizing the Interactome Big Data to improve crop yields and quality.",
33340123,Promises and perils of artificial intelligence in dentistry,2020 Dec 19.,"Artificial intelligence (AI) is a subdiscipline of computer science that has made substantial progress in medicine and there is a growing body of AI research in dentistry. Dentists should have an understanding of the foundational concepts and the ability to critically evaluate dental research in AI. Machine learning (ML) is a subfield of AI that most dental AI research is dedicated to. The most prolific area of ML research is automated interpretation of dental imaging. Other areas include providing treatment recommendations, predicting future disease and treatment outcomes. The research impact is limited by small datasets that do not harness the positive correlation between very large datasets and ML performance. There is also a need to standardize research methodologies and utilize performance metrics that are appropriate for the clinical context. In addition to research challenges, this article discusses the ethical, legal and logistical considerations associated with implementation in clinical practice. This includes explainable AI, model bias, data privacy and security. The future implications of AI in dentistry involve a promise for a novel form of practicing dentistry however, the effect of AI on patient outcomes is yet to be determined.",