pmid,title,date,text,citations
30653364,Recent advances in computational tools and resources for the self-management of type 2 diabetes,2020 Jan;45(1):77-95.,"Background: While healthcare systems are investing resources on type 2 diabetes patients, self-management is becoming the new trend for these patients. Due to the pervasiveness of computing devices, a number of computerized systems are emerging to support the self-management of patients.Objective: The primary objective of this review is to identify and categorize the computational tools that exist for the self-management of type 2 diabetes, and to identify challenges that need to be addressed.Results: The tools have been categorized into web applications, mobile applications, games and ubiquitous diabetes management systems. We provide a detailed description of the salient features of each category along with a comparison of the various tools, listing their challenges and practical implications. A list of platforms that can be used to develop new tools for the self-management of type 2 diabetes, namely mobile applications development, sensor development, cloud computing, social media, and machine learning and predictive analysis platforms, are also provided.Discussions: This paper identifies a number of challenges in the existing categories of computational tools and consequently presents possible avenues for future research. Failure to address these issues will negatively impact on the adoption rate of the self-management tools and applications.",
30650562,Predicting VTE in Cancer Patients: Candidate Biomarkers and Risk Assessment Models,2019 Jan 15;11(1):95.,"Risk prediction of chemotherapy-associated venous thromboembolism (VTE) is a compelling challenge in contemporary oncology, as VTE may result in treatment delays, impaired quality of life, and increased mortality. Current guidelines do not recommend thromboprophylaxis for primary prevention, but assessment of the patient's individual risk of VTE prior to chemotherapy is generally advocated. In recent years, efforts have been devoted to building accurate predictive tools for VTE risk assessment in cancer patients. This review focuses on candidate biomarkers and prediction models currently under investigation, considering their advantages and disadvantages, and discussing their diagnostic performance and potential pitfalls.",7.0
30650551,Optimized Clustering Algorithms for Large Wireless Sensor Networks: A Review,2019 Jan 15;19(2):322.,"During the past few years, Wireless Sensor Networks (WSNs) have become widely used due to their large amount of applications. The use of WSNs is an imperative necessity for future revolutionary areas like ecological fields or smart cities in which more than hundreds or thousands of sensor nodes are deployed. In those large scale WSNs, hierarchical approaches improve the performance of the network and increase its lifetime. Hierarchy inside a WSN consists in cutting the whole network into sub-networks called clusters which are led by Cluster Heads. In spite of the advantages of the clustering on large WSNs, it remains a non-deterministic polynomial hard problem which is not solved efficiently by traditional clustering. The recent researches conducted on Machine Learning, Computational Intelligence, and WSNs bring out the optimized clustering algorithms for WSNs. These kinds of clustering are based on environmental behaviors and outperform the traditional clustering algorithms. However, due to the diversity of WSN applications, the choice of an appropriate paradigm for a clustering solution remains a problem. In this paper, we conduct a wide review of proposed optimized clustering solutions nowadays. In order to evaluate them, we consider 10 parameters. Based on these parameters, we propose a comparison of these optimized clustering approaches. From the analysis, we observe that centralized clustering solutions based on the Swarm Intelligence paradigm are more adapted for applications with low energy consumption, high data delivery rate, or high scalability than algorithms based on the other presented paradigms. Moreover, when an application does not need a large amount of nodes within a field, the Fuzzy Logic based solution are suitable.",6.0
30645625,The PLOS ONE collection on machine learning in health and biomedicine: Towards open code and open data,2019 Jan 15;14(1):e0210232.,"Recent years have seen a surge of studies in machine learning in health and biomedicine, driven by digitalization of healthcare environments and increasingly accessible computer systems for conducting analyses. Many of us believe that these developments will lead to significant improvements in patient care. Like many academic disciplines, however, progress is hampered by lack of code and data sharing. In bringing together this PLOS ONE collection on machine learning in health and biomedicine, we sought to focus on the importance of reproducibility, making it a requirement, as far as possible, for authors to share data and code alongside their papers.",3.0
30641443,Harnessing networks and machine learning in neuropsychiatric care,2019 Apr;55:32-39.,"The development of next-generation therapies for neuropsychiatric illness will likely rely on a precise and accurate understanding of human brain dynamics. Toward this end, researchers have focused on collecting large quantities of neuroimaging data. For simplicity, we will refer to large cross-sectional neuroimaging studies as broad studies and to intensive longitudinal studies as deep studies. Recent progress in identifying illness subtypes and predicting treatment response in neuropsychiatry has been supported by these study designs, along with methods bridging machine learning and network science. Such methods combine analytic power, interpretability, and direct connection to underlying theory in cognitive neuroscience. Ultimately, we propose a general framework for the treatment of neuropsychiatric illness relying on the findings from broad and deep studies combined with basic cognitive and physiologic measurements.",2.0
30635896,Computational Resources for Prediction and Analysis of Functional miRNA and Their Targetome,2019;1912:215-250.,"microRNAs are evolutionarily conserved, endogenously produced, noncoding RNAs (ncRNAs) of approximately 19-24 nucleotides (nts) in length known to exhibit gene silencing of complementary target sequence. Their deregulated expression is reported in various disease conditions and thus has therapeutic implications. In the last decade, various computational resources are published in this field. In this chapter, we have reviewed bioinformatics resources, i.e., miRNA-centered databases, algorithms, and tools to predict miRNA targets. First section has enlisted more than 75 databases, which mainly covers information regarding miRNA registries, targets, disease associations, differential expression, interactions with other noncoding RNAs, and all-in-one resources. In the algorithms section, we have compiled about 140 algorithms from eight subcategories, viz. for the prediction of precursor (pre-) and mature miRNAs. These algorithms are developed on various sequence, structure, and thermodynamic based features incorporated into different machine learning techniques (MLTs). In addition, computational identification of miRNAs from high-throughput next generation sequencing (NGS) data and their variants, viz. isomiRs, differential expression, miR-SNPs, and functional annotation, are discussed. Prediction and analysis of miRNAs and their associated targets are also evaluated under miR-targets section providing knowledge regarding novel miRNA targets and complex host-pathogen interactions. In conclusion, we have provided comprehensive review of in silico resources published in miRNA research to help scientific community be updated and choose the appropriate tool according to their needs.",4.0
30635892,Workflow Development for the Functional Characterization of ncRNAs,2019;1912:111-132.,"During the last decade, ncRNAs have been investigated intensively and revealed their regulatory role in various biological processes. Worldwide research efforts have identified numerous ncRNAs and multiple RNA subtypes, which are attributed to diverse functionalities known to interact with different functional layers, from DNA and RNA to proteins. This makes the prediction of functions for newly identified ncRNAs challenging. Current bioinformatics and systems biology approaches show promising results to facilitate an identification of these diverse ncRNA functionalities. Here, we review (a) current experimental protocols, i.e., for Next Generation Sequencing, for a successful identification of ncRNAs; (b) sequencing data analysis workflows as well as available computational environments; and (c) state-of-the-art approaches to functionally characterize ncRNAs, e.g., by means of transcriptome-wide association studies, molecular network analyses, or artificial intelligence guided prediction. In addition, we present a strategy to cover the identification and functional characterization of unknown transcripts by using connective workflows.",2.0
30631320,"Leveraging Multilayered ""Omics"" Data for Atopic Dermatitis: A Road Map to Precision Medicine",2018 Dec 12;9:2727.,"Atopic dermatitis (AD) is a complex multifactorial inflammatory skin disease that affects ~280 million people worldwide. About 85% of AD cases begin in childhood, a significant portion of which can persist into adulthood. Moreover, a typical progression of children with AD to food allergy, asthma or allergic rhinitis has been reported (""allergic march"" or ""atopic march""). AD comprises highly heterogeneous sub-phenotypes/endotypes resulting from complex interplay between intrinsic and extrinsic factors, such as environmental stimuli, and genetic factors regulating cutaneous functions (impaired barrier function, epidermal lipid, and protease abnormalities), immune functions and the microbiome. Though the roles of high-throughput ""omics"" integrations in defining endotypes are recognized, current analyses are primarily based on individual omics data and using binary clinical outcomes. Although individual omics analysis, such as genome-wide association studies (GWAS), can effectively map variants correlated with AD, the majority of the heritability and the functional relevance of discovered variants are not explained or known by the identified variants. The limited success of singular approaches underscores the need for holistic and integrated approaches to investigate complex phenotypes using trans-omics data integration strategies. Integrating omics layers (e.g., genome, epigenome, transcriptome, proteome, metabolome, lipidome, exposome, microbiome), which often have complementary and synergistic effects, might provide the opportunity to capture the flow of information underlying AD disease manifestation. Overlapping genes/candidates derived from multiple omics types include FLG, SPINK5, S100A8, and SERPINB3 in AD pathogenesis. Overlapping pathways include macrophage, endothelial cell and fibroblast activation pathways, in addition to well-known Th1/Th2 and NFkB activation pathways. Interestingly, there was more multi-omics overlap at the pathway level than gene level. Further analysis of multi-omics overlap at the tissue level showed that among 30 tissue types from the GTEx database, skin and esophagus were significantly enriched, indicating the biological interconnection between AD and food allergy. The present work explores multi-omics integration and provides new biological insights to better define the biological basis of AD etiology and confirm previously reported AD genes/pathways. In this context, we also discuss opportunities and challenges introduced by ""big omics data"" and their integration.",13.0
30628866,A review on machine learning methods for in silico toxicity prediction,2018;36(4):169-191.,"In silico toxicity prediction plays an important role in the regulatory decision making and selection of leads in drug design as in vitro/vivo methods are often limited by ethics, time, budget, and other resources. Many computational methods have been employed in predicting the toxicity profile of chemicals. This review provides a detailed end-to-end overview of the application of machine learning algorithms to Structure-Activity Relationship (SAR)-based predictive toxicology. From raw data to model validation, the importance of data quality is stressed as it greatly affects the predictive power of derived models. Commonly overlooked challenges such as data imbalance, activity cliff, model evaluation, and definition of applicability domain are highlighted, and plausible solutions for alleviating these challenges are discussed.",6.0
30628494,Deep learning for image analysis: Personalizing medicine closer to the point of care,2019 Jan;56(1):61-73.,"The precision-based revolution in medicine continues to demand stratification of patients into smaller and more personalized subgroups. While genomic technologies have largely led this movement, diagnostic results can take days to weeks to generate. Management at, or closer to, the point of care still heavily relies on the subjective qualitative interpretation of clinical and diagnostic imaging findings. New and emerging technological advances in artificial intelligence (AI) now appear poised to help bring objectivity and precision to these traditionally qualitative analytic tools. In particular, one specific form of AI, known as deep learning, is achieving expert-level disease classifications in many areas of diagnostic medicine dependent on visual and image-based findings. Here, we briefly review concepts of deep learning, and more specifically recent developments in convolutional neural networks (CNNs), to highlight their transformative potential in personalized medicine and, in particular, diagnostic histopathology. Understanding the opportunities and challenges of these quantitative machine-based decision support tools is critical to their widespread introduction into routine diagnostics.",12.0
30627231,Radiomics - the value of the numbers in present and future radiology,2018 Apr 24;83:e171-e174.,"Radiomics is a new concept that has been functioning in medicine for only a few years. This idea, created recently, relies on processing innumerable quantities of metadata acquired from every examination, followed by extraction thereof from relevant imaging examinations, such as computer tomography (CT), magnetic resonance imaging (MRI), or positron emission tomography (PET) images, by means of appropriate created algorithms. The extracted results have great potential and broad possibilities of application. Thanks to these we can verify efficiency of treatment, predict locations of metastases of tumours, correlate results with histopathological examinations, or define the type of cancer more precisely. In effect, we obtain more personalised treatment for each patient, which is extremely important and highly recommendable in the tests and applicable treatment therapies conducted nowadays. Radiomics is a non-invasive and high efficiency post-processing method. This article is intended to explain the idea of radiomics, the mechanisms of data acquisition, existing possibilities, and the challenges incurred by radiologists and physicians at the stage of making diagnosis or conducting treatment.",1.0
30622070,Low-calorie sweeteners and health outcomes: A demonstration of rapid evidence mapping (rEM),2019 Feb;123:451-458.,"Background:                    ""Evidence Mapping"" is an emerging tool that is increasingly being used to systematically identify, review, organize, quantify, and summarize the literature. It can be used as an effective method for identifying well-studied topic areas relevant to a broad research question along with any important literature gaps. However, because the procedure can be significantly resource-intensive, approaches that can increase the speed and reproducibility of evidence mapping are in great demand.              Methods:                    We propose an alternative process called ""rapid Evidence Mapping"" (rEM) to map the scientific evidence in a time-efficient manner, while still utilizing rigorous, transparent and explicit methodological approaches. To illustrate its application, we have conducted a proof-of-concept case study on the topic of low-calorie sweeteners (LCS) with respect to human dietary exposures and health outcomes. During this process, we developed and made publicly available our study protocol, established a PECO (Participants, Exposure, Comparator, and Outcomes) statement, searched the literature, screened titles and abstracts to identify potentially relevant studies, and applied semi-automated machine learning approaches to tag and categorize the included articles. We created various visualizations including bubble plots and frequency tables to map the evidence and research gaps according to comparison type, population baseline health status, outcome group, and study sample size. We compared our results with a traditional evidence mapping of the same topic published in 2016 (Wang et al., 2016).              Results:                    We conducted an rEM of LCS, for which we identified 8122 records from a PubMed search (January 1, 1946-May 1, 2014) and then utilized machine learning (SWIFT-Active Screener) to prioritize relevant records. After screening 2267 (28%) of the total set of titles and abstracts to achieve 95% estimated recall, we ultimately included 297 relevant studies. Overall, our findings corroborated those of Wang et al. (2016) and identified that most studies were acute or short-term in healthy individuals, and studied the outcomes of appetite, energy sensing and body weight. We also identified a lack of studies assessing appetite and dietary intake related outcomes in people with diabetes. The rEM approach required approximately 100 person-hours conducted over 7 calendar months.              Conclusion:                    Rapid Evidence Mapping is an expeditious approach based on rigorous methodology that can be used to quickly summarize the available body of evidence relevant to a research question, identify gaps in the literature to inform future research, and contextualize the design of a systematic review within the broader scientific literature, significantly reducing human effort while yielding results comparable to those from traditional methods. The potential time savings of this approach in comparison to the traditional evidence mapping process make it a potentially powerful tool for rapidly translating knowledge to inform science-based decision-making.",3.0
30621954,New Concepts in Sudden Cardiac Arrest to Address an Intractable Epidemic: JACC State-of-the-Art Review,2019 Jan 8;73(1):70-88.,"Sudden cardiac arrest (SCA) is one of the largest causes of mortality globally, with an out-of-hospital survival below 10% despite intense research. This document outlines challenges in addressing the epidemic of SCA, along the framework of respond, understand and predict, and prevent. Response could be improved by technology-assisted orchestration of community responder systems, access to automated external defibrillators, and innovations to match resuscitation resources to victims in place and time. Efforts to understand and predict SCA may be enhanced by refining taxonomy along phenotypical and pathophysiological ""axes of risk,"" extending beyond cardiovascular pathology to identify less heterogeneous cohorts, facilitated by open-data platforms and analytics including machine learning to integrate discoveries across disciplines. Prevention of SCA must integrate these concepts, recognizing that all members of society are stakeholders. Ultimately, solutions to the public health challenge of SCA will require greater awareness, societal debate and focused public policy.",5.0
30621101,An Appraisal of Lung Nodules Automatic Classification Algorithms for CT Images,2019 Jan 7;19(1):194.,"Lung cancer is one of the most deadly diseases around the world representing about 26% of all cancers in 2017. The five-year cure rate is only 18% despite great progress in recent diagnosis and treatment. Before diagnosis, lung nodule classification is a key step, especially since automatic classification can help clinicians by providing a valuable opinion. Modern computer vision and machine learning technologies allow very fast and reliable CT image classification. This research area has become very hot for its high efficiency and labor saving. The paper aims to draw a systematic review of the state of the art of automatic classification of lung nodules. This research paper covers published works selected from the Web of Science, IEEEXplore, and DBLP databases up to June 2018. Each paper is critically reviewed based on objective, methodology, research dataset, and performance evaluation. Mainstream algorithms are conveyed and generic structures are summarized. Our work reveals that lung nodule classification based on deep learning becomes dominant for its excellent performance. It is concluded that the consistency of the research objective and integration of data deserves more attention. Moreover, collaborative works among developers, clinicians, and other parties should be strengthened.",6.0
30620934,Electronic nose: a non-invasive technology for breath analysis of diabetes and lung cancer patients,2019 Mar 6;13(2):024001.,"In human exhaled breath, more than 3000 volatile organic compounds (VOCs) are found, which are directly or indirectly related to internal biochemical processes in the body. Electronic noses (E-noses) could play a potential role in screening/analyzing various respiratory and systemic diseases by studying breath signatures. An E-nose integrates a sensor array and an artificial neural network that responds to specific patterns of VOCs, and thus can act as a non-invasive technology for disease monitoring. The gold standard blood glucose monitoring test for diabetes diagnostics is invasive and highly uncomfortable. This contributes to the massive need for technologies which are non-invasive and can be used as an alternative to blood measurements for glucose detection. While lung cancer is one of the deadliest cancers with the highest death rate and an extremely high yearly global burden, the conventional diagnosis means, such as sputum cytology, chest radiography, or computed tomography, do not support wide-range population screening. A few standard non-invasive techniques, such as mass spectrometry and gas chromatography, are expensive, non-portable, and require skilled personnel for operation and are again not suitable for large-scale screening. Breath contains markers for both diabetes and lung cancer along with markers for several diseases and thus, a non-invasive technique such as the E-nose would greatly improve analysis procedures over existing invasive methods. This review shows the state-of-the-art technologies for VOC detection and machine learning approaches for two clinical models: diabetes and lung cancer detection.",15.0
30619452,Recent Advances on the Machine Learning Methods in Identifying DNA Replication Origins in Eukaryotic Genomics,2018 Dec 10;9:613.,"The initiate site of DNA replication is called origins of replication (ORI) which is regulated by a set of regulatory proteins and plays important roles in the basic biochemical process during cell growth and division in all living organisms. Therefore, the study of ORIs is essential for understanding the cell-division cycle and gene expression regulation so that scholars can develop a new strategy against genetic diseases by using the knowledge of DNA replication. Thus, the accurate identification of ORIs will provide key clues for DNA replication research and clinical medicine. Although, the conventional experiments could provide accurate results, they are time-consuming and cost ineffective. On the contrary, bioinformatics-based methods can overcome these shortcomings. Especially, with the emergence of DNA sequences in the post-genomic era, it is highly expected to develop high throughput tools to identify ORIs based on sequence information. In this review, we will summarize the current progress in computational prediction of eukaryotic ORIs including the collection of benchmark dataset, the application of machine learning-based techniques, the results obtained by these methods, and the construction of web servers. Finally, we gave the future perspectives on ORIs prediction. The review provided readers with a whole background of ORIs prediction based on machine learning methods, which will be helpful for researchers to study DNA replication in-depth and drug therapy of genetic defect.",2.0
30619024,Monitoring Motor Symptoms During Activities of Daily Living in Individuals With Parkinson's Disease,2018 Dec 12;9:1036.,"This literature review addressed wearable sensor systems to monitor motor symptoms in individuals with Parkinson's disease (PD) during activities of daily living (ADLs). Specifically, progress in monitoring tremor, freezing of gait, dyskinesia, bradykinesia, and hypokinesia was reviewed. Twenty-seven studies were found that met the criteria of measuring symptoms in a home or home-like setting, with some studies examining multiple motor disorders. Accelerometers, gyroscopes, and electromyography sensors were included, with some studies using more than one type of sensor. Five studies measured tremor, five studies examined bradykinesia or hypokinesia, thirteen studies included devices to measure dyskinesia or motor fluctuations, and ten studies measured akinesia or freezing of gait. Current sensor technology can detect the presence and severity of each of these symptoms; however, most systems require sensors on multiple body parts, which is challenging for remote or ecologically valid observation. Different symptoms are detected by different sensor placement, suggesting that the goal of detecting all symptoms with a reduced set of sensors may not be achievable. For the goal of monitoring motor symptoms during ADLs in a home setting, the measurement system should be simple to use, unobtrusive to the wearer and easy for an individual with PD to put on and take off. Machine learning algorithms such as neural networks appear to be the most promising way to detect symptoms using a small number of sensors. More work should be done validating the systems during unscripted and unconstrained ADLs rather than in scripted motions.",15.0
30617331,Privacy in the age of medical big data,2019 Jan;25(1):37-43.,"Big data has become the ubiquitous watch word of medical innovation. The rapid development of machine-learning techniques and artificial intelligence in particular has promised to revolutionize medical practice from the allocation of resources to the diagnosis of complex diseases. But with big data comes big risks and challenges, among them significant questions about patient privacy. Here, we outline the legal and ethical challenges big data brings to patient privacy. We discuss, among other topics, how best to conceive of health privacy; the importance of equity, consent, and patient governance in data collection; discrimination in data uses; and how to handle data breaches. We close by sketching possible ways forward for the regulatory system.",41.0
30616329,Application of machine learning in rheumatic disease research,2019 Jul;34(4):708-722.,"Over the past decade, there has been a paradigm shift in how clinical data are collected, processed and utilized. Machine learning and artificial intelligence, fueled by breakthroughs in high-performance computing, data availability and algorithmic innovations, are paving the way to effective analyses of large, multi-dimensional collections of patient histories, laboratory results, treatments, and outcomes. In the new era of machine learning and predictive analytics, the impact on clinical decision-making in all clinical areas, including rheumatology, will be unprecedented. Here we provide a critical review of the machine-learning methods currently used in the analysis of clinical data, the advantages and limitations of these methods, and how they can be leveraged within the field of rheumatology.",5.0
30614150,Automated techniques for blood vessels segmentation through fundus retinal images: A review,2019 Feb;82(2):153-170.,"Retina is the interior part of human's eye, has a vital role in vision. The digital image captured by fundus camera is very useful to analyze the abnormalities in retina especially in retinal blood vessels. To get information of blood vessels through fundus retinal image, a precise and accurate vessels segmentation image is required. This segmented blood vessel image is most beneficial to detect retinal diseases. Many automated techniques are widely used for retinal vessels segmentation which is a primary element of computerized diagnostic systems for retinal diseases. The automatic vessels segmentation may lead to more challenging task in the presence of lesions and abnormalities. This paper briefly describes the various publicly available retinal image databases and various machine learning techniques. State of the art exhibited that researchers have proposed several vessel segmentation methods based on supervised and supervised techniques and evaluated their results mostly on publicly datasets such as digital retinal images for vessel extraction and structured analysis of the retina. A comprehensive review of existing supervised and unsupervised vessel segmentation techniques or algorithms is presented which describes the philosophy of each algorithm. This review will be useful for readers in their future research.",1.0
30613284,"The theranostic promise for Neuroendocrine Tumors in the late 2010s - Where do we stand, where do we go?",2018 Nov 29;8(22):6088-6100.,"More than 25 years after the first peptide receptor radionuclide therapy (PRRT), the concept of somatostatin receptor (SSTR)-directed imaging and therapy for neuroendocrine tumors (NET) is seeing rapidly increasing use. To maximize the full potential of its theranostic promise, efforts in recent years have expanded recommendations in current guidelines and included the evaluation of novel theranostic radiotracers for imaging and treatment of NET. Moreover, the introduction of standardized reporting framework systems may harmonize PET reading, address pitfalls in interpreting SSTR-PET/CT scans and guide the treating physician in selecting PRRT candidates. Notably, the concept of PRRT has also been applied beyond oncology, e.g. for treatment of inflammatory conditions like sarcoidosis. Future perspectives may include the efficacy evaluation of PRRT compared to other common treatment options for NET, novel strategies for closer monitoring of potential side effects, the introduction of novel radiotracers with beneficial pharmacodynamic and kinetic properties or the use of supervised machine learning approaches for outcome prediction. This article reviews how the SSTR-directed theranostic concept is currently applied and also reflects on recent developments that hold promise for the future of theranostics in this context.",14.0
30610579,Precision medicine review: rare driver mutations and their biophysical classification,2019 Feb;11(1):5-19.,"How can biophysical principles help precision medicine identify rare driver mutations? A major tenet of pragmatic approaches to precision oncology and pharmacology is that driver mutations are very frequent. However, frequency is a statistical attribute, not a mechanistic one. Rare mutations can also act through the same mechanism, and as we discuss below, ""latent driver"" mutations may also follow the same route, with ""helper"" mutations. Here, we review how biophysics provides mechanistic guidelines that extend precision medicine. We outline principles and strategies, especially focusing on mutations that drive cancer. Biophysics has contributed profoundly to deciphering biological processes. However, driven by data science, precision medicine has skirted some of its major tenets. Data science embodies genomics, tissue- and cell-specific expression levels, making it capable of defining genome- and systems-wide molecular disease signatures. It classifies cancer driver genes/mutations and affected pathways, and its associated protein structural data guide drug discovery. Biophysics complements data science. It considers structures and their heterogeneous ensembles, explains how mutational variants can signal through distinct pathways, and how allo-network drugs can be harnessed. Biophysics clarifies how one mutation-frequent or rare-can affect multiple phenotypic traits by populating conformations that favor interactions with other network modules. It also suggests how to identify such mutations and their signaling consequences. Biophysics offers principles and strategies that can help precision medicine push the boundaries to transform our insight into biological processes and the practice of personalized medicine. By contrast, ""phenotypic drug discovery,"" which capitalizes on physiological cellular conditions and first-in-class drug discovery, may not capture the proper molecular variant. This is because variants of the same protein can express more than one phenotype, and a phenotype can be encoded by several variants.",13.0
30609719,"A Comprehensive Survey on Spectrum Sensing in Cognitive Radio Networks: Recent Advances, New Challenges, and Future Research Directions",2019 Jan 2;19(1):126.,"Cognitive radio technology has the potential to address the shortage of available radio spectrum by enabling dynamic spectrum access. Since its introduction, researchers have been working on enabling this innovative technology in managing the radio spectrum. As a result, this research field has been progressing at a rapid pace and significant advances have been made. To help researchers stay abreast of these advances, surveys and tutorial papers are strongly needed. Therefore, in this paper, we aimed to provide an in-depth survey on the most recent advances in spectrum sensing, covering its development from its inception to its current state and beyond. In addition, we highlight the efficiency and limitations of both narrowband and wideband spectrum sensing techniques as well as the challenges involved in their implementation. TV white spaces are also discussed in this paper as the first real application of cognitive radio. Last but by no means least, we discuss future research directions. This survey paper was designed in a way to help new researchers in the field to become familiar with the concepts of spectrum sensing, compressive sensing, and machine learning, all of which are the enabling technologies of the future networks, yet to help researchers further improve the efficiently of spectrum sensing.",13.0
30609102,Machine learning in suicide science: Applications and ethics,2019 May;37(3):214-222.,"For decades, our ability to predict suicide has remained at near-chance levels. Machine learning has recently emerged as a promising tool for advancing suicide science, particularly in the domain of suicide prediction. The present review provides an introduction to machine learning and its potential application to open questions in suicide research. Although only a few studies have implemented machine learning for suicide prediction, results to date indicate considerable improvement in accuracy and positive predictive value. Potential barriers to algorithm integration into clinical practice are discussed, as well as attendant ethical issues. Overall, machine learning approaches hold promise for accurate, scalable, and effective suicide risk detection; however, many critical questions and issues remain unexplored.",8.0
30599936,Interplay between food and gut microbiota in health and disease,2019 Jan;115:23-31.,"Numerous microorganisms colonize the human gastrointestinal tract playing pivotal roles in relation to digestion and absorption of dietary components. They biotransform food components and produce metabolites, which in combination with food components shape and modulate the host immune system and metabolic responses. Reciprocally, the diet modulates the composition and functional capacity of the gut microbiota, which subsequently influence host biochemical processes establishing a system of mutual interaction and inter-dependency. Macronutrients, fibers, as well as polyphenols and prebiotics are strong drivers shaping the composition of the gut microbiota. Especially, short-chain fatty acids produced from ingested fibers and tryptophan metabolites are key in modulating host immune responses. Since reciprocal interactions between diet, host, and microbiota are personal, understanding this complex network of interactions calls for novel use of large datasets and the implementation of machine learning algorithms and artificial intelligence. In this review, we aim to provide a base for future investigations of how interactions between food components and gut microbiota may influence or even determine human health and disease.",15.0
30599797,Cortico-limbic connectivity as a possible biomarker for bipolar disorder: where are we now?,2019 Feb;19(2):159-172.,"The fronto-limbic network has been suggested as a key circuitry in the pathophysiology and maintenance of bipolar disorder. In the past decade, a disrupted connectivity within prefrontal-limbic structures was identified as a promising candidate biomarker for the disorder. Areas Covered: In this review, the authors examine current literature in terms of the structural, functional and effective connectivity in bipolar disorder, integrating recent findings of imaging genetics and machine learning. This paper profiles the current knowledge and identifies future perspectives to provide reliable and usable neuroimaging biomarkers for bipolar psychopathology in clinical practice. Expert Opinion: The replication and the translation of acquired knowledge into useful and usable tools represents one of the current greatest challenges in biomarker research applied to psychiatry.",2.0
30594648,RNA splicing analysis in genomic medicine,2019 Mar;108:61-71.,"High-throughput next-generation sequencing technologies have led to a rapid increase in the number of sequence variants identified in clinical practice via diagnostic genetic tests. Current bioinformatic analysis pipelines fail to take adequate account of the possible splicing effects of such variants, particularly where variants fall outwith canonical splice site sequences, and consequently the pathogenicity of such variants may often be missed. The regulation of splicing is highly complex and as a result, in silico prediction tools lack sufficient sensitivity and specificity for reliable use. Variants of all kinds can be linked to aberrant splicing in disease and the need for correct identification and diagnosis grows ever more crucial as novel splice-switching antisense oligonucleotide therapies start to enter clinical usage. RT-PCR provides a useful targeted assay of the splicing effects of identified variants, while minigene assays, massive parallel reporter assays and animal models can also be used for more detailed study of a particular splicing system, given enough time and resources. However, RNA-sequencing (RNA-seq) has the potential to be used as a rapid diagnostic tool in genomic medicine. By utilising data science approaches and machine learning, it may prove possible to finally understand and interpret the 'splicing code' and apply this knowledge in human disease diagnostics.",7.0
30594306,Toxicogenomics: A 2020 Vision,2019 Feb;40(2):92-103.,"Toxicogenomics (TGx) has contributed significantly to toxicology and now has great potential to support moves towards animal-free approaches in regulatory decision making. Here, we discuss in vitro TGx systems and their potential impact on risk assessment. We raise awareness of the rapid advancement of genomics technologies, which generates novel genomics features essential for enhanced risk assessment. We specifically emphasize the importance of reproducibility in utilizing TGx in the regulatory setting. We also highlight the role of machine learning (particularly deep learning) in developing TGx-based predictive models. Lastly, we touch on the topics of how TGx approaches could facilitate adverse outcome pathways (AOP) development and enhance read-across strategies to further regulatory application. Finally, we summarize current efforts to develop TGx for risk assessment and set out remaining challenges.",16.0
30591420,Connected orthopedics and trauma surgery: New perspectives,2019 Feb;105(1S):S15-S22.,"Information is everywhere in the surgeon's life. It can improve medical practice and allow for personalized care. To answer the question, ""How should the surgeon be connected?"" we must assess the role and limitations of digital information in daily practice, particularly through mobile applications or mHealth. These tools and their scope must be defined in order to measure their impact on our clinical practice. New regulations on medical data have been introduced imposing that privacy be maintained. Connected applications can assist the surgeon in making the diagnosis and deciding on the treatment. These tools are already being used widely. Decision algorithms based on machine learning are also a promising way to optimize patient care. Connected applications make the clinical follow-up easier by allowing more reliable, relevant and frequent data transmission. They also provide access to information and training, either early academic learning or continuing medical education. We must adapt to these new modes of learning. Thus, smartphones, tablets and digital applications now have a central role in modern orthopedic surgery. Surgeons have information, technical resources and storage for research data at their disposal, while patients can establish a link with their doctor (current or future) and find lay information about their condition.",2.0
30591356,Big Data Analysis and Machine Learning in Intensive Care Units,2019 Oct;43(7):416-426.,"Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data.",4.0
30586882,Hand Gesture Recognition in Automotive Human⁻Machine Interaction Using Depth Cameras,2018 Dec 24;19(1):59.,"In this review, we describe current Machine Learning approaches to hand gesture recognition with depth data from time-of-flight sensors. In particular, we summarise the achievements on a line of research at the Computational Neuroscience laboratory at the Ruhr West University of Applied Sciences. Relating our results to the work of others in this field, we confirm that Convolutional Neural Networks and Long Short-Term Memory yield most reliable results. We investigated several sensor data fusion techniques in a deep learning framework and performed user studies to evaluate our system in practice. During our course of research, we gathered and published our data in a novel benchmark dataset (REHAP), containing over a million unique three-dimensional hand posture samples.",5.0
30581287,Forty years of structural brain imaging in mental disorders: is it clinically useful or not?,2018 Sep;20(3):179-186.,"Structural brain imaging was introduced into routine clinical practice more than 40 years ago with the hope that it would support the diagnosis and treatment of mental disorders. It is now widely used to exclude organic brain disease (eg, brain tumors, cardiovascular, and inflammatory processes) in mental disorders. However, questions have been raised about whether structural brain imaging is still needed today and whether it could also be clinically useful to apply new biostatistical methods, such as machine learning. Therefore, the current paper not only reviews structural findings in Alzheimer disease, depression, bipolar disorder, and schizophrenia but also discusses the role of structural imaging in supporting diagnostic, prognostic, and therapeutic processes in mental disorders. Thus, it attempts to answer the questions whether, after four decades of use, structural brain imaging is clinically useful in mental disorders or whether it will become so in the future.",3.0
30580109,Driving status of patients with generalized spike-wave on EEG but no clinical seizures,2019 Mar;92:5-13.,"Generalized spike-wave discharges (SWDs) are the hallmark of generalized epilepsy on the electroencephalogram (EEG). In clinically obvious cases, generalized SWDs produce myoclonic, atonic/tonic, or absence seizures with brief episodes of staring and behavioral unresponsiveness. However, some generalized SWDs have no obvious behavioral effects. A serious challenge arises when patients with no clinical seizures request driving privileges and licensure, yet their EEG shows generalized SWD. Specialized behavioral testing has demonstrated prolonged reaction times or missed responses during SWD, which may present a driving hazard even when patients or family members do not notice any deficits. On the other hand, some SWDs are truly asymptomatic in which case driving privileges should not be restricted. Clinicians often decide on driving privileges based on SWD duration or other EEG features. However, there are currently no empirically-validated guidelines for distinguishing generalized SWDs that are ""safe"" versus ""unsafe"" for driving. Here, we review the clinical presentation of generalized SWD and recent work investigating mechanisms of behavioral impairment during SWD with implications for driving safety. As a future approach, computational analysis of large sets of EEG data during simulated driving utilizing machine learning could lead to powerful methods to classify generalized SWD as safe vs. unsafe. This may ultimately provide more objective EEG criteria to guide decisions on driving safety in people with epilepsy.",2.0
30578332,Role of imaging in progressive-fibrosing interstitial lung diseases,2018 Dec 21;27(150):180073.,"Imaging techniques are an essential component of the diagnostic process for interstitial lung diseases (ILDs). Chest radiography is frequently the initial indicator of an ILD, and comparison of radiographs taken at different time points can show the rate of disease progression. However, radiography provides only limited specificity and sensitivity and is primarily used to rule out other diseases, such as left heart failure. High-resolution computed tomography (HRCT) is a more sensitive method and is considered central in the diagnosis of ILDs. Abnormalities observed on HRCT can help identify specific ILDs. HRCT also can be used to evaluate the patient's prognosis, while disease progression can be assessed through serial imaging. Other imaging techniques such as positron emission tomography-computed tomography and magnetic resonance imaging have been investigated, but they are not commonly used to assess patients with ILDs. Disease severity may potentially be estimated using quantitative methods, as well as visual analysis of images. For example, comprehensive assessment of disease staging and progression in patients with ILDs requires visual analysis of pulmonary features that can be performed in parallel with quantitative analysis of the extent of fibrosis. New approaches to image analysis, including the application of machine learning, are being developed.",6.0
30576418,Research progress in protein posttranslational modification site prediction,2018 Jul 22;18(4):220-229.,"Posttranslational modifications (PTMs) play an important role in regulating protein folding, activity and function and are involved in almost all cellular processes. Identification of PTMs of proteins is the basis for elucidating the mechanisms of cell biology and disease treatments. Compared with the laboriousness of equivalent experimental work, PTM prediction using various machine-learning methods can provide accurate, simple and rapid research solutions and generate valuable information for further laboratory studies. In this review, we manually curate most of the bioinformatics tools published since 2008. We also summarize the approaches for predicting ubiquitination sites and glycosylation sites. Moreover, we discuss the challenges of current PTM bioinformatics tools and look forward to future research possibilities.",3.0
30575178,Deep learning in radiology: An overview of the concepts and a survey of the state of the art with focus on MRI,2019 Apr;49(4):939-954.,"Deep learning is a branch of artificial intelligence where networks of simple interconnected units are used to extract patterns from data in order to solve complex problems. Deep-learning algorithms have shown groundbreaking performance in a variety of sophisticated tasks, especially those related to images. They have often matched or exceeded human performance. Since the medical field of radiology mainly relies on extracting useful information from images, it is a very natural application area for deep learning, and research in this area has rapidly grown in recent years. In this article, we discuss the general context of radiology and opportunities for application of deep-learning algorithms. We also introduce basic concepts of deep learning, including convolutional neural networks. Then, we present a survey of the research in deep learning applied to radiology. We organize the studies by the types of specific tasks that they attempt to solve and review a broad range of deep-learning algorithms being utilized. Finally, we briefly discuss opportunities and challenges for incorporating deep learning in the radiology practice of the future. Level of Evidence: 3 Technical Efficacy: Stage 1 J. Magn. Reson. Imaging 2019;49:939-954.",42.0
30573283,The value of MR textural analysis in prostate cancer,2019 Nov;74(11):876-885.,"Current diagnosis and treatment stratification of patients with suspected prostate cancer relies on a combination of histological and magnetic resonance imaging (MRI) findings. The aim of this article is to provide a brief overview of prostate pathological grading as well as the relevant aspects of multiparametric (MRI) mpMRI, before indicating the potential that magnetic resonance textural analysis (MRTA) offers within prostate cancer. A review of the evidence base on MRTA in prostate cancer will enable discussion of the utility of this field while also indicating recommendations to future research. Radiomic textural analysis allows the assessment of spatial inter-relationships between pixels within an image by use of mathematical methods. First-order textural analysis is better understood and may have more clinical validity than higher-order textural features. Textural features extracted from apparent diffusion coefficient maps have shown the most potential for clinical utility in MRTA of prostate cancers. Future studies should aim to integrate machine learning techniques to better represent the role of MRTA in prostate cancer clinical practice. Nomenclature should be used to reduce misidentification between first-order and second-order energy and entropy. Automated methods of segmentation should be encouraged in order to reduce problems associated with inclusion of normal tissue within regions of interest. The retrospective and small-scale nature of most published studies, make it difficult to draw meaningful conclusions. Future larger prospective studies are required to validate the textural features indicated to have potential in characterisation and/or diagnosis of prostate cancer before translation into routine clinical practice.",5.0
30571146,Childhood Asthma: Advances Using Machine Learning and Mechanistic Studies,2019 Feb 15;199(4):414-422.,"A paradigm shift brought by the recognition that childhood asthma is an aggregated diagnosis that comprises several different endotypes underpinned by different pathophysiology, coupled with advances in understanding potentially important causal mechanisms, offers a real opportunity for a step change to reduce the burden of the disease on individual children, families, and society. Data-driven methodologies facilitate the discovery of ""hidden"" structures within ""big healthcare data"" to help generate new hypotheses. These findings can be translated into clinical practice by linking discovered ""phenotypes"" to specific mechanisms and clinical presentations. Epidemiological studies have provided important clues about mechanistic avenues that should be pursued to identify interventions to prevent the development or alter the natural history of asthma-related diseases. Findings from cohort studies followed by mechanistic studies in humans and in neonatal mouse models provided evidence that environments such as traditional farming may offer protection by modulating innate immune responses and that impaired innate immunity may increase susceptibility. The key question of which component of these exposures can be translated into interventions requires confirmation. Increasing mechanistic evidence is demonstrating that shaping the microbiome in early life may modulate immune function to confer protection. Iterative dialogue and continuous interaction between experts with different but complementary skill sets, including data scientists who generate information about the hidden structures within ""big data"" assets, and medical professionals, epidemiologists, basic scientists, and geneticists who provide critical clinical and mechanistic insights about the mechanisms underpinning the architecture of the heterogeneity, are keys to delivering mechanism-based stratified treatments and prevention.",9.0
30566385,The Digitization of Patient Care: A Review of the Effects of Electronic Health Records on Health Care Quality and Utilization,2019 Apr 1;40:487-500.,"Electronic health records (EHRs) adoption has become nearly universal during the past decade. Academic research into the effects of EHRs has examined factors influencing adoption, clinical care benefits, financial and cost implications, and more. We provide an interdisciplinary overview and synthesis of this literature, drawing on work in public and population health, informatics, medicine, management information systems, and economics. We then chart paths forward for policy, practice, and research.",8.0
30565841,Deep Learning in Image Cytometry: A Review,2019 Apr;95(4):366-380.,"Artificial intelligence, deep convolutional neural networks, and deep learning are all niche terms that are increasingly appearing in scientific presentations as well as in the general media. In this review, we focus on deep learning and how it is applied to microscopy image data of cells and tissue samples. Starting with an analogy to neuroscience, we aim to give the reader an overview of the key concepts of neural networks, and an understanding of how deep learning differs from more classical approaches for extracting information from image data. We aim to increase the understanding of these methods, while highlighting considerations regarding input data requirements, computational resources, challenges, and limitations. We do not provide a full manual for applying these methods to your own data, but rather review previously published articles on deep learning in image cytometry, and guide the readers toward further reading on specific networks and methods, including new methods not yet applied to cytometry data. © 2018 The Authors. Cytometry Part A published by Wiley Periodicals, Inc. on behalf of International Society for Advancement of Cytometry.",24.0
30561351,Neuroimaging and Machine Learning for Dementia Diagnosis: Recent Advancements and Future Prospects,2019;12:19-33.,"Dementia, a chronic and progressive cognitive declination of brain function caused by disease or impairment, is becoming more prevalent due to the aging population. A major challenge in dementia is achieving accurate and timely diagnosis. In recent years, neuroimaging with computer-aided algorithms have made remarkable advances in addressing this challenge. The success of these approaches is mostly attributed to the application of machine learning techniques for neuroimaging. In this review paper, we present a comprehensive survey of automated diagnostic approaches for dementia using medical image analysis and machine learning algorithms published in the recent years. Based on the rigorous review of the existing works, we have found that, while most of the studies focused on Alzheimer's disease, recent research has demonstrated reasonable performance in the identification of other types of dementia remains a major challenge. Multimodal imaging analysis deep learning approaches have shown promising results in the diagnosis of these other types of dementia. The main contributions of this review paper are as follows. 1) Based on the detailed analysis of the existing literature, this paper discusses neuroimaging procedures for dementia diagnosis. 2) It systematically explains the most recent machine learning techniques and, in particular, deep learning approaches for early detection of dementia.",9.0
30560558,An evidence-based approach to the routine use of optical coherence tomography,2019 May;102(3):242-259.,"Optical coherence tomography is an imaging technology that has revolutionised the detection, assessment and management of ocular disease. It is now a mainstream technology in clinical practice and is performed by non-specialised personnel in some settings. This article provides a clinical perspective on the implications of that movement and describes best practice using multimodal imaging and an evidence-based approach. Practical, illustrative guides on the interpretation of optical coherence tomography are provided for three major diseases of the ocular fundus, in which optical coherence tomography is often crucial to management: age-related macular degeneration, diabetic retinopathy and glaucoma. Topics discussed include: cross-sectional and longitudinal signs in ocular disease, so-called 'red-green' disease whereby clinicians rely on machine/statistical comparisons for diagnosis in managing treatment-naïve patients, and the utility of optical coherence tomography angiography and machine learning.",
30560386,High Throughput and Computational Repurposing for Neglected Diseases,2018 Dec 17;36(2):27.,"Purpose:                    Neglected tropical diseases (NTDs) represent are a heterogeneous group of communicable diseases that are found within the poorest populations of the world. There are 23 NTDs that have been prioritized by the World Health Organization, which are endemic in 149 countries and affect more than 1.4 billion people, costing these developing economies billions of dollars annually. The NTDs result from four different causative pathogens: protozoa, bacteria, helminth and virus. The majority of the diseases lack effective treatments. Therefore, new therapeutics for NTDs are desperately needed.              Methods:                    We describe various high throughput screening and computational approaches that have been performed in recent years. We have collated the molecules identified in these studies and calculated molecular properties.              Results:                    Numerous global repurposing efforts have yielded some promising compounds for various neglected tropical diseases. These compounds when analyzed as one would expect appear drug-like. Several large datasets are also now in the public domain and this enables machine learning models to be constructed that then facilitate the discovery of new molecules for these pathogens.              Conclusions:                    In the space of a few years many groups have either performed experimental or computational repurposing high throughput screens against neglected diseases. These have identified compounds which in many cases are already approved drugs. Such approaches perhaps offer a more efficient way to develop treatments which are generally not a focus for global pharmaceutical companies because of the economics or the lack of a viable market. Other diseases could perhaps benefit from these repurposing approaches.",11.0
30557052,Risk Stratification for Screening Mammography: Benefits and Harms,2019 Feb;212(2):250-258.,"Objective:                    The purpose of this article is to compare commonly used breast cancer risk assessment models, describe the machine learning approach and big data in risk prediction, and summarize the potential benefits and harms of restrictive risk-based screening.              Conclusion:                    The commonly used risk assessment models for breast cancer can be complex and cumbersome to use. Each model incorporates different sets of risk factors, which are weighted differently and can produce different results for the same patient. No model is appropriate for all subgroups of the general population and only one model incorporates mammographic breast density. Future development of risk prediction tools that are generalizable and simpler to use are needed in guiding clinical decisions.",
30557049,Artificial Intelligence for Medical Image Analysis: A Guide for Authors and Reviewers,2019 Mar;212(3):513-519.,"Objective:                    The purpose of this article is to highlight best practices for writing and reviewing articles on artificial intelligence for medical image analysis.              Conclusion:                    Artificial intelligence is in the early phases of application to medical imaging, and patient safety demands a commitment to sound methods and avoidance of rhetorical and overly optimistic claims. Adherence to best practices should elevate the quality of articles submitted to and published by clinical journals.",15.0
30555503,Statistical and Machine Learning Approaches to Predict Gene Regulatory Networks From Transcriptome Datasets,2018 Nov 29;9:1770.,"Statistical and machine learning (ML)-based methods have recently advanced in construction of gene regulatory network (GRNs) based on high-throughput biological datasets. GRNs underlie almost all cellular phenomena; hence, comprehensive GRN maps are essential tools to elucidate gene function, thereby facilitating the identification and prioritization of candidate genes for functional analysis. High-throughput gene expression datasets have yielded various statistical and ML-based algorithms to infer causal relationship between genes and decipher GRNs. This review summarizes the recent advancements in the computational inference of GRNs, based on large-scale transcriptome sequencing datasets of model plants and crops. We highlight strategies to select contextual genes for GRN inference, and statistical and ML-based methods for inferring GRNs based on transcriptome datasets from plants. Furthermore, we discuss the challenges and opportunities for the elucidation of GRNs based on large-scale datasets obtained from emerging transcriptomic applications, such as from population-scale, single-cell level, and life-course transcriptome analyses.",5.0
30555113,On medical application of neural networks trained with various types of data,2019 Jan 22;12(6):553-559.,"Neural networks have garnered attention over the past few years. A neural network is a typical model of machine learning that is used to identify visual patterns. Neural networks are used to solve a wide variety of problems, including image recognition problems and time series prediction problems. In addition, neural networks have been applied to medicine over the past few years. This paper classifies the ways in which neural networks have been applied to medicine based on the type of data used to train those networks. Applications of neural networks to medicine can be categorized two types: automated diagnosis and physician aids. Considering the number of patients per physician, neural networks could be used to diagnose diseases related to the vascular system, heart, brain, spinal column, head, neck, and tumors/cancer in three fields: vascular and interventional radiology, interventional cardiology, and neuroradiology. Lastly, this paper also considers areas of medicine where neural networks can be effectively applied in the future.",1.0
30554770,Embracing Environmental Genomics and Machine Learning for Routine Biomonitoring,2019 May;27(5):387-397.,"Genomics is fast becoming a routine tool in medical diagnostics and cutting-edge biotechnologies. Yet, its use for environmental biomonitoring is still considered a futuristic ideal. Until now, environmental genomics was mainly used as a replacement of the burdensome morphological identification, to screen known morphologically distinguishable bioindicator taxa. While prokaryotic and eukaryotic microbial diversity is of key importance in ecosystem functioning, its implementation in biomonitoring programs is still largely unappreciated, mainly because of difficulties in identifying microbes and limited knowledge of their ecological functions. Here, we argue that the combination of massive environmental genomics microbial data with machine learning algorithms can be extremely powerful for biomonitoring programs and pave the way to fill important gaps in our understanding of microbial ecology.",5.0
30553609,An overview of deep learning in medical imaging focusing on MRI,2019 May;29(2):102-127.,"What has happened in machine learning lately, and what does it mean for the future of medical image analysis? Machine learning has witnessed a tremendous amount of attention over the last few years. The current boom started around 2009 when so-called deep artificial neural networks began outperforming other established models on a number of important benchmarks. Deep neural networks are now the state-of-the-art machine learning models across a variety of areas, from image analysis to natural language processing, and widely deployed in academia and industry. These developments have a huge potential for medical imaging technology, medical data analysis, medical diagnostics and healthcare in general, slowly being realized. We provide a short overview of recent advances and some associated challenges in machine learning applied to medical image processing and image analysis. As this has become a very broad and fast expanding field we will not survey the entire landscape of applications, but put particular focus on deep learning in MRI. Our aim is threefold: (i) give a brief introduction to deep learning with pointers to core references; (ii) indicate how deep learning has been applied to the entire MRI processing chain, from acquisition to image retrieval, from segmentation to disease prediction; (iii) provide a starting point for people interested in experimenting and perhaps contributing to the field of deep learning for medical imaging by pointing out good educational resources, state-of-the-art open-source code, and interesting sources of data and problems related medical imaging.",86.0
30548534,Integrating molecular networks with genetic variant interpretation for precision medicine,2019 May;11(3):e1443.,"More reliable and cheaper sequencing technologies have revealed the vast mutational landscapes characteristic of many phenotypes. The analysis of such genetic variants has led to successful identification of altered proteins underlying many Mendelian disorders. Nevertheless the simple one-variant one-phenotype model valid for many monogenic diseases does not capture the complexity of polygenic traits and disorders. Although experimental and computational approaches have improved detection of functionally deleterious variants and important interactions between gene products, the development of comprehensive models relating genotype and phenotypes remains a challenge in the field of genomic medicine. In this context, a new view of the pathologic state as significant perturbation of the network of interactions between biomolecules is crucial for the identification of biochemical pathways associated with complex phenotypes. Seminal studies in systems biology combined the analysis of genetic variation with protein-protein interaction networks to demonstrate that even as biological systems evolve to be robust to genetic variation, their topologies create disease vulnerabilities. More recent analyses model the impact of genetic variants as changes to the ""wiring"" of the interactome to better capture heterogeneity in genotype-phenotype relationships. These studies lay the foundation for using networks to predict variant effects at scale using machine-learning or algorithmic approaches. A wealth of databases and resources for the annotation of genotype-phenotype relationships have been developed to support developments in this area. This overview describes how study of the molecular interactome has generated insights linking the organization of biological systems to disease mechanism, and how this information can enable precision medicine. This article is categorized under: Translational, Genomic, and Systems Medicine > Translational Medicine Biological Mechanisms > Cell Signaling Models of Systems Properties and Processes > Mechanistic Models Analytical and Computational Methods > Computational Methods.",11.0
30547445,Using Drug Expression Profiles and Machine Learning Approach for Drug Repurposing,2019;1903:219-237.,"The cost of new drug development has been increasing, and repurposing known medications for new indications serves as an important way to hasten drug discovery. One promising approach to drug repositioning is to take advantage of machine learning (ML) algorithms to learn patterns in biological data related to drugs and then link them up to the potential of treating specific diseases. Here we give an overview of the general principles and different types of ML algorithms, as well as common approaches to evaluating predictive performances, with reference to the application of ML algorithms to predict repurposing opportunities using drug expression data as features. We will highlight common issues and caveats when applying such models to repositioning. We also introduce resources of drug expression data and highlight recent studies employing such an approach to repositioning.",5.0
30547396,Overview and Evaluation of Recent Methods for Statistical Inference of Gene Regulatory Networks from Time Series Data,2019;1883:49-94.,"A challenging problem in systems biology is the reconstruction of gene regulatory networks from postgenomic data. A variety of reverse engineering methods from machine learning and computational statistics have been proposed in the literature. However, deciding on the best method to adopt for a particular application or data set might be a confusing task. The present chapter provides a broad overview of state-of-the-art methods with an emphasis on conceptual understanding rather than a deluge of mathematical details, and the pros and cons of the various approaches are discussed. Guidance on practical applications with pointers to publicly available software implementations are included. The chapter concludes with a comprehensive comparative benchmark study on simulated data and a real-work application taken from the current plant systems biology.",1.0
30547185,Breaking the curse of dimensionality to identify causal variants in Breeding 4,2019 Mar;132(3):559-567.,"In the past, plant breeding has undergone three major transformations and is currently transitioning to a new technological phase, Breeding 4. This phase is characterized by the development of methods for biological design of plant varieties, including transformation and gene editing techniques directed toward causal loci. The application of such technologies will require to reliably estimate the effect of loci in plant genomes by avoiding the situation where the number of loci assayed (p) surpasses the number of plant genotypes (n). Here, we discuss approaches to avoid this curse of dimensionality (n ≪ p), which will involve analyzing intermediate phenotypes such as molecular traits and component traits related to plant morphology or physiology. Because these approaches will rely on novel data types such as DNA sequences and high-throughput phenotyping images, Breeding 4 will call for analyses that are complementary to traditional quantitative genetic studies, being based on machine learning techniques which make efficient use of sequence and image data. In this article, we will present some of these techniques and their application for prioritizing causal loci and developing improved varieties in Breeding 4.",10.0
30545729,"Esophageal atresia, Europe, and the future: BAPS Journal of Pediatric Surgery Lecture",2019 Feb;54(2):217-222.,"Europe has changed remarkably over the past decades and so have concepts and outcomes of esophageal atresia repair. In this article, both the efforts to create a united Europe and the achievements in dealing with esophageal atresia from the 1950s on are outlined. Furthermore, this paper deals with the future of pediatric surgery and is focused on two aspects: the ""Fourth Industrial Revolution"" which builds on the digital revolution, artificial intelligence and robotics, and its potential impact on pediatric surgery and the life of patients. I suggest that pediatric surgeons should participate and lead in the development of machine learning, data control, assuring appropriate use of machines, control misuse, and in particular ensure appropriate maintenance of ethical standards. Changes in health care structures within Europe, in particular the effect of centralization, will affect the concept of treatment for patients with rare diseases.",1.0
30544901,Assessing the Role of Artificial Intelligence (AI) in Clinical Oncology: Utility of Machine Learning in Radiotherapy Target Volume Delineation,2018 Dec 11;5(4):131.,"The fields of radiotherapy and clinical oncology have been rapidly changed by the advances of technology. Improvement in computer processing power and imaging quality heralded precision radiotherapy allowing radiotherapy to be delivered efficiently, safely and effectively for patient benefit. Artificial intelligence (AI) is an emerging field of computer science which uses computer models and algorithms to replicate human-like intelligence and perform specific tasks which offers a huge potential to healthcare. We reviewed and presented the history, evolution and advancement in the fields of radiotherapy, clinical oncology and machine learning. Radiotherapy target delineation is a complex task of outlining tumour and organ at risks volumes to allow accurate delivery of radiotherapy. We discussed the radiotherapy planning, treatment delivery and reviewed how technology can help with this challenging process. We explored the evidence and clinical application of machine learning to radiotherapy. We concluded on the challenges, possible future directions and potential collaborations to achieve better outcome for cancer patients.",9.0
30544420,Machine learning methods for automatic pain assessment using facial expression information: Protocol for a systematic review and meta-analysis,2018 Dec;97(49):e13421.,"Introduction:                    Prediction of pain using machine learning algorithms is an emerging field in both computer science and clinical medicine. Several machine algorithms were developed and validated in recent years. However, the majority of studies in this topic was published on bioinformatics or computer science journals instead of medical journals. This tendency and preference led to a gap of knowledge and acknowledgment between computer scientists who invent the algorithm and medical researchers who may use the algorithms in practice. As a consequence, some of these prediction papers did not discuss the clinical utility aspects and were causally reported without following related professional guidelines (e.g., TRIPOD statement). The aim of this protocol is to systematically summarize the current evidences about performance and utility of different machine learning methods used for automatic pain assessments based on human facial expression. In addition, this study is aimed to demonstrate and fill the knowledge gap to promote interdisciplinary collaboration.              Methods and analysis:                    We will search all English language literature in the following electronic databases: PubMed, Web of Science and IEEE Xplore. A systematic review and meta-analysis summarizing the accuracy, interpretability, generalizability, and computational efficiency of machine learning methods will be conducted. Subgroup analyses by machine learning method types will be conducted.              Timeline:                    The formal meta-analysis will start on Jan 15, 2019 and expected to finish by April 15, 2019.              Ethics and dissemination:                    Ethical approval will be exempted or will not be required because the data collected and analyzed in this meta-analysis will not be on an individual level. The results will be disseminated in the form of an official publication in a peer-reviewed journal and/or presentation at relevant conferences.              Registration:                    PROSPERO CRD42018103059.",1.0
30541791,Big data and black-box medical algorithms,2018 Dec 12;10(471):eaao5333.,"New machine-learning techniques entering medicine present challenges in validation, regulation, and integration into practice.",10.0
30523919,A comprehensive review of EEG-based brain-computer interface paradigms,2019 Feb;16(1):011001.,"Advances in brain science and computer technology in the past decade have led to exciting developments in brain-computer interface (BCI), thereby making BCI a top research area in applied science. The renaissance of BCI opens new methods of neurorehabilitation for physically disabled people (e.g. paralyzed patients and amputees) and patients with brain injuries (e.g. stroke patients). Recent technological advances such as wireless recording, machine learning analysis, and real-time temporal resolution have increased interest in electroencephalographic (EEG) based BCI approaches. Many BCI studies have focused on decoding EEG signals associated with whole-body kinematics/kinetics, motor imagery, and various senses. Thus, there is a need to understand the various experimental paradigms used in EEG-based BCI systems. Moreover, given that there are many available options, it is essential to choose the most appropriate BCI application to properly manipulate a neuroprosthetic or neurorehabilitation device. The current review evaluates EEG-based BCI paradigms regarding their advantages and disadvantages from a variety of perspectives. For each paradigm, various EEG decoding algorithms and classification methods are evaluated. The applications of these paradigms with targeted patients are summarized. Finally, potential problems with EEG-based BCI systems are discussed, and possible solutions are proposed.",23.0
30523334,Machine-learning-based patient-specific prediction models for knee osteoarthritis,2019 Jan;15(1):49-60.,"Osteoarthritis (OA) is an extremely common musculoskeletal disease. However, current guidelines are not well suited for diagnosing patients in the early stages of disease and do not discriminate patients for whom the disease might progress rapidly. The most important hurdle in OA management is identifying and classifying patients who will benefit most from treatment. Further efforts are needed in patient subgrouping and developing prediction models. Conventional statistical modelling approaches exist; however, these models are limited in the amount of information they can adequately process. Comprehensive patient-specific prediction models need to be developed. Approaches such as data mining and machine learning should aid in the development of such models. Although a challenging task, technology is now available that should enable subgrouping of patients with OA and lead to improved clinical decision-making and precision medicine.",20.0
30522862,A Primer on Data Analytics in Functional Genomics: How to Move from Data to Insight?,2019 Jan;44(1):21-32.,"High-throughput methodologies and machine learning have been central in developing systems-level perspectives in molecular biology. Unfortunately, performing such integrative analyses has traditionally been reserved for bioinformaticians. This is now changing with the appearance of resources to help bench-side biologists become skilled at computational data analysis and handling large omics data sets. Here, we show an entry route into the field of omics data analytics. We provide information about easily accessible data sources and suggest some first steps for aspiring computational data analysts. Moreover, we highlight how machine learning is transforming the field and how it can help make sense of biological data. Finally, we suggest good starting points for self-learning and hope to convince readers that computational data analysis and programming are not intimidating.",2.0
30534555,Intelligence Algorithms for Protein Classification by Mass Spectrometry,2018 Nov 11;2018:2862458.,"Mass spectrometry (MS) is an important technique in protein research. Effective classification methods by MS data could contribute to early and less-invasive diagnosis and also facilitate developments in the bioinformatics field. As MS data is featured by high dimension, appropriate methods which can effectively deal with the large amount of MS data have been widely studied. In this paper, the applications of methods based on intelligence algorithms have been investigated. Firstly, classification and biomarker analysis methods using typical machine learning approaches have been discussed. Then those are followed by the Ensemble strategy algorithms. Clearly, simple and basic machine learning algorithms hardly addressed the various needs of protein MS classification. Preprocessing algorithms have been also studied, as these methods are useful for feature selection or feature extraction to improve classification performance. Protein MS data growing with data volume becomes complicated and large; improvements in classification methods in terms of classifier selection and combinations of different algorithms and preprocessing algorithms are more emphasized in further work.",1.0
30532667,A Review of Denoising Medical Images Using Machine Learning Approaches,2018 Oct;14(5):675-685.,"Background:                    This paper attempts to identify suitable Machine Learning (ML) approach for image denoising of radiology based medical application. The Identification of ML approach is based on (i) Review of ML approach for denoising (ii) Review of suitable Medical Denoising approach.              Discussion:                    The review focuses on six application of radiology: Medical Ultrasound (US) for fetus development, US Computer Aided Diagnosis (CAD) and detection for breast, skin lesions, brain tumor MRI diagnosis, X-Ray for chest analysis, Breast cancer using MRI imaging. This survey identifies the ML approach with better accuracy for medical diagnosis by radiologists. The image denoising approaches further includes basic filtering techniques, wavelet medical denoising, curvelet and optimization techniques. In most of the applications, the machine learning performance is better than the conventional image denoising techniques. For fast and computational results the radiologists are using the machine learning methods on MRI, US, X-Ray and Skin lesion images. The characteristics and contributions of different ML approaches are considered in this paper.              Conclusion:                    The problem faced by the researchers during image denoising techniques and machine learning applications for clinical settings have also been discussed.",4.0
30531869,Cardiovascular calcification: artificial intelligence and big data accelerate mechanistic discovery,2019 May;16(5):261-274.,"Cardiovascular calcification is a health disorder with increasing prevalence and high morbidity and mortality. The only available therapeutic options for calcific vascular and valvular heart disease are invasive transcatheter procedures or surgeries that do not fully address the wide spectrum of these conditions; therefore, an urgent need exists for medical options. Cardiovascular calcification is an active process, which provides a potential opportunity for effective therapeutic targeting. Numerous biological processes are involved in calcific disease, including matrix remodelling, transcriptional regulation, mitochondrial dysfunction, oxidative stress, calcium and phosphate signalling, endoplasmic reticulum stress, lipid and mineral metabolism, autophagy, inflammation, apoptosis, loss of mineralization inhibition, impaired mineral resorption, cellular senescence and extracellular vesicles that act as precursors of microcalcification. Advances in molecular imaging and big data technology, including in multiomics and network medicine, and the integration of these approaches are helping to provide a more comprehensive map of human disease. In this Review, we discuss ectopic calcification processes in the cardiovascular system, with an emphasis on emerging mechanistic knowledge obtained through patient data and advances in imaging methods, experimental models and multiomics-generated big data. We also highlight the potential and challenges of artificial intelligence, machine learning and deep learning to integrate imaging and mechanistic data for drug discovery.",22.0
30531846,Stimulus- and goal-oriented frameworks for understanding natural vision,2019 Jan;22(1):15-24.,"Our knowledge of sensory processing has advanced dramatically in the last few decades, but this understanding remains far from complete, especially for stimuli with the large dynamic range and strong temporal and spatial correlations characteristic of natural visual inputs. Here we describe some of the issues that make understanding the encoding of natural images a challenge. We highlight two broad strategies for approaching this problem: a stimulus-oriented framework and a goal-oriented one. Different contexts can call for one framework or the other. Looking forward, recent advances, particularly those based in machine learning, show promise in borrowing key strengths of both frameworks and by doing so illuminating a path to a more comprehensive understanding of the encoding of natural stimuli.",4.0
30531069,Opportunities and challenges for developing closed-loop bioelectronic medicines,2019 Jan;14(1):46-50.,"The peripheral nervous system plays a major role in the maintenance of our physiology. Several peripheral nerves intimately regulate the state of the brain, spinal cord, and visceral systems. A new class of therapeutics, called bioelectronic medicines, are being developed to precisely regulate physiology and treat dysfunction using peripheral nerve stimulation. In this review, we first discuss new work using closed-loop bioelectronic medicine to treat upper limb paralysis. In contrast to open-loop bioelectronic medicines, closed-loop approaches trigger 'on demand' peripheral nerve stimulation due to a change in function (e.g., during an upper limb movement or a change in cardiopulmonary state). We also outline our perspective on timing rules for closed-loop bioelectronic stimulation, interface features for non-invasively stimulating peripheral nerves, and machine learning algorithms to recognize disease events for closed-loop stimulation control. Although there will be several challenges for this emerging field, we look forward to future bioelectronic medicines that can autonomously sense changes in the body, to provide closed-loop peripheral nerve stimulation and treat disease.",1.0
30529297,Predicting eukaryotic protein secretion without signals,2019 Dec;1867(12):140174.,"Predicting unconventional protein secretion is a much harder problem than predicting signal peptide-based protein secretion, both due to the small number of examples and due to the heterogeneity and the limited knowledge of the pathways involved, especially in eukaryotes. However, the idea that secreted proteins share certain properties regardless of the secretion pathway used made it possible to construct the prediction method SecretomeP in 2004. Here, we take a critical look at SecretomeP and its successors, and we also discuss whether multi-category subcellular location predictors can be used to predict unconventional protein secretion in eukaryotes. A new benchmark shows SecretomeP to perform much worse than initially estimated, casting doubt on the underlying hypothesis. On a more positive note, recent developments in machine learning may have the potential to construct new methods which can not only predict unconventional protein secretion but also point out which parts of a sequence are important for secretion.",1.0
30529148,The algorithmic architecture of exploration in the human brain,2019 Apr;55:7-14.,"Balancing exploration and exploitation is one of the central problems in reinforcement learning. We review recent studies that have identified multiple algorithmic strategies underlying exploration. In particular, humans use a combination of random and uncertainty-directed exploration strategies, which rely on different brain systems, have different developmental trajectories, and are sensitive to different task manipulations. Humans are also able to exploit sophisticated structural knowledge to aid their exploration, such as information about correlations between options. New computational models, drawing inspiration from machine learning, have begun to formalize these ideas and offer new ways to understand the neural basis of reinforcement learning.",15.0
30527225,The application of artificial intelligence in the IMRT planning process for head and neck cancer,2018 Dec;87:111-116.,"Artificial intelligence (AI) is beginning to transform IMRT treatment planning for head and neck patients. However, the complexity and novelty of AI algorithms make them susceptible to misuse by researchers and clinicians. Understanding nuances of new technologies could serve to mitigate potential clinical implementation pitfalls. This article is intended to facilitate integration of AI into the radiotherapy clinic by providing an overview of AI algorithms, including support vector machines (SVMs), random forests (RF), gradient boosting (GB), and several variations of deep learning. This document describes current AI algorithms that have been applied to head and neck IMRT planning and identifies rapidly growing branches of AI in industry that have potential applications to head and neck cancer patients receiving IMRT. AI algorithms have great clinical potential if used correctly but can also cause harm if misused, so it is important to raise the level of AI competence within radiation oncology so that the benefits can be realized in a controlled and safe manner.",6.0
30520975,Computer vision-based phenotyping for improvement of plant productivity: a machine learning perspective,2019 Jan 1;8(1):giy153.,"Employing computer vision to extract useful information from images and videos is becoming a key technique for identifying phenotypic changes in plants. Here, we review the emerging aspects of computer vision for automated plant phenotyping. Recent advances in image analysis empowered by machine learning-based techniques, including convolutional neural network-based modeling, have expanded their application to assist high-throughput plant phenotyping. Combinatorial use of multiple sensors to acquire various spectra has allowed us to noninvasively obtain a series of datasets, including those related to the development and physiological responses of plants throughout their life. Automated phenotyping platforms accelerate the elucidation of gene functions associated with traits in model plants under controlled conditions. Remote sensing techniques with image collection platforms, such as unmanned vehicles and tractors, are also emerging for large-scale field phenotyping for crop breeding and precision agriculture. Computer vision-based phenotyping will play significant roles in both the nowcasting and forecasting of plant traits through modeling of genotype/phenotype relationships.",13.0
30507517,Into the Wild: The Challenges of Physiological Stress Detection in Laboratory and Ambulatory Settings,2019 Mar;23(2):463-473.,"Stress and mental health have become major concerns worldwide. Research has already extensively investigated physiological signals as quantitative and continuous markers of stress. In recent years, the focus of the field has shifted from the laboratory to the ambulatory environment. We provide an overview of physiological stress detection in laboratory settings with a focus on identifying physiological sensing priorities, including electrocardiogram, skin conductance, and electromyogram, and the most suitable machine learning techniques, of which the choice depends on the context of the application. Additionally, an overview is given of new challenges ahead to move toward the ambulant environment, including the influence of physical activity, lower signal quality due to motion artifacts, the lack of a stress reference, and the subject-dependent nature of the physiological stress response. Finally, several recommendations for future research are listed, focusing on large-scale, longitudinal trials across different population groups and just-in-time interventions to move toward disease prevention and interception.",5.0
30505265,"A New Frontier: The Convergence of Nanotechnology, Brain Machine Interfaces, and Artificial Intelligence",2018 Nov 16;12:843.,"A confluence of technological capabilities is creating an opportunity for machine learning and artificial intelligence (AI) to enable ""smart"" nanoengineered brain machine interfaces (BMI). This new generation of technologies will be able to communicate with the brain in ways that support contextual learning and adaptation to changing functional requirements. This applies to both invasive technologies aimed at restoring neurological function, as in the case of neural prosthesis, as well as non-invasive technologies enabled by signals such as electroencephalograph (EEG). Advances in computation, hardware, and algorithms that learn and adapt in a contextually dependent way will be able to leverage the capabilities that nanoengineering offers the design and functionality of BMI. We explore the enabling capabilities that these devices may exhibit, why they matter, and the state of the technologies necessary to build them. We also discuss a number of open technical challenges and problems that will need to be solved in order to achieve this.",3.0
30504368,Application of Artificial Intelligence-based Technology in Cancer Management: A Commentary on the Deployment of Artificial Neural Networks,2018 Dec;38(12):6607-6613.,"Artificial intelligence was recognised many years ago as a potential and powerful tool to predict disease outcome in many clinical situations. The conventional approaches using statistical methods have provided much information, but are subject to limitations imposed by the complexity of medical data. The structures of the important variants of the machine learning system artificial neural networks (ANN) are discussed and emphasis is given to the powerful analytical support that could be provided by ANN for the prediction of cancer progression and prognosis. The predictive ability of the cellular markers, DNA ploidy and cell-cycle profiles, and molecular markers, such as tumour promoter and suppressor gene, and growth factor and steroid hormone receptors in breast cancer management were also analysed. ANN systems have been successfully deployed to evaluate microRNA profiles of tumours which saliently sway cancer progression and prognosis of the disease, thus counteracting the negative implications of their numerical abundance. Finally, in this setting, the prospective technical improvements in artificial neural networks, as hybrid systems in combination with fuzzy logic and artificial immune networks were also addressed.",3.0
30503919,What does a pain 'biomarker' mean and can a machine be taught to measure pain?,2019 May 29;702:40-43.,"Artificial intelligence allows machines to predict human faculties such as image and voice recognition. Can machines be taught to measure pain? We argue that the two fundamental requirements for a device with 'pain biomarker' capabilities are hardware and software. We discuss the merits and limitations of electroencephalography (EEG) as the hardware component of a putative embodiment of the device, and advances in the application of machine learning approaches to EEG for predicting pain.",3.0
30502096,Artificial intelligence and machine learning | applications in musculoskeletal physiotherapy,2019 Feb;39:164-169.,"Introduction:                    Artificial intelligence (AI) is a field of mathematical engineering which has potential to enhance healthcare through new care delivery strategies, informed decision making and facilitation of patient engagement. Machine learning (ML) is a form of narrow artificial intelligence which can be used to automate decision making and make predictions based upon patient data.              Purpose:                    This review outlines key applications of supervised and unsupervised machine learning in musculoskeletal medicine; such as diagnostic imaging, patient measurement data, and clinical decision support. The current literature base is examined to identify areas where ML performs equal to or more accurately than human levels.              Implications:                    Potential is apparent for intelligent machines to enhance various areas of physiotherapy practice through automization of tasks which involve data analysis, classification and prediction. Changes to service provision through applications of ML, should encourage physiotherapists to increase their awareness of and experiences with emerging technologies. Data literacy should be a component of professional development plans to assist physiotherapists in the application of ML and the preparation of information technology systems to use these techniques.",4.0
30516837,From high definition precision healthcare to precision public oral health: opportunities and challenges,2020 Mar;80 Suppl 1:S23-S30.,"In anticipation of a major transformation in healthcare, this review provides highlights that anticipate the near future for oral public health (and beyond). Personalized or precision healthcare reflects the expectation that advances in genomics, imaging, and other domains will extend our risk assessment, diagnostic, and prognostic capabilities, and enables more effective prevention and therapeutic options for all Americans. Meanwhile, the current healthcare system does not meet cost, access, or quality criteria for all Americans. It is now an imperative that the success of ""smart,"" quality, and cost-effective high definition precision healthcare requires a public health perspective for several reasons: a) to enhance generalizability, b) to assess methods of implementation, and c) to focus on both risk and prevention in large and small populations, thereby providing a balance between the generation of long-term knowledge and short-term health gains. Sensitivity and resolution, reasonable cost, access to all Americans, coordinated comprehensive care, and advances in whole genome sequencing (WGS) and big data analyses, coupled to other advances in biotechnology and digital/artificial intelligence/machine learning devices, and the behavioral, social, and environmental sciences, offer remarkable opportunities to improve the health and wellness of the American people [genotype + phenotype + environment + behavior = high definition healthcare]. The opportunity is to significantly improve the well-being and life expectancy of all people across the lifespan including the least-advantaged people in our society and potentially increase access, reduce the national costs, and improve health outcomes.",1.0
30516106,Understanding Membrane Protein Drug Targets in Computational Perspective,2019;20(5):551-564.,"Membrane proteins play crucial physiological roles in vivo and are the major category of drug targets for pharmaceuticals. The research on membrane protein is a significant part in the drug discovery. The biological process is a cycled network, and the membrane protein is a vital hub in the network since most drugs achieve the therapeutic effect via interacting with the membrane protein. In this review, typical membrane protein targets are described, including GPCRs, transporters and ion channels. Also, we conclude network servers and databases that are referring to the drug, drug-target information and their relevant data. Furthermore, we chiefly introduce the development and practice of modern medicines, particularly demonstrating a series of state-of-the-art computational models for the prediction of drug-target interaction containing network-based approach and machine-learningbased approach as well as showing current achievements. Finally, we discuss the prospective orientation of drug repurposing and drug discovery as well as propose some improved framework in bioactivity data, created or improved predicted approaches, alternative understanding approaches of drugs bioactivity and their biological processes.",3.0
30515717,"Big data, artificial intelligence, and structured reporting",2018 Dec 5;2(1):42.,"The past few years have seen a considerable rise in interest towards artificial intelligence and machine learning applications in radiology. However, in order for such systems to perform adequately, large amounts of training data are required. These data should ideally be standardised and of adequate quality to allow for further usage in training of artificial intelligence algorithms. Unfortunately, in many current clinical and radiological information technology ecosystems, access to relevant pieces of information is difficult. This is mostly because a significant portion of information is handled as a collection of narrative texts and interoperability is still lacking. This review aims at giving a brief overview on how structured reporting can help to facilitate research in artificial intelligence and the context of big data.",11.0
30510440,"Precision pharmacotherapy: psychiatry's future direction in preventing, diagnosing, and treating mental disorders",2018 Nov 19;11:211-222.,"Mental disorders account for around one-third of disability worldwide and cause enormous personal and societal burden. Current pharmacotherapies and nonpharmacotherapies do help many patients, but there are still high rates of partial or no response, delayed effect, and unfavorable adverse effects. The current diagnostic taxonomy of mental disorders by the Diagnostic and Statistical Manual of Mental Disorders and the International Classification of Diseases relies on presenting signs and symptoms, but does not reflect evidence from neurobiological and behavioral systems. However, in the last decades, the understanding of biological mechanisms underlying mental disorders has grown and can be used for the development of precision medicine, that is, to deliver a patient-tailored individual treatment. Precision medicine may incorporate genetic variants contributing to the mental disorder and the response to pharmacotherapies, but also consider gene ¥ environment interactions, blood-based markers, neuropsychological tests, data from electronic health records, early life adversity, stressful life events, and very proximal factors such as lifestyle, nutrition, and sport. Methods such as artificial intelligence and the underlying machine learning and deep learning approaches provide the framework to stratify patients, initiate specific tailored treatments and thus increase response rates, reduce adverse effects and medical errors. In conclusion, precision medicine uses measurable health parameters to identify individuals at risk of a mental disorder, to improve the diagnostic process and to deliver a patient-tailored treatment.",11.0
30500991,Computational aspects underlying genome to phenome analysis in plants,2019 Jan;97(1):182-198.,"Recent advances in genomics technologies have greatly accelerated the progress in both fundamental plant science and applied breeding research. Concurrently, high-throughput plant phenotyping is becoming widely adopted in the plant community, promising to alleviate the phenotypic bottleneck. While these technological breakthroughs are significantly accelerating quantitative trait locus (QTL) and causal gene identification, challenges to enable even more sophisticated analyses remain. In particular, care needs to be taken to standardize, describe and conduct experiments robustly while relying on plant physiology expertise. In this article, we review the state of the art regarding genome assembly and the future potential of pangenomics in plant research. We also describe the necessity of standardizing and describing phenotypic studies using the Minimum Information About a Plant Phenotyping Experiment (MIAPPE) standard to enable the reuse and integration of phenotypic data. In addition, we show how deep phenotypic data might yield novel trait-trait correlations and review how to link phenotypic data to genomic data. Finally, we provide perspectives on the golden future of machine learning and their potential in linking phenotypes to genomic features.",13.0
30500302,Introduction to Machine Learning for Ophthalmologists,2019;34(1):19-41.,"New diagnostic and imaging techniques generate such an incredible amount of data that it is often a challenge to extract all information that could be possibly useful in clinical practice. Machine Learning techniques emerged as an objective tool to assist practitioners to diagnose certain conditions and take clinical decisions. In particular, Machine Learning techniques have repeatedly shown their usefulness for ophthalmologists. The possible applications of this technology go much further than been used as diagnostic tool, as it may also be used to grade the severity of a pathology, perform early disease detection, or predict the evolution of a condition. This work reviews not only the latest achievements of Machine Learning in ocular sciences, but also aims to be a comprehensive and concise overview of all steps of the process, with clear and easy explanation for each technical term, focusing on the basic knowledge required to understand Machine Learning.",3.0
30499008,Mental state and emotion detection from musically stimulated EEG,2018 Nov 29;5(2):14.,"This literature survey attempts to clarify different approaches considered to study the impact of the musical stimulus on the human brain using EEG Modality. Glancing at the field through various aspects of such studies specifically an experimental protocol, the EEG machine, number of channels investigated, feature extracted, categories of emotions, the brain area, the brainwaves, statistical tests, machine learning algorithms used for classification and validation of the developed model. This article comments on how these different approaches have particular weaknesses and strengths. Ultimately, this review concludes a suitable method to study the impact of the musical stimulus on brain and implications of such kind of studies.",
30498877,Machine learning studies on major brain diseases: 5-year trends of 2014-2018,2019 Jan;37(1):34-72.,"In the recent 5 years (2014-2018), there has been growing interest in the use of machine learning (ML) techniques to explore image diagnosis and prognosis of therapeutic lesion changes within the area of neuroradiology. However, to date, the majority of research trend and current status have not been clearly illuminated in the neuroradiology field. More than 1000 papers have been published during the past 5 years on subject classification and prediction focused on multiple brain disorders. We provide a survey of 209 papers in this field with a focus on top ten active areas of research; i.e., Alzheimer's disease/mild cognitive impairment, brain tumor; schizophrenia, depressive disorders, Parkinson's disease, attention-deficit hyperactivity disorder, autism spectrum disease, epilepsy, multiple sclerosis, stroke, and traumatic brain injury. Detailed information of these studies, such as ML methods, sample size, type of inputted features and reported accuracy, are summarized. This paper reviews the evidences, current limitations and status of studies using ML to assess brain disorders in neuroimaging data. The main bottleneck of this research field is still the limited sample size, which could be potentially addressed by modern data sharing models, such as ADNI.",25.0
30496527,Recurrent Neural Networks in Mobile Sampling and Intervention,2019 Mar 7;45(2):272-276.,"The rapid rise and now widespread distribution of handheld and wearable devices, such as smartphones, fitness trackers, or smartwatches, has opened a new universe of possibilities for monitoring emotion and cognition in everyday-life context, and for applying experience- and context-specific interventions in psychosis. These devices are equipped with multiple sensors, recording channels, and app-based opportunities for assessment using experience sampling methodology (ESM), which enables to collect vast amounts of temporally highly resolved and ecologically valid personal data from various domains in daily life. In psychosis, this allows to elucidate intermediate and clinical phenotypes, psychological processes and mechanisms, and their interplay with socioenvironmental factors, as well as to evaluate the effects of treatments for psychosis on important clinical and social outcomes. Although these data offer immense opportunities, they also pose tremendous challenges for data analysis. These challenges include the sheer amount of time series data generated and the many different data modalities and their specific properties and sampling rates. After a brief review of studies and approaches to ESM and ecological momentary interventions in psychosis, we will discuss recurrent neural networks (RNNs) as a powerful statistical machine learning approach for time series analysis and prediction in this context. RNNs can be trained on multiple data modalities simultaneously to learn a dynamical model that could be used to forecast individual trajectories and schedule online feedback and intervention accordingly. Future research using this approach is likely going to offer new avenues to further our understanding and treatments of psychosis.",4.0
30488745,Computational approaches for skin sensitization prediction,2018 Oct;48(9):738-760.,"Drugs, cosmetics, preservatives, fragrances, pesticides, metals, and other chemicals can cause skin sensitization. The ability to predict the skin sensitization potential and potency of substances is therefore of enormous importance to a host of different industries, to customers' and workers' safety. Animal experiments have been the preferred testing method for most risk assessment and regulatory purposes but considerable efforts to replace them with non-animal models and in silico models are ongoing. This review provides a comprehensive overview of the computational approaches and models that have been developed for skin sensitization prediction over the last 10 years. The scope and limitations of rule-based approaches, read-across, linear and nonlinear (quantitative) structure-activity relationship ((Q)SAR) modeling, hybrid or combined approaches, and models integrating computational methods with experimental results are discussed followed by examples of relevant models. Emphasis is placed on models that are accessible to the scientific community, and on model validation. A dedicated section reports on comparative performance assessments of various approaches and models. The review also provides a concise overview of relevant data sources on skin sensitization.",3.0
30488731,Advances with support vector machines for novel drug discovery,2019 Jan;14(1):23-33.,"Novel drug discovery remains an enormous challenge, with various computer-aided drug design (CADD) approaches having been widely employed for this purpose. CADD, specifically the commonly used support vector machines (SVMs), can employ machine learning techniques. SVMs and their variations offer numerous drug discovery applications, which range from the classification of substances (as active or inactive) to the construction of regression models and the ranking/virtual screening of databased compounds. Areas covered: Herein, the authors consider some of the applications of SVMs in medicinal chemistry, illustrating their main advantages and disadvantages, as well as trends in their utilization, via the available published literature. The aim of this review is to provide an up-to-date review of the recent applications of SVMs in drug discovery as described by the literature, thereby highlighting their strengths, weaknesses, and future challenges. Expert opinion: Techniques based on SVMs are considered as powerful approaches in early drug discovery. The ability of SVMs to classify active or inactive compounds has enabled the prioritization of substances for virtual screening. Indeed, one of the main advantages of SVMs is related to their potential in the analysis of nonlinear problems. However, despite successes in employing SVMs, the challenges of improving accuracy remain.",4.0
30483163,Is It Possible to Predict the Future in First-Episode Psychosis?,2018 Nov 13;9:580.,"The outcome of first-episode psychosis (FEP) is highly variable, ranging from early sustained recovery to antipsychotic treatment resistance from the onset of illness. For clinicians, a possibility to predict patient outcomes would be highly valuable for the selection of antipsychotic treatment and in tailoring psychosocial treatments and psychoeducation. This selective review summarizes current knowledge of prognostic markers in FEP. We sought potential outcome predictors from clinical and sociodemographic factors, cognition, brain imaging, genetics, and blood-based biomarkers, and we considered different outcomes, like remission, recovery, physical comorbidities, and suicide risk. Based on the review, it is currently possible to predict the future for FEP patients to some extent. Some clinical features-like the longer duration of untreated psychosis (DUP), poor premorbid adjustment, the insidious mode of onset, the greater severity of negative symptoms, comorbid substance use disorders (SUDs), a history of suicide attempts and suicidal ideation and having non-affective psychosis-are associated with a worse outcome. Of the social and demographic factors, male gender, social disadvantage, neighborhood deprivation, dysfunctional family environment, and ethnicity may be relevant. Treatment non-adherence is a substantial risk factor for relapse, but a small minority of patients with acute onset of FEP and early remission may benefit from antipsychotic discontinuation. Cognitive functioning is associated with functional outcomes. Brain imaging currently has limited utility as an outcome predictor, but this may change with methodological advancements. Polygenic risk scores (PRSs) might be useful as one component of a predictive tool, and pharmacogenetic testing is already available and valuable for patients who have problems in treatment response or with side effects. Most blood-based biomarkers need further validation. None of the currently available predictive markers has adequate sensitivity or specificity used alone. However, personalized treatment of FEP will need predictive tools. We discuss some methodologies, such as machine learning (ML), and tools that could lead to the improved prediction and clinical utility of different prognostic markers in FEP. Combination of different markers in ML models with a user friendly interface, or novel findings from e.g., molecular genetics or neuroimaging, may result in computer-assisted clinical applications in the near future.",12.0
30478442,A primer on deep learning in genomics,2019 Jan;51(1):12-18.,"Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial.",95.0
30472716,Machine Learning and Imaging Informatics in Oncology,2020;98(6):344-362.,"In the era of personalized and precision medicine, informatics technologies utilizing machine learning (ML) and quantitative imaging are witnessing a rapidly increasing role in medicine in general and in oncology in particular. This expanding role ranges from computer-aided diagnosis to decision support of treatments with the potential to transform the current landscape of cancer management. In this review, we aim to provide an overview of ML methodologies and imaging informatics techniques and their recent application in modern oncology. We will review example applications of ML in oncology from the literature, identify current challenges and highlight future potentials.",4.0
30471192,Computational methods and tools to predict cytochrome P450 metabolism for drug discovery,2019 Apr;93(4):377-386.,"In this review, we present important, recent developments in the computational prediction of cytochrome P450 (CYP) metabolism in the context of drug discovery. We discuss in silico models for the various aspects of CYP metabolism prediction, including CYP substrate and inhibitor predictors, site of metabolism predictors (i.e., metabolically labile sites within potential substrates) and metabolite structure predictors. We summarize the different approaches taken by these models, such as rule-based methods, machine learning, data mining, quantum chemical methods, molecular interaction fields, and docking. We highlight the scope and limitations of each method and discuss future implications for the field of metabolism prediction in drug discovery.",10.0
30470933,Precision immunoprofiling by image analysis and artificial intelligence,2019 Apr;474(4):511-522.,"Clinical success of immunotherapy is driving the need for new prognostic and predictive assays to inform patient selection and stratification. This requirement can be met by a combination of computational pathology and artificial intelligence. Here, we critically assess computational approaches supporting the development of a standardized methodology in the assessment of immune-oncology biomarkers, such as PD-L1 and immune cell infiltrates. We examine immunoprofiling through spatial analysis of tumor-immune cell interactions and multiplexing technologies as a predictor of patient response to cancer treatment. Further, we discuss how integrated bioinformatics can enable the amalgamation of complex morphological phenotypes with the multiomics datasets that drive precision medicine. We provide an outline to machine learning (ML) and artificial intelligence tools and illustrate fields of application in immune-oncology, such as pattern-recognition in large and complex datasets and deep learning approaches for survival analysis. Synergies of surgical pathology and computational analyses are expected to improve patient stratification in immuno-oncology. We propose that future clinical demands will be best met by (1) dedicated research at the interface of pathology and bioinformatics, supported by professional societies, and (2) the integration of data sciences and digital image analysis in the professional education of pathologists.",20.0
30468663,State-of-the-art review on deep learning in medical imaging,2019 Jan 1;24:392-426.,"Deep learning (DL) is affecting each and every sphere of public and private lives and becoming a tool for daily use. The power of DL lies in the fact that it tries to imitate the activities of neurons in the neocortex of human brain where the thought process takes place. Therefore, like the brain, it tries to learn and recognize patterns in the form of digital images. This power is built on the depth of many layers of computing neurons backed by high power processors and graphics processing units (GPUs) easily available today. In the current scenario, we have provided detailed survey of various types of DL systems available today, and specifically, we have concentrated our efforts on current applications of DL in medical imaging. We have also focused our efforts on explaining the readers the rapid transition of technology from machine learning to DL and have tried our best in reasoning this paradigm shift. Further, a detailed analysis of complexities involved in this shift and possible benefits accrued by the users and developers.",17.0
30467491,Machine Learning in Acute Ischemic Stroke Neuroimaging,2018 Nov 8;9:945.,"Machine Learning (ML) through pattern recognition algorithms is currently becoming an essential aid for the diagnosis, treatment, and prediction of complications and patient outcomes in a number of neurological diseases. The evaluation and treatment of Acute Ischemic Stroke (AIS) have experienced a significant advancement over the past few years, increasingly requiring the use of neuroimaging for decision-making. In this review, we offer an insight into the recent developments and applications of ML in neuroimaging focusing on acute ischemic stroke.",10.0
30465503,Intelligently Applying Artificial Intelligence in Chemoinformatics,2018;18(20):1804-1826.,"The intertwining of chemoinformatics with artificial intelligence (AI) has given a tremendous fillip to the field of drug discovery. With the rapid growth of chemical data from high throughput screening and combinatorial synthesis, AI has become an indispensable tool for drug designers to mine chemical information from large compound databases for developing drugs at a much faster rate as never before. The applications of AI have gone beyond bioactivity predictions and have shown promise in addressing diverse problems in drug discovery like de novo molecular design, synthesis prediction and biological image analysis. In this article, we provide an overview of all the algorithms under the umbrella of AI, enlist the tools/frameworks required for implementing these algorithms as well as present a compendium of web servers, databases and open-source platforms implicated in drug discovery, Quantitative Structure-Activity Relationship (QSAR), data mining, solvation free energy and molecular graph mining.",2.0
30458727,Prognostic models for intracerebral hemorrhage: systematic review and meta-analysis,2018 Nov 20;18(1):145.,"Background:                    Prognostic tools for intracerebral hemorrhage (ICH) patients are potentially useful for ascertaining prognosis and recommended in guidelines to facilitate streamline assessment and communication between providers. In this systematic review with meta-analysis we identified and characterized all existing prognostic tools for this population, performed a methodological evaluation of the conducting and reporting of such studies and compared different methods of prognostic tool derivation in terms of discrimination for mortality and functional outcome prediction.              Methods:                    PubMed, ISI, Scopus and CENTRAL were searched up to 15th September 2016, with additional studies identified using reference check. Two reviewers independently extracted data regarding the population studied, process of tool derivation, included predictors and discrimination (c statistic) using a predesignated spreadsheet based in the CHARMS checklist. Disagreements were solved by consensus. C statistics were pooled using robust variance estimation and meta-regression was applied for group comparisons using random effect models.              Results:                    Fifty nine studies were retrieved, including 48,133 patients and reporting on the derivation of 72 prognostic tools. Data on discrimination (c statistic) was available for 53 tools, 38 focusing on mortality and 15 focusing on functional outcome. Discrimination was high for both outcomes, with a pooled c statistic of 0.88 for mortality and 0.87 for functional outcome. Forty three tools were regression based and nine tools were derived using machine learning algorithms, with no differences found between the two methods in terms of discrimination (p = 0.490). Several methodological issues however were identified, relating to handling of missing data, low number of events per variable, insufficient length of follow-up, absence of blinding, infrequent use of internal validation, and underreporting of important model performance measures.              Conclusions:                    Prognostic tools for ICH discriminated well for mortality and functional outcome in derivation studies but methodological issues require confirmation of these findings in validation studies. Logistic regression based risk scores are particularly promising given their good performance and ease of application.",7.0
30455357,Computational approaches for the analysis of RNA-protein interactions: A primer for biologists,2019 Jan 4;294(1):1-9.,"RNA-binding proteins (RBPs) play important roles in the control of gene expression and the coordination of different layers of post-transcriptional regulation. Interactions between certain RBPs and mRNA transcripts are notoriously difficult to predict, as any given protein-RNA interaction may rely not only on RNA sequence, but also on three-dimensional RNA structures, competitive inhibition from other RBPs, and input from cellular signaling pathways. Advanced and high-throughput technologies for the identification of RNA-protein interactions have come to the rescue, but the identification of binding sites and downstream functional effects of RBPs from the resulting data can be challenging. In this review, we discuss statistical inference and machine-learning approaches and tools relevant for the study of RBPs and the analysis of large-scale RNA-protein interaction datasets. This primer is intended for life scientists who are interested in incorporating these tools into their own research. We begin with the demystification of regression models, as used in the analysis of next-generation sequencing data, and progress to a discussion of Hidden Markov Models, which are of particular value in analyzing cross-linking followed by immunoprecipitation data. We then continue with examples of machine learning techniques, such as support vector machines and gradient tree boosting. We close with a brief discussion of current trends in the field, including deep learning architectures.",2.0
30455216,The use and misuse of herbarium specimens in evaluating plant extinction risks,2018 Nov 19;374(1763):20170402.,"Herbarium specimens provide verifiable and citable evidence of the occurrence of particular plants at particular points in space and time, and are vital resources for assessing extinction risk in the tropics, where plant diversity and threats to plants are greatest. We reviewed approaches to assessing extinction risk in response to the Convention on Biological Diversity's Global Strategy for Plant Conservation Target 2: an assessment of the conservation status of all known plant species by 2020. We tested five alternative approaches, using herbarium-derived data for trees, shrubs and herbs in five different plant groups from temperate and tropical regions. All species were previously fully assessed for the IUCN Red List. We found significant variation in the accuracy with which different approaches classified species as threatened or not threatened. Accuracy was highest for the machine learning model (90%) but the least data-intensive approach also performed well (82%). Despite concerns about spatial, temporal and taxonomic biases and uncertainties in herbarium data, when specimens represent the best available evidence for particular species, their use as a basis for extinction risk assessment is appropriate, necessary and urgent. Resourcing herbaria to maintain, increase and disseminate their specimen data is essential to guide and focus conservation action.This article is part of the theme issue 'Biological collections for understanding biodiversity in the Anthropocene'.",7.0
30453459,Machine learning applications for the differentiation of primary central nervous system lymphoma from glioblastoma on imaging: a systematic review and meta-analysis,2018 Nov 1;45(5):E5.,"OBJECTIVEGlioblastoma (GBM) and primary central nervous system lymphoma (PCNSL) are common intracranial pathologies encountered by neurosurgeons. They often may have similar radiological findings, making diagnosis difficult without surgical biopsy; however, management is quite different between these two entities. Recently, predictive analytics, including machine learning (ML), have garnered attention for their potential to aid in the diagnostic assessment of a variety of pathologies. Several ML algorithms have recently been designed to differentiate GBM from PCNSL radiologically with a high sensitivity and specificity. The objective of this systematic review and meta-analysis was to evaluate the implementation of ML algorithms in differentiating GBM and PCNSL.METHODSThe authors performed a systematic review of the literature using PubMed in accordance with PRISMA guidelines to select and evaluate studies that included themes of ML and brain tumors. These studies were further narrowed down to focus on works published between January 2008 and May 2018 addressing the use of ML in training models to distinguish between GBM and PCNSL on radiological imaging. Outcomes assessed were test characteristics such as accuracy, sensitivity, specificity, and area under the receiver operating characteristic curve (AUC).RESULTSEight studies were identified addressing use of ML in training classifiers to distinguish between GBM and PCNSL on radiological imaging. ML performed well with the lowest reported AUC being 0.878. In studies in which ML was directly compared with radiologists, ML performed better than or as well as the radiologists. However, when ML was applied to an external data set, it performed more poorly.CONCLUSIONSFew studies have applied ML to solve the problem of differentiating GBM from PCNSL using imaging alone. Of the currently published studies, ML algorithms have demonstrated promising results and certainly have the potential to aid radiologists with difficult cases, which could expedite the neurosurgical decision-making process. It is likely that ML algorithms will help to optimize neurosurgical patient outcomes as well as the cost-effectiveness of neurosurgical care if the problem of overfitting can be overcome.",2.0
30448825,"Cycles, Arrows and Turbulence: Time Patterns in Renal Disease, a Path from Epidemiology to Personalized Medicine?",2019;47(1-3):171-184.,"Patients with end-stage renal disease (ESRD) experience unique patterns in their lifetime, such as the start of dialysis and renal transplantation. In addition, there is also an intricate link between ESRD and biological time patterns. In terms of cyclic patterns, the circadian blood pressure (BP) rhythm can be flattened, contributing to allostatic load, whereas the circadian temperature rhythm is related to the decline in BP during hemodialysis (HD). Seasonal variations in BP and interdialytic-weight gain have been observed in ESRD patients in addition to a profound relative increase in mortality during the winter period. Moreover, nonphysiological treatment patters are imposed in HD patients, leading to an excess mortality at the end of the long interdialytic interval. Recently, new evidence has emerged on the prognostic impact of trajectories of common clinical and laboratory parameters such as BP, body temperature, and serum albumin, in addition to single point in time measurements. Backward analysis of changes in cardiovascular, nutritional, and inflammatory parameters before the occurrence as hospitalization or death has shown that changes may already occur within months to even 1-2 years before the event, possibly providing a window of opportunity for earlier interventions. Disturbances in physiological variability, such as in heart rate, characterized by a loss of fractal patterns, are associated with increased mortality. In addition, an increase in random variability in different parameters such as BP and sodium is also associated with adverse outcomes. Novel techniques, based on time-dependent analysis of variability and trends and interactions of multiple physiological and laboratory parameters, for which machine-learning -approaches may be necessary, are likely of help to the clinician in the future. However, upcoming research should also evaluate whether dynamic patterns observed in large epidemiological studies have relevance for the individual risk profile of the patient.",3.0
30443413,Digital Epidemiology: Use of Digital Data Collected for Non-epidemiological Purposes in Epidemiological Studies,2018 Oct;24(4):253-262.,"Objectives:                    We reviewed digital epidemiological studies to characterize how researchers are using digital data by topic domain, study purpose, data source, and analytic method.              Methods:                    We reviewed research articles published within the last decade that used digital data to answer epidemiological research questions. Data were abstracted from these articles using a data collection tool that we developed. Finally, we summarized the characteristics of the digital epidemiological studies.              Results:                    We identified six main topic domains: infectious diseases (58.7%), non-communicable diseases (29.4%), mental health and substance use (8.3%), general population behavior (4.6%), environmental, dietary, and lifestyle (4.6%), and vital status (0.9%). We identified four categories for the study purpose: description (22.9%), exploration (34.9%), explanation (27.5%), and prediction and control (14.7%). We identified eight categories for the data sources: web search query (52.3%), social media posts (31.2%), web portal posts (11.9%), webpage access logs (7.3%), images (7.3%), mobile phone network data (1.8%), global positioning system data (1.8%), and others (2.8%). Of these, 50.5% used correlation analyses, 41.3% regression analyses, 25.6% machine learning, and 19.3% descriptive analyses.              Conclusions:                    Digital data collected for non-epidemiological purposes are being used to study health phenomena in a variety of topic domains. Digital epidemiology requires access to large datasets and advanced analytics. Ensuring open access is clearly at odds with the desire to have as little personal data as possible in these large datasets to protect privacy. Establishment of data cooperatives with restricted access may be a solution to this dilemma.",9.0
30442428,Rethinking multiscale cardiac electrophysiology with machine learning and predictive modelling,2019 Jan;104:339-351.,"We review some of the latest approaches to analysing cardiac electrophysiology data using machine learning and predictive modelling. Cardiac arrhythmias, particularly atrial fibrillation, are a major global healthcare challenge. Treatment is often through catheter ablation, which involves the targeted localised destruction of regions of the myocardium responsible for initiating or perpetuating the arrhythmia. Ablation targets are either anatomically defined, or identified based on their functional properties as determined through the analysis of contact intracardiac electrograms acquired with increasing spatial density by modern electroanatomic mapping systems. While numerous quantitative approaches have been investigated over the past decades for identifying these critical curative sites, few have provided a reliable and reproducible advance in success rates. Machine learning techniques, including recent deep-learning approaches, offer a potential route to gaining new insight from this wealth of highly complex spatio-temporal information that existing methods struggle to analyse. Coupled with predictive modelling, these techniques offer exciting opportunities to advance the field and produce more accurate diagnoses and robust personalised treatment. We outline some of these methods and illustrate their use in making predictions from the contact electrogram and augmenting predictive modelling tools, both by more rapidly predicting future states of the system and by inferring the parameters of these models from experimental observations.",13.0
