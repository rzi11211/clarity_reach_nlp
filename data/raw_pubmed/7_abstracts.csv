pmid,title,date,text,citations
32673788,Extraction of temporal relations from clinical free text: A systematic review of current approaches,2020 Aug;108:103488.,"Background:                    Temporal relations between clinical events play an important role in clinical assessment and decision making. Extracting such relations from free text data is a challenging task because it lies on between medical natural language processing, temporal representation and temporal reasoning.              Objectives:                    To survey existing methods for extracting temporal relations (TLINKs) between events from clinical free text in English; to establish the state-of-the-art in this field; and to identify outstanding methodological challenges.              Methods:                    A systematic search in PubMed and the DBLP computer science bibliography was conducted for studies published between January 2006 and December 2018. The relevant studies were identified by examining the titles and abstracts. Then, the full text of selected studies was analyzed in depth and information were collected on TLINK tasks, TLINK types, data sources, features selection, methods used, and reported performance.              Results:                    A total of 2834 publications were identified for title and abstract screening. Of these publications, 51 studies were selected. Thirty-two studies used machine learning approaches, 15 studies used a hybrid approaches, and only four studies used a rule-based approach. The majority of studies use publicly available corpora: THYME (28 studies) and the i2b2 corpus (17 studies).              Conclusion:                    The performance of TLINK extraction methods ranges widely depending on relation types and events (e.g. from 32% to 87% F-score for identifying relations between clinical events and document creation time). A small set of TLINKs (before, after, overlap and contains) has been widely studied with relatively good performance, whereas other types of TLINK (e.g., started by, finished by, precedes) are rarely studied and remain challenging. Machine learning classifiers (such as Support Vector Machine and Conditional Random Fields) and Deep Neural Networks were among the best performing methods for extracting TLINKs, but nearly all the work has been carried out and tested on two publicly available corpora only. The field would benefit from the availability of more publicly available, high-quality, annotated clinical text corpora.",
32672961,Transfer Learning for Drug Discovery,2020 Aug 27;63(16):8683-8694.,"The data sets available to train models for in silico drug discovery efforts are often small. Indeed, the sparse availability of labeled data is a major barrier to artificial-intelligence-assisted drug discovery. One solution to this problem is to develop algorithms that can cope with relatively heterogeneous and scarce data. Transfer learning is a type of machine learning that can leverage existing, generalizable knowledge from other related tasks to enable learning of a separate task with a small set of data. Deep transfer learning is the most commonly used type of transfer learning in the field of drug discovery. This Perspective provides an overview of transfer learning and related applications to drug discovery to date. Furthermore, it provides outlooks on the future development of transfer learning for drug discovery.",
32671229,Harnessing repeated measurements of predictor variables for clinical risk prediction: a review of existing methods,2020 Jul 9;4:9.,"Background:                    Clinical prediction models (CPMs) predict the risk of health outcomes for individual patients. The majority of existing CPMs only harness cross-sectional patient information. Incorporating repeated measurements, such as those stored in electronic health records, into CPMs may provide an opportunity to enhance their performance. However, the number and complexity of methodological approaches available could make it difficult for researchers to explore this opportunity. Our objective was to review the literature and summarise existing approaches for harnessing repeated measurements of predictor variables in CPMs, primarily to make this field more accessible for applied researchers.              Methods:                    MEDLINE, Embase and Web of Science were searched for articles reporting the development of a multivariable CPM for individual-level prediction of future binary or time-to-event outcomes and modelling repeated measurements of at least one predictor. Information was extracted on the following: the methodology used, its specific aim, reported advantages and limitations, and software available to apply the method.              Results:                    The search revealed 217 relevant articles. Seven methodological frameworks were identified: time-dependent covariate modelling, generalised estimating equations, landmark analysis, two-stage modelling, joint-modelling, trajectory classification and machine learning. Each of these frameworks satisfies at least one of three aims: to better represent the predictor-outcome relationship over time, to infer a covariate value at a pre-specified time and to account for the effect of covariate change.              Conclusions:                    The applicability of identified methods depends on the motivation for including longitudinal information and the method's compatibility with the clinical context and available patient data, for both model development and risk estimation in practice.",1.0
32670710,The Future of Concurrent Automated Coronary Artery Calcium Scoring on Screening Low-Dose Computed Tomography,2020 Jun 12;12(6):e8574.,"Low-dose computed tomography (LDCT) has been extensively validated for lung cancer screening in selected patient populations. Additionally, the use of gated cardiac CT to assess coronary artery calcium (CAC) burden has been validated to determine a patient's risk for major cardiovascular adverse events. This is typically performed by calculating an Agatston score based on density and overall burden of calcified plaque within the coronary arteries. Patients that qualify for LDCT for lung cancer screening commonly share major risk factors for coronary artery disease and would frequently benefit from an additional gated cardiac CT for the assessment of CAC. Given the widespread use of LDCT for lung cancer screening, we evaluated current literature regarding the use of non-gated chest CT, specifically LDCT, for the detection and grading of coronary artery calcifications. Additionally, given the evolving and increasing use of artificial intelligence (AI) in the interpretation of radiologic studies, current literature for the use of AI in CAC assessment was reviewed. We reviewed primary scientific literature dating up to April 2020 using Pubmed and Google Scholar, with the search terms low dose CT, lung cancer screening, coronary artery calcium, EKG/cardiac gated CT, deep learning, machine learning, and AI. These publications were then independently evaluated by each member of our team. Overall, there was a consensus within these papers that LDCT for lung cancer screening plays a role in the evaluation of CAC. Most studies note the inherent problems with the evaluation of the density of coronary calcifications on LDCT to give an accurate numeric calcium or Agatston score. The current method of evaluating CAC on LDCT involves using a qualitative categorical system (none, mild, moderate, or severe). When performed by cardiac imaging experts, this method broadly correlates with traditional CAC score groups (0, 1 to 100, 101 to 400, and > 400). Furthermore, given the high sensitivity of a properly protocolled LDCT for coronary calcium, a negative study for CAC precludes the need for a dedicated gated CT assessment. However, qualitative methods are not as accurate or reproducible when performed by general radiologists. The implementation of AI in the LDCT screening process has the potential to give a quantifiable and reproducible numeric value to the calcium score, based on whole heart volume scoring of calcium. This more closely aligns with the Agatston score and serves as a better guide for treatment and risk assessment using current guidelines. We conclude that CAC should be assessed on all LDCT performed for lung cancer screening and that a qualitative categorical scoring system should be provided in the impression for each patient. Early studies involving AI for the assessment of CAC are promising, but more extensive studies are needed before a final recommendation for its use can be given. The implementation of an accurate, automated AI CAC assessment tool would improve radiologist compliance and ease of overall workflow. Ultimately, the potential end result would be improved turnaround time, better patient outcomes, and reduced healthcare costs by maximizing preventative care in this high-risk population.",
32670510,Assessment of vector-host-pathogen relationships using data mining and machine learning,2020 Jun 25;18:1704-1721.,"Infectious diseases, including vector-borne diseases transmitted by arthropods, are a leading cause of morbidity and mortality worldwide. In the era of big data, addressing broad-scale, fundamental questions regarding the complex dynamics of these diseases will increasingly require the integration of diverse datasets to produce new biological knowledge. This review provides a current snapshot of the systematic assessment of the relationships between microbial pathogens, arthropod vectors and mammalian hosts using data mining and machine learning. We employ PRISMA to identify 32 key papers relevant to this topic. Our analysis shows an increasing use of data mining and machine learning tasks and techniques, including prediction, classification, clustering, association rules mining, and deep learning, over the last decade. However, it also reveals a number of critical challenges in applying these to the study of vector-host-pathogen interactions at various systems biology levels. Here, relevant studies, current limitations and future directions are discussed. Furthermore, the quality of data in relevant papers was assessed using the FAIR (Findable, Accessible, Interoperable, Reusable) compliance criteria to evaluate and encourage reproducibility and shareability of research outcomes. Although shortcomings in their application remain, data mining and machine learning have significant potential to break new ground in understanding fundamental aspects of vector-host-pathogen relationships and their application in this field should be encouraged. In particular, while predictive modeling, feature engineering and supervised machine learning are already being used in the field, other data mining and machine learning methods such as deep learning and association rules analysis lag behind and should be implemented in combination with established methods to accelerate hypothesis and knowledge generation in the domain.",1.0
32670474,Artificial Intelligence in Cardiovascular Imaging,Apr-Jun 2020;16(2):138-145.,"The number of cardiovascular imaging studies is growing exponentially, and so is the need to improve clinical workflow efficiency and avoid missed diagnoses. With the availability and use of large datasets, artificial intelligence (AI) has the potential to improve patient care at every stage of the imaging chain. Current literature indicates that in the short-term, AI has the capacity to reduce human error and save time in the clinical workflow through automated segmentation of cardiac structures. In the future, AI may expand the informational value of diagnostic images based on images alone or a combination of images and clinical variables, thus facilitating disease detection, prognosis, and decision making. This review describes the role of AI, specifically machine learning, in multimodality imaging, including echocardiography, nuclear imaging, computed tomography, and cardiac magnetic resonance, and highlights current uses of AI as well as potential challenges to its widespread implementation.",
32669685,Applications of machine learning to diagnosis and treatment of neurodegenerative diseases,2020 Aug;16(8):440-456.,"Globally, there is a huge unmet need for effective treatments for neurodegenerative diseases. The complexity of the molecular mechanisms underlying neuronal degeneration and the heterogeneity of the patient population present massive challenges to the development of early diagnostic tools and effective treatments for these diseases. Machine learning, a subfield of artificial intelligence, is enabling scientists, clinicians and patients to address some of these challenges. In this Review, we discuss how machine learning can aid early diagnosis and interpretation of medical images as well as the discovery and development of new therapies. A unifying theme of the different applications of machine learning is the integration of multiple high-dimensional sources of data, which all provide a different view on disease, and the automated derivation of actionable insights.",4.0
32668634,Gallium Nitride (GaN) Nanostructures and Their Gas Sensing Properties: A Review,2020 Jul 13;20(14):3889.,"In the last two decades, GaN nanostructures of various forms like nanowires (NWs), nanotubes (NTs), nanofibers (NFs), nanoparticles (NPs) and nanonetworks (NNs) have been reported for gas sensing applications. In this paper, we have reviewed our group's work and the works published by other groups on the advances in GaN nanostructures-based sensors for detection of gases such as hydrogen (H2), alcohols (R-OH), methane (CH4), benzene and its derivatives, nitric oxide (NO), nitrogen dioxide (NO2), sulfur-dioxide (SO2), ammonia (NH3), hydrogen sulfide (H2S) and carbon dioxide (CO2). The important sensing performance parameters like limit of detection, response/recovery time and operating temperature for different type of sensors have been summarized and tabulated to provide a thorough performance comparison. A novel metric, the product of response time and limit of detection, has been established, to quantify and compare the overall sensing performance of GaN nanostructure-based devices reported so far. According to this metric, it was found that the InGaN/GaN NW-based sensor exhibits superior overall sensing performance for H2 gas sensing, whereas the GaN/(TiO2-Pt) nanowire-nanoclusters (NWNCs)-based sensor is better for ethanol sensing. The GaN/TiO2 NWNC-based sensor is also well suited for TNT sensing. This paper has also reviewed density-functional theory (DFT)-based first principle studies on the interaction between gas molecules and GaN. The implementation of machine learning algorithms on GaN nanostructured sensors and sensor array has been analyzed as well. Finally, gas sensing mechanism on GaN nanostructure-based sensors at room temperature has been discussed.",3.0
32668442,Deep learning for small and big data in psychiatry,2021 Jan;46(1):176-190.,"Psychiatry today must gain a better understanding of the common and distinct pathophysiological mechanisms underlying psychiatric disorders in order to deliver more effective, person-tailored treatments. To this end, it appears that the analysis of 'small' experimental samples using conventional statistical approaches has largely failed to capture the heterogeneity underlying psychiatric phenotypes. Modern algorithms and approaches from machine learning, particularly deep learning, provide new hope to address these issues given their outstanding prediction performance in other disciplines. The strength of deep learning algorithms is that they can implement very complicated, and in principle arbitrary predictor-response mappings efficiently. This power comes at a cost, the need for large training (and test) samples to infer the (sometimes over millions of) model parameters. This appears to be at odds with the as yet rather 'small' samples available in psychiatric human research to date (n < 10,000), and the ambition of predicting treatment at the single subject level (n = 1). Here, we aim at giving a comprehensive overview on how we can yet use such models for prediction in psychiatry. We review how machine learning approaches compare to more traditional statistical hypothesis-driven approaches, how their complexity relates to the need of large sample sizes, and what we can do to optimally use these powerful techniques in psychiatric neuroscience.",3.0
32665978,Artificial intelligence to improve back pain outcomes and lessons learnt from clinical classification approaches: three systematic reviews,2020 Jul 9;3:93.,"Artificial intelligence and machine learning (AI/ML) could enhance the ability to detect patterns of clinical characteristics in low-back pain (LBP) and guide treatment. We conducted three systematic reviews to address the following aims: (a) review the status of AI/ML research in LBP, (b) compare its status to that of two established LBP classification systems (STarT Back, McKenzie). AI/ML in LBP is in its infancy: 45 of 48 studies assessed sample sizes <1000 people, 19 of 48 studies used ≤5 parameters in models, 13 of 48 studies applied multiple models and attained high accuracy, 25 of 48 studies assessed the binary classification of LBP versus no-LBP only. Beyond the 48 studies using AI/ML for LBP classification, no studies examined use of AI/ML in prognosis prediction of specific sub-groups, and AI/ML techniques are yet to be implemented in guiding LBP treatment. In contrast, the STarT Back tool has been assessed for internal consistency, test-retest reliability, validity, pain and disability prognosis, and influence on pain and disability treatment outcomes. McKenzie has been assessed for inter- and intra-tester reliability, prognosis, and impact on pain and disability outcomes relative to other treatments. For AI/ML methods to contribute to the refinement of LBP (sub-)classification and guide treatment allocation, large data sets containing known and exploratory clinical features should be examined. There is also a need to establish reliability, validity, and prognostic capacity of AI/ML techniques in LBP as well as its ability to inform treatment allocation for improved patient outcomes and/or reduced healthcare costs.",2.0
32664491,Prevention of Prosthetic Joint Infection: From Traditional Approaches towards Quality Improvement and Data Mining,2020 Jul 11;9(7):2190.,"A projected increased use of total joint arthroplasties will naturally result in a related increase in the number of prosthetic joint infections (PJIs). Suppression of the local peri-implant immune response counters efforts to eradicate bacteria, allowing the formation of biofilms and compromising preventive measures taken in the operating room. For these reasons, the prevention of PJI should focus concurrently on the following targets: (i) identifying at-risk patients; (ii) reducing ""bacterial load"" perioperatively; (iii) creating an antibacterial/antibiofilm environment at the site of surgery; and (iv) stimulating the local immune response. Despite considerable recent progress made in experimental and clinical research, a large discrepancy persists between proposed and clinically implemented preventative strategies. The ultimate anti-infective strategy lies in an optimal combination of all preventative approaches into a single ""clinical pack"", applied rigorously in all settings involving prosthetic joint implantation. In addition, ""anti-infective"" implants might be a choice in patients who have an increased risk for PJI. However, further progress in the prevention of PJI is not imaginable without a close commitment to using quality improvement tools in combination with continual data mining, reflecting the efficacy of the preventative strategy in a particular clinical setting.",2.0
32663517,Advancing computer-aided drug discovery (CADD) by big data and data-driven machine learning modeling,2020 Sep;25(9):1624-1638.,"Advancing a new drug to market requires substantial investments in time as well as financial resources. Crucial bioactivities for drug candidates, including their efficacy, pharmacokinetics (PK), and adverse effects, need to be investigated during drug development. With advancements in chemical synthesis and biological screening technologies over the past decade, a large amount of biological data points for millions of small molecules have been generated and are stored in various databases. These accumulated data, combined with new machine learning (ML) approaches, such as deep learning, have shown great potential to provide insights into relevant chemical structures to predict in vitro, in vivo, and clinical outcomes, thereby advancing drug discovery and development in the big data era.",2.0
32657885,Machine learning for classification and prediction of brain diseases: recent advances and upcoming challenges,2020 Aug;33(4):439-450.,"Purpose of review:                    Machine learning is an artificial intelligence technique that allows computers to perform a task without being explicitly programmed. Machine learning can be used to assist diagnosis and prognosis of brain disorders. Although the earliest articles date from more than ten years ago, research increases at a very fast pace.              Recent findings:                    Recent works using machine learning for diagnosis have moved from classification of a given disease versus controls to differential diagnosis. Intense research has been devoted to the prediction of the future patient state. Although a lot of earlier works focused on neuroimaging as data source, the current trend is on the integration of multimodal data. In terms of targeted diseases, dementia remains dominant but approaches have been developed for a wide variety of neurological and psychiatric diseases.              Summary:                    Machine learning is extremely promising for assisting diagnosis and prognosis in brain disorders. Nevertheless, we argue that key challenges remain to be addressed by the community for bringing these tools in clinical routine: good practices regarding validation and reproducible research need to be more widely adopted; extensive generalization studies are required; interpretable models are needed to overcome the limitations of black-box approaches.",2.0
32656188,On the Conformational Dynamics of β-Amyloid Forming Peptides: A Computational Perspective,2020 Jun 3;8:532.,"Understanding the conformational dynamics of proteins and peptides involved in important functions is still a difficult task in computational structural biology. Because such conformational transitions in β-amyloid (Aβ) forming peptides play a crucial role in many neurological disorders, researchers from different scientific fields have been trying to address issues related to the folding of Aβ forming peptides together. Many theoretical models have been proposed in the recent years for studying Aβ peptides using mathematical, physicochemical, and molecular dynamics simulation, and machine learning approaches. In this article, we have comprehensively reviewed the developmental advances in the theoretical models for Aβ peptide folding and interactions, particularly in the context of neurological disorders. Furthermore, we have extensively reviewed the advances in molecular dynamics simulation as a tool used for studying the conversions between polymorphic amyloid forms and applications of using machine learning approaches in predicting Aβ peptides and aggregation-prone regions in proteins. We have also provided details on the theoretical advances in the study of Aβ peptides, which would enhance our understanding of these peptides at the molecular level and eventually lead to the development of targeted therapies for certain acute neurological disorders such as Alzheimer's disease in the future.",2.0
32655344,A Review of Sensory Feedback in Upper-Limb Prostheses From the Perspective of Human Motor Control,2020 Jun 23;14:345.,"This manuscript reviews historical and recent studies that focus on supplementary sensory feedback for use in upper limb prostheses. It shows that the inability of many studies to speak to the issue of meaningful performance improvements in real-life scenarios is caused by the complexity of the interactions of supplementary sensory feedback with other types of feedback along with other portions of the motor control process. To do this, the present manuscript frames the question of supplementary feedback from the perspective of computational motor control, providing a brief review of the main advances in that field over the last 20 years. It then separates the studies on the closed-loop prosthesis control into distinct categories, which are defined by relating the impact of feedback to the relevant components of the motor control framework, and reviews the work that has been done over the last 50+ years in each of those categories. It ends with a discussion of the studies, along with suggestions for experimental construction and connections with other areas of research, such as machine learning.",5.0
32655294,A Brief Survey for MicroRNA Precursor Identification Using Machine Learning Methods,2020 Jan;21(1):11-25.,"MicroRNAs, a group of short non-coding RNA molecules, could regulate gene expression. Many diseases are associated with abnormal expression of miRNAs. Therefore, accurate identification of miRNA precursors is necessary. In the past 10 years, experimental methods, comparative genomics methods, and artificial intelligence methods have been used to identify pre-miRNAs. However, experimental methods and comparative genomics methods have their disadvantages, such as time-consuming. In contrast, machine learning-based method is a better choice. Therefore, the review summarizes the current advances in pre-miRNA recognition based on computational methods, including the construction of benchmark datasets, feature extraction methods, prediction algorithms, and the results of the models. And we also provide valid information about the predictors currently available. Finally, we give the future perspectives on the identification of pre-miRNAs. The review provides scholars with a whole background of pre-miRNA identification by using machine learning methods, which can help researchers have a clear understanding of progress of the research in this field.",
32655293,A Mini-review of the Computational Methods Used in Identifying RNA 5-Methylcytosine Sites,2020 Jan;21(1):3-10.,"RNA 5-methylcytosine (m5C) is one of the pillars of post-transcriptional modification (PTCM). A growing body of evidence suggests that m5C plays a vital role in RNA metabolism. Accurate localization of RNA m5C sites in tissue cells is the premise and basis for the in-depth understanding of the functions of m5C. However, the main experimental methods of detecting m5C sites are limited to varying degrees. Establishing a computational model to predict modification sites is an excellent complement to wet experiments for identifying m5C sites. In this review, we summarized some available m5C predictors and discussed the characteristics of these methods.",1.0
32655135,Future possibilities for artificial intelligence in the practical management of hypertension,2020 Dec;43(12):1327-1337.,"The use of artificial intelligence in numerous prediction and classification tasks, including clinical research and healthcare management, is becoming increasingly more common. This review describes the current status and a future possibility for artificial intelligence in blood pressure management, that is, the possibility of accurately predicting and estimating blood pressure using large-scale data, such as personal health records and electronic medical records. Individual blood pressure continuously changes because of lifestyle habits and the environment. This review focuses on two topics regarding controlling changing blood pressure: a novel blood pressure measurement system and blood pressure analysis using artificial intelligence. Regarding the novel blood pressure measurement system, we compare the conventional cuff-less method with the analysis of pulse waves using artificial intelligence for blood pressure estimation. Then, we describe the prediction of future blood pressure values using machine learning and deep learning. In addition, we summarize factor analysis using ""explainable AI"" to solve a black-box problem of artificial intelligence. Overall, we show that artificial intelligence is advantageous for hypertension management and can be used to establish clinical evidence for the practical management of hypertension.",
32654970,The future of cerebral organoids in drug discovery,2021 Mar;111:67-73.,"Until the discovery of human embryonic stem cells and human induced pluripotent stem cells, biotechnology companies were severely limited in the number of human tissues that they could model in large-scale in vitro studies. Until this point, companies have been limited to immortalized cancer lines or a small number of primary cell types that could be extracted and expanded. Nowadays, protocols continue to be developed in the stem cell field, enabling researchers to model an ever-growing library of cell types in controlled, large-scale screens. One differentiation method in particular- cerebral organoids- shows substantial potential in the field of neuroscience and developmental neurobiology. Cerebral organoid technology is still in an early phase of development, and there are several challenges that are currently being addressed by academic and industrial researchers alike. Here we briefly describe some of the early adopters of cerebral organoids, several of the challenges that they are likely facing, and various technologies that are currently being implemented to overcome them.",2.0
32652384,Predicting the rate constants of semivolatile organic compounds with hydroxyl radicals and ozone in indoor air,2020 Nov;266(Pt 2):115050.,"Semivolatile organic compounds (SVOCs) in air can react with hydroxyl radicals (OH), nitrate radicals (NO3) and ozone (O3). Two questions regarding SVOC reactivity with OH, NO3 and O3 in the gas and particle phases remain to be addressed: according to the existing measurements in the literature, which are the most reactive SVOCs in air, and how can the SVOC reactivity in the gas and particle phases be predicted? In the present study, a literature review of the second-order rate constant (k) was carried out to determine the SVOC reactivity with OH, NO3 and O3 in the gas and particle phases in ambient and indoor air at room temperature. Measured k values were available in the literature for 90 polycyclic aromatic hydrocarbons (PAHs), polychlorinated biphenyls (PCBs), organophosphates, dioxins, di(2-ethylhexyl)phthalate (DEHP) and pesticides including pyrifenox, carbamates and terbuthylazine. PAHs and organophosphates were found to be more reactive than dioxins and PCBs. Based on the obtained data, quantitative structure-activity relationship (QSAR) models were developed to predict the k value using quantum chemical, molecular, physical property and environmental descriptors. Eight linear and nonlinear statistical models were employed, including regression models, bagging, random forest and gradient boosting. QSAR models were developed for SVOC/OH reactions in the gas and particle phases and SVOC/O3 reactions in the particle phase. Models for SVOC/NO3 and SVOC/O3 reactions in the gas phase could not be developed due to the lack of measured k values for model training. The least absolute shrinkage and selection operator (LASSO) regression and random forest models were identified as the most effective models for SVOC reactivity prediction according to a comparison of model performance metrics.",
32652309,Bayer's in silico ADMET platform: a journey of machine learning over the past two decades,2020 Sep;25(9):1702-1709.,"Over the past two decades, an in silico absorption, distribution, metabolism, and excretion (ADMET) platform has been created at Bayer Pharma with the goal to generate models for a variety of pharmacokinetic and physicochemical endpoints in early drug discovery. These tools are accessible to all scientists within the company and can be a useful in assisting with the selection and design of novel leads, as well as the process of lead optimization. Here. we discuss the development of machine-learning (ML) approaches with special emphasis on data, descriptors, and algorithms. We show that high company internal data quality and tailored descriptors, as well as a thorough understanding of the experimental endpoints, are essential to the utility of our models. We discuss the recent impact of deep neural networks and show selected application examples.",2.0
32652095,Addressing Reduced Laboratory-Based Pulmonary Function Testing During a Pandemic,2020 Dec;158(6):2502-2510.,"To reduce the spread of the severe acute respiratory syndrome coronavirus 2, many pulmonary function testing (PFT) laboratories have been closed or have significantly reduced their testing capacity. Because these mitigation strategies may be necessary for the next 6 to 18 months to prevent recurrent peaks in disease prevalence, fewer objective measurements of lung function will alter the diagnosis and care of patients with chronic respiratory diseases. PFT, which includes spirometry, lung volume, and diffusion capacity measurement, is essential to the diagnosis and management of patients with asthma, COPD, and other chronic lung conditions. Both traditional and innovative alternatives to conventional testing must now be explored. These may include peak expiratory flow devices, electronic portable spirometers, portable exhaled nitric oxide measurement, airwave oscillometry devices, and novel digital health tools such as smartphone microphone spirometers and mobile health technologies along with integration of machine learning approaches. The adoption of some novel approaches may not merely replace but could improve existing management strategies and alter common diagnostic paradigms. With these options comes important technical, privacy, ethical, financial, and medicolegal barriers that must be addressed. However, the coronavirus disease 19 pandemic also presents a unique opportunity to augment conventional testing by including innovative and emerging approaches to measuring lung function remotely in patients with respiratory disease. The benefits of such an approach have the potential to enhance respiratory care and empower patient self-management well beyond the current global pandemic.",6.0
32648130,Heart Failure with Preserved Ejection Fraction-a Concise Review,2020 Jul 9;22(9):82.,"Purpose of review:                    Heart failure with preserved ejection fraction (HFpEF) is a relatively new disease entity used in medical terminology; however, both the number of patients and its clinical significance are growing. HFpEF used to be seen as a mild condition; however, the symptoms and quality of life of the patients are comparable to those with reduced ejection fraction. The disease is much more complex than previously thought. In this article, information surrounding the etiology, diagnosis, prognosis, and possible therapeutic options of HFpEF are reviewed and summarized.              Recent findings:                    It has recently been proposed that heart failure (HF) is rather a heterogeneous syndrome with a spectrum of overlapping and distinct characteristics. HFpEF itself can be distilled into different phenotypes based on the underlying biology. The etiological factors of HFpEF are unclear; however, systemic low-grade inflammation and microvascular damage as a consequence of comorbidities associated with endothelial dysfunction, oxidative stress, myocardial remodeling, and fibrosis are considered to play a crucial role in the pathogenesis of a disease. The H2FPEF score and the HFpEF nomogram are recently validated highly sensitive tools employed for risk assessment of subclinical heart failure. Despite numerous studies, there is still no evidence-based pharmacotherapy for HFpEF and the mortality and morbidity associated with HFpEF remain high. A better understanding of the etiological factors, the impact of comorbidities, the phenotypes of the disease, and implementation of machine learning algorithms may play a key role in the development of future therapeutic strategies.",2.0
32648059,Radiomics in Echocardiography: Deep Learning and Echocardiographic Analysis,2020 Jul 9;22(9):89.,"Purpose of review:                    Recent development in artificial intelligence (AI) for cardiovascular imaging analysis, involving deep learning, is the start of a new phase in the research field. We review the current state of AI in cardiovascular field and discuss about its potential to improve clinical workflows and accuracy of diagnosis.              Recent findings:                    In the AI cardiovascular imaging field, there are many applications involving efficient image reconstruction, patient triage, and support for clinical decisions. These tools have a role to support repetitive clinical tasks. Although they will be powerful in some situations, these applications may have new potential in the hands of echo cardiologists, assisting but not replacing the human observer. We believe AI has the potential to improve the quality of echocardiography. Someday AI may be incorporated into the daily clinical setting, being an instrumental tool for cardiologists dealing with cardiovascular diseases.",
32647932,Machine Learning and Coronary Artery Calcium Scoring,2020 Jul 9;22(9):90.,"Purpose of review:                    To summarize current artificial intelligence (AI)-based applications for coronary artery calcium scoring (CACS) and their potential clinical impact.              Recent findings:                    Recent evolution of AI-based technologies in medical imaging has accelerated progress in CACS performed in diverse types of CT examinations, providing promising results for future clinical application in this field. CACS plays a key role in risk stratification of coronary artery disease (CAD) and patient management. Recent emergence of AI algorithms, particularly deep learning (DL)-based applications, have provided considerable progress in CACS. Many investigations have focused on the clinical role of DL models in CACS and showed excellent agreement between those algorithms and manual scoring, not only in dedicated coronary calcium CT but also in coronary CT angiography (CCTA), low-dose chest CT, and standard chest CT. Therefore, the potential of AI-based CACS may become more influential in the future.",
32647917,"Radiomics in radiation oncology-basics, methods, and limitations",2020 Oct;196(10):848-855.,"Over the past years, the quantity and complexity of imaging data available for the clinical management of patients with solid tumors has increased substantially. Without the support of methods from the field of artificial intelligence (AI) and machine learning, a complete evaluation of the available image information is hardly feasible in clinical routine. Especially in radiotherapy planning, manual detection and segmentation of lesions is laborious, time consuming, and shows significant variability among observers. Here, AI already offers techniques to support radiation oncologists, whereby ultimately, the productivity and the quality are increased, potentially leading to an improved patient outcome. Besides detection and segmentation of lesions, AI allows the extraction of a vast number of quantitative imaging features from structural or functional imaging data that are typically not accessible by means of human perception. These features can be used alone or in combination with other clinical parameters to generate mathematical models that allow, for example, prediction of the response to radiotherapy. Within the large field of AI, radiomics is the subdiscipline that deals with the extraction of quantitative image features as well as the generation of predictive or prognostic mathematical models. This review gives an overview of the basics, methods, and limitations of radiomics, with a focus on patients with brain tumors treated by radiation therapy.",1.0
32647898,Rage Against the Machine: Advancing the study of aggression ethology via machine learning,2020 Sep;237(9):2569-2588.,"Rationale:                    Aggression, comorbid with neuropsychiatric disorders, exhibits with diverse clinical presentations and places a significant burden on patients, caregivers, and society. This diversity is observed because aggression is a complex behavior that can be ethologically demarcated as either appetitive (rewarding) or reactive (defensive), each with its own behavioral characteristics, functionality, and neural basis that may transition from adaptive to maladaptive depending on genetic and environmental factors. There has been a recent surge in the development of preclinical animal models for studying appetitive aggression-related behaviors and identifying the neural mechanisms guiding their progression and expression. However, adoption of these procedures is often impeded by the arduous task of manually scoring complex social interactions. Manual observations are generally susceptible to observer drift, long analysis times, and poor inter-rater reliability, and are further incompatible with the sampling frequencies required of modern neuroscience methods.              Objectives:                    In this review, we discuss recent advances in the preclinical study of appetitive aggression in mice, paired with our perspective on the potential for machine learning techniques in producing automated, robust scoring of aggressive social behavior. We discuss critical considerations for implementing valid computer classifications within behavioral pharmacological studies.              Key results:                    Open-source automated classification platforms can match or exceed the performance of human observers while removing the confounds of observer drift, bias, and inter-rater reliability. Furthermore, unsupervised approaches can identify previously uncharacterized aggression-related behavioral repertoires in model species.              Discussion and conclusions:                    Advances in open-source computational approaches hold promise for overcoming current manual annotation caveats while also introducing and generalizing computational neuroethology to the greater behavioral neuroscience community. We propose that currently available open-source approaches are sufficient for overcoming the main limitations preventing wide adoption of machine learning within the context of preclinical aggression behavioral research.",1.0
32647386,"Gut microbiome, big data and machine learning to promote precision medicine for cancer",2020 Oct;17(10):635-648.,"The gut microbiome has been implicated in cancer in several ways, as specific microbial signatures are known to promote cancer development and influence safety, tolerability and efficacy of therapies. The 'omics' technologies used for microbiome analysis continuously evolve and, although much of the research is still at an early stage, large-scale datasets of ever increasing size and complexity are being produced. However, there are varying levels of difficulty in realizing the full potential of these new tools, which limit our ability to critically analyse much of the available data. In this Perspective, we provide a brief overview on the role of gut microbiome in cancer and focus on the need, role and limitations of a machine learning-driven approach to analyse large amounts of complex health-care information in the era of big data. We also discuss the potential application of microbiome-based big data aimed at promoting precision medicine in cancer.",14.0
32645448,Machine learning and AI-based approaches for bioactive ligand discovery and GPCR-ligand recognition,2020 Aug 1;180:89-110.,"In the last decade, machine learning and artificial intelligence applications have received a significant boost in performance and attention in both academic research and industry. The success behind most of the recent state-of-the-art methods can be attributed to the latest developments in deep learning. When applied to various scientific domains that are concerned with the processing of non-tabular data, for example, image or text, deep learning has been shown to outperform not only conventional machine learning but also highly specialized tools developed by domain experts. This review aims to summarize AI-based research for GPCR bioactive ligand discovery with a particular focus on the most recent achievements and research trends. To make this article accessible to a broad audience of computational scientists, we provide instructive explanations of the underlying methodology, including overviews of the most commonly used deep learning architectures and feature representations of molecular data. We highlight the latest AI-based research that has led to the successful discovery of GPCR bioactive ligands. However, an equal focus of this review is on the discussion of machine learning-based technology that has been applied to ligand discovery in general and has the potential to pave the way for successful GPCR bioactive ligand discovery in the future. This review concludes with a brief outlook highlighting the recent research trends in deep learning, such as active learning and semi-supervised learning, which have great potential for advancing bioactive ligand discovery.",
32644061,AI on a chip,2020 Aug 26;20(17):3074-3090.,"Artificial intelligence (AI) has dramatically changed the landscape of science, industry, defence, and medicine in the last several years. Supported by considerably enhanced computational power and cloud storage, the field of AI has shifted from mostly theoretical studies in the discipline of computer science to diverse real-life applications such as drug design, material discovery, speech recognition, self-driving cars, advertising, finance, medical imaging, and astronomical observation, where AI-produced outcomes have been proven to be comparable or even superior to the performance of human experts. In these applications, what is essentially important for the development of AI is the data needed for machine learning. Despite its prominent importance, the very first process of the AI development, namely data collection and data preparation, is typically the most laborious task and is often a limiting factor of constructing functional AI algorithms. Lab-on-a-chip technology, in particular microfluidics, is a powerful platform for both the construction and implementation of AI in a large-scale, cost-effective, high-throughput, automated, and multiplexed manner, thereby overcoming the above bottleneck. On this platform, high-throughput imaging is a critical tool as it can generate high-content information (e.g., size, shape, structure, composition, interaction) of objects on a large scale. High-throughput imaging can also be paired with sorting and DNA/RNA sequencing to conduct a massive survey of phenotype-genotype relations whose data is too complex to analyze with traditional computational tools, but is analyzable with the power of AI. In addition to its function as a data provider, lab-on-a-chip technology can also be employed to implement the developed AI for accurate identification, characterization, classification, and prediction of objects in mixed, heterogeneous, or unknown samples. In this review article, motivated by the excellent synergy between AI and lab-on-a-chip technology, we outline fundamental elements, recent advances, future challenges, and emerging opportunities of AI with lab-on-a-chip technology or ""AI on a chip"" for short.",4.0
32642182,Path to precision: prevention of post-operative atrial fibrillation,2020 May;12(5):2735-2746.,"Development of post-operative atrial fibrillation (POAF) following open-heart surgery is a significant clinical and economic burden. Despite advancements in medical therapies, the incidence of POAF remains elevated at 25-40%. Early work focused on detecting arrhythmias from electrocardiograms as well as identifying pre-operative risk factors from medical records. However, further progress has been stagnant, and a deeper understanding of pathogenesis and significant influences is warranted. With the advent of more complex machine learning (ML) algorithms and high-throughput sequencing, we have an unprecedented ability to capture and predict POAF in real-time. Integration of multimodal heterogeneous data and application of ML can generate a paradigm shift for diagnosis and treatment. This will require a concerted effort to consolidate and streamline real-time data. Herein, we will review the current literature and emerging opportunities aimed at predictive targets and new insights into the mechanisms underlying long-term sequelae of POAF.",
32639061,"Modeling, instrumentation, automation, and optimization of water resource recovery facilities (2019) DIRECT",2020 Oct;92(10):1499-1503.,"A review of the literature published in 2019 on topics relating to water resource recovery facilities (WRRFs) in the areas of modeling, automation, measurement and sensors, and optimization of wastewater treatment (or water resource reclamation) is presented.",
32637935,Artificial intelligence in luminal endoscopy,2020 Jun 23;13:2631774520935220.,"Artificial intelligence is a strong focus of interest for global health development. Diagnostic endoscopy is an attractive substrate for artificial intelligence with a real potential to improve patient care through standardisation of endoscopic diagnosis and to serve as an adjunct to enhanced imaging diagnosis. The possibility to amass large data to refine algorithms makes adoption of artificial intelligence into global practice a potential reality. Initial studies in luminal endoscopy involve machine learning and are retrospective. Improvement in diagnostic performance is appreciable through the adoption of deep learning. Research foci in the upper gastrointestinal tract include the diagnosis of neoplasia, including Barrett's, squamous cell and gastric where prospective and real-time artificial intelligence studies have been completed demonstrating a benefit of artificial intelligence-augmented endoscopy. Deep learning applied to small bowel capsule endoscopy also appears to enhance pathology detection and reduce capsule reading time. Prospective evaluation including the first randomised trial has been performed in the colon, demonstrating improved polyp and adenoma detection rates; however, these appear to be relevant to small polyps. There are potential additional roles of artificial intelligence relevant to improving the quality of endoscopic examinations, training and triaging of referrals. Further large-scale, multicentre and cross-platform validation studies are required for the robust incorporation of artificial intelligence-augmented diagnostic luminal endoscopy into our routine clinical practice.",
32637301,Calibration and validation of accelerometry using cut-points to assess physical activity in paediatric clinical groups: A systematic review,2020 Jun 8;19:101142.,"Regular physical activity is associated with physiological and psychosocial benefits in both healthy and clinical populations. However, little is known about tailoring the analysis of physical activity using accelerometers to the specific characteristics of chronic conditions. Whilst accelerometry is broadly used to assess physical activity, recommendations on calibration in paediatric clinical groups are warranted. The aim of this systematic review was to provide a critical overview of protocols used to calibrate accelerometry in children and adolescents with clinical conditions, as well as to develop recommendations for calibration and validation of accelerometry in such populations. The search was performed between March to July 2017 using text words and subject headings in six databases. Studies had to develop moderate-to-vigorous intensity physical activity (MVPA) cut-points for paediatric clinical populations to be included. Risk of bias was assessed using a specific checklist. A total of 540,630 titles were identified, with 323 full-text articles assessed. Five studies involving 347 participants aged 9 to 15 years were included. Twenty-four MVPA cut-points were reported across seven clinical conditions, 16 of which were developed for different models of ActiGraph, seven for Actical and one for Tritrac-R3D. Statistical approaches included mixed regression, machine learning and receiver operating characteristic analyses. Disease-specific MVPA cut-points ranged from 152 to 735 counts·15 s-1, with lower cut-points found for inherited muscle disease and higher cut-points associated with intellectual disabilities. The lower MVPA cut-points for diseases characterised by both ambulatory and metabolic impairments likely reflect the higher energetic demands associated with those conditions.",
32637044,Deep learning models in genomics; are we there yet?,2020 Jun 17;18:1466-1473.,"With the evolution of biotechnology and the introduction of the high throughput sequencing, researchers have the ability to produce and analyze vast amounts of genomics data. Since genomics produce big data, most of the bioinformatics algorithms are based on machine learning methodologies, and lately deep learning, to identify patterns, make predictions and model the progression or treatment of a disease. Advances in deep learning created an unprecedented momentum in biomedical informatics and have given rise to new bioinformatics and computational biology research areas. It is evident that deep learning models can provide higher accuracies in specific tasks of genomics than the state of the art methodologies. Given the growing trend on the application of deep learning architectures in genomics research, in this mini review we outline the most prominent models, we highlight possible pitfalls and discuss future directions. We foresee deep learning accelerating changes in the area of genomics, especially for multi-scale and multimodal data analysis for precision medicine.",4.0
32637040,Constructing knowledge graphs and their biomedical applications,2020 Jun 2;18:1414-1428.,"Knowledge graphs can support many biomedical applications. These graphs represent biomedical concepts and relationships in the form of nodes and edges. In this review, we discuss how these graphs are constructed and applied with a particular focus on how machine learning approaches are changing these processes. Biomedical knowledge graphs have often been constructed by integrating databases that were populated by experts via manual curation, but we are now seeing a more robust use of automated systems. A number of techniques are used to represent knowledge graphs, but often machine learning methods are used to construct a low-dimensional representation that can support many different applications. This representation is designed to preserve a knowledge graph's local and/or global structure. Additional machine learning methods can be applied to this representation to make predictions within genomic, pharmaceutical, and clinical domains. We frame our discussion first around knowledge graph construction and then around unifying representational learning techniques and unifying applications. Advances in machine learning for biomedicine are creating new opportunities across many domains, and we note potential avenues for future work with knowledge graphs that appear particularly promising.",3.0
32635375,When I Look into Your Eyes: A Survey on Computer Vision Contributions for Human Gaze Estimation and Tracking,2020 Jul 3;20(13):3739.,"The automatic detection of eye positions, their temporal consistency, and their mapping into a line of sight in the real world (to find where a person is looking at) is reported in the scientific literature as gaze tracking. This has become a very hot topic in the field of computer vision during the last decades, with a surprising and continuously growing number of application fields. A very long journey has been made from the first pioneering works, and this continuous search for more accurate solutions process has been further boosted in the last decade when deep neural networks have revolutionized the whole machine learning area, and gaze tracking as well. In this arena, it is being increasingly useful to find guidance through survey/review articles collecting most relevant works and putting clear pros and cons of existing techniques, also by introducing a precise taxonomy. This kind of manuscripts allows researchers and technicians to choose the better way to move towards their application or scientific goals. In the literature, there exist holistic and specifically technological survey documents (even if not updated), but, unfortunately, there is not an overview discussing how the great advancements in computer vision have impacted gaze tracking. Thus, this work represents an attempt to fill this gap, also introducing a wider point of view that brings to a new taxonomy (extending the consolidated ones) by considering gaze tracking as a more exhaustive task that aims at estimating gaze target from different perspectives: from the eye of the beholder (first-person view), from an external camera framing the beholder's, from a third-person view looking at the scene where the beholder is placed in, and from an external view independent from the beholder.",2.0
32633921,"A Pangenomic Perspective on the Emergence, Maintenance, and Predictability of Antibiotic Resistance",,"The rapidly expanding number of sequenced bacterial strains and species, and the ongoing curation of bacterial pangenomes has uncovered unexpected complexities in understanding and addressing antibiotic resistance in the context of the pangenome. It is becoming apparent that differences in the genetic background can cause species and strain-specific responses to the same antibiotic, triggering differential selective pressures and thereby strain or species-specific adaptive outcomes. In this chapter, we consider how the pangenome, on a between and within species level, can affect the response to antibiotics and the development of resistance as well as the role selective pressures such as antibiotics play in shaping and maintaining the pangenome. We review the tools that are used to study antibiotic resistance within a pangenomic context, highlight recent findings, discuss strategies for predicting the emergence of resistance and consider how effective therapies can be developed in the context of the pangenome.",
32634717,Application of Artificial Intelligence in COVID-19 drug repurposing,Sep-Oct 2020;14(5):1027-1031.,"Background and aim:                    COVID-19 outbreak has created havoc and a quick cure for the disease will be a therapeutic medicine that has usage history in patients to resolve the current pandemic. With technological advancements in Artificial Intelligence (AI) coupled with increased computational power, the AI-empowered drug repurposing can prove beneficial in the COVID-19 scenario.              Methods:                    The recent literature is studied and analyzed from various sources such as Scopus, Google Scholar, PubMed, and IEEE Xplore databases. The search terms used are 'COVID-19', ' AI ', and 'Drug Repurposing'.              Results:                    AI is implemented in the field design through the generation of the learning-prediction model and performs a quick virtual screening to accurately display the output. With a drug-repositioning strategy, AI can quickly detect drugs that can fight against emerging diseases such as COVID-19. This technology has the potential to improve the drug discovery, planning, treatment, and reported outcomes of the COVID-19 patient, being an evidence-based medical tool.              Conclusions:                    Thus, there are chances that the application of the AI approach in drug discovery is feasible. With prior usage experiences in patients, few of the old drugs, if shown active against SARS-CoV-2, can be readily applied to treat the COVID-19 patients. With the collaboration of AI with pharmacology, the efficiency of drug repurposing can improve significantly.",13.0
32634438,Update on therapeutic approaches and emerging therapies for SARS-CoV-2 virus,2020 Sep 15;883:173348.,"The global pandemic of coronavirus disease 2019 (COVID-19), caused by novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), has resulted in over 7,273,958 cases with almost over 413,372 deaths worldwide as per the WHO situational report 143 on COVID-19. There are no known treatment regimens with proven efficacy and vaccines thus far, posing an unprecedented challenge to identify effective drugs and vaccines for prevention and treatment. The urgency for its prevention and cure has resulted in an increased number of proposed treatment options. The high rate and volume of emerging clinical trials on therapies for COVID-19 need to be compared and evaluated to provide scientific evidence for effective medical options. Other emerging non-conventional drug discovery techniques such as bioinformatics and cheminformatics, structure-based drug design, network-based methods for prediction of drug-target interactions, artificial intelligence (AI) and machine learning (ML) and phage technique could provide alternative routes to discovering potent Anti-SARS-CoV2 drugs. While drugs are being repurposed and discovered for COVID-19, novel drug delivery systems will be paramount for efficient delivery and avoidance of possible drug resistance. This review describes the proposed drug targets for therapy, and outcomes of clinical trials that have been reported. It also identifies the adopted treatment modalities that are showing promise, and those that have failed as drug candidates. It further highlights various emerging therapies and future strategies for the treatment of COVID-19 and delivery of Anti-SARS-CoV2 drugs.",18.0
32633615,Probing the characteristics and biofunctional effects of disease-affected cells and drug response via machine learning applications,2020 Nov;40(7):951-977.,"Drug-induced transformations in disease characteristics at the cellular and molecular level offers the opportunity to predict and evaluate the efficacy of pharmaceutical ingredients whilst enabling the optimal design of new and improved drugs with enhanced pharmacokinetics and pharmacodynamics. Machine learning is a promising in-silico tool used to simulate cells with specific disease properties and to determine their response toward drug uptake. Differences in the properties of normal and infected cells, including biophysical, biochemical and physiological characteristics, plays a key role in developing fundamental cellular probing platforms for machine learning applications. Cellular features can be extracted periodically from both the drug treated, infected, and normal cells via image segmentations in order to probe dynamic differences in cell behavior. Cellular segmentation can be evaluated to reflect the levels of drug effect on a distinct cell or group of cells via probability scoring. This article provides an account for the use of machine learning methods to probe differences in the biophysical, biochemical and physiological characteristics of infected cells in response to pharmacokinetics uptake of drug ingredients for application in cancer, diabetes and neurodegenerative disease therapies.",2.0
32632888,A-learning: A new formulation of associative learning theory,2020 Dec;27(6):1166-1194.,"We present a new mathematical formulation of associative learning focused on non-human animals, which we call A-learning. Building on current animal learning theory and machine learning, A-learning is composed of two learning equations, one for stimulus-response values and one for stimulus values (conditioned reinforcement). A third equation implements decision-making by mapping stimulus-response values to response probabilities. We show that A-learning can reproduce the main features of: instrumental acquisition, including the effects of signaled and unsignaled non-contingent reinforcement; Pavlovian acquisition, including higher-order conditioning, omission training, autoshaping, and differences in form between conditioned and unconditioned responses; acquisition of avoidance responses; acquisition and extinction of instrumental chains and Pavlovian higher-order conditioning; Pavlovian-to-instrumental transfer; Pavlovian and instrumental outcome revaluation effects, including insight into why these effects vary greatly with training procedures and with the proximity of a response to the reinforcer. We discuss the differences between current theory and A-learning, such as its lack of stimulus-stimulus and response-stimulus associations, and compare A-learning with other temporal-difference models from machine learning, such as Q-learning, SARSA, and the actor-critic model. We conclude that A-learning may offer a more convenient view of associative learning than current mathematical models, and point out areas that need further development.",
32632670,Artificial Intelligence and Myocardial Contrast Enhancement Pattern,2020 Jul 7;22(8):77.,"Purpose of review:                    Machine learning (ML) and deep learning (DL) are two important categories of AI algorithms. Nowadays, AI technology has been gradually applied to cardiac magnetic resonance imaging (CMRI), covering the fields of myocardial contrast enhancement (MCE) pattern and automatic ventricular segmentation. This paper mainly discusses the relationship between machine learning and deep learning based on AI and pattern of MCE in CMRI.              Recent findings:                    It found that some histogram and GLCM parameters in ML algorithm had significant statistical differences in diagnosis of cardiomyopathy and differentiation of fibrosis and normal myocardial tissue. In the DL algorithm, there was no significant difference between CNN and observers in measuring myocardial fibrosis. The rapid development of texture parameter analysis methods would promote the medical imaging based on AI into a new era. Histogram and GLCM parameters are the research hotspot of unsupervised learning of MCE images. CNN has a great advantage in automatically identifying and quantifying myocardial fibrosis reflected by LGE images.",
32631256,MASS: predict the global qualities of individual protein models using random forests and novel statistical potentials,2020 Jul 6;21(Suppl 4):246.,"Background:                    Protein model quality assessment (QA) is an essential procedure in protein structure prediction. QA methods can predict the qualities of protein models and identify good models from decoys. Clustering-based methods need a certain number of models as input. However, if a pool of models are not available, methods that only need a single model as input are indispensable.              Results:                    We developed MASS, a QA method to predict the global qualities of individual protein models using random forests and various novel energy functions. We designed six novel energy functions or statistical potentials that can capture the structural characteristics of a protein model, which can also be used in other protein-related bioinformatics research. MASS potentials demonstrated higher importance than the energy functions of RWplus, GOAP, DFIRE and Rosetta when the scores they generated are used as machine learning features. MASS outperforms almost all of the four CASP11 top-performing single-model methods for global quality assessment in terms of all of the four evaluation criteria officially used by CASP, which measure the abilities to assign relative and absolute scores, identify the best model from decoys, and distinguish between good and bad models. MASS has also achieved comparable performances with the leading QA methods in CASP12 and CASP13.              Conclusions:                    MASS and the source code for all MASS potentials are publicly available at http://dna.cs.miami.edu/MASS/ .",
32631041,Recent Advances in the Application of Artificial Intelligence in Otorhinolaryngology-Head and Neck Surgery,2020 Nov;13(4):326-339.,"This study presents an up-to-date survey of the use of artificial intelligence (AI) in the field of otorhinolaryngology, considering opportunities, research challenges, and research directions. We searched PubMed, the Cochrane Central Register of Controlled Trials, Embase, and the Web of Science. We initially retrieved 458 articles. The exclusion of non-English publications and duplicates yielded a total of 90 remaining studies. These 90 studies were divided into those analyzing medical images, voice, medical devices, and clinical diagnoses and treatments. Most studies (42.2%, 38/90) used AI for image-based analysis, followed by clinical diagnoses and treatments (24 studies). Each of the remaining two subcategories included 14 studies. Machine learning and deep learning have been extensively applied in the field of otorhinolaryngology. However, the performance of AI models varies and research challenges remain.",
32629327,The role of chronobiology in drug-resistance epilepsy: The potential use of a variability and chronotherapy-based individualized platform for improving the response to anti-seizure drugs,2020 Aug;80:201-211.,"Despite progress in the development of anti-seizure drugs, drug-resistant epilepsy (DRE) occurs in a third of patients. DRE is associated with poor quality of life and increased risk of sudden, unexplained death. The autonomic nervous system and chronobiology play a role in DRE. In the present paper, we provide a narrative review the mechanisms that underlie DRE and characterize some of the autonomic- and chronotherapy-associated parameters that contribute to the degree of response to therapy. Variability describes the functions of many biological systems, which are dynamic and continuously change over time. These systems are required for responses to continuing internal and external triggers, in order to maintain homeostasis and normal function. Both intra- and inter-subject variability in biological systems have been described. We present a platform, which comprises a personalized-based machine learning closed loop algorithm built on epilepsy-related signatures, autonomic signals, and chronotherapy, as a means for overcoming DRE, improving the response, and reducing the toxicity of current therapies.",2.0
32628863,Artificial Intelligence and Machine Learning in Arrhythmias and Cardiac Electrophysiology,2020 Aug;13(8):e007952.,"Artificial intelligence (AI) and machine learning (ML) in medicine are currently areas of intense exploration, showing potential to automate human tasks and even perform tasks beyond human capabilities. Literacy and understanding of AI/ML methods are becoming increasingly important to researchers and clinicians. The first objective of this review is to provide the novice reader with literacy of AI/ML methods and provide a foundation for how one might conduct an ML study. We provide a technical overview of some of the most commonly used terms, techniques, and challenges in AI/ML studies, with reference to recent studies in cardiac electrophysiology to illustrate key points. The second objective of this review is to use examples from recent literature to discuss how AI and ML are changing clinical practice and research in cardiac electrophysiology, with emphasis on disease detection and diagnosis, prediction of patient outcomes, and novel characterization of disease. The final objective is to highlight important considerations and challenges for appropriate validation, adoption, and deployment of AI technologies into clinical practice.",2.0
32627972,Artificial Intelligence and Machine Learning in Computational Nanotoxicology: Unlocking and Empowering Nanomedicine,2020 Sep;9(17):e1901862.,"Advances in nanomedicine, coupled with novel methods of creating advanced materials at the nanoscale, have opened new perspectives for the development of healthcare and medical products. Special attention must be paid toward safe design approaches for nanomaterial-based products. Recently, artificial intelligence (AI) and machine learning (ML) gifted the computational tool for enhancing and improving the simulation and modeling process for nanotoxicology and nanotherapeutics. In particular, the correlation of in vitro generated pharmacokinetics and pharmacodynamics to in vivo application scenarios is an important step toward the development of safe nanomedicinal products. This review portrays how in vitro and in vivo datasets are used in in silico models to unlock and empower nanomedicine. Physiologically based pharmacokinetic (PBPK) modeling and absorption, distribution, metabolism, and excretion (ADME)-based in silico methods along with dosimetry models as a focus area for nanomedicine are mainly described. The computational OMICS, colloidal particle determination, and algorithms to establish dosimetry for inhalation toxicology, and quantitative structure-activity relationships at nanoscale (nano-QSAR) are revisited. The challenges and opportunities facing the blind spots in nanotoxicology in this computationally dominated era are highlighted as the future to accelerate nanomedicine clinical translation.",5.0
32626645,A systematic review on spatial crime forecasting,2020;9(1):7.,"Background:                    Predictive policing and crime analytics with a spatiotemporal focus get increasing attention among a variety of scientific communities and are already being implemented as effective policing tools. The goal of this paper is to provide an overview and evaluation of the state of the art in spatial crime forecasting focusing on study design and technical aspects.              Methods:                    We follow the PRISMA guidelines for reporting this systematic literature review and we analyse 32 papers from 2000 to 2018 that were selected from 786 papers that entered the screening phase and a total of 193 papers that went through the eligibility phase. The eligibility phase included several criteria that were grouped into: (a) the publication type, (b) relevance to research scope, and (c) study characteristics.              Results:                    The most predominant type of forecasting inference is the hotspots (i.e. binary classification) method. Traditional machine learning methods were mostly used, but also kernel density estimation based approaches, and less frequently point process and deep learning approaches. The top measures of evaluation performance are the Prediction Accuracy, followed by the Prediction Accuracy Index, and the F1-Score. Finally, the most common validation approach was the train-test split while other approaches include the cross-validation, the leave one out, and the rolling horizon.              Limitations:                    Current studies often lack a clear reporting of study experiments, feature engineering procedures, and are using inconsistent terminology to address similar problems.              Conclusions:                    There is a remarkable growth in spatial crime forecasting studies as a result of interdisciplinary technical work done by scholars of various backgrounds. These studies address the societal need to understand and combat crime as well as the law enforcement interest in almost real-time prediction.              Implications:                    Although we identified several opportunities and strengths there are also some weaknesses and threats for which we provide suggestions. Future studies should not neglect the juxtaposition of (existing) algorithms, of which the number is constantly increasing (we enlisted 66). To allow comparison and reproducibility of studies we outline the need for a protocol or standardization of spatial forecasting approaches and suggest the reporting of a study's key data items.",1.0
32625083,Artificial Intelligence and Machine Learning Applied at the Point of Care,2020 Jun 18;11:759.,"Introduction:                    The increasing availability of healthcare data and rapid development of big data analytic methods has opened new avenues for use of Artificial Intelligence (AI)- and Machine Learning (ML)-based technology in medical practice. However, applications at the point of care are still scarce.              Objective:                    Review and discuss case studies to understand current capabilities for applying AI/ML in the healthcare setting, and regulatory requirements in the US, Europe and China.              Methods:                    A targeted narrative literature review of AI/ML based digital tools was performed. Scientific publications (identified in PubMed) and grey literature (identified on the websites of regulatory agencies) were reviewed and analyzed.              Results:                    From the regulatory perspective, AI/ML-based solutions can be considered medical devices (i.e., Software as Medical Device, SaMD). A case series of SaMD is presented. First, tools for monitoring and remote management of chronic diseases are presented. Second, imaging applications for diagnostic support are discussed. Finally, clinical decision support tools to facilitate the choice of treatment and precision dosing are reviewed. While tested and validated algorithms for precision dosing exist, their implementation at the point of care is limited, and their regulatory and commercialization pathway is not clear. Regulatory requirements depend on the level of risk associated with the use of the device in medical practice, and can be classified into administrative (manufacturing and quality control), software-related (design, specification, hazard analysis, architecture, traceability, software risk analysis, cybersecurity, etc.), clinical evidence (including patient perspectives in some cases), non-clinical evidence (dosing validation and biocompatibility/toxicology) and other, such as e.g. benefit-to-risk determination, risk assessment and mitigation. There generally is an alignment between the US and Europe. China additionally requires that the clinical evidence is applicable to the Chinese population and recommends that a third-party central laboratory evaluates the clinical trial results.              Conclusions:                    The number of promising AI/ML-based technologies is increasing, but few have been implemented widely at the point of care. The need for external validation, implementation logistics, and data exchange and privacy remain the main obstacles.",
32623625,Ischemia and outcome prediction by cardiac CT based machine learning,2020 Dec;36(12):2429-2439.,"Cardiac CT using non-enhanced coronary artery calcium scoring (CACS) and coronary CT angiography (cCTA) has been proven to provide excellent evaluation of coronary artery disease (CAD) combining anatomical and morphological assessment of CAD for cardiovascular risk stratification and therapeutic decision-making, in addition to providing prognostic value for the occurrence of adverse cardiac outcome. In recent years, artificial intelligence (AI) and, in particular, the application of machine learning (ML) algorithms, have been promoted in cardiovascular CT imaging for improved decision pathways, risk stratification, and outcome prediction in a more objective, reproducible, and rational manner. AI is based on computer science and mathematics that are based on big data, high performance computational infrastructure, and applied algorithms. The application of ML in daily routine clinical practice may hold potential to improve imaging workflow and to promote better outcome prediction and more effective decision-making in patient management. Moreover, CT represents a field wherein ML may be particularly useful, such as CACS and cCTA. Thus, the purpose of this review is to give a short overview about the contemporary state of ML based algorithms in cardiac CT, as well as to provide clinicians with currently available scientific data on clinical validation and implementation of these algorithms for the prediction of ischemia-specific CAD and cardiovascular outcome.",
32622833,Social media based surveillance systems for healthcare using machine learning: A systematic review,2020 Aug;108:103500.,"Background:                    Real-time surveillance in the field of health informatics has emerged as a growing domain of interest among worldwide researchers. Evolution in this field has helped in the introduction of various initiatives related to public health informatics. Surveillance systems in the area of health informatics utilizing social media information have been developed for early prediction of disease outbreaks and to monitor diseases. In the past few years, the availability of social media data, particularly Twitter data, enabled real-time syndromic surveillance that provides immediate analysis and instant feedback to those who are charged with follow-ups and investigation of potential outbreaks. In this paper, we review the recent work, trends, and machine learning(ML) text classification approaches used by surveillance systems seeking social media data in the healthcare domain. We also highlight the limitations and challenges followed by possible future directions that can be taken further in this domain.              Methods:                    To study the landscape of research in health informatics performing surveillance of the various health-related data posted on social media or web-based platforms, we present a bibliometric analysis of the 1240 publications indexed in multiple scientific databases (IEEE, ACM Digital Library, ScienceDirect, PubMed) from the year 2010-2018. The papers were further reviewed based on the various machine learning algorithms used for analyzing health-related text posted on social media platforms.              Findings:                    Based on the corpus of 148 selected articles, the study finds the types of social media or web-based platforms used for surveillance in the healthcare domain, along with the health topic(s) studied by them. In the corpus of selected articles, we found 26 articles were using machine learning technique. These articles were studied to find commonly used ML techniques. The majority of studies (24%) focused on the surveillance of flu or influenza-like illness (ILI). Twitter (64%) is the most popular data source to perform surveillance research using social media text data, and Support Vector Machine (SVM) (33%) being the most used ML algorithm for text classification.              Conclusions:                    The inclusion of online data in surveillance systems has improved the disease prediction ability over traditional syndromic surveillance systems. However, social media based surveillance systems have many limitations and challenges, including noise, demographic bias, privacy issues, etc. Our paper mentions future directions, which can be useful for researchers working in the area. Researchers can use this paper as a library for social media based surveillance systems in the healthcare domain and can expand such systems by incorporating the future works discussed in our paper.",2.0
32622173,How to do things with (thousands of) words: Computational approaches to discourse analysis in Alzheimer's disease,2020 Aug;129:446-463.,"Natural Language Processing (NLP) is an ever-growing field of computational science that aims to model natural human language. Combined with advances in machine learning, which learns patterns in data, it offers practical capabilities including automated language analysis. These approaches have garnered interest from clinical researchers seeking to understand the breakdown of language due to pathological changes in the brain, offering fast, replicable and objective methods. The study of Alzheimer's disease (AD), and preclinical Mild Cognitive Impairment (MCI), suggests that changes in discourse (connected speech or writing) may be key to early detection of disease. There is currently no disease-modifying treatment for AD, the leading cause of dementia in people over the age of 65, but detection of those at risk of developing the disease could help with the identification and testing of medications which can take effect before the underlying pathology has irreversibly spread. We outline important components of natural language, as well as NLP tools and approaches with which they can be extracted, analysed and used for disease identification and risk prediction. We review literature using these tools to model discourse across the spectrum of AD, including the contribution of machine learning approaches and Automatic Speech Recognition (ASR). We conclude that NLP and machine learning techniques are starting to greatly enhance research in the field, with measurable and quantifiable language components showing promise for early detection of disease, but there remain research and practical challenges for clinical implementation of these approaches. Challenges discussed include the availability of large and diverse datasets, ethics of data collection and sharing, diagnostic specificity and clinical acceptability.",
32621201,Current applications of artificial intelligence for intraoperative decision support in surgery,2020 Aug;14(4):369-381.,"Research into medical artificial intelligence (AI) has made significant advances in recent years, including surgical applications. This scoping review investigated AI-based decision support systems targeted at the intraoperative phase of surgery and found a wide range of technological approaches applied across several surgical specialties. Within the twenty-one (n = 21) included papers, three main categories of motivations were identified for developing such technologies: (1) augmenting the information available to surgeons, (2) accelerating intraoperative pathology, and (3) recommending surgical steps. While many of the proposals hold promise for improving patient outcomes, important methodological shortcomings were observed in most of the reviewed papers that made it difficult to assess the clinical significance of the reported performance statistics. Despite limitations, the current state of this field suggests that a number of opportunities exist for future researchers and clinicians to work on AI for surgical decision support with exciting implications for improving surgical care.",1.0
32621068,A mapping study of ensemble classification methods in lung cancer decision support systems,2020 Oct;58(10):2177-2193.,"Achieving a high level of classification accuracy in medical datasets is a capital need for researchers to provide effective decision systems to assist doctors in work. In many domains of artificial intelligence, ensemble classification methods are able to improve the performance of single classifiers. This paper reports the state of the art of ensemble classification methods in lung cancer detection. We have performed a systematic mapping study to identify the most interesting papers concerning this topic. A total of 65 papers published between 2000 and 2018 were selected after an automatic search in four digital libraries and a careful selection process. As a result, it was observed that diagnosis was the task most commonly studied; homogeneous ensembles and decision trees were the most frequently adopted for constructing ensembles; and the majority voting rule was the predominant combination rule. Few studies considered the parameter tuning of the techniques used. These findings open several perspectives for researchers to enhance lung cancer research by addressing the identified gaps, such as investigating different classification methods, proposing other heterogeneous ensemble methods, and using new combination rules. Graphical abstract Main features of the mapping study performed in ensemble classification methods applied on lung cancer decision support systems.",
32620005,Advances in the computational understanding of mental illness,2021 Jan;46(1):3-19.,"Computational psychiatry is a rapidly growing field attempting to translate advances in computational neuroscience and machine learning into improved outcomes for patients suffering from mental illness. It encompasses both data-driven and theory-driven efforts. Here, recent advances in theory-driven work are reviewed. We argue that the brain is a computational organ. As such, an understanding of the illnesses arising from it will require a computational framework. The review divides work up into three theoretical approaches that have deep mathematical connections: dynamical systems, Bayesian inference and reinforcement learning. We discuss both general and specific challenges for the field, and suggest ways forward.",1.0
32618714,Machine learning methods in organ transplantation,2020 Aug;25(4):399-405.,"Purpose of review:                    Machine learning techniques play an important role in organ transplantation. Analysing the main tasks for which they are being applied, together with the advantages and disadvantages of their use, can be of crucial interest for clinical practitioners.              Recent findings:                    In the last 10 years, there has been an explosion of interest in the application of machine-learning techniques to organ transplantation. Several approaches have been proposed in the literature aiming to find universal models by considering multicenter cohorts or from different countries. Moreover, recently, deep learning has also been applied demonstrating a notable ability when dealing with a vast amount of information.              Summary:                    Organ transplantation can benefit from machine learning in such a way to improve the current procedures for donor--recipient matching or to improve standard scores. However, a correct preprocessing is needed to provide consistent and high quality databases for machine-learning algorithms, aiming to robust and fair approaches to support expert decision-making systems.",
32618431,Advances in accelerometry for cardiovascular patients: a systematic review with practical recommendations,2020 Oct;7(5):2021-2031.,"Aims:                    Accelerometers are becoming increasingly commonplace for assessing physical activity; however, their use in patients with cardiovascular diseases is relatively substandard. We aimed to systematically review the methods used for collecting and processing accelerometer data in cardiology, using the example of heart failure, and to provide practical recommendations on how to improve objective physical activity assessment in patients with cardiovascular diseases by using accelerometers.              Methods and results:                    Four electronic databases were searched up to September 2019 for observational, interventional, and validation studies using accelerometers to assess physical activity in patients with heart failure. Study and population characteristics, details of accelerometry data collection and processing, and description of physical activity metrics were extracted from the eligible studies and synthesized. To assess the quality and completeness of accelerometer reporting, the studies were scored using 12 items on data collection and processing, such as the placement of accelerometer, days of data collected, and criteria for non-wear of the accelerometer. In 60 eligible studies with 3500 patients (of those, 536 were heart failure with preserved ejection fraction patients), a wide variety of accelerometer brands (n = 27) and models (n = 46) were used, with Actigraph being the most frequent (n = 12), followed by Fitbit (n = 5). The accelerometer was usually worn on the hip (n = 32), and the most prevalent wear period was 7 days (n = 22). The median wear time required for a valid day was 600 min, and between two and five valid days was required for a patient to be included in the analysis. The most common measures of physical activity were steps (n = 20), activity counts (n = 15), and time spent in moderate-to-vigorous physical activity (n = 14). Only three studies validated accelerometers in a heart failure population, showing that their accuracy deteriorates at slower speeds. Studies failed to report between one and six (median 4) of the 12 scored items, with non-wear time criteria and valid day definition being the most underreported items.              Conclusions:                    The use of accelerometers in cardiology lacks consistency and reporting on data collection, and processing methods need to be improved. Furthermore, calculating metrics based on raw acceleration and machine learning techniques is lacking, opening the opportunity for future exploration. Therefore, we encourage researchers and clinicians to improve the quality and transparency of data collection and processing by following our proposed practical recommendations for using accelerometers in patients with cardiovascular diseases, which are outlined in the article.",3.0
32617720,From CT to artificial intelligence for complex assessment of plaque-associated risk,2020 Dec;36(12):2403-2427.,"The recent technological developments in the field of cardiac imaging have established coronary computed tomography angiography (CCTA) as a first-line diagnostic tool in patients with suspected coronary artery disease (CAD). CCTA offers robust information on the overall coronary circulation and luminal stenosis, also providing the ability to assess the composition, morphology, and vulnerability of atherosclerotic plaques. In addition, the perivascular adipose tissue (PVAT) has recently emerged as a marker of increased cardiovascular risk. The addition of PVAT quantification to standard CCTA imaging may provide the ability to extract information on local inflammation, for an individualized approach in coronary risk stratification. The development of image post-processing tools over the past several years allowed CCTA to provide a significant amount of data that can be incorporated into machine learning (ML) applications. ML algorithms that use radiomic features extracted from CCTA are still at an early stage. However, the recent development of artificial intelligence will probably bring major changes in the way we integrate clinical, biological, and imaging information, for a complex risk stratification and individualized therapeutic decision making in patients with CAD. This review aims to present the current evidence on the complex role of CCTA in the detection and quantification of vulnerable plaques and the associated coronary inflammation, also describing the most recent developments in the radiomics-based machine learning approach for complex assessment of plaque-associated risk.",2.0
32617334,Application of artificial intelligence in anterior segment ophthalmic diseases: diversity and standardization,2020 Jun;8(11):714.,"Artificial intelligence (AI) based on machine learning (ML) and deep learning (DL) techniques has gained tremendous global interest in this era. Recent studies have demonstrated the potential of AI systems to provide improved capability in various tasks, especially in image recognition field. As an image-centric subspecialty, ophthalmology has become one of the frontiers of AI research. Trained on optical coherence tomography, slit-lamp images and even ordinary eye images, AI can achieve robust performance in the detection of glaucoma, corneal arcus and cataracts. Moreover, AI models based on other forms of data also performed satisfactorily. Nevertheless, several challenges with AI application in ophthalmology have also arisen, including standardization of data sets, validation and applicability of AI models, and ethical issues. In this review, we provided a summary of the state-of-the-art AI application in anterior segment ophthalmic diseases, potential challenges in clinical implementation and our prospects.",1.0
32617332,The combination of brain-computer interfaces and artificial intelligence: applications and challenges,2020 Jun;8(11):712.,"Brain-computer interfaces (BCIs) have shown great prospects as real-time bidirectional links between living brains and actuators. Artificial intelligence (AI), which can advance the analysis and decoding of neural activity, has turbocharged the field of BCIs. Over the past decade, a wide range of BCI applications with AI assistance have emerged. These ""smart"" BCIs including motor and sensory BCIs have shown notable clinical success, improved the quality of paralyzed patients' lives, expanded the athletic ability of common people and accelerated the evolution of robots and neurophysiological discoveries. However, despite technological improvements, challenges remain with regard to the long training periods, real-time feedback, and monitoring of BCIs. In this article, the authors review the current state of AI as applied to BCIs and describe advances in BCI applications, their challenges and where they could be headed in the future.",1.0
32617080,Artificial intelligence in radiotherapy,Jul-Aug 2020;25(4):656-666.,"Artificial intelligence (AI) has already been implemented widely in the medical field in the recent years. This paper first reviews the background of AI and radiotherapy. Then it explores the basic concepts of different AI algorithms and machine learning methods, such as neural networks, that are available to us today and how they are being implemented in radiotherapy and diagnostic processes, such as medical imaging, treatment planning, patient simulation, quality assurance and radiation dose delivery. It also explores the ongoing research on AI methods that are to be implemented in radiotherapy in the future. The review shows very promising progress and future for AI to be widely used in various areas of radiotherapy. However, basing on various concerns such as availability and security of using big data, and further work on polishing and testing AI algorithms, it is found that we may not ready to use AI primarily in radiotherapy at the moment.",2.0
32615232,Automation of data analysis in molecular cancer imaging and its potential impact on future clinical practice,2021 Apr;188:30-36.,"Digitalization, especially the use of machine learning and computational intelligence, is considered to dramatically shape medical procedures in the near future. In the field of cancer diagnostics, radiomics, the extraction of multiple quantitative image features and their clustered analysis, is gaining increasing attention to obtain more detailed, reproducible, and meaningful information about the disease entity, its prognosis and the ideal therapeutic option. In this context, automation of diagnostic procedures can improve the entire pipeline, which comprises patient registration, planning and performing an imaging examination at the scanner, image reconstruction, image analysis, and feeding the diagnostic information from various sources into decision support systems. With a focus on cancer diagnostics, this review article reports and discusses how computer-assistance can be integrated into diagnostic procedures and which benefits and challenges arise from it. Besides a strong view on classical imaging modalities like x-ray, CT, MRI, ultrasound, PET, SPECT and hybrid imaging devices thereof, it is outlined how imaging data can be combined with data deriving from patient anamnesis, clinical chemistry, pathology, and different omics. In this context, the article also discusses IT infrastructures that are required to realize this integration in the clinical routine. Although there are still many challenges to comprehensively implement automated and integrated data analysis in molecular cancer imaging, the authors conclude that we are entering a new era of medical diagnostics and precision medicine.",1.0
32612866,Current status and future directions of high-throughput ADME screening in drug discovery,2020 Jun;10(3):201-208.,"During the last decade high-throughput in vitro absorption, distribution, metabolism and excretion (HT-ADME) screening has become an essential part of any drug discovery effort of synthetic molecules. The conduct of HT-ADME screening has been ""industrialized"" due to the extensive development of software and automation tools in cell culture, assay incubation, sample analysis and data analysis. The HT-ADME assay portfolio continues to expand in emerging areas such as drug-transporter interactions, early soft spot identification, and ADME screening of peptide drug candidates. Additionally, thanks to the very large and high-quality HT-ADME data sets available in many biopharma companies, in silico prediction of ADME properties using machine learning has also gained much momentum in recent years. In this review, we discuss the current state-of-the-art practices in HT-ADME screening including assay portfolio, assay automation, sample analysis, data processing, and prediction model building. In addition, we also offer perspectives in future development of this exciting field.",
32612756,Seq-ing answers: Current data integration approaches to uncover mechanisms of transcriptional regulation,2020 May 31;18:1330-1341.,"Advancements in the field of next generation sequencing lead to the generation of ever-more data, with the challenge often being how to combine and reconcile results from different OMICs studies such as genome, epigenome and transcriptome. Here we provide an overview of the standard processing pipelines for ChIP-seq and RNA-seq as well as common downstream analyses. We describe popular multi-omics data integration approaches used to identify target genes and co-factors, and we discuss how machine learning techniques may predict transcriptional regulators and gene expression.",2.0
32612753,Deep learning methods in protein structure prediction,2020 Jan 22;18:1301-1310.,"Protein Structure Prediction is a central topic in Structural Bioinformatics. Since the '60s statistical methods, followed by increasingly complex Machine Learning and recently Deep Learning methods, have been employed to predict protein structural information at various levels of detail. In this review, we briefly introduce the problem of protein structure prediction and essential elements of Deep Learning (such as Convolutional Neural Networks, Recurrent Neural Networks and basic feed-forward Neural Networks they are founded on), after which we discuss the evolution of predictive methods for one-dimensional and two-dimensional Protein Structure Annotations, from the simple statistical methods of the early days, to the computationally intensive highly-sophisticated Deep Learning algorithms of the last decade. In the process, we review the growth of the databases these algorithms are based on, and how this has impacted our ability to leverage knowledge about evolution and co-evolution to achieve improved predictions. We conclude this review outlining the current role of Deep Learning techniques within the wider pipelines to predict protein structures and trying to anticipate what challenges and opportunities may arise next.",10.0
32610220,Blurred lines: integrating emerging technologies to advance plant biosecurity,2020 Aug;56:127-134.,"Plant diseases threaten global food security and biodiversity. Rapid dispersal of pathogens particularly via human means has accelerated in recent years. Timely detection of plant pathogens is essential to limit their spread. At the same time, international regulations must keep abreast of advances in plant disease diagnostics. In this review we describe recent progress in developing modern plant disease diagnostics based on detection of pathogen components, high-throughput image analysis, remote sensing, and machine learning. We discuss how different diagnostic approaches can be integrated in detection frameworks that can work at different scales and account for sampling biases. Lastly, we briefly discuss the requirements to apply these advances under regulatory settings to improve biosecurity measures globally.",1.0
32607906,MR Image-Based Attenuation Correction of Brain PET Imaging: Review of Literature on Machine Learning Approaches for Segmentation,2020 Oct;33(5):1224-1241.,"Recent emerging hybrid technology of positron emission tomography/magnetic resonance (PET/MR) imaging has generated a great need for an accurate MR image-based PET attenuation correction. MR image segmentation, as a robust and simple method for PET attenuation correction, has been clinically adopted in commercial PET/MR scanners. The general approach in this method is to segment the MR image into different tissue types, each assigned an attenuation constant as in an X-ray CT image. Machine learning techniques such as clustering, classification and deep networks are extensively used for brain MR image segmentation. However, only limited work has been reported on using deep learning in brain PET attenuation correction. In addition, there is a lack of clinical evaluation of machine learning methods in this application. The aim of this review is to study the use of machine learning methods for MR image segmentation and its application in attenuation correction for PET brain imaging. Furthermore, challenges and future opportunities in MR image-based PET attenuation correction are discussed.",
32607629,Machine learning for the identification of clinically significant prostate cancer on MRI: a meta-analysis,2020 Dec;30(12):6877-6887.,"Objectives:                    The aim of this study was to systematically review the literature and perform a meta-analysis of machine learning (ML) diagnostic accuracy studies focused on clinically significant prostate cancer (csPCa) identification on MRI.              Methods:                    Multiple medical databases were systematically searched for studies on ML applications in csPCa identification up to July 31, 2019. Two reviewers screened all papers independently for eligibility. The area under the receiver operating characteristic curves (AUC) was pooled to quantify predictive accuracy. A random-effects model estimated overall effect size while statistical heterogeneity was assessed with the I2 value. A funnel plot was used to investigate publication bias. Subgroup analyses were performed based on reference standard (biopsy or radical prostatectomy) and ML type (deep and non-deep).              Results:                    After the final revision, 12 studies were included in the analysis. Statistical heterogeneity was high both in overall and in subgroup analyses. The overall pooled AUC for ML in csPCa identification was 0.86, with 0.81-0.91 95% confidence intervals (95%CI). The biopsy subgroup (n = 9) had a pooled AUC of 0.85 (95%CI = 0.79-0.91) while the radical prostatectomy one (n = 3) of 0.88 (95%CI = 0.76-0.99). Deep learning ML (n = 4) had a 0.78 AUC (95%CI = 0.69-0.86) while the remaining 8 had AUC = 0.90 (95%CI = 0.85-0.94).              Conclusions:                    ML pipelines using prostate MRI to identify csPCa showed good accuracy and should be further investigated, possibly with better standardisation in design and reporting of results.              Key points:                    • Overall pooled AUC was 0.86 with 0.81-0.91 95% confidence intervals. • In the reference standard subgroup analysis, algorithm accuracy was similar with pooled AUCs of 0.85 (0.79-0.91 95% confidence intervals) and 0.88 (0.76-0.99 95% confidence intervals) for studies employing biopsies and radical prostatectomy, respectively. • Deep learning pipelines performed worse (AUC = 0.78, 0.69-0.86 95% confidence intervals) than other approaches (AUC = 0.90, 0.85-0.94 95% confidence intervals).",1.0
32605325,"Path Planning Strategies to Optimize Accuracy, Quality, Build Time and Material Use in Additive Manufacturing: A Review",2020 Jun 28;11(7):633.,"Additive manufacturing (AM) is the process of joining materials layer by layer to fabricate products based on 3D models. Due to the layer-by-layer nature of AM, parts with complex geometries, integrated assemblies, customized geometry or multifunctional designs can now be manufactured more easily than traditional subtractive manufacturing. Path planning in AM is an important step in the process of manufacturing products. The final fabricated qualities, properties, etc., will be different when using different path strategies, even using the same AM machine and process parameters. Currently, increasing research studies have been published on path planning strategies with different aims. Due to the rapid development of path planning in AM and various newly proposed strategies, there is a lack of comprehensive reviews on this topic. Therefore, this paper gives a comprehensive understanding of the current status and challenges of AM path planning. This paper reviews and discusses path planning strategies in three categories: improving printed qualities, saving materials/time and achieving objective printed properties. The main findings of this review include: new path planning strategies can be developed by combining some of the strategies in literature with better performance; a path planning platform can be developed to help select the most suitable path planning strategy with required properties; research on path planning considering energy consumption can be carried out in the future; a benchmark model for testing the performance of path planning strategies can be designed; the trade-off among different fabricated properties can be considered as a factor in future path planning design processes; and lastly, machine learning can be a powerful tool to further improve path planning strategies in the future.",2.0
32605178,A Survey of IoT Security Based on a Layered Architecture of Sensing and Data Analysis,2020 Jun 28;20(13):3625.,"The Internet of Things (IoT) is leading today's digital transformation. Relying on a combination of technologies, protocols, and devices such as wireless sensors and newly developed wearable and implanted sensors, IoT is changing every aspect of daily life, especially recent applications in digital healthcare. IoT incorporates various kinds of hardware, communication protocols, and services. This IoT diversity can be viewed as a double-edged sword that provides comfort to users but can lead also to a large number of security threats and attacks. In this survey paper, a new compacted and optimized architecture for IoT is proposed based on five layers. Likewise, we propose a new classification of security threats and attacks based on new IoT architecture. The IoT architecture involves a physical perception layer, a network and protocol layer, a transport layer, an application layer, and a data and cloud services layer. First, the physical sensing layer incorporates the basic hardware used by IoT. Second, we highlight the various network and protocol technologies employed by IoT, and review the security threats and solutions. Transport protocols are exhibited and the security threats against them are discussed while providing common solutions. Then, the application layer involves application protocols and lightweight encryption algorithms for IoT. Finally, in the data and cloud services layer, the main important security features of IoT cloud platforms are addressed, involving confidentiality, integrity, authorization, authentication, and encryption protocols. The paper is concluded by presenting the open research issues and future directions towards securing IoT, including the lack of standardized lightweight encryption algorithms, the use of machine-learning algorithms to enhance security and the related challenges, the use of Blockchain to address security challenges in IoT, and the implications of IoT deployment in 5G and beyond.",1.0
32605077,Brain-Computer Interface-Based Humanoid Control: A Review,2020 Jun 27;20(13):3620.,"A Brain-Computer Interface (BCI) acts as a communication mechanism using brain signals to control external devices. The generation of such signals is sometimes independent of the nervous system, such as in Passive BCI. This is majorly beneficial for those who have severe motor disabilities. Traditional BCI systems have been dependent only on brain signals recorded using Electroencephalography (EEG) and have used a rule-based translation algorithm to generate control commands. However, the recent use of multi-sensor data fusion and machine learning-based translation algorithms has improved the accuracy of such systems. This paper discusses various BCI applications such as tele-presence, grasping of objects, navigation, etc. that use multi-sensor fusion and machine learning to control a humanoid robot to perform a desired task. The paper also includes a review of the methods and system design used in the discussed applications.",
32604065,AI in mental health,2020 Dec;36:112-117.,"With the advent of digital approaches to mental health, modern artificial intelligence (AI), and machine learning in particular, is being used in the development of prediction, detection and treatment solutions for mental health care. In terms of treatment, AI is being incorporated into digital interventions, particularly web and smartphone apps, to enhance user experience and optimise personalised mental health care. In terms of prediction and detection, modern streams of abundant data mean that data-driven AI methods can be employed to develop prediction/detection models for mental health conditions. In particular, an individual's 'digital exhaust', the data gathered from their numerous personal digital device and social media interactions, can be mined for behavioural or mental health insights. Language, long considered a window into the human mind, can now be quantitatively harnessed as data with powerful computer-based natural language processing to also provide a method of inferring mental health. Furthermore, natural language processing can also be used to develop conversational agents used for therapeutic intervention.",3.0
32603804,Digital microbiology,2020 Oct;26(10):1324-1331.,"Background:                    Digitalization and artificial intelligence have an important impact on the way microbiology laboratories will work in the near future. Opportunities and challenges lie ahead to digitalize the microbiological workflows. Making efficient use of big data, machine learning, and artificial intelligence in clinical microbiology requires a profound understanding of data handling aspects.              Objective:                    This review article summarizes the most important concepts of digital microbiology. The article gives microbiologists, clinicians and data scientists a viewpoint and practical examples along the diagnostic process.              Sources:                    We used peer-reviewed literature identified by a PubMed search for digitalization, machine learning, artificial intelligence and microbiology.              Content:                    We describe the opportunities and challenges of digitalization in microbiological diagnostic processes with various examples. We also provide in this context key aspects of data structure and interoperability, as well as legal aspects. Finally, we outline the way for applications in a modern microbiology laboratory.              Implications:                    We predict that digitalization and the usage of machine learning will have a profound impact on the daily routine of laboratory staff. Along the analytical process, the most important steps should be identified, where digital technologies can be applied and provide a benefit. The education of all staff involved should be adapted to prepare for the advances in digital microbiology.",
32602844,Artificial Intelligence Education and Tools for Medical and Health Informatics Students: Systematic Review,2020 Jun 30;6(1):e19285.,"Background:                    The use of artificial intelligence (AI) in medicine will generate numerous application possibilities to improve patient care, provide real-time data analytics, and enable continuous patient monitoring. Clinicians and health informaticians should become familiar with machine learning and deep learning. Additionally, they should have a strong background in data analytics and data visualization to use, evaluate, and develop AI applications in clinical practice.              Objective:                    The main objective of this study was to evaluate the current state of AI training and the use of AI tools to enhance the learning experience.              Methods:                    A comprehensive systematic review was conducted to analyze the use of AI in medical and health informatics education, and to evaluate existing AI training practices. PRISMA-P (Preferred Reporting Items for Systematic Reviews and Meta-Analysis Protocols) guidelines were followed. The studies that focused on the use of AI tools to enhance medical education and the studies that investigated teaching AI as a new competency were categorized separately to evaluate recent developments.              Results:                    This systematic review revealed that recent publications recommend the integration of AI training into medical and health informatics curricula.              Conclusions:                    To the best of our knowledge, this is the first systematic review exploring the current state of AI education in both medicine and health informatics. Since AI curricula have not been standardized and competencies have not been determined, a framework for specialized AI training in medical and health informatics education is proposed.",4.0
32602650,A Cancer Biologist's Primer on Machine Learning Applications in High-Dimensional Cytometry,2020 Aug;97(8):782-799.,"The application of machine learning and artificial intelligence to high-dimensional cytometry data sets has increasingly become a staple of bioinformatic data analysis over the past decade. This is especially true in the field of cancer biology, where protocols for collecting multiparameter single-cell data in a high-throughput fashion are rapidly developed. As the use of machine learning methodology in cytometry becomes increasingly common, there is a need for cancer biologists to understand the basic theory and applications of a variety of algorithmic tools for analyzing and interpreting cytometry data. We introduce the reader to several keystone machine learning-based analytic approaches with an emphasis on defining key terms and introducing a conceptual framework for making translational or clinically relevant discoveries. The target audience consists of cancer cell biologists and physician-scientists interested in applying these tools to their own data, but who may have limited training in bioinformatics. © 2020 International Society for Advancement of Cytometry.",5.0
32602593,Machine learning and artificial intelligence in haematology,2021 Jan;192(2):239-250.,"Digitalization of the medical record and integration of genomic methods into clinical practice have resulted in an unprecedented wealth of data. Machine learning is a subdomain of artificial intelligence that attempts to computationally extract meaningful insights from complex data structures. Applications of machine learning in haematological scenarios are steadily increasing. However, basic concepts are often unfamiliar to clinicians and investigators. The purpose of this review is to provide readers with tools to interpret and critically appraise machine learning literature. We begin with the elucidation of standard terminology and then review examples in haematology. Guidelines for designing and evaluating machine-learning studies are provided. Finally, we discuss limitations of the machine-learning approach.",2.0
32602066,Prognostic factors of biochemical remission after transsphenoidal surgery for acromegaly: a structured review,2020 Oct;23(5):582-594.,"Purpose:                    Biochemical control is the main determinant of survival, clinical manifestations and comorbidities in acromegaly. Transsphenoidal selective adenomectomy (TSA) is the initial treatment of choice with reported biochemical remission rates varying between 32 and 85%. Understanding the limiting factors is essential for identification of patients who require medical treatment.              Methods:                    We reviewed the English literature published in Medline/Pubmed until Dec 31, 2019 to identify eligible studies that described outcomes of TSA as primary therapy and performed analyses to determine the main predictors of remission.              Results:                    Most publications reported single-institution, retrospective studies. The following preoperative parameters were consistently associated with lower remission rates: cavernous sinus invasion by imaging, larger tumor size and higher GH levels. Young age and preoperative IGF-1 levels were predictive in some studies. When controlled for covariates, the best single preoperative predictor was cavernous sinus invasion, followed by preoperative GH levels. Conversely, low GH level in the first few days postoperatively was a robust predictor of durable remission. The influence of tumor histology (sparsely granular pattern, co-expression of prolactin and proliferation markers) on surgical remission remains to be established. Few studies developed predictive models that yielded much higher predictive values than individual parameters.              Conclusion:                    Surgical outcome prognostication systems could be further generated by machine learning algorithms in order to support development and implementation of personalized care in patients with acromegaly.",2.0
32601582,Clinical applications and performance of intelligent systems in dental and maxillofacial radiology: A review,2020 Jun;50(2):81-92.,"Intelligent systems (i.e., artificial intelligence), particularly deep learning, are machines able to mimic the cognitive functions of humans to perform tasks of problem-solving and learning. This field deals with computational models that can think and act intelligently, like the human brain, and construct algorithms that can learn from data to make predictions. Artificial intelligence is becoming important in radiology due to its ability to detect abnormalities in radiographic images that are unnoticed by the naked human eye. These systems have reduced radiologists' workload by rapidly recording and presenting data, and thereby monitoring the treatment response with a reduced risk of cognitive bias. Intelligent systems have an important role to play and could be used by dentists as an adjunct to other imaging modalities in making appropriate diagnoses and treatment plans. In the field of maxillofacial radiology, these systems have shown promise for the interpretation of complex images, accurate localization of landmarks, characterization of bone architecture, estimation of oral cancer risk, and the assessment of metastatic lymph nodes, periapical pathologies, and maxillary sinus pathologies. This review discusses the clinical applications and scope of intelligent systems such as machine learning, artificial intelligence, and deep learning programs in maxillofacial imaging.",2.0
32600802,Theory and practical use of Bayesian methods in interpreting clinical trial data: a narrative review,2020 Aug;125(2):201-207.,"The critical reading of scientific articles is necessary for the daily practice of evidence-based medicine. Rigorous comprehension of statistical methods is essential, as reflected by the extensive use of statistics in the biomedical literature. In contrast to the customary frequentist approach, which never uses or gives the probability of a hypothesis, Bayesian theory uses probabilities for both hypotheses and data. This statistical approach is increasingly used for analyses of clinical trial data and for applied machine learning. The aim of this review is to compare general Bayesian concepts with frequentist methods to facilitate a better understanding of Bayesian theory for readers who are not familiar with this approach. The review is intended to be used in combination with a checklist we have devised for reading reports analysed by Bayesian methods. We compare and contrast the different approaches of Bayesian vs frequentist statistical methods by considering data from a clinical trial that lends itself to this comparative approach.",1.0
32600638,Common Data Elements in Head and Neck Radiology Reporting,2020 Aug;30(3):379-391.,"Radiologists must convert the complex information in head and neck imaging into text reports that can be understood and used by clinicians, patients, and fellow radiologists for patient care, research, and quality initiatives. Common data elements in reporting, through use of defined questions with constrained answers and terminology, allow radiologists to incorporate best practice standards and improve communication of information regardless of individual reporting style. Use of common data elements for head and neck reporting has the potential to improve outcomes, reduce errors, and transition data consumption not only for humans but future machine learning systems.",
32600636,Artificial Intelligence in Head and Neck Imaging: A Glimpse into the Future,2020 Aug;30(3):359-368.,"Artificial intelligence, specifically machine learning and deep learning, is a rapidly developing field in imaging sciences with the potential to improve the efficiency and effectiveness of radiologists. This review covers common technical terms and basic concepts in imaging artificial intelligence and briefly reviews the application of these techniques to general imaging as well as head and neck imaging. Artificial intelligence has the potential to contribute improvements to all areas of patient care, including image acquisition, processing, segmentation, automated detection of findings, integration of clinical information, quality improvement, and research. Numerous challenges remain, however, before widespread imaging clinical adoption and integration occur.",
32600633,Dual Energy Computed Tomography in Head and Neck Imaging: Pushing the Envelope,2020 Aug;30(3):311-323.,"Multiple applications of dual energy computed tomography (DECT) have been described for the evaluation of disorders in the head and neck, especially in oncology. We review the body of evidence suggesting advantages of DECT for the evaluation of the neck compared with conventional single energy computed tomography scans, but the full potential of DECT is still to be realized. There is early evidence suggesting significant advantages of DECT for the extraction of quantitative biomarkers using radiomics and machine learning, representing a new horizon that may enable this technology to reach its full potential.",
32599515,Challenges and opportunities with CRISPR activation in bacteria for data-driven metabolic engineering,2020 Aug;64:190-198.,"Creating CRISPR gene activation (CRISPRa) technologies in industrially promising bacteria could be transformative for accelerating data-driven metabolic engineering and strain design. CRISPRa has been widely used in eukaryotes, but applications in bacterial systems have remained limited. Recent work shows that multiple features of bacterial promoters impose stringent requirements on CRISPRa-mediated gene activation. However, by systematically defining rules for effective bacterial CRISPRa sites and developing new approaches for encoding complex functions in engineered guide RNAs, there are now clear routes to generalize synthetic gene regulation in bacteria. When combined with multi-omics data collection and machine learning, the full development of bacterial CRISPRa will dramatically improve the ability to rapidly engineer bacteria for bioproduction through accelerated design-build-test-learn cycles.",
32596957,Magnetic resonance fingerprinting: from evolution to clinical applications,2020 Dec;67(4):333-344.,"In 2013, Magnetic Resonance Fingerprinting (MRF) emerged as a method for fast, quantitative Magnetic Resonance Imaging. This paper reviews the current status of MRF up to early 2020 and aims to highlight the advantages MRF can offer medical imaging professionals. By acquiring scan data as pseudorandom samples, MRF elicits a unique signal evolution, or 'fingerprint', from each tissue type. It matches 'randomised' free induction decay acquisitions against pre-computed simulated tissue responses to generate a set of quantitative images of T1 , T2 and proton density (PD) with co-registered voxels, rather than as traditional relative T1 - and T2 -weighted images. MRF numeric pixel values retain accuracy and reproducibility between 2% and 8%. MRF acquisition is robust to strong undersampling of k-space. Scan sequences have been optimised to suppress sub-sampling artefacts, while artificial intelligence and machine learning techniques have been employed to increase matching speed and precision. MRF promises improved patient comfort with reduced scan times and fewer image artefacts. Quantitative MRF data could be used to define population-wide numeric biomarkers that classify normal versus diseased tissue. Certification of clinical centres for MRF scan repeatability would permit numeric comparison of sequential images for any individual patient and the pooling of multiple patient images across large, cross-site imaging studies. MRF has to date shown promising results in early clinical trials, demonstrating reliable differentiation between malignant and benign prostate conditions, and normal and sclerotic hippocampal tissue. MRF is now undergoing small-scale trials at several sites across the world; moving it closer to routine clinical application.",1.0
32596403,Using Artificial Intelligence Resources in Dialysis and Kidney Transplant Patients: A Literature Review,2020 Jun 10;2020:9867872.,"Background:                    The purpose of this review is to depict current research and impact of artificial intelligence/machine learning (AI/ML) algorithms on dialysis and kidney transplantation. Published studies were presented from two points of view: What medical aspects were covered? What AI/ML algorithms have been used?              Methods:                    We searched four electronic databases or studies that used AI/ML in hemodialysis (HD), peritoneal dialysis (PD), and kidney transplantation (KT). Sixty-nine studies were split into three categories: AI/ML and HD, PD, and KT, respectively. We identified 43 trials in the first group, 8 in the second, and 18 in the third. Then, studies were classified according to the type of algorithm.              Results:                    AI and HD trials covered: (a) dialysis service management, (b) dialysis procedure, (c) anemia management, (d) hormonal/dietary issues, and (e) arteriovenous fistula assessment. PD studies were divided into (a) peritoneal technique issues, (b) infections, and (c) cardiovascular event prediction. AI in transplantation studies were allocated into (a) management systems (ML used as pretransplant organ-matching tools), (b) predicting graft rejection, (c) tacrolimus therapy modulation, and (d) dietary issues.              Conclusions:                    Although guidelines are reluctant to recommend AI implementation in daily practice, there is plenty of evidence that AI/ML algorithms can predict better than nephrologists: volumes, Kt/V, and hypotension or cardiovascular events during dialysis. Altogether, these trials report a robust impact of AI/ML on quality of life and survival in G5D/T patients. In the coming years, one would probably witness the emergence of AI/ML devices that facilitate the management of dialysis patients, thus increasing the quality of life and survival.",2.0
32596246,Review of Machine Learning in Predicting Dermatological Outcomes,2020 Jun 12;7:266.,"Artificial intelligence is a broad branch of computer science that has garnered significant interest in the field of medicine because of its problem solving, decision making and pattern recognition abilities. Machine learning, a subset of artificial intelligence, hones in on the ability of computers to receive data and learn for themselves, manipulating algorithms as they organize the information they are processing. Dermatology is at a particular advantage in the implementation of machine learning due to the availability of large clinical image databases that can be used for machine training and interpretation. While numerous studies have implemented machine learning in the diagnostic aspect of dermatology, less research has been conducted on the use of machine learning in predicting long-term outcomes in skin disease, with only a few studies published to date. Such an approach would assist physicians in selecting the best treatment methods, save patients' time, reduce treatment costs and improve the quality of treatment overall by reducing the amount of trial-and-error in the treatment process. In this review, we aim to provide a brief and relevant introduction to basic artificial intelligence processes, and to consolidate and examine the published literature on the use of machine learning in predicting clinical outcomes in dermatology.",
32594605,Cardiac mechanics in heart failure with preserved ejection fraction,2020 Nov;37(11):1936-1943.,"Heart failure with preserved ejection fraction (HFpEF) is a complex clinical entity associated with significant morbidity and mortality. Common comorbidities including hypertension, coronary artery disease, diabetes, chronic kidney disease, obesity, and increasing age predispose to preclinical diastolic dysfunction that often progresses to frank HFpEF. Clinical HFpEF is typically associated with some degree of diastolic dysfunction, but can occur in the absence of many conventional diastolic dysfunction indices. The exact biologic links between risk factors, structural changes, and clinical manifestations are not clearly apparent. Innovative approaches including deformation imaging have enabled deeper understanding of HFpEF cardiac mechanics beyond conventional metrics. Furthermore, predictive analytics through data-driven platforms have allowed for a deeper understanding of HFpEF phenotypes. This review focuses on the changes in cardiac mechanics that occur through preclinical myocardial dysfunction to clinically apparent HFpEF.",2.0
32594407,Non-invasive Imaging Techniques: From Histology to In Vivo Imaging : Chapter of Imaging in Oncology,2020;216:795-812.,"In this chapter, we will introduce and review molecular-sensitive imaging techniques, which close the gap between ex vivo and in vivo analysis. In detail, we will introduce spontaneous Raman spectral imaging, coherent anti-Stokes Raman scattering (CARS), stimulated Raman scattering (SRS), second-harmonic generation (SHG) and third-harmonic generation (THG), two-photon excited fluorescence (TPEF), and fluorescence lifetime imaging (FLIM). After reviewing these imaging techniques, we shortly introduce chemometric methods and machine learning techniques, which are needed to use these imaging techniques in diagnostic applications.",
32594406,Image-Guided Radiooncology: The Potential of Radiomics in Clinical Application,2020;216:773-794.,"Medical imaging plays an imminent role in today's radiation oncology workflow. Predominantly based on semantic image analysis, malignant tumors are diagnosed, staged, and therapy decisions are made. The field of ""radiomics"" promises to extract complementary, objective information from medical images. In radiomics, predefined quantitative features including intensity statistics, texture, shape, or filtering techniques are combined into statistical or machine learning models to predict clinical or biological outcomes. Alternatively, deep neural networks can directly analyze medical images and provide predictions. A large number of research studies could demonstrate that radiomics prediction models may provide significant benefits in the radiation oncology workflow including diagnostics, tumor characterization, target volume segmentation, prognostic stratification, and prediction of therapy response or treatment-related toxicities. This chapter provides an overview of techniques within the radiomics toolbox, potential clinical application, and current limitations. A literature overview of four selected malignant entities including non-small cell lung cancer, head and neck squamous cell carcinomas, soft tissue sarcomas, and gliomas is given.",1.0
32589980,Machine learning in haematological malignancies,2020 Jul;7(7):e541-e550.,"Machine learning is a branch of computer science and statistics that generates predictive or descriptive models by learning from training data rather than by being rigidly programmed. It has attracted substantial attention for its many applications in medicine, both as a catalyst for research and as a means of improving clinical care across the cycle of diagnosis, prognosis, and treatment of disease. These applications include the management of haematological malignancy, in which machine learning has created inroads in pathology, radiology, genomics, and the analysis of electronic health record data. As computational power becomes cheaper and the tools for implementing machine learning become increasingly democratised, it is likely to become increasingly integrated into the research and practice landscape of haematology. As such, machine learning merits understanding and attention from researchers and clinicians alike. This narrative Review describes important concepts in machine learning for unfamiliar readers, details machine learning's current applications in haematological malignancy, and summarises important concepts for clinicians to be aware of when appraising research that uses machine learning.",5.0
32587159,Insights into the growing popularity of artificial intelligence in ophthalmology,2020 Jul;68(7):1339-1346.,"Artificial intelligence (AI) in healthcare is the use of computer-algorithms in analyzing complex medical data to detect associations and provide diagnostic support outputs. AI and deep learning (DL) find obvious applications in fields like ophthalmology wherein huge amount of image-based data need to be analyzed; however, the outcomes related to image recognition are reasonably well-defined. AI and DL have found important roles in ophthalmology in early screening and detection of conditions such as diabetic retinopathy (DR), age-related macular degeneration (ARMD), retinopathy of prematurity (ROP), glaucoma, and other ocular disorders, being successful inroads as far as early screening and diagnosis are concerned and appear promising with advantages of high-screening accuracy, consistency, and scalability. AI algorithms need equally skilled manpower, trained optometrists/ophthalmologists (annotators) to provide accurate ground truth for training the images. The basis of diagnoses made by AI algorithms is mechanical, and some amount of human intervention is necessary for further interpretations. This review was conducted after tracing the history of AI in ophthalmology across multiple research databases and aims to summarise the journey of AI in ophthalmology so far, making a close observation of most of the crucial studies conducted. This article further aims to highlight the potential impact of AI in ophthalmology, the pitfalls, and how to optimally use it to the maximum benefits of the ophthalmologists, the healthcare systems and the patients, alike.",3.0
32584780,Approaches Based on Artificial Intelligence and the Internet of Intelligent Things to Prevent the Spread of COVID-19: Scoping Review,2020 Aug 10;22(8):e19104.,"Background:                    Artificial intelligence (AI) and the Internet of Intelligent Things (IIoT) are promising technologies to prevent the concerningly rapid spread of coronavirus disease (COVID-19) and to maximize safety during the pandemic. With the exponential increase in the number of COVID-19 patients, it is highly possible that physicians and health care workers will not be able to treat all cases. Thus, computer scientists can contribute to the fight against COVID-19 by introducing more intelligent solutions to achieve rapid control of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus that causes the disease.              Objective:                    The objectives of this review were to analyze the current literature, discuss the applicability of reported ideas for using AI to prevent and control COVID-19, and build a comprehensive view of how current systems may be useful in particular areas. This may be of great help to many health care administrators, computer scientists, and policy makers worldwide.              Methods:                    We conducted an electronic search of articles in the MEDLINE, Google Scholar, Embase, and Web of Knowledge databases to formulate a comprehensive review that summarizes different categories of the most recently reported AI-based approaches to prevent and control the spread of COVID-19.              Results:                    Our search identified the 10 most recent AI approaches that were suggested to provide the best solutions for maximizing safety and preventing the spread of COVID-19. These approaches included detection of suspected cases, large-scale screening, monitoring, interactions with experimental therapies, pneumonia screening, use of the IIoT for data and information gathering and integration, resource allocation, predictions, modeling and simulation, and robotics for medical quarantine.              Conclusions:                    We found few or almost no studies regarding the use of AI to examine COVID-19 interactions with experimental therapies, the use of AI for resource allocation to COVID-19 patients, or the use of AI and the IIoT for COVID-19 data and information gathering/integration. Moreover, the adoption of other approaches, including use of AI for COVID-19 prediction, use of AI for COVID-19 modeling and simulation, and use of AI robotics for medical quarantine, should be further emphasized by researchers because these important approaches lack sufficient numbers of studies. Therefore, we recommend that computer scientists focus on these approaches, which are still not being adequately addressed.",15.0
32583141,Computer-aided diagnosis systems for osteoporosis detection: a comprehensive survey,2020 Sep;58(9):1873-1917.,"Computer-aided diagnosis (CAD) has revolutionized the field of medical diagnosis. They assist in improving the treatment potentials and intensify the survival frequency by early diagnosing the diseases in an efficient, timely, and cost-effective way. The automatic segmentation has led the radiologist to successfully segment the region of interest to improve the diagnosis of diseases from medical images which is not so efficiently possible by manual segmentation. The aim of this paper is to survey the vision-based CAD systems especially focusing on the segmentation techniques for the pathological bone disease known as osteoporosis. Osteoporosis is the state of the bones where the mineral density of bones decreases and they become porous, making the bones easily susceptible to fractures by small injury or a fall. The article covers the image acquisition techniques for acquiring the medical images for osteoporosis diagnosis. The article also discusses the advanced machine learning paradigms employed in segmentation for osteoporosis disease. Other image processing steps in osteoporosis like feature extraction and classification are also briefly described. Finally, the paper gives the future directions to improve the osteoporosis diagnosis and presents the proposed architecture. Graphical abstract.",2.0
32582539,Machine Learning-Based Models for Prediction of Toxicity Outcomes in Radiotherapy,2020 Jun 5;10:790.,"In order to limit radiotherapy (RT)-related side effects, effective toxicity prediction and assessment schemes are essential. In recent years, the growing interest toward artificial intelligence and machine learning (ML) within the science community has led to the implementation of innovative tools in RT. Several researchers have demonstrated the high performance of ML-based models in predicting toxicity, but the application of these approaches in clinics is still lagging, partly due to their low interpretability. Therefore, an overview of contemporary research is needed in order to familiarize practitioners with common methods and strategies. Here, we present a review of ML-based models for predicting and classifying RT-induced complications from both a methodological and a clinical standpoint, focusing on the type of features considered, the ML methods used, and the main results achieved. Our work overviews published research in multiple cancer sites, including brain, breast, esophagus, gynecological, head and neck, liver, lung, and prostate cancers. The aim is to define the current state of the art and main achievements within the field for both researchers and clinicians.",1.0
32581758,"Current Status, Challenges, and Possible Solutions of EEG-Based Brain-Computer Interface: A Comprehensive Review",2020 Jun 3;14:25.,"Brain-Computer Interface (BCI), in essence, aims at controlling different assistive devices through the utilization of brain waves. It is worth noting that the application of BCI is not limited to medical applications, and hence, the research in this field has gained due attention. Moreover, the significant number of related publications over the past two decades further indicates the consistent improvements and breakthroughs that have been made in this particular field. Nonetheless, it is also worth mentioning that with these improvements, new challenges are constantly discovered. This article provides a comprehensive review of the state-of-the-art of a complete BCI system. First, a brief overview of electroencephalogram (EEG)-based BCI systems is given. Secondly, a considerable number of popular BCI applications are reviewed in terms of electrophysiological control signals, feature extraction, classification algorithms, and performance evaluation metrics. Finally, the challenges to the recent BCI systems are discussed, and possible solutions to mitigate the issues are recommended.",7.0
32581642,Applications of Machine Learning in miRNA Discovery and Target Prediction,2019 Dec;20(8):537-544.,"MicroRNA (miRNA) is a small non-coding molecule that is involved in gene regulation and RNA silencing by complementary on their targets. Experimental methods for target prediction can be time-consuming and expensive. Thus, the application of the computational approach is implicated to enlighten these complications with experimental studies. However, there is still a need for an optimized approach in miRNA biology. Therefore, machine learning (ML) would initiate a new era of research in miRNA biology towards potential diseases biomarker. In this article, we described the application of ML approaches in miRNA discovery and target prediction with functions and future prospective. The implementation of a new era of computational methodologies in this direction would initiate further advanced levels of discoveries in miRNA.",1.0
32580330,Gait Analysis in Parkinson's Disease: An Overview of the Most Accurate Markers for Diagnosis and Symptoms Monitoring,2020 Jun 22;20(12):3529.,"The aim of this review is to summarize that most relevant technologies used to evaluate gait features and the associated algorithms that have shown promise to aid diagnosis and symptom monitoring in Parkinson's disease (PD) patients. We searched PubMed for studies published between 1 January 2005, and 30 August 2019 on gait analysis in PD. We selected studies that have either used technologies to distinguish PD patients from healthy subjects or stratified PD patients according to motor status or disease stages. Only those studies that reported at least 80% sensitivity and specificity were included. Gait analysis algorithms used for diagnosis showed a balanced accuracy range of 83.5-100%, sensitivity of 83.3-100% and specificity of 82-100%. For motor status discrimination the gait analysis algorithms showed a balanced accuracy range of 90.8-100%, sensitivity of 92.5-100% and specificity of 88-100%. Despite a large number of studies on the topic of objective gait analysis in PD, only a limited number of studies reported algorithms that were accurate enough deemed to be useful for diagnosis and symptoms monitoring. In addition, none of the reported algorithms and technologies has been validated in large scale, independent studies.",3.0
32579720,Synthesizing Systems Biology Knowledge from Omics Using Genome-Scale Models,2020 Sep;20(17-18):e1900282.,"Omic technologies have enabled the complete readout of the molecular state of a cell at different biological scales. In principle, the combination of multiple omic data types can provide an integrated view of the entire biological system. This integration requires appropriate models in a systems biology approach. Here, genome-scale models (GEMs) are focused upon as one computational systems biology approach for interpreting and integrating multi-omic data. GEMs convert the reactions (related to metabolism, transcription, and translation) that occur in an organism to a mathematical formulation that can be modeled using optimization principles. A variety of genome-scale modeling methods used to interpret multiple omic data types, including genomics, transcriptomics, proteomics, metabolomics, and meta-omics are reviewed. The ability to interpret omics in the context of biological systems has yielded important findings for human health, environmental biotechnology, bioenergy, and metabolic engineering. The authors find that concurrent with advancements in omic technologies, genome-scale modeling methods are also expanding to enable better interpretation of omic data. Therefore, continued synthesis of valuable knowledge, through the integration of omic data with GEMs, are expected.",1.0
32578340,Microdissection-An Essential Prerequisite for Spatial Cancer Omics,2020 Sep;20(17-18):e2000077.,"The problem with cancer tissue is that its intratumoral heterogeneity and its complexity is extremely high as cells possess, depending on their location and function, different mutations, different mRNA expression and the highest intricacy in the protein pattern. Prior to genomic and proteomic analyses, it is therefore indispensable to identify the exact part of the tissue or even the exact cell. Laser-based microdissection is a tried and tested technique able to produce pure and well-defined cell material for further analysis with proteomic and genomic techniques. It sheds light on the heterogeneity of cancer or other complex diseases and enables the identification of biomarkers. This review aims to raise awareness for the reconsideration of laser-based microdissection and seeks to present current state-of-the-art combinations with omic techniques.",
