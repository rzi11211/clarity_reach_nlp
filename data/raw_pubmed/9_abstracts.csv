pmid,citations,title,date,text
32416782,10.0,Artificial intelligence and the future of global health,2020 May 16;395(10236):1579-1586.,"Concurrent advances in information technology infrastructure and mobile computing power in many low and middle-income countries (LMICs) have raised hopes that artificial intelligence (AI) might help to address challenges unique to the field of global health and accelerate achievement of the health-related sustainable development goals. A series of fundamental questions have been raised about AI-driven health interventions, and whether the tools, methods, and protections traditionally used to make ethical and evidence-based decisions about new technologies can be applied to AI. Deployment of AI has already begun for a broad range of health issues common to LMICs, with interventions focused primarily on communicable diseases, including tuberculosis and malaria. Types of AI vary, but most use some form of machine learning or signal processing. Several types of machine learning methods are frequently used together, as is machine learning with other approaches, most often signal processing. AI-driven health interventions fit into four categories relevant to global health researchers: (1) diagnosis, (2) patient morbidity or mortality risk assessment, (3) disease outbreak prediction and surveillance, and (4) health policy and planning. However, much of the AI-driven intervention research in global health does not describe ethical, regulatory, or practical considerations required for widespread use or deployment at scale. Despite the field remaining nascent, AI-driven health interventions could lead to improved health outcomes in LMICs. Although some challenges of developing and deploying these interventions might not be unique to these settings, the global health community will need to work quickly to establish guidelines for development, testing, and use, and develop a user-driven research agenda to facilitate equitable and ethical use."
32414188,,Future Is Unlicensed: Private 5G Unlicensed Network for Connecting Industries of Future,2020 May 13;20(10):2774.,"This paper aims to unlock the unlicensed band potential in realizing the Industry 4.0 communication goals of the Fifth-Generation (5G) and beyond. New Radio in the Unlicensed band (NR-U) is a new NR Release 16 mode of operation that has the capability to offer the necessary technology for cellular operators to integrate the unlicensed spectrum into 5G networks. NR-U enables both uplink and downlink operation in unlicensed bands, supporting 5G advanced features of ultra-high-speed, high bandwidth, low latency, and improvement in the reliability of wireless communications, which is essential to address massive-scale and highly-diverse future industrial networks. This paper highlights NR-U as a next-generation communication technology for smart industrial network communication and discusses the technology trends adopted by 5G in support of the Industry 4.0 revolution. However, due to operation in the shared/unlicensed spectrum, NR-U possesses several regulatory and coexistence challenges, limiting its application for operationally intensive environments such as manufacturing, supply chain, transportation systems, and energy. Thus, we discuss the significant challenges and potential solution approaches such as shared maximum channel occupancy time (MCOT), handover skipping, the self-organized network (SON), the adaptive back-off mechanism, and the multi-domain coexistence approach to overcome the unlicensed/shared band challenges and boost the realization of NR-U technology in mission-critical industrial applications. Further, we highlight the role of machine learning in providing the necessary intelligence and adaptation mechanisms for the realization of industrial 5G communication goals."
32413821,23.0,A review of modern technologies for tackling COVID-19 pandemic,Jul-Aug 2020;14(4):569-573.,"Objective:                    Science and technology sector constituting of data science, machine learning and artificial intelligence are contributing towards COVID-19. The aim of the present study is to discuss the various aspects of modern technology used to fight against COVID-19 crisis at different scales, including medical image processing, disease tracking, prediction outcomes, computational biology and medicines.              Methods:                    A progressive search of the database related to modern technology towards COVID-19 is made. Further, a brief review is done on the extracted information by assessing the various aspects of modern technologies for tackling COVID-19 pandemic.              Results:                    We provide a window of thoughts on review of the technology advances used to decrease and smother the substantial impact of the outburst. Though different studies relating to modern technology towards COVID-19 have come up, yet there are still constrained applications and contributions of technology in this fight.              Conclusions:                    On-going progress in the modern technology has contributed in improving people's lives and hence there is a solid conviction that validated research plans including artificial intelligence will be of significant advantage in helping people to fight this infection."
32411818,3.0,Report on computational assessment of Tumor Infiltrating Lymphocytes from the International Immuno-Oncology Biomarker Working Group,2020 May 12;6:16.,"Assessment of tumor-infiltrating lymphocytes (TILs) is increasingly recognized as an integral part of the prognostic workflow in triple-negative (TNBC) and HER2-positive breast cancer, as well as many other solid tumors. This recognition has come about thanks to standardized visual reporting guidelines, which helped to reduce inter-reader variability. Now, there are ripe opportunities to employ computational methods that extract spatio-morphologic predictive features, enabling computer-aided diagnostics. We detail the benefits of computational TILs assessment, the readiness of TILs scoring for computational assessment, and outline considerations for overcoming key barriers to clinical translation in this arena. Specifically, we discuss: 1. ensuring computational workflows closely capture visual guidelines and standards; 2. challenges and thoughts standards for assessment of algorithms including training, preanalytical, analytical, and clinical validation; 3. perspectives on how to realize the potential of machine learning models and to overcome the perceptual and practical limits of visual scoring."
32410553,,Application of Artificial Intelligence in Pharmaceutical and Biomedical Studies,2020;26(29):3569-3578.,"Background:                    Artificial intelligence (AI) is the way to model human intelligence to accomplish certain tasks without much intervention of human beings. The term AI was first used in 1956 with The Logic Theorist program, which was designed to simulate problem-solving ability of human beings. There have been a significant amount of research works using AI in order to determine the advantages and disadvantages of its applicabication and, future perspectives that impact different areas of society. Even the remarkable impact of AI can be transferred to the field of healthcare with its use in pharmaceutical and biomedical studies crucial for the socioeconomic development of the population in general within different studies, we can highlight those that have been conducted with the objective of treating diseases, such as cancer, neurodegenerative diseases, among others. In parallel, the long process of drug development also requires the application of AI to accelerate research in medical care.              Methods:                    This review is based on research material obtained from PubMed up to Jan 2020. The search terms include ""artificial intelligence"", ""machine learning"" in the context of research on pharmaceutical and biomedical applications.              Results:                    This study aimed to highlight the importance of AI in the biomedical research and also recent studies that support the use of AI to generate tools using patient data to improve outcomes. Other studies have demonstrated the use of AI to create prediction models to determine response to cancer treatment.              Conclusion:                    The application of AI in the field of pharmaceutical and biomedical studies has been extensive, including cancer research, for diagnosis as well as prognosis of the disease state. It has become a tool for researchers in the management of complex data, ranging from obtaining complementary results to conventional statistical analyses. AI increases the precision in the estimation of treatment effect in cancer patients and determines prediction outcomes."
32410356,2.0,Quantitative Prostate MRI,2020 May 15.,"Prostate MRI is reported in clinical practice using the Prostate Imaging and Data Reporting System (PI-RADS). PI-RADS aims to standardize, as much as possible, the acquisition, interpretation, reporting, and ultimately the performance of prostate MRI. PI-RADS relies upon mainly subjective analysis of MR imaging findings, with very few incorporated quantitative features. The shortcomings of PI-RADS are mainly: low-to-moderate interobserver agreement and modest accuracy for detection of clinically significant tumors in the transition zone. The use of a more quantitative analysis of prostate MR imaging findings is therefore of interest. Quantitative MR imaging features including: tumor size and volume, tumor length of capsular contact, tumor apparent diffusion coefficient (ADC) metrics, tumor T1 and T2 relaxation times, tumor shape, and texture analyses have all shown value for improving characterization of observations detected on prostate MRI and for differentiating between tumors by their pathological grade and stage. Quantitative analysis may therefore improve diagnostic accuracy for detection of cancer and could be a noninvasive means to predict patient prognosis and guide management. Since quantitative analysis of prostate MRI is less dependent on an individual users' assessment, it could also improve interobserver agreement. Semi- and fully automated analysis of quantitative (radiomic) MRI features using artificial neural networks represent the next step in quantitative prostate MRI and are now being actively studied. Validation, through high-quality multicenter studies assessing diagnostic accuracy for clinically significant prostate cancer detection, in the domain of quantitative prostate MRI is needed. This article reviews advances in quantitative prostate MRI, highlighting the strengths and limitations of existing and emerging techniques, as well as discussing opportunities and challenges for evaluation of prostate MRI in clinical practice when using quantitative assessment. LEVEL OF EVIDENCE: 5 TECHNICAL EFFICACY: Stage 2."
32408531,7.0,"Massive MIMO Systems for 5G and Beyond Networks-Overview, Recent Trends, Challenges, and Future Research Direction",2020 May 12;20(10):2753.,"The global bandwidth shortage in the wireless communication sector has motivated the study and exploration of wireless access technology known as massive Multiple-Input Multiple-Output (MIMO). Massive MIMO is one of the key enabling technology for next-generation networks, which groups together antennas at both transmitter and the receiver to provide high spectral and energy efficiency using relatively simple processing. Obtaining a better understating of the massive MIMO system to overcome the fundamental issues of this technology is vital for the successful deployment of 5G-and beyond-networks to realize various applications of the intelligent sensing system. In this paper, we present a comprehensive overview of the key enabling technologies required for 5G and 6G networks, highlighting the massive MIMO systems. We discuss all the fundamental challenges related to pilot contamination, channel estimation, precoding, user scheduling, energy efficiency, and signal detection in a massive MIMO system and discuss some state-of-the-art mitigation techniques. We outline recent trends such as terahertz communication, ultra massive MIMO (UM-MIMO), visible light communication (VLC), machine learning, and deep learning for massive MIMO systems. Additionally, we discuss crucial open research issues that direct future research in massive MIMO systems for 5G and beyond networks."
32407044,,The Role of Research and Technology in the Changing Ocean Economy: Proceedings of a Workshop—in Brief,,"Oceans have long been a frontier of opportunity for exploration, scientific understanding, commerce, and trade for the United States. The transformative technologies of the fourth industrial revolution — artificial intelligence, machine learning, robotics, Internet of Things, biotechnology, advanced materials — are expected to recondition traditional ocean-based industries and enable the growth of new markets prioritizing sustainability. At the nexus of unprecedented environmental change and rapid technology innovation, how should the United States position itself as a leader in the global ocean economy? On February 4 and 5, 2020, the Government-University-Industry Research Roundtable convened experts to discuss the importance of cross-sector collaboration and the opportunities for U.S. leadership in the context of a changing ocean and a changing ocean economy. This publication highlights the presentation and discussion of the workshop."
32408309,1.0,Oncology Informatics: Status Quo and Outlook,2020;98(6):329-331.,"Oncology has undergone rapid progress, with emerging developments in areas including cancer stem cells, molecularly targeted therapies, genomic analyses, and individually tailored immunotherapy. These advances have expanded the tools available in the fight against cancer. Some of these have seen broad media coverage resulting in justified public attention. However, these achievements have only been possible due to rapid developments in the expanding field of biomedical informatics and information technology (IT). Artificial intelligence, radiomics, electronic health records, and electronic patient-reported outcome measures (ePROMS) are only a few of the developments enabling further progress in oncology. The promising impact of IT in oncology will only become reality through a multidisciplinary approach to the complex challenges ahead."
32405554,2.0,Imaging in Spine Surgery: Current Concepts and Future Directions,2019 Nov 1;4(2):99-110.,"Objective:                    To review and highlight the historical and recent advances of imaging in spine surgery and to discuss current applications and future directions.              Methods:                    A PubMed review of the current literature was performed on all relevant articles that examined historical and recent imaging techniques used in spine surgery. Studies were examined for their thoroughness in description of various modalities and applications in current and future management.              Results:                    We reviewed 97 articles that discussed past, present, and future applications for imaging in spine surgery. Although most historical approaches relied heavily upon basic radiography, more recent advances have begun to expand upon advanced modalities, including the integration of more sophisticated equipment and artificial intelligence.              Conclusions:                    Since the days of conventional radiography, various modalities have emerged and become integral components of the spinal surgeon's diagnostic armamentarium. As such, it behooves the practitioner to remain informed on the current trends and potential developments in spinal imaging, as rapid adoption and interpretation of new techniques may make significant differences in patient management and outcomes. Future directions will likely become increasingly sophisticated as the implementation of machine learning, and artificial intelligence has become more commonplace in clinical practice."
32403240,3.0,Applications of Artificial Intelligence to Prostate Multiparametric MRI (mpMRI): Current and Emerging Trends,2020 May 11;12(5):1204.,"Prostate carcinoma is one of the most prevalent cancers worldwide. Multiparametric magnetic resonance imaging (mpMRI) is a non-invasive tool that can improve prostate lesion detection, classification, and volume quantification. Machine learning (ML), a branch of artificial intelligence, can rapidly and accurately analyze mpMRI images. ML could provide better standardization and consistency in identifying prostate lesions and enhance prostate carcinoma management. This review summarizes ML applications to prostate mpMRI and focuses on prostate organ segmentation, lesion detection and segmentation, and lesion characterization. A literature search was conducted to find studies that have applied ML methods to prostate mpMRI. To date, prostate organ segmentation and volume approximation have been well executed using various ML techniques. Prostate lesion detection and segmentation are much more challenging tasks for ML and were attempted in several studies. They largely remain unsolved problems due to data scarcity and the limitations of current ML algorithms. By contrast, prostate lesion characterization has been successfully completed in several studies because of better data availability. Overall, ML is well situated to become a tool that enhances radiologists' accuracy and speed."
32396837,6.0,Opening the Black Box: Interpretable Machine Learning for Geneticists,2020 Jun;36(6):442-455.,"Because of its ability to find complex patterns in high dimensional and heterogeneous data, machine learning (ML) has emerged as a critical tool for making sense of the growing amount of genetic and genomic data available. While the complexity of ML models is what makes them powerful, it also makes them difficult to interpret. Fortunately, efforts to develop approaches that make the inner workings of ML models understandable to humans have improved our ability to make novel biological insights. Here, we discuss the importance of interpretable ML, different strategies for interpreting ML models, and examples of how these strategies have been applied. Finally, we identify challenges and promising future directions for interpretable ML in genetics and genomics."
32395545,3.0,"Bridging the ""last mile"" gap between AI implementation and operation: ""data awareness"" that matters",2020 Apr;8(7):501.,"Interest in the application of machine learning (ML) techniques to medicine is growing fast and wide because of their ability to endow decision support systems with so-called artificial intelligence, particularly in those medical disciplines that extensively rely on digital imaging. Nonetheless, achieving a pragmatic and ecological validation of medical AI systems in real-world settings is difficult, even when these systems exhibit very high accuracy in laboratory settings. This difficulty has been called the ""last mile of implementation."" In this review of the concept, we claim that this metaphorical mile presents two chasms: the hiatus of human trust and the hiatus of machine experience. The former hiatus encompasses all that can hinder the concrete use of AI at the point of care, including availability and usability issues, but also the contradictory phenomena of cognitive ergonomics, such as automation bias (overreliance on technology) and prejudice against the machine (clearly the opposite). The latter hiatus, on the other hand, relates to the production and availability of a sufficient amount of reliable and accurate clinical data that is suitable to be the ""experience"" with which a machine can be trained. In briefly reviewing the existing literature, we focus on this latter hiatus of the last mile, as it has been largely neglected by both ML developers and doctors. In doing so, we argue that efforts to cross this chasm require data governance practices and a focus on data work, including the practices of data awareness and data hygiene. To address the challenge of bridging the chasms in the last mile of medical AI implementation, we discuss the six main socio-technical challenges that must be overcome in order to build robust bridges and deploy potentially effective AI in real-world clinical settings."
32394199,9.0,A practical guide to amplicon and metagenomic analysis of microbiome data,2020 May 11.,"Advances in high-throughput sequencing (HTS) have fostered rapid developments in the field of microbiome research, and massive microbiome datasets are now being generated. However, the diversity of software tools and the complexity of analysis pipelines make it difficult to access this field. Here, we systematically summarize the advantages and limitations of microbiome methods. Then, we recommend specific pipelines for amplicon and metagenomic analyses, and describe commonly-used software and databases, to help researchers select the appropriate tools. Furthermore, we introduce statistical and visualization methods suitable for microbiome analysis, including alpha- and beta-diversity, taxonomic composition, difference comparisons, correlation, networks, machine learning, evolution, source tracing, and common visualization styles to help researchers make informed choices. Finally, a step-by-step reproducible analysis guide is introduced. We hope this review will allow researchers to carry out data analysis more effectively and to quickly select the appropriate tools in order to efficiently mine the biological significance behind the data."
32394100,2.0,Applications of radiomics and machine learning for radiotherapy of malignant brain tumors,2020 Oct;196(10):856-867.,"Background:                    Magnetic resonance imaging (MRI) and amino acid positron-emission tomography (PET) of the brain contain a vast amount of structural and functional information that can be analyzed by machine learning algorithms and radiomics for the use of radiotherapy in patients with malignant brain tumors.              Methods:                    This study is based on comprehensive literature research on machine learning and radiomics analyses in neuroimaging and their potential application for radiotherapy in patients with malignant glioma or brain metastases.              Results:                    Feature-based radiomics and deep learning-based machine learning methods can be used to improve brain tumor diagnostics and automate various steps of radiotherapy planning. In glioma patients, important applications are the determination of WHO grade and molecular markers for integrated diagnosis in patients not eligible for biopsy or resection, automatic image segmentation for target volume planning, prediction of the location of tumor recurrence, and differentiation of pseudoprogression from actual tumor progression. In patients with brain metastases, radiomics is applied for additional detection of smaller brain metastases, accurate segmentation of multiple larger metastases, prediction of local response after radiosurgery, and differentiation of radiation injury from local brain metastasis relapse. Importantly, high diagnostic accuracies of 80-90% can be achieved by most approaches, despite a large variety in terms of applied imaging techniques and computational methods.              Conclusion:                    Clinical application of automated image analyses based on radiomics and artificial intelligence has a great potential for improving radiotherapy in patients with malignant brain tumors. However, a common problem associated with these techniques is the large variability and the lack of standardization of the methods applied."
32393820,3.0,Illuminating dendritic function with computational models,2020 Jun;21(6):303-321.,"Dendrites have always fascinated researchers: from the artistic drawings by Ramon y Cajal to the beautiful recordings of today, neuroscientists have been striving to unravel the mysteries of these structures. Theoretical work in the 1960s predicted important dendritic effects on neuronal processing, establishing computational modelling as a powerful technique for their investigation. Since then, modelling of dendrites has been instrumental in driving neuroscience research in a targeted manner, providing experimentally testable predictions that range from the subcellular level to the systems level, and their relevance extends to fields beyond neuroscience, such as machine learning and artificial intelligence. Validation of modelling predictions often requires - and drives - new technological advances, thus closing the loop with theory-driven experimentation that moves the field forward. This Review features the most important, to our understanding, contributions of modelling of dendritic computations, including those pending experimental verification, and highlights studies of successful interactions between the modelling and experimental neuroscience communities."
32393561,2.0,Artificial Intelligence and Primary Care Research: A Scoping Review,2020 May;18(3):250-258.,"Purpose:                    Rapid increases in technology and data motivate the application of artificial intelligence (AI) to primary care, but no comprehensive review exists to guide these efforts. Our objective was to assess the nature and extent of the body of research on AI for primary care.              Methods:                    We performed a scoping review, searching 11 published or gray literature databases with terms pertaining to AI (eg, machine learning, bayes* network) and primary care (eg, general pract*, nurse). We performed title and abstract and then full-text screening using Covidence. Studies had to involve research, include both AI and primary care, and be published in Eng-lish. We extracted data and summarized studies by 7 attributes: purpose(s); author appointment(s); primary care function(s); intended end user(s); health condition(s); geographic location of data source; and AI subfield(s).              Results:                    Of 5,515 unique documents, 405 met eligibility criteria. The body of research focused on developing or modifying AI methods (66.7%) to support physician diagnostic or treatment recommendations (36.5% and 13.8%), for chronic conditions, using data from higher-income countries. Few studies (14.1%) had even a single author with a primary care appointment. The predominant AI subfields were supervised machine learning (40.0%) and expert systems (22.2%).              Conclusions:                    Research on AI for primary care is at an early stage of maturity. For the field to progress, more interdisciplinary research teams with end-user engagement and evaluation studies are needed."
32393540,4.0,Machine learning in GI endoscopy: practical guidance in how to interpret a novel field,2020 Nov;69(11):2035-2045.,"There has been a vast increase in GI literature focused on the use of machine learning in endoscopy. The relative novelty of this field poses a challenge for reviewers and readers of GI journals. To appreciate scientific quality and novelty of machine learning studies, understanding of the technical basis and commonly used techniques is required. Clinicians often lack this technical background, while machine learning experts may be unfamiliar with clinical relevance and implications for daily practice. Therefore, there is an increasing need for a multidisciplinary, international evaluation on how to perform high-quality machine learning research in endoscopy. This review aims to provide guidance for readers and reviewers of peer-reviewed GI journals to allow critical appraisal of the most relevant quality requirements of machine learning studies. The paper provides an overview of common trends and their potential pitfalls and proposes comprehensive quality requirements in six overarching themes: terminology, data, algorithm description, experimental setup, interpretation of results and machine learning in clinical practice."
32391171,6.0,"Applications of radiomics in precision diagnosis, prognostication and treatment planning of head and neck squamous cell carcinomas",2020 May 4;5:6.,"Recent advancements in computational power, machine learning, and artificial intelligence technology have enabled automated evaluation of medical images to generate quantitative diagnostic and prognostic biomarkers. Such objective biomarkers are readily available and have the potential to improve personalized treatment, precision medicine, and patient selection for clinical trials. In this article, we explore the merits of the most recent addition to the ""-omics"" concept for the broader field of head and neck cancer - ""Radiomics"". This review discusses radiomics studies focused on (molecular) characterization, classification, prognostication and treatment guidance for head and neck squamous cell carcinomas (HNSCC). We review the underlying hypothesis, general concept and typical workflow of radiomic analysis, and elaborate on current and future challenges to be addressed before routine clinical application."
32389272,1.0,Unsupervised Machine Learning in Pathology: The Next Frontier,2020 Jun;13(2):349-358.,"Applications of artificial intelligence and particularly deep learning to aid pathologists in carrying out laborious and qualitative tasks in histopathologic image analysis have now become ubiquitous. We introduce and illustrate how unsupervised machine learning workflows can be deployed in existing pathology workflows to begin learning autonomously through exploration and without the need for extensive direction. Although still in its infancy, this type of machine learning, which more closely mirrors human intelligence, stands to add another exciting layer of innovation to computational pathology and accelerate the transition to autonomous pathologic tissue analysis."
32388726,,Predicting Patient-Centered Outcomes from Spine Surgery Using Risk Assessment Tools: a Systematic Review,2020 Jun;13(3):247-263.,"Purpose of review:                    The purpose of this systematic review is to evaluate the current literature in patients undergoing spine surgery in the cervical, thoracic, and lumbar spine to determine the available risk assessment tools to predict the patient-centered outcomes of pain, disability, physical function, quality of life, psychological disposition, and return to work after surgery.              Recent findings:                    Risk assessment tools can assist surgeons and other healthcare providers in identifying the benefit-risk ratio of surgical candidates. These tools gather demographic, medical history, and other pertinent patient-reported measures to calculate a probability utilizing regression or machine learning statistical foundations. Currently, much is still unknown about the use of these tools to predict quality of life, disability, and other factors following spine surgery. A systematic review was conducted using PRISMA guidelines that identified risk assessment tools that utilized patient-reported outcome measures as part of the calculation. From 8128 identified studies, 13 articles met inclusion criteria and were accepted into this review. The range of c-index values reported in the studies was between 0.63 and 0.84, indicating fair to excellent model performance. Post-surgical patient-reported outcomes were identified in the following categories (n = total number of predictive models): return to work (n = 3), pain (n = 9), physical functioning and disability (n = 5), quality of life (QOL) (n = 6), and psychosocial disposition (n = 2). Our review has synthesized the available evidence on risk assessment tools for predicting patient-centered outcomes in patients undergoing spine surgery and described their findings and clinical utility."
32387803,7.0,Understanding artificial intelligence based radiology studies: What is overfitting?,2020 Sep;65:96-99.,"Artificial intelligence (AI) is a broad umbrella term used to encompass a wide variety of subfields dedicated to creating algorithms to perform tasks that mimic human intelligence. As AI development grows closer to clinical integration, radiologists will need to become familiar with the principles of artificial intelligence to properly evaluate and use this powerful tool. This series aims to explain certain basic concepts of artificial intelligence, and their applications in medical imaging starting with a concept of overfitting."
32384762,1.0,Virtual Network Embedding for Multi-Domain Heterogeneous Converged Optical Networks: Issues and Challenges,2020 May 6;20(9):2655.,"The emerging 5G applications and the connectivity of billions of devices have driven the investigation of multi-domain heterogeneous converged optical networks. To support emerging applications with their diverse quality of service requirements, network slicing has been proposed as a promising technology. Network virtualization is an enabler for network slicing, where the physical network can be partitioned into different configurable slices in the multi-domain heterogeneous converged optical networks. An efficient resource allocation mechanism for multiple virtual networks in network virtualization is one of the main challenges referred as virtual network embedding (VNE). This paper is a survey on the state-of-the-art works for the VNE problem towards multi-domain heterogeneous converged optical networks, providing the discussion on future research issues and challenges. In this paper, we describe VNE in multi-domain heterogeneous converged optical networks with enabling network orchestration technologies and analyze the literature about VNE algorithms with various network considerations for each network domain. The basic VNE problem with various motivations and performance metrics for general scenarios is discussed. A VNE algorithm taxonomy is presented and discussed by classifying the major VNE algorithms into three categories according to existing literature. We analyze and compare the attributes of algorithms such as node and link embedding methods, objectives, and network architecture, which can give a selection or baseline for future work of VNE. Finally, we explore some broader perspectives in future research issues and challenges on 5G scenario, field trail deployment, and machine learning-based algorithms."
32380203,,Towards the quantum-enabled technologies for development of drugs or delivery systems,2020 Aug 10;324:260-279.,"Enormous advances in technology and science have provided outstanding innovations including the development of quantum computers (QCs) capable of performing various tasks much more efficiently and quickly than the classical computers. Integrating and analyzing gigantic amounts of data, ultra-rapid calculations, solving intractable problems, secure communications, providing novel insights into the material design or biosystems, advanced simulations, rapid genome analysis and sequencing, early cancer detection, identifying novel drug applications, accelerated discovery of new molecules, targets, or theranostic agents and evaluation of their behaviors, and acquiring a deeper knowledge about the complex data patterns, formation of proteins, or mechanism of disease progression and evolution by QCs may indeed revolutionize conventional technologies and strategies. Application of quantum computing and machine learning for accelerated analysis of the biological or medical data, uncovering the mechanisms of chemical reactions or action of drug candidates, and creation of patient-specific treatment strategies using genomics data can result in the development of more effective and less toxic drugs or personalized therapy. This article highlights the importance of QCs in designing drugs and delivery systems, limitations, and possible solutions."
32378359,,Modeling the Physicochemical Properties of Natural Deep Eutectic Solvents,2020 May 7.,"Natural deep eutectic solvents (NADES) are mixtures of naturally derived compounds with a significantly decreased melting point owing to specific interactions among the constituents. NADES have benign properties (low volatility, flammability, toxicity, cost) and tailorable physicochemical properties (by altering the type and molar ratio of constituents); hence, they are often considered to be a green alternative to common organic solvents. Modeling the relation between their composition and properties is crucial though, both for understanding and predicting their behavior. Several efforts have been made to this end. This Review aims at structuring the present knowledge as an outline for future research. First, the key properties of NADES are reviewed and related to their structure on the basis of the available experimental data. Second, available modeling methods applicable to NADES are reviewed. At the molecular level, DFT and molecular dynamics allow density differences and vibrational spectra to be interpreted, and interaction energies to be computed. Additionally, properties at the level of the bulk medium can be explained and predicted by semi-empirical methods based on ab initio methods (COSMO-RS) and equation of state models (PC-SAFT). Finally, methods based on large datasets are discussed: models based on group-contribution methods and machine learning. A combination of bulk-medium and dataset modeling allows qualitative prediction and interpretation of phase equilibria properties on the one hand, and quantitative prediction of melting point, density, viscosity, surface tension, and refractive index on the other. Multiscale modeling, combining molecular and macroscale methods, is expected to strongly enhance the predictability of NADES properties and their interaction with solutes, and thus yield truly tailorable solvents to accommodate (bio)chemical reactions."
32378163,,Big Data and Atrial Fibrillation: Current Understanding and New Opportunities,2020 Dec;13(6):944-952.,"Atrial fibrillation (AF) is the most common arrhythmia with diverse etiology that remarkably relates to high morbidity and mortality. With the advancements in intensive clinical and basic research, the understanding of electrophysiological and pathophysiological mechanism, as well as treatment of AF have made huge progress. However, many unresolved issues remain, including the core mechanisms and key intervention targets. Big data approach has produced new insights into the improvement of the situation. A large amount of data have been accumulated in the field of AF research, thus using the big data to achieve prevention and precise treatment of AF may be the direction of future development. In this review, we will discuss the current understanding of big data and explore the potential applications of big data in AF research, including predictive models of disease processes, disease heterogeneity, drug safety and development, precision medicine, and the potential source for big data acquisition. Grapical abstract."
32374075,3.0,Towards a brain-based predictome of mental illness,2020 Aug 15;41(12):3468-3535.,"Neuroimaging-based approaches have been extensively applied to study mental illness in recent years and have deepened our understanding of both cognitively healthy and disordered brain structure and function. Recent advancements in machine learning techniques have shown promising outcomes for individualized prediction and characterization of patients with psychiatric disorders. Studies have utilized features from a variety of neuroimaging modalities, including structural, functional, and diffusion magnetic resonance imaging data, as well as jointly estimated features from multiple modalities, to assess patients with heterogeneous mental disorders, such as schizophrenia and autism. We use the term ""predictome"" to describe the use of multivariate brain network features from one or more neuroimaging modalities to predict mental illness. In the predictome, multiple brain network-based features (either from the same modality or multiple modalities) are incorporated into a predictive model to jointly estimate features that are unique to a disorder and predict subjects accordingly. To date, more than 650 studies have been published on subject-level prediction focusing on psychiatric disorders. We have surveyed about 250 studies including schizophrenia, major depression, bipolar disorder, autism spectrum disorder, attention-deficit hyperactivity disorder, obsessive-compulsive disorder, social anxiety disorder, posttraumatic stress disorder, and substance dependence. In this review, we present a comprehensive review of recent neuroimaging-based predictomic approaches, current trends, and common shortcomings and share our vision for future directions."
32373125,2.0,Biomarkers for Allogeneic HCT Outcomes,2020 Apr 21;11:673.,"Allogeneic hematopoietic cell transplantation (HCT) remains the only curative therapy for many hematological malignant and non-malignant disorders. However, key obstacles to the success of HCT include graft-versus-host disease (GVHD) and disease relapse due to absence of graft-versus-tumor (GVT) effect. Over the last decade, advances in ""omics"" technologies and systems biology analysis, have allowed for the discovery and validation of blood biomarkers that can be used as diagnostic test and prognostic test (that risk-stratify patients before disease occurrence) for acute and chronic GVHD and recently GVT. There are also predictive biomarkers that categorize patients based on their likely to respond to therapy. Newer mathematical analysis such as machine learning is able to identify different predictors of GVHD using clinical characteristics pre-transplant and possibly in the future combined with other biomarkers. Biomarkers are not only useful to identify patients with higher risk of disease progression, but also help guide treatment decisions and/or provide a basis for specific therapeutic interventions. This review summarizes biomarkers definition, omics technologies, acute, chronic GVHD and GVT biomarkers currently used in clinic or with potential as targets for existing or new drugs focusing on novel published work."
32372937,1.0,"Attention in Psychology, Neuroscience, and Machine Learning",2020 Apr 16;14:29.,"Attention is the important ability to flexibly control limited computational resources. It has been studied in conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, executive control, and learning. It has also recently been applied in several domains in machine learning. The relationship between the study of biological attention and its use as a tool to enhance artificial neural networks is not always clear. This review starts by providing an overview of how attention is conceptualized in the neuroscience and psychology literature. It then covers several use cases of attention in machine learning, indicating their biological counterparts where they exist. Finally, the ways in which artificial attention can be further inspired by biology for the production of complex and integrative systems is explored."
32370835,6.0,Artificial Intelligence in Cardiology: Present and Future,2020 May;95(5):1015-1039.,"Artificial intelligence (AI) is a nontechnical, popular term that refers to machine learning of various types but most often to deep neural networks. Cardiology is at the forefront of AI in medicine. For this review, we searched PubMed and MEDLINE databases with no date restriction using search terms related to AI and cardiology. Articles were selected for inclusion on the basis of relevance. We highlight the major achievements in recent years in nearly all areas of cardiology and underscore the mounting evidence suggesting how AI will take center stage in the field. Artificial intelligence requires a close collaboration among computer scientists, clinical investigators, clinicians, and other users in order to identify the most relevant problems to be solved. Best practices in the generation and implementation of AI include the selection of ideal data sources, taking into account common challenges during the interpretation, validation, and generalizability of findings, and addressing safety and ethical concerns before final implementation. The future of AI in cardiology and in medicine in general is bright as the collaboration between investigators and clinicians continues to excel."
32367456,3.0,Radiomics and deep learning in lung cancer,2020 Oct;196(10):879-887.,"Lung malignancies have been extensively characterized through radiomics and deep learning. By providing a three-dimensional characterization of the lesion, models based on radiomic features from computed tomography (CT) and positron-emission tomography (PET) have been developed to detect nodules, distinguish malignant from benign lesions, characterize their histology, stage, and genotype. Deep learning models have been applied to automatically segment organs at risk in lung cancer radiotherapy, stratify patients according to the risk for local and distant recurrence, and identify patients candidate for molecular targeted therapy and immunotherapy. Moreover, radiomics has also been applied successfully to predict side effects such as radiation- and immunotherapy-induced pneumonitis and differentiate lung injury from recurrence. Radiomics could also untap the potential for further use of the cone beam CT acquired for treatment image guidance, four-dimensional CT, and dose-volume data from radiotherapy treatment plans. Radiomics is expected to increasingly affect the clinical practice of treatment of lung tumors, optimizing the end-to-end diagnosis-treatment-follow-up chain. The main goal of this article is to provide an update on the current status of lung cancer radiomics."
32365645,2.0,Edge Machine Learning for AI-Enabled IoT Devices: A Review,2020 Apr 29;20(9):2533.,"In a few years, the world will be populated by billions of connected devices that will be placed in our homes, cities, vehicles, and industries. Devices with limited resources will interact with the surrounding environment and users. Many of these devices will be based on machine learning models to decode meaning and behavior behind sensors' data, to implement accurate predictions and make decisions. The bottleneck will be the high level of connected things that could congest the network. Hence, the need to incorporate intelligence on end devices using machine learning algorithms. Deploying machine learning on such edge devices improves the network congestion by allowing computations to be performed close to the data sources. The aim of this work is to provide a review of the main techniques that guarantee the execution of machine learning models on hardware with low performances in the Internet of Things paradigm, paving the way to the Internet of Conscious Things. In this work, a detailed review on models, architecture, and requirements on solutions that implement edge machine learning on Internet of Things devices is presented, with the main goal to define the state of the art and envisioning development requirements. Furthermore, an example of edge machine learning implementation on a microcontroller will be provided, commonly regarded as the machine learning ""Hello World""."
32364202,6.0,Engineering biosynthetic enzymes for industrial natural product synthesis,2020 Aug 19;37(8):1122-1143.,"Covering: 2000 to 2020 Natural products and their derivatives are commercially important medicines, agrochemicals, flavors, fragrances, and food ingredients. Industrial strategies to produce these structurally complex molecules encompass varied combinations of chemical synthesis, biocatalysis, and extraction from natural sources. Interest in engineering natural product biosynthesis began with the advent of genetic tools for pathway discovery. Genes and strains can now readily be synthesized, mutated, recombined, and sequenced. Enzyme engineering has succeeded commercially due to the development of genetic methods, analytical technologies, and machine learning algorithms. Today, engineered biosynthetic enzymes from organisms spanning the tree of life are used industrially to produce diverse molecules. These biocatalytic processes include single enzymatic steps, multienzyme cascades, and engineered native and heterologous microbial strains. This review will describe how biosynthetic enzymes have been engineered to enable commercial and near-commercial syntheses of natural products and their analogs."
32363543,1.0,"A Systematic Review of Methodological Variation in Healthcare Provider Perspective Tuberculosis Costing Papers Conducted in Low- and Middle-Income Settings, Using An Intervention-Standardised Unit Cost Typology",2020 Aug;38(8):819-837.,"Background:                    There is a need for easily accessible tuberculosis unit cost data, as well as an understanding of the variability of methods used and reporting standards of that data.              Objective:                    The aim of this systematic review was to descriptively review papers reporting tuberculosis unit costs from a healthcare provider perspective looking at methodological variation; to assess quality using a study quality rating system and machine learning to investigate the indicators of reporting quality; and to identify the data gaps to inform standardised tuberculosis unit cost collection and consistent principles for reporting going forward.              Methods:                    We searched grey and published literature in five sources and eight databases, respectively, using search terms linked to cost, tuberculosis and tuberculosis health services including tuberculosis treatment and prevention. For inclusion, the papers needed to contain empirical unit cost estimates for tuberculosis interventions from low- and middle-income countries, with reference years between 1990 and 2018. A total of 21,691 papers were found and screened in a phased manner. Data were extracted from the eligible papers into a detailed Microsoft Excel tool, extensively cleaned and analysed with R software (R Project, Vienna, Austria) using the user interface of RStudio. A study quality rating was applied to the reviewed papers based on the inclusion or omission of a selection of variables and their relative importance. Following this, machine learning using a recursive partitioning method was utilised to construct a classification tree to assess the reporting quality.              Results:                    This systematic review included 103 provider perspective papers with 627 unit costs (costs not presented here) for tuberculosis interventions among a total of 140 variables. The interventions covered were active, passive and intensified case finding; tuberculosis treatment; above-service costs; and tuberculosis prevention. Passive case finding is the detection of tuberculosis cases where individuals self-identify at health facilities; active case finding is detection of cases of those not in health facilities, such as through outreach; and intensified case finding is detection of cases in high-risk populations. There was heterogeneity in some of the reported methods used such cost allocation, amortisation and the use of top-down, bottom-up or mixed approaches to the costing. Uncertainty checking through sensitivity analysis was only reported on by half of the papers (54%), while purposive and convenience sampling was reported by 72% of papers. Machine learning indicated that reporting on 'Intervention' (in particular), 'Urbanicity' and 'Site Sampling', were the most likely indicators of quality of reporting. The largest data gap identified was for tuberculosis vaccination cost data, the Bacillus Calmette-Guérin (BCG) vaccine in particular. There is a gap in available unit costs for 12 of 30 high tuberculosis burden countries, as well as for the interventions of above-service costs, tuberculosis prevention, and active and intensified case finding.              Conclusion:                    Variability in the methods and reporting used makes comparison difficult and makes it hard for decision makers to know which unit costs they can trust. The study quality rating system used in this review as well as the classification tree enable focus on specific reporting aspects that should improve variability and increase confidence in unit costs. Researchers should endeavour to be explicit and transparent in how they cost interventions following the principles as laid out in the Global Health Cost Consortium's Reference Case for Estimating the Costs of Global Health Services and Interventions, which in turn will lead to repeatability, comparability and enhanced learning from others."
32361380,1.0,Application of artificial intelligence in cardiac CT: From basics to clinical practice,2020 Jul;128:108969.,"Research into the possibilities of AI in cardiac CT has been growing rapidly in the last decade. With the rise of publicly available databases and AI algorithms, many researchers and clinicians have started investigations into the use of AI in the clinical workflow. This review is a comprehensive overview on the types of tasks and applications in which AI can aid the clinician in cardiac CT, and can be used as a primer for medical researchers starting in the field of AI. The applications of AI algorithms are explained and recent examples in cardiac CT of these algorithms are further elaborated on. The critical factors for implementation in the future are discussed."
32359808,2.0,"Machine learning, the kidney, and genotype-phenotype analysis",2020 Jun;97(6):1141-1149.,"With biomedical research transitioning into data-rich science, machine learning provides a powerful toolkit for extracting knowledge from large-scale biological data sets. The increasing availability of comprehensive kidney omics compendia (transcriptomics, proteomics, metabolomics, and genome sequencing), as well as other data modalities such as electronic health records, digital nephropathology repositories, and radiology renal images, makes machine learning approaches increasingly essential for analyzing human kidney data sets. Here, we discuss how machine learning approaches can be applied to the study of kidney disease, with a particular focus on how they can be used for understanding the relationship between genotype and phenotype."
32358210,11.0,Technology Use for Adolescent Health and Wellness,2020 May;145(Suppl 2):S186-S194.,"As avid users of technology, adolescents are a key demographic to engage when designing and developing technology applications for health. There are multiple opportunities for improving adolescent health, from promoting preventive behaviors to providing guidance for adolescents with chronic illness in supporting treatment adherence and transition to adult health care systems. This article will provide a brief overview of current technologies and then highlight new technologies being used specifically for adolescent health, such as artificial intelligence, virtual and augmented reality, and machine learning. Because there is paucity of evidence in this field, we will make recommendations for future research."
32357923,5.0,How to develop a meaningful radiomic signature for clinical use in oncologic patients,2020 May 1;20(1):33.,"During the last decade, there is an increasing usage of quantitative methods in Radiology in an effort to reduce the diagnostic variability associated with a subjective manner of radiological interpretation. Combined approaches where visual assessment made by the radiologist is augmented by quantitative imaging biomarkers are gaining attention. Advances in machine learning resulted in the rise of radiomics that is a new methodology referring to the extraction of quantitative information from medical images. Radiomics are based on the development of computational models, referred to as ""Radiomic Signatures"", trying to address either unmet clinical needs, mostly in the field of oncologic imaging, or to compare radiomics performance with that of radiologists. However, to explore this new technology, initial publications did not consider best practices in the field of machine learning resulting in publications with questionable clinical value. In this paper, our effort was concentrated on how to avoid methodological mistakes and consider critical issues in the workflow of the development of clinically meaningful radiomic signatures."
32357816,1.0,Computational Approaches for the Design of (Mutant-)Selective Tyrosine Kinase Inhibitors: State-of-the-Art and Future Prospects,2020;20(17):1564-1575.,"Kinases remain one of the major attractive therapeutic targets for a large number of indications such as cancer, rheumatoid arthritis, cardiac failure and many others. Design and development of kinase inhibitors (ATP-competitive, allosteric or covalent) is a clinically validated and successful strategy in the pharmaceutical industry. The perks come with limitations, particularly the development of resistance to highly potent and selective inhibitors. When this happens, the cycle needs to be repeated, i.e., the design and development of kinase inhibitors active against the mutated forms. The complexity of tumor milieu makes it awfully difficult for these molecularly-targeted therapies to work. Every year newer and better versions of these agents are introduced in the clinic. Several computational approaches such as structure-, ligand-based or hybrid ones continue to live up to their potential in discovering novel kinase inhibitors. New schools of thought in this area continue to emerge, e.g., development of dual-target kinase inhibitors. But there are fundamental issues with this approach. It is indeed difficult to selectively optimize binding at two entirely different or related kinases. In addition to the conventional strategies, modern technologies (machine learning, deep learning, artificial intelligence, etc.) started yielding the results and building success stories. Computational tools invariably played a critical role in catalysing the phenomenal progress in kinase drug discovery field. The present review summarized the progress in utilizing computational methods and tools for discovering (mutant-)selective tyrosine kinase inhibitor drugs in the last three years (2017-2019). Representative investigations have been discussed, while others are merely listed. The author believes that the enthusiastic reader will be inspired to dig out the cited literature extensively to appreciate the progress made so far and the future prospects of the field."
32356548,23.0,QSAR without borders,2020 Jun 7;49(11):3525-3564.,"Prediction of chemical bioactivity and physical properties has been one of the most important applications of statistical and more recently, machine learning and artificial intelligence methods in chemical sciences. This field of research, broadly known as quantitative structure-activity relationships (QSAR) modeling, has developed many important algorithms and has found a broad range of applications in physical organic and medicinal chemistry in the past 55+ years. This Perspective summarizes recent technological advances in QSAR modeling but it also highlights the applicability of algorithms, modeling methods, and validation practices developed in QSAR to a wide range of research areas outside of traditional QSAR boundaries including synthesis planning, nanotechnology, materials science, biomaterials, and clinical informatics. As modern research methods generate rapidly increasing amounts of data, the knowledge of robust data-driven modelling methods professed within the QSAR field can become essential for scientists working both within and outside of chemical research. We hope that this contribution highlighting the generalizable components of QSAR modeling will serve to address this challenge."
32355335,15.0,Autism spectrum heterogeneity: fact or artifact?,2020 Dec;25(12):3178-3185.,"The current diagnostic practices are linked to a 20-fold increase in the reported prevalence of ASD over the last 30 years. Fragmenting the autism phenotype into dimensional ""autistic traits"" results in the alleged recognition of autism-like symptoms in any psychiatric or neurodevelopemental condition and in individuals decreasingly distant from the typical population, and prematurely dismisses the relevance of a diagnostic threshold. Non-specific socio-communicative and repetitive DSM 5 criteria, combined with four quantitative specifiers as well as all their possible combinations, render limitless variety of presentations consistent with the categorical diagnosis of ASD. We propose several remedies to this problem: maintain a line of research on prototypical autism; limit the heterogeneity compatible with a categorical diagnosis to situations with a phenotypic overlap and a validated etiological link with prototypical autism; reintroduce the qualitative properties of autism presentations and of current dimensional specifiers, language, intelligence, comorbidity, and severity in the criteria used to diagnose autism in replacement of quantitative ""social"" and ""repetitive"" criteria; use these qualitative features combined with the clinical intuition of experts and machine-learning algorithms to differentiate coherent subgroups in today's autism spectrum; study these subgroups separately, and then compare them; and question the autistic nature of ""autistic traits""."
32354020,1.0,A Review of Deep Learning Methods for Antibodies,2020 Apr 28;9(2):12.,"Driven by its successes across domains such as computer vision and natural language processing, deep learning has recently entered the field of biology by aiding in cellular image classification, finding genomic connections, and advancing drug discovery. In drug discovery and protein engineering, a major goal is to design a molecule that will perform a useful function as a therapeutic drug. Typically, the focus has been on small molecules, but new approaches have been developed to apply these same principles of deep learning to biologics, such as antibodies. Here we give a brief background of deep learning as it applies to antibody drug development, and an in-depth explanation of several deep learning algorithms that have been proposed to solve aspects of both protein design in general, and antibody design in particular."
32353725,1.0,Sustainable soil use and management: An interdisciplinary and systematic approach,2020 Aug 10;729:138961.,"Soil is a key component of Earth's critical zone. It provides essential services for agricultural production, plant growth, animal habitation, biodiversity, carbon sequestration and environmental quality, which are crucial for achieving the United Nations' Sustainable Development Goals (SDGs). However, soil degradation has occurred in many places throughout the world due to factors such as soil pollution, erosion, salinization, and acidification. In order to achieve the SDGs by the target date of 2030, soils may need to be used and managed in a manner that is more sustainable than is currently practiced. Here we show that research in the field of sustainable soil use and management should prioritize the multifunctional value of soil health and address interdisciplinary linkages with major issues such as biodiversity and climate change. As soil is the largest terrestrial carbon pool, as well as a significant contributor of greenhouse gases, much progress can be made toward curtailing the climate crisis by sustainable soil management practices. One identified option is to increase soil organic carbon levels, especially with recalcitrant forms of carbon (e.g., biochar application). In general, soil health is primarily determined by the actions of the farming community. Therefore, information management and knowledge sharing are necessary to improve the sustainable behavior of practitioners and end-users. Scientists and policy makers are important actors in this social learning process, not only to disseminate evidence-based scientific knowledge, but also in generating new knowledge in close collaboration with farmers. While governmental funding for soil data collection has been generally decreasing, newly available 5G telecommunications, big data and machine learning based data collection and analytical tools are maturing. Interdisciplinary studies that incorporate such advances may lead to the formation of innovative sustainable soil use and management strategies that are aimed toward optimizing soil health and achieving the SDGs."
32351968,2.0,"Malnutrition, Health and the Role of Machine Learning in Clinical Setting",2020 Apr 15;7:44.,"Nutrition plays a vital role in health and the recovery process. Deficiencies in macronutrients and micronutrients can impact the development and progression of various disorders. However, malnutrition screening tools and their utility in the clinical setting remain largely understudied. In this study, we summarize the importance of nutritional adequacy and its association with neurological, cardiovascular, and immune-related disorders. We also examine general and specific malnutrition assessment tools utilized in healthcare settings. Since the implementation of the screening process in 2016, malnutrition data from hospitalized patients in the Geisinger Health System is presented and discussed as a case study. Clinical data from five Geisinger hospitals shows that ~10% of all admitted patients are acknowledged for having some form of nutritional deficiency, from which about 60-80% of the patients are targeted for a more comprehensive assessment. Finally, we conclude that with a reflection on how technological advances, specifically machine learning-based algorithms, can be integrated into electronic health records to provide decision support system to care providers in the identification and management of patients at higher risk of malnutrition."
32351543,4.0,Reaching the End-Game for GWAS: Machine Learning Approaches for the Prioritization of Complex Disease Loci,2020 Apr 15;11:350.,"Genome-wide association studies (GWAS) have revealed thousands of genetic loci that underpin the complex biology of many human traits. However, the strength of GWAS - the ability to detect genetic association by linkage disequilibrium (LD) - is also its limitation. Whilst the ever-increasing study size and improved design have augmented the power of GWAS to detect effects, differentiation of causal variants or genes from other highly correlated genes associated by LD remains the real challenge. This has severely hindered the biological insights and clinical translation of GWAS findings. Although thousands of disease susceptibility loci have been reported, causal genes at these loci remain elusive. Machine learning (ML) techniques offer an opportunity to dissect the heterogeneity of variant and gene signals in the post-GWAS analysis phase. ML models for GWAS prioritization vary greatly in their complexity, ranging from relatively simple logistic regression approaches to more complex ensemble models such as random forests and gradient boosting, as well as deep learning models, i.e., neural networks. Paired with functional validation, these methods show important promise for clinical translation, providing a strong evidence-based approach to direct post-GWAS research. However, as ML approaches continue to evolve to meet the challenge of causal gene identification, a critical assessment of the underlying methodologies and their applicability to the GWAS prioritization problem is needed. This review investigates the landscape of ML applications in three parts: selected models, input features, and output model performance, with a focus on prioritizations of complex disease associated loci. Overall, we explore the contributions ML has made towards reaching the GWAS end-game with consequent wide-ranging translational impact."
32349877,4.0,Dentronics: Towards robotics and artificial intelligence in dentistry,2020 Jun;36(6):765-778.,"Objectives:                    This paper provides an overview of existing applications and concepts of robotic systems and artificial intelligence in dentistry. This review aims to provide the community with novel inputs and argues for an increased utilization of these recent technological developments, referred to as Dentronics, in order to advance dentistry.              Methods:                    First, background on developments in robotics, artificial intelligence (AI) and machine learning (ML) are reviewed that may enable novel assistive applications in dentistry (Sec A). Second, a systematic technology review that evaluates existing state-of-the-art applications in AI, ML and robotics in the context of dentistry is presented (Sec B).              Results:                    A systematic literature research in pubmed yielded in a total of 558 results. 41 studies related to ML, 53 studies related to AI and 49 original research papers on robotics application in dentistry were included. ML and AI have been applied in dental research to analyze large amounts of data to eventually support dental decision making, diagnosis, prognosis and treatment planning with the help of data-driven analysis algorithms based on machine learning. So far, only few robotic applications have made it to reality, mostly restricted to pilot use cases.              Significance:                    The authors believe that dentistry can greatly benefit from the current rise of digital human-centered automation and be transformed towards a new robotic, ML and AI-enabled era. In the future, Dentronics will enhance reliability, reproducibility, accuracy and efficiency in dentistry through the democratized use of modern dental technologies, such as medical robot systems and specialized artificial intelligence. Dentronics will increase our understanding of disease pathogenesis, improve risk-assessment-strategies, diagnosis, disease prediction and finally lead to better treatment outcomes."
32349232,5.0,Real-Time Hand Gesture Recognition Using Surface Electromyography and Machine Learning: A Systematic Literature Review,2020 Apr 27;20(9):2467.,"Today, daily life is composed of many computing systems, therefore interacting with them in a natural way makes the communication process more comfortable. Human-Computer Interaction (HCI) has been developed to overcome the communication barriers between humans and computers. One form of HCI is Hand Gesture Recognition (HGR), which predicts the class and the instant of execution of a given movement of the hand. One possible input for these models is surface electromyography (EMG), which records the electrical activity of skeletal muscles. EMG signals contain information about the intention of movement generated by the human brain. This systematic literature review analyses the state-of-the-art of real-time hand gesture recognition models using EMG data and machine learning. We selected and assessed 65 primary studies following the Kitchenham methodology. Based on a common structure of machine learning-based systems, we analyzed the structure of the proposed models and standardized concepts in regard to the types of models, data acquisition, segmentation, preprocessing, feature extraction, classification, postprocessing, real-time processing, types of gestures, and evaluation metrics. Finally, we also identified trends and gaps that could open new directions of work for future research in the area of gesture recognition using EMG."
32348823,1.0,Technological advances for the detection of melanoma: Advances in diagnostic techniques,2020 Oct;83(4):983-992.,"Managing the balance between accurately identifying early stage melanomas while avoiding obtaining biopsy specimens of benign lesions (ie, overbiopsy) is the major challenge of melanoma detection. Decision making can be especially difficult in patients with extensive atypical nevi. Recognizing that the primary screening modality for melanoma is subjective examination, studies have shown a tendency toward overbiopsy. Even low-risk routine surgical procedures are associated with morbidity, mounting health care costs, and patient anxiety. Recent advancements in noninvasive diagnostic modalities have helped improve diagnostic accuracy, especially when managing melanocytic lesions of uncertain diagnosis. Breakthroughs in artificial intelligence have also shown exciting potential in changing the landscape of melanoma detection. In the first article in this continuing medical education series, we review novel diagnostic technologies, such as automated 2- and 3-dimensional total body imaging with sequential digital dermoscopic imaging, reflectance confocal microscopy, and electrical impedance spectroscopy, and we explore the logistics and implications of potentially integrating artificial intelligence into existing melanoma management paradigms."
32347446,3.0,Artificial Intelligence and Machine Learning for HIV Prevention: Emerging Approaches to Ending the Epidemic,2020 Jun;17(3):171-179.,"Purpose of review:                    We review applications of artificial intelligence (AI), including machine learning (ML), in the field of HIV prevention.              Recent findings:                    ML approaches have been used to identify potential candidates for preexposure prophylaxis (PrEP) in healthcare settings in the USA and Denmark and in a population-based research setting in Eastern Africa. Although still in the proof-of-concept stage, other applications include ML with smartphone-collected and social media data to promote real-time HIV risk reduction, virtual reality tools to facilitate HIV serodisclosure, and chatbots for HIV education. ML has also been used for causal inference in HIV prevention studies. ML has strong potential to improve delivery of PrEP, with this approach moving from development to implementation. Development and evaluation of AI and ML strategies for HIV prevention may benefit from an implementation science approach, including qualitative assessments with end users, and should be developed and evaluated with attention to equity."
32346642,1.0,How Far Will Clinical Application of AI Applications Advance for Colorectal Cancer Diagnosis?,2020 Apr 28;4(2):47-50.,"Integrating artificial intelligence (AI) applications into colonoscopy practice is being accelerated as deep learning technologies emerge. In this field, most of the preceding research has focused on polyp detection and characterization, which can mitigate inherent human errors accompanying colonoscopy procedures. On the other hand, more challenging research areas are currently capturing attention: the automated prediction of invasive cancers. Colorectal cancers (CRCs) harbor potential lymph node metastasis when they invade deeply into submucosal layers, which should be resected surgically rather than endoscopically. However, pretreatment discrimination of deeply invasive submucosal CRCs is considered difficult, according to previous prospective studies (e.g., <70% sensitivity), leading to an increased number of unnecessary surgeries for large adenomas or slightly invasive submucosal CRCs. AI is now expected to overcome this challenging hurdle because it is considered to provide better performance in predicting invasive cancer than non-expert endoscopists. In this review, we introduce five relevant publications in this area. Unfortunately, progress in this research area is in a very preliminary phase, compared to that of automated polyp detection and characterization, because of the lack of number of invasive CRCs used for machine learning. However, this issue will be overcome with more target images and cases. The research field of AI for invasive CRCs is just starting but could be a game changer of patient care in the near future, given rapidly growing technologies, and research will gradually increase."
32344674,1.0,"Predictive Maintenance for Pump Systems and Thermal Power Plants: State-of-the-Art Review, Trends and Challenges",2020 Apr 24;20(8):2425.,"Thermal power plants are an important asset in the current energy infrastructure, delivering ancillary services, power, and heat to their respective consumers. Faults on critical components, such as large pumping systems, can lead to material damage and opportunity losses. Pumps plays an essential role in various industries and as such clever maintenance can ensure cost reductions and high availability. Prognostics and Health Management, PHM, is the study utilizing data to estimate the current and future conditions of a system. Within the field of PHM, Predictive Maintenance, PdM, has been gaining increased attention. Data-driven models can be built to estimate the remaining-useful-lifetime of complex systems that would be difficult to identify by man. With the increased attention that the Predictive Maintenance field is receiving, review papers become increasingly important to understand what research has been conducted and what challenges need to be addressed. This paper does so by initially conceptualising the PdM field. A structured overview of literature in regard to application within PdM is presented, before delving into the domain of thermal power plants and pump systems. Finally, related challenges and trends will be outlined. This paper finds that a large number of experimental data-driven models have been successfully deployed, but the PdM field would benefit from more industrial case studies. Furthermore, investigations into the scale-ability of models would benefit industries that are looking into large-scale implementations. Here, examining a method for automatic maintenance of the developed model will be of interest. This paper can be used to understand the PdM field as a broad concept but does also provide a niche understanding of the domain in focus."
32340618,5.0,Imaging biomarkers in neurodegeneration: current and future practices,2020 Apr 27;12(1):49.,"There is an increasing role for biological markers (biomarkers) in the understanding and diagnosis of neurodegenerative disorders. The application of imaging biomarkers specifically for the in vivo investigation of neurodegenerative disorders has increased substantially over the past decades and continues to provide further benefits both to the diagnosis and understanding of these diseases. This review forms part of a series of articles which stem from the University College London/University of Gothenburg course ""Biomarkers in neurodegenerative diseases"". In this review, we focus on neuroimaging, specifically positron emission tomography (PET) and magnetic resonance imaging (MRI), giving an overview of the current established practices clinically and in research as well as new techniques being developed. We will also discuss the use of machine learning (ML) techniques within these fields to provide additional insights to early diagnosis and multimodal analysis."
32339630,,Electrospun nanofiber-based cancer sensors: A review,2020 Jun 15;583:119364.,"Cancer is a malignancy engendering enormous global mortality, steering extensive research for early diagnosis and efficacious prognosis leading to emergence of cancer sensing technologies for multitudinous biomarkers. In this context, nanofibers, imparting high surface area, facile production, morphology control, and synergistic properties attainable, are poised to be inevitable in futuristic sensing devices for predictive diagnostics when integrated with artificial intelligence and machine learning. To this end, fundamentals governing the sensor response and their analytical performance have been discussed. The headways in organic and inorganic nanofibers for biomarker gas sensing, fluid sample sensing and imaging have been supplemented with discussions on materials for nanofiber formation, along with sensitizing materials, and formation of sensing elements by processes like surface deposition on nanofibers, immobilising, calcination, etc. and their effect on final sensing device properties. The review culminates by summarising the conceptual understanding of the hitherto progress leading to achievement of excellent analytical performance giving detection limits to the order of 1.6 pM concentration and response time of as low as 0.5 s. Current bottlenecks in this state of the art have been delineated and pathways for future research are discussed."
32339122,3.0,A review of computational approaches for evaluation of rehabilitation exercises,2020 Apr;119:103687.,"Recent advances in data analytics and computer-aided diagnostics stimulate the vision of patient-centric precision healthcare, where treatment plans are customized based on the health records and needs of every patient. In physical rehabilitation, the progress in machine learning and the advent of affordable and reliable motion capture sensors have been conducive to the development of approaches for automated assessment of patient performance and progress toward functional recovery. The presented study reviews computational approaches for evaluating patient performance in rehabilitation programs using motion capture systems. Such approaches will play an important role in supplementing traditional rehabilitation assessment performed by trained clinicians, and in assisting patients participating in home-based rehabilitation. The reviewed computational methods for exercise evaluation are grouped into three main categories: discrete movement score, rule-based, and template-based approaches. The review places an emphasis on the application of machine learning methods for movement evaluation in rehabilitation. Related work in the literature on data representation, feature engineering, movement segmentation, and scoring functions is presented. The study also reviews existing sensors for capturing rehabilitation movements and provides an informative listing of pertinent benchmark datasets. The significance of this paper is in being the first to provide a comprehensive review of computational methods for evaluation of patient performance in rehabilitation programs."
32337704,1.0,Importance of protein Ser/Thr/Tyr phosphorylation for bacterial pathogenesis,2020 Aug;594(15):2339-2369.,"Protein phosphorylation regulates a large variety of biological processes in all living cells. In pathogenic bacteria, the study of serine, threonine, and tyrosine (Ser/Thr/Tyr) phosphorylation has shed light on the course of infectious diseases, from adherence to host cells to pathogen virulence, replication, and persistence. Mass spectrometry (MS)-based phosphoproteomics has provided global maps of Ser/Thr/Tyr phosphosites in bacterial pathogens. Despite recent developments, a quantitative and dynamic view of phosphorylation events that occur during bacterial pathogenesis is currently lacking. Temporal, spatial, and subpopulation resolution of phosphorylation data is required to identify key regulatory nodes underlying bacterial pathogenesis. Herein, we discuss how technological improvements in sample handling, MS instrumentation, data processing, and machine learning should improve bacterial phosphoproteomic datasets and the information extracted from them. Such information is expected to significantly extend the current knowledge of Ser/Thr/Tyr phosphorylation in pathogenic bacteria and should ultimately contribute to the design of novel strategies to combat bacterial infections."
32336400,5.0,Neuroimaging-based Individualized Prediction of Cognition and Behavior for Mental Disorders and Health: Methods and Promises,2020 Dec 1;88(11):818-828.,"The neuroimaging community has witnessed a paradigm shift in biomarker discovery from using traditional univariate brain mapping approaches to multivariate predictive models, allowing the field to move toward a translational neuroscience era. Regression-based multivariate models (hereafter ""predictive modeling"") provide a powerful and widely used approach to predict human behavior with neuroimaging features. These studies maintain a focus on decoding individual differences in a continuously behavioral phenotype from neuroimaging data, opening up an exciting opportunity to describe the human brain at the single-subject level. In this survey, we provide an overview of recent studies that utilize machine learning approaches to identify neuroimaging predictors over the past decade. We first review regression-based approaches and highlight connectome-based predictive modeling, which has grown in popularity in recent years. Next, we systematically describe recent representative studies using these tools in the context of cognitive function, symptom severity, personality traits, and emotion processing. Finally, we highlight a few challenges related to combining multimodal data, longitudinal prediction, external validations, and the employment of deep learning methods that have emerged from our review of the existing literature, as well as present some promising and challenging future directions."
32334372,8.0,A review of original articles published in the emerging field of radiomics,2020 Jun;127:108991.,"Purpose:                    To determine the characteristics of and trends in research in the emerging field of radiomics through bibliometric and hotspot analyses of relevant original articles published between 2013 and 2018.              Methods:                    We evaluated 553 original articles concerning radiomics, published in a total of 61 peer-reviewed journals between 2013 and 2018. The following information was retrieved for each article: radiological subspecialty, imaging technique(s), machine learning technique(s), sample size, study setting and design, statistical result(s), study purpose, software used for feature calculation, funding declarations, author number, first author's affiliation, study origin, and journal name. Qualitative and quantitative analyses were performed for the manually extracted data for identification and visualization of the trends in radiomics research.              Results:                    The annual growth rate in the number of published papers was 177.82% (p < 0.001). The characteristics and trends of research hotspots in the field of radiomics were clarified and visualized in this study. It was found that the field of radiomics is at a more mature stage for lung, breast, and prostate cancers than for other sites. Radiomics studies primarily focused on radiological characterization (215) and monitoring (182). Logistic regression and LASSO were the two most commonly used techniques for feature selection. Non-clinical researchers without a medical background dominated radiomics studies (70.52%), the vast majority of which only highlighted positive results (97.80%) while downplaying negative findings.              Conclusions:                    The reporting of quantifiable knowledge about the characteristics and trajectories of radiomics can inform researchers about the gaps in the field of radiomics and guide its future direction."
32333084,3.0,"Circulating tumor cells as Trojan Horse for understanding, preventing, and treating cancer: a critical appraisal",2020 Sep;77(18):3671-3690.,"Circulating tumor cells (CTCs) are regarded as harbingers of metastases. Their ability to predict response to therapy, relapse, and resistance to treatment has proposed their value as putative diagnostic and prognostic indicators. CTCs represent one of the zeniths of cancer evolution in terms of cell survival; however, the triggers of CTC generation, the identification of potentially metastatic CTCs, and the mechanisms contributing to their heterogeneity and aggressiveness represent issues not yet fully deciphered. Thus, prior to enabling liquid biopsy applications to reach clinical prime time, understanding how the above mechanistic information can be applied to improve treatment decisions is a key challenge. Here, we provide our perspective on how CTCs can provide mechanistic insights into tumor pathogenesis, as well as on CTC clinical value. In doing so, we aim to (a) describe how CTCs disseminate from the primary tumor, and their link to epithelial-mesenchymal transition (EMT); (b) trace the route of CTCs through the circulation, focusing on tumor self-seeding and the possibility of tertiary metastasis; (c) describe possible mechanisms underlying the enhanced metastatic potential of CTCs; (d) discuss how CTC could provide further information on the tissue of origin, especially in cancer of unknown primary origin. We also provide a comprehensive review of meta-analyses assessing the prognostic significance of CTCs, to highlight the emerging role of CTCs in clinical oncology. We also explore how cell-free circulating tumor DNA (ctDNA) analysis, using a combination of genomic and phylogenetic analysis, can offer insights into CTC biology, including our understanding of CTC heterogeneity and tumor evolution. Last, we discuss emerging technologies, such as high-throughput quantitative imaging, radiogenomics, machine learning approaches, and the emerging breath biopsy. These technologies could compliment CTC and ctDNA analyses, and they collectively represent major future steps in cancer detection, monitoring, and management."
32331327,4.0,"Emotion Recognition Using Eye-Tracking: Taxonomy, Review and Current Challenges",2020 Apr 22;20(8):2384.,"The ability to detect users' emotions for the purpose of emotion engineering is currently one of the main endeavors of machine learning in affective computing. Among the more common approaches to emotion detection are methods that rely on electroencephalography (EEG), facial image processing and speech inflections. Although eye-tracking is fast in becoming one of the most commonly used sensor modalities in affective computing, it is still a relatively new approach for emotion detection, especially when it is used exclusively. In this survey paper, we present a review on emotion recognition using eye-tracking technology, including a brief introductory background on emotion modeling, eye-tracking devices and approaches, emotion stimulation methods, the emotional-relevant features extractable from eye-tracking data, and most importantly, a categorical summary and taxonomy of the current literature which relates to emotion recognition using eye-tracking. This review concludes with a discussion on the current open research problems and prospective future research directions that will be beneficial for expanding the body of knowledge in emotion detection using eye-tracking as the primary sensor modality."
32326049,3.0,Bioinformatics Methods for Mass Spectrometry-Based Proteomics Data Analysis,2020 Apr 20;21(8):2873.,"Recent advances in mass spectrometry (MS)-based proteomics have enabled tremendous progress in the understanding of cellular mechanisms, disease progression, and the relationship between genotype and phenotype. Though many popular bioinformatics methods in proteomics are derived from other omics studies, novel analysis strategies are required to deal with the unique characteristics of proteomics data. In this review, we discuss the current developments in the bioinformatics methods used in proteomics and how they facilitate the mechanistic understanding of biological processes. We first introduce bioinformatics software and tools designed for mass spectrometry-based protein identification and quantification, and then we review the different statistical and machine learning methods that have been developed to perform comprehensive analysis in proteomics studies. We conclude with a discussion of how quantitative protein data can be used to reconstruct protein interactions and signaling networks."
32325045,2.0,Artificial Intelligence: The Future for Diabetes Care,2020 Aug;133(8):895-900.,"Artificial intelligence (AI) is a fast-growing field and its applications to diabetes, a global pandemic, can reform the approach to diagnosis and management of this chronic condition. Principles of machine learning have been used to build algorithms to support predictive models for the risk of developing diabetes or its consequent complications. Digital therapeutics have proven to be an established intervention for lifestyle therapy in the management of diabetes. Patients are increasingly being empowered for self-management of diabetes, and both patients and health care professionals are benefitting from clinical decision support. AI allows a continuous and burden-free remote monitoring of the patient's symptoms and biomarkers. Further, social media and online communities enhance patient engagement in diabetes care. Technical advances have helped to optimize resource use in diabetes. Together, these intelligent technical reforms have produced better glycemic control with reductions in fasting and postprandial glucose levels, glucose excursions, and glycosylated hemoglobin. AI will introduce a paradigm shift in diabetes care from conventional management strategies to building targeted data-driven precision care."
32324706,8.0,E-health and multiple sclerosis,2020 Jun;33(3):271-276.,"Purpose of review:                    To outline recent applications of e-health data and digital tools for improving the care and management of healthcare for people with multiple sclerosis.              Recent findings:                    The digitization of most clinical data, along with developments in communication technologies, miniaturization of sensors and computational advances are enabling aggregation and clinically meaningful analyses of real-world data from patient registries, digital patient-reported outcomes and electronic health records (EHR). These data are allowing more confident descriptions of prognoses for multiple sclerosis patients and the long-term relative benefits and safety of disease-modifying treatments (DMT). Registries allow detailed, multiple sclerosis-specific data to be shared between clinicians more easily, provide data needed to improve the impact of DMT and, with EHR, characterize clinically relevant interactions between multiple sclerosis and other diseases. Wearable sensors provide continuous, long-term measures of performance dynamics in relevant ecological settings. In conjunction with telemedicine and online apps, they promise a major expansion of the scope for patients to manage aspects of their own care. Advances in disease understanding, decision support and self-management using these Big Data are being accelerated by machine learning and artificial intelligence.              Summary:                    Both health professionals and patients can employ e-health approaches and tools for development of a more patient-centred learning health system."
32324659,,State of the art in clinical decision support applications in pediatric perioperative medicine,2020 Jun;33(3):388-394.,"Purpose of review:                    The goal of this review is to describe the recent improvements in clinical decision tools applied to the increasingly large and complex datasets in the pediatric ambulatory and inpatient setting.              Recent findings:                    Clinical decision support has evolved beyond simple static alerts to complex dynamic alerts for: diagnosis, medical decision-making, monitoring of physiological, laboratory, and pharmacologic inputs, and adherence to institutional and national guidelines for both the patient and the healthcare team. Artificial intelligence and machine learning have enabled advances in predicting outcomes, such as sepsis and early deterioration, and assisting in procedural technique.              Summary:                    With more than a decade of electronic medical data generation, clinical decision support tools have begun to evolve into more sophisticated and complex algorithms capable of transforming large datasets into succinct, timely, and pertinent summaries for treatment and management of pediatric patients. Future developments will need to leverage patient-generated health data, integrated device data, and provider-entered data to complete the continuum of patient care and will likely demonstrate improvements in patient outcomes."
32324658,1.0,Augmented intelligence in pediatric anesthesia and pediatric critical care,2020 Jun;33(3):404-410.,"Purpose of review:                    Acute care technologies, including novel monitoring devices, big data, increased computing capabilities, machine-learning algorithms and automation, are converging. This enables the application of augmented intelligence for improved outcome predictions, clinical decision-making, and offers unprecedented opportunities to improve patient outcomes, reduce costs, and improve clinician workflow. This article briefly explores recent work in the areas of automation, artificial intelligence and outcome prediction models in pediatric anesthesia and pediatric critical care.              Recent findings:                    Recent years have yielded little published research into pediatric physiological closed loop control (a type of automation) beyond studies focused on glycemic control for type 1 diabetes. However, there has been a greater range of research in augmented decision-making, leveraging artificial intelligence and machine-learning techniques, in particular, for pediatric ICU outcome prediction.              Summary:                    Most studies focusing on artificial intelligence demonstrate good performance on prediction or classification, whether they use traditional statistical tools or novel machine-learning approaches. Yet the challenges of implementation, user acceptance, ethics and regulation cannot be underestimated. Areas in which there is easy access to routinely labeled data and robust outcomes, such as those collected through national networks and quality improvement programs, are likely to be at the forefront of the adoption of these advances."
32324388,,Statistics in Proteomics: A Meta-analysis of 100 Proteomics Papers Published in 2019,2020 Jul 1;31(7):1337-1343.,"We randomly selected 100 journal articles published in five proteomics journals in 2019 and manually examined each of them against a set of 13 criteria concerning the statistical analyses used, all of which were based on items mentioned in the journals' instructions to authors. This included questions such as whether a pilot study was conducted and whether false discovery rate calculation was employed at either the quantitation or identification stage. These data were then transformed to binary inputs, analyzed via machine learning algorithms, and classified accordingly, with the aim of determining if clusters of data existed for specific journals or if certain statistical measures correlated with each other. We applied a variety of classification methods including principal component analysis decomposition, agglomerative clustering, and multinomial and Bernoulli naïve Bayes classification and found that none of these could readily determine journal identity given extracted statistical features. Logistic regression was useful in determining high correlative potential between statistical features such as false discovery rate criteria and multiple testing corrections methods, but was similarly ineffective at determining correlations between statistical features and specific journals. This meta-analysis highlights that there is a very wide variety of approaches being used in statistical analysis of proteomics data, many of which do not conform to published journal guidelines, and that contrary to implicit assumptions in the field there are no clear correlations between statistical methods and specific journals."
32323066,3.0,Artificial Intelligence in radiotherapy: state of the art and future directions,2020 Apr 22;37(6):50.,"Recent advances in computing capability allowed the development of sophisticated predictive models to assess complex relationships within observational data, described as Artificial Intelligence. Medicine is one of the several fields of application and Radiation oncology could benefit from these approaches, particularly in patients' medical records, imaging, baseline pathology, planning or instrumental data. Artificial Intelligence systems could simplify many steps of the complex workflow of radiotherapy such as segmentation, planning or delivery. However, Artificial Intelligence could be considered as a ""black box"" in which human operator may only understand input and output predictions and its application to the clinical practice remains a challenge. The low transparency of the overall system is questionable from manifold points of view (ethical included). Given the complexity of this issue, we collected the basic definitions to help the clinician to understand current literature, and overviewed experiences regarding implementation of AI within radiotherapy clinical workflow, aiming to describe this field from the clinician perspective."
32322599,2.0,Application of machine learning in ophthalmic imaging modalities,2020 Apr 16;7:22.,"In clinical ophthalmology, a variety of image-related diagnostic techniques have begun to offer unprecedented insights into eye diseases based on morphological datasets with millions of data points. Artificial intelligence (AI), inspired by the human multilayered neuronal system, has shown astonishing success within some visual and auditory recognition tasks. In these tasks, AI can analyze digital data in a comprehensive, rapid and non-invasive manner. Bioinformatics has become a focus particularly in the field of medical imaging, where it is driven by enhanced computing power and cloud storage, as well as utilization of novel algorithms and generation of data in massive quantities. Machine learning (ML) is an important branch in the field of AI. The overall potential of ML to automatically pinpoint, identify and grade pathological features in ocular diseases will empower ophthalmologists to provide high-quality diagnosis and facilitate personalized health care in the near future. This review offers perspectives on the origin, development, and applications of ML technology, particularly regarding its applications in ophthalmic imaging modalities."
32318338,9.0,Computational Oncology in the Multi-Omics Era: State of the Art,2020 Apr 7;10:423.,"Cancer is the quintessential complex disease. As technologies evolve faster each day, we are able to quantify the different layers of biological elements that contribute to the emergence and development of malignancies. In this multi-omics context, the use of integrative approaches is mandatory in order to gain further insights on oncological phenomena, and to move forward toward the precision medicine paradigm. In this review, we will focus on computational oncology as an integrative discipline that incorporates knowledge from the mathematical, physical, and computational fields to further the biomedical understanding of cancer. We will discuss the current roles of computation in oncology in the context of multi-omic technologies, which include: data acquisition and processing; data management in the clinical and research settings; classification, diagnosis, and prognosis; and the development of models in the research setting, including their use for therapeutic target identification. We will discuss the machine learning and network approaches as two of the most promising emerging paradigms, in computational oncology. These approaches provide a foundation on how to integrate different layers of biological description into coherent frameworks that allow advances both in the basic and clinical settings."
32318028,5.0,"The Computational Diet: A Review of Computational Methods Across Diet, Microbiome, and Health",2020 Apr 3;11:393.,"Food and human health are inextricably linked. As such, revolutionary impacts on health have been derived from advances in the production and distribution of food relating to food safety and fortification with micronutrients. During the past two decades, it has become apparent that the human microbiome has the potential to modulate health, including in ways that may be related to diet and the composition of specific foods. Despite the excitement and potential surrounding this area, the complexity of the gut microbiome, the chemical composition of food, and their interplay in situ remains a daunting task to fully understand. However, recent advances in high-throughput sequencing, metabolomics profiling, compositional analysis of food, and the emergence of electronic health records provide new sources of data that can contribute to addressing this challenge. Computational science will play an essential role in this effort as it will provide the foundation to integrate these data layers and derive insights capable of revealing and understanding the complex interactions between diet, gut microbiome, and health. Here, we review the current knowledge on diet-health-gut microbiota, relevant data sources, bioinformatics tools, machine learning capabilities, as well as the intellectual property and legislative regulatory landscape. We provide guidance on employing machine learning and data analytics, identify gaps in current methods, and describe new scenarios to be unlocked in the next few years in the context of current knowledge."
32317574,3.0,Machine Learning/Deep Neuronal Network: Routine Application in Chest Computed Tomography and Workflow Considerations,2020 May;35 Suppl 1:S21-S27.,"The constantly increasing number of computed tomography (CT) examinations poses major challenges for radiologists. In this article, the additional benefits and potential of an artificial intelligence (AI) analysis platform for chest CT examinations in routine clinical practice will be examined. Specific application examples include AI-based, fully automatic lung segmentation with emphysema quantification, aortic measurements, detection of pulmonary nodules, and bone mineral density measurement. This contribution aims to appraise this AI-based application for value-added diagnosis during routine chest CT examinations and explore future development perspectives."
32317161,,Biomarkers for posttraumatic epilepsy,2020 Apr 18;107080.,"A biomarker is a characteristic that can be objectively measured as an indicator of normal biologic processes, pathogenic processes, or responses to an exposure or intervention, including therapeutic interventions. Biomarker modalities include molecular, histologic, radiographic, or physiologic characteristics. To improve the understanding and use of biomarker terminology in biomedical research, clinical practice, and medical product development, the Food and Drug Administration (FDA)-National Institutes of Health (NIH) Joint Leadership Council developed the BEST Resource (Biomarkers, EndpointS, and other Tools). The seven BEST biomarker categories include the following: (a) susceptibility/risk biomarkers, (b) diagnostic biomarkers, (c) monitoring biomarkers, (d) prognostic biomarkers, (e) predictive biomarkers, (f) pharmacodynamic/response biomarkers, and (g) safety biomarkers. We hypothesize some potential overlap between the reported biomarkers of traumatic brain injury (TBI), epilepsy, and posttraumatic epilepsy (PTE). Here, we tested this hypothesis by reviewing studies focusing on biomarker discovery for posttraumatic epileptogenesis and epilepsy. The biomarker modalities reviewed here include plasma/serum and cerebrospinal fluid molecular biomarkers, imaging biomarkers, and electrophysiologic biomarkers. Most of the reported biomarkers have an area under the receiver operating characteristic curve greater than 0.800, suggesting both high sensitivity and high specificity. Our results revealed little overlap in the biomarker candidates between TBI, epilepsy, and PTE. In addition to using single parameters as biomarkers, machine learning approaches have highlighted the potential for utilizing patterns of markers as biomarkers. Although published data suggest the possibility of identifying biomarkers for PTE, we are still in the early phase of the development curve. Many of the seven biomarker categories lack PTE-related biomarkers. Thus, further exploration using proper, statistically powered, and standardized study designs with validation cohorts, and by developing and applying novel analytical methods, is needed for PTE biomarker discovery."
32316682,,Machine Learning Approaches for Quality Assessment of Protein Structures,2020 Apr 17;10(4):626.,"Protein structures play a very important role in biomedical research, especially in drug discovery and design, which require accurate protein structures in advance. However, experimental determinations of protein structure are prohibitively costly and time-consuming, and computational predictions of protein structures have not been perfected. Methods that assess the quality of protein models can help in selecting the most accurate candidates for further work. Driven by this demand, many structural bioinformatics laboratories have developed methods for estimating model accuracy (EMA). In recent years, EMA by machine learning (ML) have consistently ranked among the top-performing methods in the community-wide CASP challenge. Accordingly, we systematically review all the major ML-based EMA methods developed within the past ten years. The methods are grouped by their employed ML approach-support vector machine, artificial neural networks, ensemble learning, or Bayesian learning-and their significances are discussed from a methodology viewpoint. To orient the reader, we also briefly describe the background of EMA, including the CASP challenge and its evaluation metrics, and introduce the major ML/DL techniques. Overall, this review provides an introductory guide to modern research on protein quality assessment and directions for future research in this area."
32315515,,Continuous glucose monitoring for hypoglycaemia in children: Perspectives in 2020,2020 Aug;21(5):697-706.,"Hypoglycaemia in children is a major risk factor for adverse neurodevelopment with rates as high as 50% in hyperinsulinaemic hypoglycaemia (HH). A key part of management relies upon timely identification and treatment of hypoglycaemia. The current standard of care for glucose monitoring is by infrequent fingerprick plasma glucose testing but this carries a high risk of missed hypoglycaemia identification. High-frequency Continuous Glucose Monitoring (CGM) offers an attractive alternative for glucose trend monitoring and glycaemic phenotyping but its utility remains largely unestablished in disorders of hypoglycaemia. Attempts to determine accuracy through correlation with plasma glucose measurements using conventional methods such as Mean Absolute Relative Difference (MARD) overestimate accuracy at hypoglycaemia. The inaccuracy of CGM in true hypoglycaemia is amplified by calibration algorithms that prioritize hyperglycaemia over hypoglycaemia with minimal objective evidence of efficacy in HH. Conversely, alternative algorithm design has significant potential for predicting hypoglycaemia to prevent neuroglycopaenia and consequent brain dysfunction in childhood disorders. Delays in the detection of hypoglycaemia, alarm fatigue, device calibration and current high cost are all barriers to the wider adoption of CGM in disorders of hypoglycaemia. However, machine learning, artificial intelligence and other computer-generated algorithms now offer significant potential for further improvement in CGM device technology and widespread application in childhood hypoglycaemia."
32315260,4.0,Artificial Intelligence in Dentistry: Chances and Challenges,2020 Jul;99(7):769-774.,"The term ""artificial intelligence"" (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which ""learns"" intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (""explainable AI""). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce."
32313813,3.0,Different fundus imaging modalities and technical factors in AI screening for diabetic retinopathy: a review,2020 Apr 14;7:21.,"Background:                    Effective screening is a desirable method for the early detection and successful treatment for diabetic retinopathy, and fundus photography is currently the dominant medium for retinal imaging due to its convenience and accessibility. Manual screening using fundus photographs has however involved considerable costs for patients, clinicians and national health systems, which has limited its application particularly in less-developed countries. The advent of artificial intelligence, and in particular deep learning techniques, has however raised the possibility of widespread automated screening.              Main text:                    In this review, we first briefly survey major published advances in retinal analysis using artificial intelligence. We take care to separately describe standard multiple-field fundus photography, and the newer modalities of ultra-wide field photography and smartphone-based photography. Finally, we consider several machine learning concepts that have been particularly relevant to the domain and illustrate their usage with extant works.              Conclusions:                    In the ophthalmology field, it was demonstrated that deep learning tools for diabetic retinopathy show clinically acceptable diagnostic performance when using colour retinal fundus images. Artificial intelligence models are among the most promising solutions to tackle the burden of diabetic retinopathy management in a comprehensive manner. However, future research is crucial to assess the potential clinical deployment, evaluate the cost-effectiveness of different DL systems in clinical practice and improve clinical acceptance."
32313006,3.0,Translating research findings into clinical practice: a systematic and critical review of neuroimaging-based clinical tools for brain disorders,2020 Apr 20;10(1):107.,"A pivotal aim of psychiatric and neurological research is to promote the translation of the findings into clinical practice to improve diagnostic and prognostic assessment of individual patients. Structural neuroimaging holds much promise, with neuroanatomical measures accounting for up to 40% of the variance in clinical outcome. Building on these findings, a number of imaging-based clinical tools have been developed to make diagnostic and prognostic inferences about individual patients from their structural Magnetic Resonance Imaging scans. This systematic review describes and compares the technical characteristics of the available tools, with the aim to assess their translational potential into real-world clinical settings. The results reveal that a total of eight tools. All of these were specifically developed for neurological disorders, and as such are not suitable for application to psychiatric disorders. Furthermore, most of the tools were trained and validated in a single dataset, which can result in poor generalizability, or using a small number of individuals, which can cause overoptimistic results. In addition, all of the tools rely on two strategies to detect brain abnormalities in single individuals, one based on univariate comparison, and the other based on multivariate machine-learning algorithms. We discuss current barriers to the adoption of these tools in clinical practice and propose a checklist of pivotal characteristics that should be included in an ""ideal"" neuroimaging-based clinical tool for brain disorders."
32311376,3.0,Computational predictive approaches for interaction and structure of aptamers,2020 Jul 21;497:110268.,"Aptamers are short single-strand sequences that can bind to their specific targets with high affinity and specificity. Usually, aptamers are selected experimentally via systematic evolution of ligands by exponential enrichment (SELEX), an evolutionary process that consists of multiple cycles of selection and amplification. The SELEX process is expensive, time-consuming, and its success rates are relatively low. To overcome these difficulties, in recent years, several computational techniques have been developed in aptamer sciences that bring together different disciplines and branches of technologies. In this paper, a complementary review on computational predictive approaches of the aptamer has been organized. Generally, the computational prediction approaches of aptamer have been proposed to carry out in two main categories: interaction-based prediction and structure-based predictions. Furthermore, the available software packages and toolkits in this scope were reviewed. The aim of describing computational methods and tools in aptamer science is that aptamer scientists might take advantage of these computational techniques to develop more accurate and more sensitive aptamers."
32305325,2.0,Toward a Revised Nosology for Attention-Deficit/Hyperactivity Disorder Heterogeneity,2020 Aug;5(8):726-737.,"Attention-deficit/hyperactivity disorder (ADHD) is among the many syndromes in the psychiatric nosology for which etiological signal and clinical prediction are weak. Reducing phenotypic and mechanistic heterogeneity should be useful to arrive at stronger etiological and clinical prediction signals. We discuss key conceptual and methodological issues, highlighting the role of dimensional features aligned with Research Domain Criteria and cognitive, personality, and temperament theory as well as neurobiology. We describe several avenues of work in this area, utilizing different statistical, computational, and machine learning approaches to resolve heterogeneity in ADHD. We offer methodological and conceptual recommendations. Methodologically, we propose that an integrated approach utilizing theory and advanced computational logic to address targeted questions, with consideration of developmental context, can render the heterogeneity problem tractable for ADHD. Conceptually, we conclude that the field is on the cusp of justifying an emotionally dysregulated subprofile in ADHD that may be useful for clinical prediction and treatment testing. Cognitive profiles, while more nascent, may be useful for clinical prediction and treatment assignment in different ways depending on developmental stage. Targeting these psychological profiles for neurobiological and etiological study to capture different pathophysiological routes remains a near-term opportunity. Subtypes are likely to be multifactorial, cut across multiple dimensions, and depend on the research or clinical outcomes of interest for their ultimate selection. In this context parallel profiles based on cognition, emotion, and specific neural signatures appear to be on the horizon, each with somewhat different utilities. Efforts to integrate such cross-cutting profiles within a conceptual dysregulation framework are well underway."
32305218,2.0,Individualized Diagnostic and Prognostic Models for Patients With Psychosis Risk Syndromes: A Meta-analytic View on the State of the Art,2020 Aug 15;88(4):349-360.,"Background:                    The clinical high risk (CHR) paradigm has facilitated research into the underpinnings of help-seeking individuals at risk for developing psychosis, aiming at predicting and possibly preventing transition to the overt disorder. Statistical methods such as machine learning and Cox regression have provided the methodological basis for this research by enabling the construction of diagnostic models (i.e., distinguishing CHR individuals from healthy individuals) and prognostic models (i.e., predicting a future outcome) based on different data modalities, including clinical, neurocognitive, and neurobiological data. However, their translation to clinical practice is still hindered by the high heterogeneity of both CHR populations and methodologies applied.              Methods:                    We systematically reviewed the literature on diagnostic and prognostic models built on Cox regression and machine learning. Furthermore, we conducted a meta-analysis on prediction performances investigating heterogeneity of methodological approaches and data modality.              Results:                    A total of 44 articles were included, covering 3707 individuals for prognostic studies and 1052 individuals for diagnostic studies (572 CHR patients and 480 healthy control subjects). CHR patients could be classified against healthy control subjects with 78% sensitivity and 77% specificity. Across prognostic models, sensitivity reached 67% and specificity reached 78%. Machine learning models outperformed those applying Cox regression by 10% sensitivity. There was a publication bias for prognostic studies yet no other moderator effects.              Conclusions:                    Our results may be driven by substantial clinical and methodological heterogeneity currently affecting several aspects of the CHR field and limiting the clinical implementability of the proposed models. We discuss conceptual and methodological harmonization strategies to facilitate more reliable and generalizable models for future clinical practice."
32305024,84.0,Artificial Intelligence (AI) applications for COVID-19 pandemic,Jul-Aug 2020;14(4):337-339.,"Background and aims:                    Healthcare delivery requires the support of new technologies like Artificial Intelligence (AI), Internet of Things (IoT), Big Data and Machine Learning to fight and look ahead against the new diseases. We aim to review the role of AI as a decisive technology to analyze, prepare us for prevention and fight with COVID-19 (Coronavirus) and other pandemics.              Methods:                    The rapid review of the literature is done on the database of Pubmed, Scopus and Google Scholar using the keyword of COVID-19 or Coronavirus and Artificial Intelligence or AI. Collected the latest information regarding AI for COVID-19, then analyzed the same to identify its possible application for this disease.              Results:                    We have identified seven significant applications of AI for COVID-19 pandemic. This technology plays an important role to detect the cluster of cases and to predict where this virus will affect in future by collecting and analyzing all previous data.              Conclusions:                    Healthcare organizations are in an urgent need for decision-making technologies to handle this virus and help them in getting proper suggestions in real-time to avoid its spread. AI works in a proficient way to mimic like human intelligence. It may also play a vital role in understanding and suggesting the development of a vaccine for COVID-19. This result-driven technology is used for proper screening, analyzing, prediction and tracking of current patients and likely future patients. The significant applications are applied to tracks data of confirmed, recovered and death cases."
32304429,,Machine-learning approaches to substance-abuse research: emerging trends and their implications,2020 Jul;33(4):334-342.,"Purpose of review:                    To provide an accessible overview of some of the most recent trends in the application of machine learning to the field of substance use disorders and their implications for future research and practice.              Recent findings:                    Machine-learning (ML) techniques have recently been applied to substance use disorder (SUD) data for multiple predictive applications including detecting current abuse, assessing future risk and predicting treatment success. These models cover a wide range of machine-learning techniques and data types including physiological measures, longitudinal surveys, treatment outcomes, national surveys, medical records and social media.              Summary:                    The application of machine-learning models to substance use disorder data shows significant promise, with some use cases and data types showing high predictive accuracy, particularly for models of physiological and behavioral measures for predicting current substance use, portending potential clinical diagnostic applications; however, these results are uneven, with some models performing poorly or at chance, a limitation likely reflecting insufficient data and/or weak validation methods. The field will likely benefit from larger and more multimodal datasets, greater standardization of data recording and rigorous testing protocols as well as greater use of modern deep neural network models applied to multimodal unstructured datasets."
32302888,1.0,Modeling regulatory networks using machine learning for systems metabolic engineering,2020 Oct;65:163-170.,"Systems metabolic engineering attempts to engineer a production host's biological network to overproduce valuable chemicals and materials in a sustainable manner. In contrast to genome-scale metabolic models that are well established, regulatory network models have not been sufficiently considered in systems metabolic engineering despite their importance and recent notable advances. In this paper, recent studies on inferring and characterizing regulatory networks at both transcriptional and translational levels are reviewed. The recent studies discussed herein suggest that their corresponding computational methods and models can be effectively applied to optimize a production host's regulatory networks for the enhanced biological production. For the successful application of regulatory network models, datasets on biological sequence-phenotype relationship need to be more generated."
32299466,1.0,Diagnosis support systems for rare diseases: a scoping review,2020 Apr 16;15(1):94.,"Introduction:                    Rare diseases affect approximately 350 million people worldwide. Delayed diagnosis is frequent due to lack of knowledge of most clinicians and a small number of expert centers. Consequently, computerized diagnosis support systems have been developed to address these issues, with many relying on rare disease expertise and taking advantage of the increasing volume of generated and accessible health-related data. Our objective is to perform a review of all initiatives aiming to support the diagnosis of rare diseases.              Methods:                    A scoping review was conducted based on methods proposed by Arksey and O'Malley. A charting form for relevant study analysis was developed and used to categorize data.              Results:                    Sixty-eight studies were retained at the end of the charting process. Diagnosis targets varied from 1 rare disease to all rare diseases. Material used for diagnosis support consisted mostly of phenotype concepts, images or fluids. Fifty-seven percent of the studies used expert knowledge. Two-thirds of the studies relied on machine learning algorithms, and one-third used simple similarities. Manual algorithms were encountered as well. Most of the studies presented satisfying performance of evaluation by comparison with references or with external validation. Fourteen studies provided online tools, most of which aimed to support the diagnosis of all rare diseases by considering queries based on phenotype concepts.              Conclusion:                    Numerous solutions relying on different materials and use of various methodologies are emerging with satisfying preliminary results. However, the variability of approaches and evaluation processes complicates the comparison of results. Efforts should be made to adequately validate these tools and guarantee reproducibility and explicability."
32298457,1.0,Repositories for Taxonomic Data: Where We Are and What is Missing,2020 Nov 1;69(6):1231-1253.,"Natural history collections are leading successful large-scale projects of specimen digitization (images, metadata, DNA barcodes), thereby transforming taxonomy into a big data science. Yet, little effort has been directed towards safeguarding and subsequently mobilizing the considerable amount of original data generated during the process of naming 15,000-20,000 species every year. From the perspective of alpha-taxonomists, we provide a review of the properties and diversity of taxonomic data, assess their volume and use, and establish criteria for optimizing data repositories. We surveyed 4113 alpha-taxonomic studies in representative journals for 2002, 2010, and 2018, and found an increasing yet comparatively limited use of molecular data in species diagnosis and description. In 2018, of the 2661 papers published in specialized taxonomic journals, molecular data were widely used in mycology (94%), regularly in vertebrates (53%), but rarely in botany (15%) and entomology (10%). Images play an important role in taxonomic research on all taxa, with photographs used in >80% and drawings in 58% of the surveyed papers. The use of omics (high-throughput) approaches or 3D documentation is still rare. Improved archiving strategies for metabarcoding consensus reads, genome and transcriptome assemblies, and chemical and metabolomic data could help to mobilize the wealth of high-throughput data for alpha-taxonomy. Because long-term-ideally perpetual-data storage is of particular importance for taxonomy, energy footprint reduction via less storage-demanding formats is a priority if their information content suffices for the purpose of taxonomic studies. Whereas taxonomic assignments are quasifacts for most biological disciplines, they remain hypotheses pertaining to evolutionary relatedness of individuals for alpha-taxonomy. For this reason, an improved reuse of taxonomic data, including machine-learning-based species identification and delimitation pipelines, requires a cyberspecimen approach-linking data via unique specimen identifiers, and thereby making them findable, accessible, interoperable, and reusable for taxonomic research. This poses both qualitative challenges to adapt the existing infrastructure of data centers to a specimen-centered concept and quantitative challenges to host and connect an estimated $ \le $2 million images produced per year by alpha-taxonomic studies, plus many millions of images from digitization campaigns. Of the 30,000-40,000 taxonomists globally, many are thought to be nonprofessionals, and capturing the data for online storage and reuse therefore requires low-complexity submission workflows and cost-free repository use. Expert taxonomists are the main stakeholders able to identify and formalize the needs of the discipline; their expertise is needed to implement the envisioned virtual collections of cyberspecimens. [Big data; cyberspecimen; new species; omics; repositories; specimen identifier; taxonomy; taxonomic data.]."
32296743,6.0,Applied machine learning and artificial intelligence in rheumatology,2020 Feb 19;4(1):rkaa005.,"Machine learning as a field of artificial intelligence is increasingly applied in medicine to assist patients and physicians. Growing datasets provide a sound basis with which to apply machine learning methods that learn from previous experiences. This review explains the basics of machine learning and its subfields of supervised learning, unsupervised learning, reinforcement learning and deep learning. We provide an overview of current machine learning applications in rheumatology, mainly supervised learning methods for e-diagnosis, disease detection and medical image analysis. In the future, machine learning will be likely to assist rheumatologists in predicting the course of the disease and identifying important disease factors. Even more interestingly, machine learning will probably be able to make treatment propositions and estimate their expected benefit (e.g. by reinforcement learning). Thus, in future, shared decision-making will not only include the patient's opinion and the rheumatologist's empirical and evidence-based experience, but it will also be influenced by machine-learned evidence."
32296706,3.0,Artificial Intelligence Applications in Dermatology: Where Do We Stand?,2020 Mar 31;7:100.,"Artificial intelligence (AI) has become a progressively prevalent Research Topic in medicine and is increasingly being applied to dermatology. There is a need to understand this technology's progress to help guide and shape the future for medical care providers and recipients. We reviewed the literature to evaluate the types of publications on the subject, the specific dermatological topics addressed by AI, and the most challenging barriers to its implementation. A substantial number of original articles and commentaries have been published to date and only few detailed reviews exist. Most AI applications focus on differentiating between benign and malignant skin lesions, however; others exist pertaining to ulcers, inflammatory skin diseases, allergen exposure, dermatopathology, and gene expression profiling. Applications commonly analyze and classify images, however, other tools such as risk assessment calculators are becoming increasingly available. Although many applications are technologically feasible, important implementation barriers have been identified including systematic biases, difficulty of standardization, interpretability, and acceptance by physicians and patients alike. This review provides insight into future research needs and possibilities. There is a strong need for clinical investigation in dermatology providing evidence of success overcoming the identified barriers. With these research goals in mind, an appropriate role for AI in dermatology may be achieved in not so distant future."
32294230,1.0,Leading a Digital Transformation in the Pharmaceutical Industry: Reimagining the Way We Work in Global Drug Development,2020 Oct;108(4):756-761.,"We are experiencing seminal times in computing that seem to define a fourth industrial revolution. This may fundamentally change the way we live, work, and relate to one another. Embracing data and digital information is a top priority for most industries these days, and Life Sciences is no exception. The pharmaceutical industry in particular is fundamentally a data-driven business. Inspired by a desire to ""Go Big on Data,"" we developed a strategic roadmap defining a digital transformation to reimagine the way we work in Novartis Global Drug Development, leveraging data science to generate and inject actionable insights into our best practices. We launched a program called Nerve Live, and built a state-of-the-art data and analytics platform to harness past and present operational data, providing access to decades of drug development ""experience"" buried across multiple sources. The platform enabled the systematic application of machine learning and predictive analytics to generate ""intelligence"": new insights across multiple functional areas. To action the insights and create ""value,"" we crafted skillfully designed end-user applications for domain experts to plan, track, predict, compare and monitor domain activities, optimize costs, and maximize quality. Today, the Nerve Live program enables insights-driven decision making at scale, unlocking productivity, and providing transparency across the Novartis Global Drug Development organization and beyond. We identified three main drivers making the Nerve Live program successful and enabling the associated digital transformation to flourish. We discuss the challenges, highlight the benefits, and see the importance of leading the way to become future proof."
32293466,1.0,Machine learning applied to retinal image processing for glaucoma detection: review and perspective,2020 Apr 15;19(1):20.,"Introduction:                    This is a systematic review on the main algorithms using machine learning (ML) in retinal image processing for glaucoma diagnosis and detection. ML has proven to be a significant tool for the development of computer aided technology. Furthermore, secondary research has been widely conducted over the years for ophthalmologists. Such aspects indicate the importance of ML in the context of retinal image processing.              Methods:                    The publications that were chosen to compose this review were gathered from Scopus, PubMed, IEEEXplore and Science Direct databases. Then, the papers published between 2014 and 2019 were selected . Researches that used the segmented optic disc method were excluded. Moreover, only the methods which applied the classification process were considered. The systematic analysis was performed in such studies and, thereupon, the results were summarized.              Discussion:                    Based on architectures used for ML in retinal image processing, some studies applied feature extraction and dimensionality reduction to detect and isolate important parts of the analyzed image. Differently, other works utilized a deep convolutional network. Based on the evaluated researches, the main difference between the architectures is the number of images demanded for processing and the high computational cost required to use deep learning techniques.              Conclusions:                    All the analyzed publications indicated it was possible to develop an automated system for glaucoma diagnosis. The disease severity and its high occurrence rates justify the researches which have been carried out. Recent computational techniques, such as deep learning, have shown to be promising technologies in fundus imaging. Although such a technique requires an extensive database and high computational costs, the studies show that the data augmentation and transfer learning techniques have been applied as an alternative way to optimize and reduce networks training."
32290639,4.0,Physiological and Behavior Monitoring Systems for Smart Healthcare Environments: A Review,2020 Apr 12;20(8):2186.,"Healthcare optimization has become increasingly important in the current era, where numerous challenges are posed by population ageing phenomena and the demand for higher quality of the healthcare services. The implementation of Internet of Things (IoT) in the healthcare ecosystem has been one of the best solutions to address these challenges and therefore to prevent and diagnose possible health impairments in people. The remote monitoring of environmental parameters and how they can cause or mediate any disease, and the monitoring of human daily activities and physiological parameters are among the vast applications of IoT in healthcare, which has brought extensive attention of academia and industry. Assisted and smart tailored environments are possible with the implementation of such technologies that bring personal healthcare to any individual, while living in their preferred environments. In this paper we address several requirements for the development of such environments, namely the deployment of physiological signs monitoring systems, daily activity recognition techniques, as well as indoor air quality monitoring solutions. The machine learning methods that are most used in the literature for activity recognition and body motion analysis are also referred. Furthermore, the importance of physical and cognitive training of the elderly population through the implementation of exergames and immersive environments is also addressed."
32285013,5.0,The need for a system view to regulate artificial intelligence/machine learning-based software as medical device,2020 Apr 7;3:53.,"Artificial intelligence (AI) and Machine learning (ML) systems in medicine are poised to significantly improve health care, for example, by offering earlier diagnoses of diseases or recommending optimally individualized treatment plans. However, the emergence of AI/ML in medicine also creates challenges, which regulators must pay attention to. Which medical AI/ML-based products should be reviewed by regulators? What evidence should be required to permit marketing for AI/ML-based software as a medical device (SaMD)? How can we ensure the safety and effectiveness of AI/ML-based SaMD that may change over time as they are applied to new data? The U.S. Food and Drug Administration (FDA), for example, has recently proposed a discussion paper to address some of these issues. But it misses an important point: we argue that regulators like the FDA need to widen their scope from evaluating medical AI/ML-based products to assessing systems. This shift in perspective-from a product view to a system view-is central to maximizing the safety and efficacy of AI/ML in health care, but it also poses significant challenges for agencies like the FDA who are used to regulating products, not systems. We offer several suggestions for regulators to make this challenging but important transition."
32281460,,Association between diabetic retinopathy and interleukin-related gene polymorphisms: a machine learning aided meta-analysis,2020 Jun;41(3):216-222.,"Background:                    Diabetic retinopathy (DR) is a severe complication of diabetes and a common cause of visual loss in adults. We aimed to assess the correlation between IL gene-related SNPs and the incidence of DR and attempted to predict DR with combined mutation site detection.              Methods:                    A systematic search of databases was performed up to August 2019. Five genetic models were used to analyze associations. Machine learning methods were implemented to improve SNP-related disease prediction.              Results:                    Sixteen trials assessing a total of 7221 patients were included in our meta-analysis. IL6/rs1800795, rs1800796, and IL10/rs1800896 were analyzed. For the IL-6 gene, there was no significant association between rs1800795 and the incidence of DR (allelic model: OR, 1.091; 95% CI, 0.892-1.334; p = .396). There was no significant correlation between rs1800796 (allelic model: OR, 1.135; 95% CI, 0.678-1.901; p = .63), rs1800896 (allelic model: OR, 1.047; 95% CI, 0.788-1.392; p = .752) and the incidence of DR. Unfortunately, the machine learning results also showed that the combined detection of two SNPs could not accurately predict DR occurrence.              Conclusion:                    rs1800795 and rs1800796 in the IL-6 gene and rs1800896 in IL-10 gene are not related to the incidence of DR. Mutations in multiple SNPs for each DR patient still need to be specifically assessed to increase prediction accuracy."
32279157,3.0,Enabling pregnant women and their physicians to make informed medication decisions using artificial intelligence,2020 Aug;47(4):305-318.,"The role of artificial intelligence (AI) in healthcare for pregnant women. To assess the role of AI in women's health, discover gaps, and discuss the future of AI in maternal health. A systematic review of English articles using EMBASE, PubMed, and SCOPUS. Search terms included pregnancy and AI. Research articles and book chapters were included, while conference papers, editorials and notes were excluded from the review. Included papers focused on pregnancy and AI methods, and pertained to pharmacologic interventions. We identified 376 distinct studies from our queries. A final set of 31 papers were included for the review. Included papers represented a variety of pregnancy concerns and multidisciplinary applications of AI. Few studies relate to pregnancy, AI, and pharmacologics and therefore, we review carefully those studies. External validation of models and techniques described in the studies is limited, impeding on generalizability of the studies. Our review describes how AI has been applied to address maternal health, throughout the pregnancy process: preconception, prenatal, perinatal, and postnatal health concerns. However, there is a lack of research applying AI methods to understand how pharmacologic treatments affect pregnancy. We identify three areas where AI methods could be used to improve our understanding of pharmacological effects of pregnancy, including: (a) obtaining sound and reliable data from clinical records (15 studies), (b) designing optimized animal experiments to validate specific hypotheses (1 study) to (c) implementing decision support systems that inform decision-making (11 studies). The largest literature gap that we identified is with regards to using AI methods to optimize translational studies between animals and humans for pregnancy-related drug exposures."
32276469,3.0,"Transcriptomics in Toxicogenomics, Part III: Data Modelling for Risk Assessment",2020 Apr 8;10(4):708.,"Transcriptomics data are relevant to address a number of challenges in Toxicogenomics (TGx). After careful planning of exposure conditions and data preprocessing, the TGx data can be used in predictive toxicology, where more advanced modelling techniques are applied. The large volume of molecular profiles produced by omics-based technologies allows the development and application of artificial intelligence (AI) methods in TGx. Indeed, the publicly available omics datasets are constantly increasing together with a plethora of different methods that are made available to facilitate their analysis, interpretation and the generation of accurate and stable predictive models. In this review, we present the state-of-the-art of data modelling applied to transcriptomics data in TGx. We show how the benchmark dose (BMD) analysis can be applied to TGx data. We review read across and adverse outcome pathways (AOP) modelling methodologies. We discuss how network-based approaches can be successfully employed to clarify the mechanism of action (MOA) or specific biomarkers of exposure. We also describe the main AI methodologies applied to TGx data to create predictive classification and regression models and we address current challenges. Finally, we present a short description of deep learning (DL) and data integration methodologies applied in these contexts. Modelling of TGx data represents a valuable tool for more accurate chemical safety assessment. This review is the third part of a three-article series on Transcriptomics in Toxicogenomics."
32276442,1.0,Integration of Novel Sensors and Machine Learning for Predictive Maintenance in Medium Voltage Switchgear to Enable the Energy and Mobility Revolutions,2020 Apr 8;20(7):2099.,"The development of renewable energies and smart mobility has profoundly impacted the future of the distribution grid. An increasing bidirectional energy flow stresses the assets of the distribution grid, especially medium voltage switchgear. This calls for improved maintenance strategies to prevent critical failures. Predictive maintenance, a maintenance strategy relying on current condition data of assets, serves as a guideline. Novel sensors covering thermal, mechanical, and partial discharge aspects of switchgear, enable continuous condition monitoring of some of the most critical assets of the distribution grid. Combined with machine learning algorithms, the demands put on the distribution grid by the energy and mobility revolutions can be handled. In this paper, we review the current state-of-the-art of all aspects of condition monitoring for medium voltage switchgear. Furthermore, we present an approach to develop a predictive maintenance system based on novel sensors and machine learning. We show how the existing medium voltage grid infrastructure can adapt these new needs on an economic scale."
32274856,2.0,Using Artificial Intelligence for Predicting Survival of Individual Grafts in Liver Transplantation: A Systematic Review,2020 Jul;26(7):922-934.,"The demand for liver transplantation far outstrips the supply of deceased donor organs, and so, listing and allocation decisions aim to maximize utility. Most existing methods for predicting transplant outcomes use basic methods, such as regression modeling, but newer artificial intelligence (AI) techniques have the potential to improve predictive accuracy. The aim was to perform a systematic review of studies predicting graft outcomes following deceased donor liver transplantation using AI techniques and to compare these findings to linear regression and standard predictive modeling: donor risk index (DRI), Model for End-Stage Liver Disease (MELD), and Survival Outcome Following Liver Transplantation (SOFT). After reviewing available article databases, a total of 52 articles were reviewed for inclusion. Of these articles, 9 met the inclusion criteria, which reported outcomes from 18,771 liver transplants. Artificial neural networks (ANNs) were the most commonly used methodology, being reported in 7 studies. Only 2 studies directly compared machine learning (ML) techniques to liver scoring modalities (i.e., DRI, SOFT, and balance of risk [BAR]). Both studies showed better prediction of individual organ survival with the optimal ANN model, reporting an area under the receiver operating characteristic curve (AUROC) 0.82 compared with BAR (0.62) and SOFT (0.57), and the other ANN model gave an AUC ROC of 0.84 compared with a DRI (0.68) and SOFT (0.64). AI techniques can provide high accuracy in predicting graft survival based on donors and recipient variables. When compared with the standard techniques, AI methods are dynamic and are able to be trained and validated within every population. However, the high accuracy of AI may come at a cost of losing explainability (to patients and clinicians) on how the technology works."
32272169,6.0,"Biohorology and biomarkers of aging: Current state-of-the-art, challenges and opportunities",2020 Jul;60:101050.,"The aging process results in multiple traceable footprints, which can be quantified and used to estimate an organism's age. Examples of such aging biomarkers include epigenetic changes, telomere attrition, and alterations in gene expression and metabolite concentrations. More than a dozen aging clocks use molecular features to predict an organism's age, each of them utilizing different data types and training procedures. Here, we offer a detailed comparison of existing mouse and human aging clocks, discuss their technological limitations and the underlying machine learning algorithms. We also discuss promising future directions of research in biohorology - the science of measuring the passage of time in living systems. Overall, we expect deep learning, deep neural networks and generative approaches to be the next power tools in this timely and actively developing field."
32271281,1.0,"Machine Learning and Deep Neural Network Applications in the Thorax: Pulmonary Embolism, Chronic Thromboembolic Pulmonary Hypertension, Aorta, and Chronic Obstructive Pulmonary Disease",2020 May;35 Suppl 1:S40-S48.,"The radiologic community is rapidly integrating a revolution that has not fully entered daily practice. It necessitates a close collaboration between computer scientists and radiologists to move from concepts to practical applications. This article reviews the current littérature on machine learning and deep neural network applications in the field of pulmonary embolism, chronic thromboembolic pulmonary hypertension, aorta, and chronic obstructive pulmonary disease."
32269464,,Machine Learning Methods for Precision Medicine Research Designed to Reduce Health Disparities: A Structured Tutorial,2020 Apr 2;30(Suppl 1):217-228.,"Precision medicine research designed to reduce health disparities often involves studying multi-level datasets to understand how diseases manifest disproportionately in one group over another, and how scarce health care resources can be directed precisely to those most at risk for disease. In this article, we provide a structured tutorial for medical and public health researchers on the application of machine learning methods to conduct precision medicine research designed to reduce health disparities. We review key terms and concepts for understanding machine learning papers, including supervised and unsupervised learning, regularization, cross-validation, bagging, and boosting. Metrics are reviewed for evaluating machine learners and major families of learning approaches, including tree-based learning, deep learning, and ensemble learning. We highlight the advantages and disadvantages of different learning approaches, describe strategies for interpreting ""black box"" models, and demonstrate the application of common methods in an example dataset with open-source statistical code in R."
32269329,2.0,Next-generation robotics in gastrointestinal surgery,2020 Jul;17(7):430-440.,"The global numbers of robotic gastrointestinal surgeries are increasing. However, the evidence base for robotic gastrointestinal surgery does not yet support its widespread adoption or justify its cost. The reasons for its continued popularity are complex, but a notable driver is the push for innovation - robotic surgery is seen as a compelling solution for delivering on the promise of minimally invasive precision surgery - and a changing commercial landscape delivers the promise of increased affordability. Novel systems will leverage the robot as a data-driven platform, integrating advances in imaging, artificial intelligence and machine learning for decision support. However, if this vision is to be realized, lessons must be heeded from current clinical trials and translational strategies, which have failed to demonstrate patient benefit. In this Perspective, we critically appraise current research to define the principles on which the next generation of gastrointestinal robotics trials should be based. We also discuss the emerging commercial landscape and define existing and new technologies."
32266827,,The State of Data Science in Genomic Nursing,2020 Jul;22(3):309-318.,"Nurse scientists are generating, acquiring, distributing, processing, storing, and analyzing greater volumes of complex omics data than ever before. To take full advantage of big omics data, to address core biological questions, and to enhance patient care, however, genomic nurse scientists must embrace data science. Intended for readership with limited but expanding data science knowledge and skills, this article aims to provide a brief overview of the state of data science in genomic nursing. Our goal is to introduce key data science concepts to genomic nurses who participate at any stage of the data science lifecycle, from research patient recruitment to data wrangling, preprocessing, and analysis to implementation in clinical practice to policy creation. We address three major components in this review: (1) fundamental terminology for the field of genomic nursing data science, (2) current genomic nursing data science research exemplars, and (3) the spectrum of genomic nursing data science roles as well as education pathways and training opportunities. Links to helpful resources are included throughout the article."
