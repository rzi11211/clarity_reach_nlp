pmid,citations,title,date,text
33071481,4.0,A survey on artificial intelligence approaches in supporting frontline workers and decision makers for the COVID-19 pandemic,2020 Dec;141:110337.,"While the world has experience with many different types of infectious diseases, the current crisis related to the spread of COVID-19 has challenged epidemiologists and public health experts alike, leading to a rapid search for, and development of, new and innovative solutions to combat its spread. The transmission of this virus has infected more than 18.92 million people as of August 6, 2020, with over half a million deaths across the globe; the World Health Organization (WHO) has declared this a global pandemic. A multidisciplinary approach needs to be followed for diagnosis, treatment and tracking, especially between medical and computer sciences, so, a common ground is available to facilitate the research work at a faster pace. With this in mind, this survey paper aimed to explore and understand how and which different technological tools and techniques have been used within the context of COVID-19. The primary contribution of this paper is in its collation of the current state-of-the-art technological approaches applied to the context of COVID-19, and doing this in a holistic way, covering multiple disciplines and different perspectives. The analysis is widened by investigating Artificial Intelligence (AI) approaches for the diagnosis, anticipate infection and mortality rate by tracing contacts and targeted drug designing. Moreover, the impact of different kinds of medical data used in diagnosis, prognosis and pandemic analysis is also provided. This review paper covers both medical and technological perspectives to facilitate the virologists, AI researchers and policymakers while in combating the COVID-19 outbreak."
33070881,1.0,Tele-robotics and artificial-intelligence in stroke care,2020 Sep;79:129-132.,"In the last forty years, the field of medicine has experienced dramatic shifts in technology-enhanced surgical procedures - from its initial use in 1985 for neurosurgical biopsies to current implementation of systems such as magnetic-guided catheters for endovascular procedures. Systems such as the Niobe Magnetic Navigation system and CorPath GRX have allowed for utilization of a fully integrated surgical robotic systems for perioperative manipulation, as well as tele-controlled manipulation systems for telemedicine. These robotic systems hold tremendous potential for future implementation in cerebrovascular procedures, but lack of relevant clinical experience and uncharted ethical and legal territory for real-life tele-robotics have stalled their adoption for neurovascular surgery, and might present significant challenges for future development and widespread implementation. Yet, the promise that these technologies hold for dramatically improving the quality and accessibility of cerebrovascular procedures such as thrombectomy for acute stroke, drives the research and development of surgical robotics. These technologies, coupled with artificial intelligence (AI) capabilities such as machine learning, deep-learning, and outcome-based analyses and modifications, have the capability to uncover new dimensions within the realm of cerebrovascular surgery."
33070540,,Usefulness of machine learning in COVID-19 for the detection and prognosis of cardiovascular complications,2020 Sep 30;21(3):345-352.,"Since January 2020, coronavirus disease 2019 (COVID-19) has rapidly become a global concern, and its cardiovascular manifestations have highlighted the need for fast, sensitive and specific tools for early identification and risk stratification. Machine learning is a software solution with the ability to analyze large amounts of data and make predictions without prior programming. When faced with new problems with unique challenges as evident in the COVID-19 pandemic, machine learning can offer solutions that are not apparent on the surface by sifting quickly through massive quantities of data and making associations that may have been missed. Artificial intelligence is a broad term that encompasses different tools, including various types of machine learning and deep learning. Here, we review several cardiovascular applications of machine learning and artificial intelligence and their potential applications to cardiovascular diagnosis, prognosis, and therapy in COVID-19 infection."
33068919,,Transboundary Pathogenic microRNA Analysis Framework for Crop Fungi Driven by Biological Big Data and Artificial Intelligence Model,2020 Dec;89:107401.,"Plant fungal diseases have been affecting the world's agricultural production and economic levels for a long time, such as rice blast, gray tomato mold, potato late blight etc. Recent studies have shown that fungal pathogens transmit microRNA as an effector to host plants for infection. However, bioassay-based verification analysis is time-consuming and challenging, and it is difficult to analyze from a global perspective. With the accumulation of fungal and plant-related data, data analysis methods can be used to analyze pathogenic fungal microRNA further. Based on the microRNA expression data of fungal pathogens infecting plants before and after, this paper discusses the selection strategy of sample data, the extraction strategy of pathogenic fungal microRNA, the prediction strategy of a fungal pathogenic microRNA target gene, the bicluster-based fungal pathogenic microRNA functional analysis strategy and experimental verification methods. A general analysis pipeline based on machine learning and bicluster-based function module was proposed for plant-fungal pathogenic microRNA.The pipeline proposed in this paper is applied to the infection process of Magnaporthe oryzae and the infection process of potato late blight. It has been verified to prove the feasibility of the pipeline. It can be extended to other relevant crop pathogen research, providing a new idea for fungal research on plant diseases. It can be used as a reference for understanding the interaction between fungi and plants."
33066636,1.0,Statistical and Machine-Learning Analyses in Nutritional Genomics Studies,2020 Oct 14;12(10):3140.,"Nutritional compounds may have an influence on different OMICs levels, including genomics, epigenomics, transcriptomics, proteomics, metabolomics, and metagenomics. The integration of OMICs data is challenging but may provide new knowledge to explain the mechanisms involved in the metabolism of nutrients and diseases. Traditional statistical analyses play an important role in description and data association; however, these statistical procedures are not sufficiently enough powered to interpret the large integrated multiple OMICs (multi-OMICS) datasets. Machine learning (ML) approaches can play a major role in the interpretation of multi-OMICS in nutrition research. Specifically, ML can be used for data mining, sample clustering, and classification to produce predictive models and algorithms for integration of multi-OMICs in response to dietary intake. The objective of this review was to investigate the strategies used for the analysis of multi-OMICs data in nutrition studies. Sixteen recent studies aimed to understand the association between dietary intake and multi-OMICs data are summarized. Multivariate analysis in multi-OMICs nutrition studies is used more commonly for analyses. Overall, as nutrition research incorporated multi-OMICs data, the use of novel approaches of analysis such as ML needs to complement the traditional statistical analyses to fully explain the impact of nutrition on health and disease."
33065754,,Artificial intelligence for the management of pancreatic diseases,2021 Jan;33(2):231-241.,"Novel artificial intelligence techniques are emerging in all fields of healthcare, including gastroenterology. The aim of this review is to give an overview of artificial intelligence applications in the management of pancreatic diseases. We performed a systematic literature search in PubMed and Medline up to May 2020 to identify relevant articles. Our results showed that the development of machine-learning based applications is rapidly evolving in the management of pancreatic diseases, guiding precision medicine in clinical, endoscopic and radiologic settings. Before implementation into clinical practice, further research should focus on the external validation of novel techniques, clarifying the accuracy and robustness of these models."
33065195,,Closing the translation gap: AI applications in digital pathology,2021 Jan;1875(1):188452.,"Recent advances in artificial intelligence show tremendous promise to improve the accuracy, reproducibility, and availability of medical diagnostics across a number of medical subspecialities. This is especially true in the field of digital pathology, which has recently witnessed a surge in publications describing state-of-the-art performance for machine learning models across a wide range of diagnostic applications. Nonetheless, despite this promise, there remain significant gaps in translating applications for any of these technologies into actual clinical practice. In this review, we will first give a brief overview of the recent progress in applying AI to digitized pathology images, focusing on how these tools might be applied in clinical workflows in the near term to improve the accuracy and efficiency of pathologists. Then we define and describe in detail the various factors that need to be addressed in order to successfully close the ""translation gap"" for AI applications in digital pathology."
33063054,,A Study on Fight Against COVID-19 from Latest Technological Intervention,2020;1(5):277.,"Uncontrolled spread of pandemic COVID-19 in India and across the globe over several months, created an impact as never before any pandemic would have created. This certainly demands a technological intervention from all possibility to overcome the situation and lead a normal life as early as possible. AI/Machine learning responds to the situation, through inspecting different aspects of the pandemic. This paper analyses and studies those aspects, (I) Quarantine and statistical aspect: Quarantine potentially affected candidates (person who is in touch, travel history) through Data analytics/Machine learning. (II) Diagnosis and Treatment aspect: Early detection and fast treatment will save lives. Diagnosis using deep learning assists radiologist from saving their effort and time to a greater extent and arrives faster conclusion. (III) Prevention aspect: Monitoring and enforce social distancing through visual social distancing using deep learning and Computer vision."
33062908,,"Quantification and classification of potassium and calcium disorders with the electrocardiogram: What do clinical studies, modeling, and reconstruction tell us?",2020 Oct 2;4(4):041501.,"Diseases caused by alterations of ionic concentrations are frequently observed challenges and play an important role in clinical practice. The clinically established method for the diagnosis of electrolyte concentration imbalance is blood tests. A rapid and non-invasive point-of-care method is yet needed. The electrocardiogram (ECG) could meet this need and becomes an established diagnostic tool allowing home monitoring of the electrolyte concentration also by wearable devices. In this review, we present the current state of potassium and calcium concentration monitoring using the ECG and summarize results from previous work. Selected clinical studies are presented, supporting or questioning the use of the ECG for the monitoring of electrolyte concentration imbalances. Differences in the findings from automatic monitoring studies are discussed, and current studies utilizing machine learning are presented demonstrating the potential of the deep learning approach. Furthermore, we demonstrate the potential of computational modeling approaches to gain insight into the mechanisms of relevant clinical findings and as a tool to obtain synthetic data for methodical improvements in monitoring approaches."
33059823,1.0,Multimodality Imaging and Artificial Intelligence for Tumor Characterization: Current Status and Future Perspective,2020 Nov;50(6):541-548.,"Research in medical imaging has yet to do to achieve precision oncology. Over the past 30 years, only the simplest imaging biomarkers (RECIST, SUV,…) have become widespread clinical tools. This may be due to our inability to accurately characterize tumors and monitor intratumoral changes in imaging. Artificial intelligence, through machine learning and deep learning, opens a new path in medical research because it can bring together a large amount of heterogeneous data into the same analysis to reach a single outcome. Supervised or unsupervised learning may lead to new paradigms by identifying unrevealed structural patterns across data. Deep learning will provide human-free, undefined upstream, reproducible, and automated quantitative imaging biomarkers. Since tumor phenotype is driven by its genotype and thus indirectly defines tumoral progression, tumor characterization using machine learning and deep learning algorithms will allow us to monitor molecular expression noninvasively, anticipate therapeutic failure, and lead therapeutic management. To follow this path, quality standards have to be set: standardization of imaging acquisition as it has been done in the field of biology, transparency of the model development as it should be reproducible by different institutions, validation, and testing through a high-quality process using large and complex open databases and better interpretability of these algorithms."
33059822,1.0,A Role for FDG PET Radiomics in Personalized Medicine?,2020 Nov;50(6):532-540.,"Radiomics describes the extraction of multiple features from medical images, including molecular imaging modalities, that with bioinformatic approaches, provide additional clinically relevant information that may be invisible to the human eye. This information may complement standard radiological interpretation with data that may better characterize a disease or that may provide predictive or prognostic information. Progressing from predefined image features, often describing heterogeneity of voxel intensities within a volume of interest, there is increasing use of machine learning to classify disease characteristics and deep learning methods based on artificial neural networks that can learn features without a priori definition and without the need for preprocessing of images. There have been advances in standardization and harmonization of methods to a level that should support multicenter studies. However, in this relatively early phase of research in the field, there are limited aspects that have been adopted into routine practice. Most of the reports in the molecular imaging field describe radiomic approaches in cancer using 18F-fluorodeoxyglucose positron emission tomography (18F-FDG-PET). In this review, we will describe radiomics in molecular imaging and summarize the pertinent literature in lung cancer where reports are most prevalent and mature."
33059819,,Imaging for Response Assessment in Cancer Clinical Trials,2020 Nov;50(6):488-504.,"The use of biomarkers is integral to the routine management of cancer patients, including diagnosis of disease, clinical staging and response to therapeutic intervention. Advanced imaging metrics with computed tomography (CT), magnetic resonance imaging (MRI), and positron emission tomography (PET) are used to assess response during new drug development and in cancer research for predictive metrics of response. Key components and challenges to identifying an appropriate imaging biomarker are selection of integral vs integrated biomarkers, choosing an appropriate endpoint and modality, and standardization of the imaging biomarkers for cooperative and multicenter trials. Imaging biomarkers lean on the original proposed quantified metrics derived from imaging such as tumor size or longest dimension, with the most commonly implemented metrics in clinical trials coming from the Response Evaluation Criteria in Solid Tumors (RECIST) criteria, and then adapted versions such as immune-RECIST (iRECIST) and Positron Emission Tomography Response Criteria in Solid Tumors (PERCIST) for immunotherapy response and PET imaging, respectively. There have been many widely adopted biomarkers in clinical trials derived from MRI including metrics that describe cellularity and vascularity from diffusion-weighted (DW)-MRI apparent diffusion coefficient (ADC) and Dynamic Susceptibility Contrast (DSC) or dynamic contrast enhanced (DCE)-MRI (Ktrans, relative cerebral blood volume (rCBV)), respectively. Furthermore, Fluorodexoyglucose (FDG), fluorothymidine (FLT), and fluoromisonidazole (FMISO)-PET imaging, which describe molecular markers of glucose metabolism, proliferation and hypoxia have been implemented into various cancer types to assess therapeutic response to a wide variety of targeted- and chemotherapies. Recently, there have been many functional and molecular novel imaging biomarkers that are being developed that are rapidly being integrated into clinical trials (with anticipation of being implemented into clinical workflow in the future), such as artificial intelligence (AI) and machine learning computational strategies, antibody and peptide specific molecular imaging, and advanced diffusion MRI. These include prostate-specific membrane antigen (PSMA) and trastuzumab-PET, vascular tumor burden extracted from contrast-enhanced CT, diffusion kurtosis imaging, and CD8 or Granzyme B PET imaging. Further excitement surrounds theranostic procedures such as the combination of 68Ga/111In- and 177Lu-DOTATATE to use integral biomarkers to direct care and personalize therapy. However, there are many challenges in the implementation of imaging biomarkers that remains, including understand the accuracy, repeatability and reproducibility of both acquisition and analysis of these imaging biomarkers. Despite the challenges associated with the biological and technical validation of novel imaging biomarkers, a distinct roadmap has been created that is being implemented into many clinical trials to advance the development and implementation to create specific and sensitive novel imaging biomarkers of therapeutic response to continue to transform medical oncology."
33059367,1.0,Mapping scientific landscapes in UMLS research: a scientometric review,2020 Oct 1;27(10):1612-1624.,"Objective:                    The Unified Medical Language System (UMLS) is 1 of the most successful, collaborative efforts of terminology resource development in biomedicine. The present study aims to 1) survey historical footprints, emerging technologies, and the existing challenges in the use of UMLS resources and tools, and 2) present potential future directions.              Materials and methods:                    We collected 10 469 bibliographic records published between 1986 and 2019, using a Web of Science database. graph analysis, data visualization, and text mining to analyze domain-level citations, subject categories, keyword co-occurrence and bursts, document co-citation networks, and landmark papers.              Results:                    The findings show that the development of UMLS resources and tools have been led by interdisciplinary collaboration among medicine, biology, and computer science. Efforts encompassing multiple disciplines, such as medical informatics, biochemical sciences, and genetics, were the driving forces behind the domain's growth. The following topics were found to be the dominant research themes from the early phases to mid-phases: 1) development and extension of ontologies and 2) enhancing the integrity and accessibility of these resources. Knowledge discovery using machine learning and natural language processing and applications in broader contexts such as drug safety surveillance have recently been receiving increasing attention.              Discussion:                    Our analysis confirms that while reaching its scientific maturity, UMLS research aims to boundary-span to more variety in the biomedical context. We also made some recommendations for editorship and authorship in the domain.              Conclusion:                    The present study provides a systematic approach to map the intellectual growth of science, as well as a self-explanatory bibliometric profile of the published UMLS literature. It also suggests potential future directions. Using the findings of this study, the scientific community can better align the studies within the emerging agenda and current challenges."
33059075,,Deep learning in next-generation sequencing,2021 Jan;26(1):173-180.,"Next-generation sequencing (NGS) methods lie at the heart of large parts of biological and medical research. Their fundamental importance has created a continuously increasing demand for processing and analysis methods of the data sets produced, addressing questions such as variant calling, metagenomic classification and quantification, genomic feature detection, or downstream analysis in larger biological or medical contexts. In addition to classical algorithmic approaches, machine-learning (ML) techniques are often used for such tasks. In particular, deep learning (DL) methods that use multilayered artificial neural networks (ANNs) for supervised, semisupervised, and unsupervised learning have gained significant traction for such applications. Here, we highlight important network architectures, application areas, and DL frameworks in a NGS context."
33044239,,Identification of acute kidney injury subphenotypes,2020 Dec;26(6):519-524.,"Purpose of review:                    AKI is a complex clinical syndrome with many causes and there is a broad range of clinical presentations that vary according to duration, severity and context. Established consensus definitions of AKI are nonspecific and limited to kidney function. This reduces treatment options to generic approaches rather than individualized, cause-based strategies that have limited both understanding and management of AKI.              Recent findings:                    The context and the temporal phase of kidney injury are critical features in the course of AKI and critical to timing-relevant intervention. These features are missing in generic definitions and terms used to describe AKI. Subphenotypes of AKI can be identified from novel damage biomarkers, from functional changes including creatinine trajectories, from the duration of change and from associated clinical characteristics and comorbidities. Subphenotype parameters can be combined in risk scores, or by association strategies ranging from a simple function-damage matrix to complex methods, such as machine learning. Examples of such strategies are reviewed along with tentative proposals for a revised nomenclature to facilitate description of AKI subphenotypes.              Summary:                    Appropriate intervention requires refinement of the nomenclature of AKI to identify subphenotypes that facilitate correctly timed and selectively targeted intervention."
33043272,1.0,Redesigning COVID-19 Care With Network Medicine and Machine Learning,2020 Dec;4(6):725-732.,"Emerging evidence regarding COVID-19 highlights the role of individual resistance and immune function in both susceptibility to infection and severity of disease. Multiple factors influence the response of the human host on exposure to viral pathogens. Influencing an individual's susceptibility to infection are such factors as nutritional status, physical and psychosocial stressors, obesity, protein-calorie malnutrition, emotional resilience, single-nucleotide polymorphisms, environmental toxins including air pollution and firsthand and secondhand tobacco smoke, sleep habits, sedentary lifestyle, drug-induced nutritional deficiencies and drug-induced immunomodulatory effects, and availability of nutrient-dense food and empty calories. This review examines the network of interacting cofactors that influence the host-pathogen relationship, which in turn determines one's susceptibility to viral infections like COVID-19. It then evaluates the role of machine learning, including predictive analytics and random forest modeling, to help clinicians assess patients' risk for development of active infection and to devise a comprehensive approach to prevention and treatment."
33042915,1.0,Predicting Apnoeic Events in Preterm Infants,2020 Sep 16;8:570.,"Apnoea, a pause in respiration, is almost ubiquitous in preterm infants born before completing 30 weeks gestation. Apnoea often begets hypoxemia and/or bradycardia, and has the potential to result in adverse neurodevelopmental consequences. Our current inability to predict apnoeic events in preterm infants requires apnoea to first be detected by monitoring device/s in order to trigger an intervention by bedside (medical or nursing) staff. Such a reactive management approach is laborious, and makes the consequences of apnoeic events inevitable. Recent technological advances and improved signal processing have allowed the possibility of developing prediction models for apnoeic events in preterm infants. However, the development of such models has numerous challenges and is only starting to show potential. This paper identifies requisite components and current gaps in developing prediction models for apnoeic events, and reviews previous studies on predicting apnoeic events in preterm infants."
33042325,,Management of Acute Pulmonary Embolism,2020;14(12):24.,"Purpose of the review:                    Over 100,000 cardiovascular-related deaths annually are caused by acute pulmonary embolism (PE). While anticoagulation has historically been the foundation for treatment of PE, this review highlights the recent rapid expansion in the interventional strategies for this condition.              Recent findings:                    At the time of diagnosis, appropriate risk stratification helps to accurately identify patients who may be candidates for advanced therapeutic interventions. While systemic thrombolytics (ST) is the mostly commonly utilized intervention for high-risk PE, the risk profile of ST for intermediate-risk PE limits its use. Assessment of an individualized patient risk profile, often via a multidisciplinary pulmonary response team (PERT) model, there are various interventional strategies to consider for PE management. Novel therapeutic options include catheter-directed thrombolysis, catheter-based embolectomy, or mechanical circulatory support for certain high-risk PE patients. Current data has established safety and efficacy for catheter-based treatment of PE based on surrogate outcome measures. However, there is limited long-term data or prospective comparisons between treatment modalities and ST. While PE diagnosis has improved with modern cross-sectional imaging, there is interest in improved diagnostic models for PE that incorporate artificial intelligence and machine learning techniques.              Summary:                    In patients with acute pulmonary embolism, after appropriate risk stratification, some intermediate and high-risk patients should be considered for interventional-based treatment for PE."
33041533,5.0,Applications of artificial intelligence in battling against covid-19: A literature review,2021 Jan;142:110338.,"Colloquially known as coronavirus, the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2), that causes CoronaVirus Disease 2019 (COVID-19), has become a matter of grave concern for every country around the world. The rapid growth of the pandemic has wreaked havoc and prompted the need for immediate reactions to curb the effects. To manage the problems, many research in a variety of area of science have started studying the issue. Artificial Intelligence is among the area of science that has found great applications in tackling the problem in many aspects. Here, we perform an overview on the applications of AI in a variety of fields including diagnosis of the disease via different types of tests and symptoms, monitoring patients, identifying severity of a patient, processing covid-19 related imaging tests, epidemiology, pharmaceutical studies, etc. The aim of this paper is to perform a comprehensive survey on the applications of AI in battling against the difficulties the outbreak has caused. Thus we cover every way that AI approaches have been employed and to cover all the research until the writing of this paper. We try organize the works in a way that overall picture is comprehensible. Such a picture, although full of details, is very helpful in understand where AI sits in current pandemonium. We also tried to conclude the paper with ideas on how the problems can be tackled in a better way and provide some suggestions for future works."
33040399,3.0,Digital cardiovascular care in COVID-19 pandemic: A potential alternative?,2020 Dec;35(12):3545-3550.,"Background:                    Cardiovascular patients are at increased risk of acquiring coronavirus disease 2019 (COVID-19) infection while their visit to healthcare facilities. There is a need for alternative tools for optimal monitoring and management of cardiovascular patients in the present pandemic situation. Digital health care may prove to be a new revolutionary tool to protect cardiovascular patients from coronavirus disease by avoiding routine visits to health care facilities that are already overwhelmed with COVID-19 patients.              Methods:                    To evaluate the role of digital health care in the present era of the COVID-19 pandemic, we have reviewed the published literature on digital health services providing cardiovascular care.              Results and conclusion:                    Digital health including telemedicine services, robotic telemedicine carts, use of artificial intelligence and machine learning, use of digital gadgets like smartwatches and web-based applications may be a safe alternative for the management of cardiovascular patients in the present pandemic situation."
33039573,,Ensemble learning models that predict surface protein abundance from single-cell multimodal omics data,2021 May;189:65-73.,"Single-cell protein abundance is a fundamental type of information to characterize cell states. Due to high cost and technical barriers, however, direct quantification of proteins is difficult. Single-cell RNA sequencing (scRNA-seq) data, serving as a cost-effective substitute of single-cell proteomics, may not accurately reflect protein expression levels due to measurement error, noise, post-transcriptional and translational regulation, etc. The recently emerging single-cell multimodal omics data, e.g. CITE-seq and REAP-seq, can simultaneously profile RNA and protein abundances in single cells, providing labeled data for predictive modeling in a supervised learning framework. Deep neural network-based transfer learning method has been applied to imputation of surface protein abundances from single-cell transcriptomic data. However, it is unclear if the artificial neural network is the best model, and it is desirable to improve the prediction performance (e.g. accuracy, interpretability) of machine learning models. In this paper, we compared several tree-based ensemble learning methods with neural network models, and found that ensemble learning often performed better than neural network, and Random Forest (RF) performed the best overall. Moreover, we used the feature importance scores from RF to interpret biological mechanisms underlying the prediction. Our study demonstrates the effectiveness of ensemble learning for reliable protein abundances prediction using single-cell multimodal omics data, and paves the way for knowledge discovery by mining single-cell multi-omics data in large scale."
33039428,1.0,The role of computational methods for automating and improving clinical target volume definition,2020 Dec;153:15-25.,"Treatment planning in radiotherapy distinguishes three target volume concepts: the gross tumor volume (GTV), the clinical target volume (CTV), and the planning target volume (PTV). Over time, GTV definition and PTV margins have improved through the development of novel imaging techniques and better image guidance, respectively. CTV definition is sometimes considered the weakest element in the planning process. CTV definition is particularly complex since the extension of microscopic disease cannot be seen using currently available in-vivo imaging techniques. Instead, CTV definition has to incorporate knowledge of the patterns of tumor progression. While CTV delineation has largely been considered the domain of radiation oncologists, this paper, arising from a 2019 ESTRO Physics research workshop, discusses the contributions that medical physics and computer science can make by developing computational methods to support CTV definition. First, we overview the role of image segmentation algorithms, which may in part automate CTV delineation through segmentation of lymph node stations or normal tissues representing anatomical boundaries of microscopic tumor progression. The recent success of deep convolutional neural networks has also enabled learning entire CTV delineations from examples. Second, we discuss the use of mathematical models of tumor progression for CTV definition, using as example the application of glioma growth models to facilitate GTV-to-CTV expansion for glioblastoma that is consistent with neuroanatomy. We further consider statistical machine learning models to quantify lymphatic metastatic progression of tumors, which may eventually improve elective CTV definition. Lastly, we discuss approaches to incorporate uncertainty in CTV definition into treatment plan optimization as well as general limitations of the CTV concept in the case of infiltrating tumors without natural boundaries."
33039027,,Commentary on a combined approach to the problem of developing biomarkers for the prediction of spontaneous preterm labor that leads to preterm birth,2020 Sep 1;98:13-23.,"Introduction:                    Globally, preterm birth has replaced congenital malformation as the major cause of perinatal mortality and morbidity. The reduced rate of congenital malformation was not achieved through a single biophysical or biochemical marker at a specific gestational age, but rather through a combination of clinical, biophysical and biochemical markers at different gestational ages. Since the aetiology of spontaneous preterm birth is also multifactorial, it is unlikely that a single biomarker test, at a specific gestational age will emerge as the definitive predictive test.              Methods:                    The Biomarkers Group of PREBIC, comprising clinicians, basic scientists and other experts in the field, with a particular interest in preterm birth have produced this commentary with short, medium and long-term aims: i) to alert clinicians to the advances that are being made in the prediction of spontaneous preterm birth; ii) to encourage clinicians and scientists to continue their efforts in this field, and not to be disheartened or nihilistic because of a perceived lack of progress and iii) to enable development of novel interventions that can reduce the mortality and morbidity associated with preterm birth.              Results:                    Using language that we hope is clear to practising clinicians, we have identified 11 Sections in which there exists the potential, feasibility and capability of technologies for candidate biomarkers in the prediction of spontaneous preterm birth and how current limitations to this research might be circumvented.              Discussion:                    The combination of biophysical, biochemical, immunological, microbiological, fetal cell, exosomal, or cell free RNA at different gestational ages, integrated as part of a multivariable predictor model may be necessary to advance our attempts to predict sPTL and PTB. This will require systems biological data using ""omics"" data and artificial intelligence/machine learning to manage the data appropriately. The ultimate goal is to reduce the mortality and morbidity associated with preterm birth."
33039003,1.0,Overview of Machine Learning Part 1: Fundamentals and Classic Approaches,2020 Nov;30(4):e17-e32.,The extensive body of research and advances in machine learning (ML) and the availability of a large volume of patient data make ML a powerful tool for producing models with the potential for widespread deployment in clinical settings. This article provides an overview of the classic supervised and unsupervised ML methods as well as fundamental concepts required for understanding how to develop generalizable and high-performing ML applications. It also describes the important steps for developing a ML model and how decisions made in these steps affect model performance and ability to generalize.
33039002,,"Artificial Intelligence Applications for Workflow, Process Optimization and Predictive Analytics",2020 Nov;30(4):e1-e15.,"There is great potential for artificial intelligence (AI) applications, especially machine learning and natural language processing, in medical imaging. Much attention has been garnered by the image analysis tasks for diagnostic decision support and precision medicine, but there are many other potential applications of AI in radiology and have potential to enhance all levels of the radiology workflow and practice, including workflow optimization and support for interpretation tasks, quality and safety, and operational efficiency. This article reviews the important potential applications of informatics and AI related to process improvement and operations in the radiology department."
33039001,,Machine Learning Applications for Head and Neck Imaging,2020 Nov;30(4):517-529.,The head and neck (HN) consists of a large number of vital anatomic structures within a compact area. Imaging plays a central role in the diagnosis and management of major disorders affecting the HN. This article reviews the recent applications of machine learning (ML) in HN imaging with a focus on deep learning approaches. It categorizes ML applications in HN imaging into deep learning and traditional ML applications and provides examples of each category. It also discusses the main challenges facing the successful deployment of ML-based applications in the clinical setting and provides suggestions for addressing these challenges.
33038999,,Updates on Deep Learning and Glioma: Use of Convolutional Neural Networks to Image Glioma Heterogeneity,2020 Nov;30(4):493-503.,"Deep learning represents end-to-end machine learning in which feature selection from images and classification happen concurrently. This articles provides updates on how deep learning is being applied to the study of glioma and its genetic heterogeneity. Deep learning algorithms can detect patterns in routine and advanced MR imaging that elude the eyes of neuroradiologists and make predictions about glioma genetics, which impact diagnosis, treatment response, patient management, and long-term survival. The success of these deep learning initiatives may enhance the performance of neuroradiologists and add greater value to patient care by expediting treatment."
33038998,,Artificial Intelligence and Stroke Imaging: A West Coast Perspective,2020 Nov;30(4):479-492.,"Artificial intelligence (AI) advancements have significant implications for medical imaging. Stroke is the leading cause of disability and the fifth leading cause of death in the United States. AI applications for stroke imaging are a topic of intense research. AI techniques are well-suited for dealing with vast amounts of stroke imaging data and a large number of multidisciplinary approaches used in classification, risk assessment, segmentation tasks, diagnosis, prognosis, and even prediction of therapy responses. This article addresses this topic and seeks to present an overview of machine learning and/or deep learning applied to stroke imaging."
33038997,,An East Coast Perspective on Artificial Intelligence and Machine Learning: Part 2: Ischemic Stroke Imaging and Triage,2020 Nov;30(4):467-478.,"Acute ischemic stroke constitutes approximately 85% of strokes. Most strokes occur in community settings; thus, automatic algorithms techniques are attractive for managing these cases. This article reviews the use of deep learning convolutional neural networks in the management of ischemic stroke. Artificial intelligence-based algorithms may be used in patient triage to detect and sound the alarm based on early imaging, alert care teams, and assist in treatment selection. This article reviews algorithms for artificial intelligence techniques that may be used to detect and localize acute ischemic stroke. We describe artificial intelligence algorithms for these tasks and illustrate them with examples."
33038996,,An East Coast Perspective on Artificial Intelligence and Machine Learning: Part 1: Hemorrhagic Stroke Imaging and Triage,2020 Nov;30(4):459-466.,"Hemorrhagic stroke is a medical emergency. Artificial intelligence techniques and algorithms may be used to automatically detect and quantitate intracranial hemorrhage in a semiautomated fashion. This article reviews the use of deep learning convolutional neural networks for managing hemorrhagic stroke. Such a capability may be used to alert appropriate care teams, make decisions about patient transport from a primary care center to a comprehensive stroke center, and assist in treatment selection. This article reviews artificial intelligence algorithms for intracranial hemorrhage detection, quantification, and prognostication. Multiple algorithms currently being explored are described and illustrated with the help of examples."
33038995,,Review of Natural Language Processing in Radiology,2020 Nov;30(4):447-458.,"Natural language processing (NLP) is an interdisciplinary field, combining linguistics, computer science, and artificial intelligence to enable machines to read and understand human language for meaningful purposes. Recent advancements in deep learning have begun to offer significant improvements in NLP task performance. These techniques have the potential to create new automated tools that could improve clinical workflows and unlock unstructured textual information contained in radiology and clinical reports for the development of radiology and clinical artificial intelligence applications. These applications will combine the appropriate application of classic linguistic and NLP preprocessing techniques, modern NLP techniques, and modern deep learning techniques."
33038994,,Machine Learning Algorithm Validation: From Essentials to Advanced Applications and Implications for Regulatory Certification and Deployment,2020 Nov;30(4):433-445.,"The deployment of machine learning (ML) models in the health care domain can increase the speed and accuracy of diagnosis and improve treatment planning and patient care. Translating academic research to applications that are deployable in clinical settings requires the ability to generalize and high reproducibility, which are contingent on a rigorous and sound methodology for the development and evaluation of ML models. This article describes the fundamental concepts and processes for ML model evaluation and highlights common workflows. It concludes with a discussion of the requirements for the deployment of ML models in clinical settings."
33038993,,Overview of Machine Learning: Part 2: Deep Learning for Medical Image Analysis,2020 Nov;30(4):417-431.,"Deep learning has contributed to solving complex problems in science and engineering. This article provides the fundamental background required to understand and develop deep learning models for medical imaging applications. The authors review the main deep learning architectures such as multilayer perceptron, convolutional neural networks, autoencoders, recurrent neural networks, and generative adversarial neural networks. They also discuss the strategies for training deep learning models when the available datasets are imbalanced or of limited size and conclude with a discussion of the obstacles and challenges hindering the deployment of deep learning solutions in clinical settings."
33038992,,Knowledge Based Versus Data Based: A Historical Perspective on a Continuum of Methodologies for Medical Image Analysis,2020 Nov;30(4):401-415.,"The advent of big data and deep learning algorithms has promoted a major shift toward data-driven methods in medical image analysis recently. However, the medical image analysis field has a long and rich history inclusive of both knowledge-driven and data-driven methodologies. In the present article, we provide a historical review of an illustrative sample of medical image analysis methods and locate them along a knowledge-driven versus data-driven continuum. In doing so, we highlight the historical importance as well as current-day relevance of more traditional, knowledge-based artificial intelligence approaches and their complementarity with fully data-driven techniques such as deep learning."
33038991,,Brief History of Artificial Intelligence,2020 Nov;30(4):393-399.,"This article reviews the history of artificial intelligence and introduces the reader to major events that prompted interest in the field, as well as pitfalls and challenges that have slowed its development. The purpose of this article is to provide a high-level historical perspective on the development of the field over the past decades, highlighting the potential of the field for transforming health care, but also the importance of setting realistic expectations for artificial intelligence applications to avoid repeating historical cyclical trends and a third ""artificial intelligence winter."""
33038981,1.0,"Acute myeloid leukemia and artificial intelligence, algorithms and new scores",2020 Sep;33(3):101192.,"Artificial intelligence, and more narrowly machine-learning, is beginning to expand humanity's capacity to analyze increasingly large and complex datasets. Advances in computer hardware and software have led to breakthroughs in multiple sectors of our society, including a burgeoning role in medical research and clinical practice. As the volume of medical data grows at an apparently exponential rate, particularly since the human genome project laid the foundation for modern genetic inquiry, informatics tools like machine learning are becoming crucial in analyzing these data to provide meaningful tools for diagnostic, prognostic, and therapeutic purposes. Within medicine, hematologic diseases can be particularly challenging to understand and treat given the increasingly complex and intercalated genetic, epigenetic, immunologic, and regulatory pathways that must be understood to optimize patient outcomes. In acute myeloid leukemia (AML), new developments in machine learning algorithms have enabled a deeper understanding of disease biology and the development of better prognostic and predictive tools. Ongoing work in the field brings these developments incrementally closer to clinical implementation."
33037949,,Machine Learning in Electrocardiography and Echocardiography: Technological Advances in Clinical Cardiology,2020 Oct 10;22(12):161.,"Purpose of review:                    Electrocardiography (ECG) and echocardiography are the most widely used diagnostic tools in clinical cardiology. This review focuses on recent advancements in applying machine learning (ML) in ECG and echocardiography and potential synergistic ML integration of ECG and echocardiography.              Recent findings:                    ML algorithms have been used in ECG for technical quality assurance, arrhythmia identification, and prognostic predictions, and in echocardiography to recognize image views, quantify measurements, and identify pathologic patterns. Synergistic application of ML in ECG and echocardiograph has demonstrated the potential to optimize therapeutic response, improve risk stratification, and generate new disease classification. There is mounting evidence that ML potentially outperforms in disease diagnoses and outcome prediction with ECG and echocardiography when compared with trained healthcare professionals. The applications of ML in ECG and echocardiography are playing increasingly greater roles in medical research and clinical practice, particularly for their contributions to developing novel diagnostic/prognostic prediction models. The automation in data acquisition, processing, and interpretation help streamline the workflows of ECG and echocardiography in contemporary cardiology practice."
33037325,2.0,Integration of novel monitoring devices with machine learning technology for scalable cardiovascular management,2021 Feb;18(2):75-91.,"Ambulatory monitoring is increasingly important for cardiovascular care but is often limited by the unpredictability of cardiovascular events, the intermittent nature of ambulatory monitors and the variable clinical significance of recorded data in patients. Technological advances in computing have led to the introduction of novel physiological biosignals that can increase the frequency at which abnormalities in cardiovascular parameters can be detected, making expert-level, automated diagnosis a reality. However, use of these biosignals for diagnosis also raises numerous concerns related to accuracy and actionability within clinical guidelines, in addition to medico-legal and ethical issues. Analytical methods such as machine learning can potentially increase the accuracy and improve the actionability of device-based diagnoses. Coupled with interoperability of data to widen access to all stakeholders, seamless connectivity (an internet of things) and maintenance of anonymity, this approach could ultimately facilitate near-real-time diagnosis and therapy. These tools are increasingly recognized by regulatory agencies and professional medical societies, but several technical and ethical issues remain. In this Review, we describe the current state of cardiovascular monitoring along the continuum from biosignal acquisition to the identification of novel biosensors and the development of analytical techniques and ultimately to regulatory and ethical issues. Furthermore, we outline new paradigms for cardiovascular monitoring."
33035522,4.0,I tried a bunch of things: The dangers of unexpected overfitting in classification of brain data,2020 Dec;119:456-467.,"Machine learning has enhanced the abilities of neuroscientists to interpret information collected through EEG, fMRI, and MEG data. With these powerful techniques comes the danger of overfitting of hyperparameters which can render results invalid. We refer to this problem as 'overhyping' and show that it is pernicious despite commonly used precautions. Overhyping occurs when analysis decisions are made after observing analysis outcomes and can produce results that are partially or even completely spurious. It is commonly assumed that cross-validation is an effective protection against overfitting or overhyping, but this is not actually true. In this article, we show that spurious results can be obtained on random data by modifying hyperparameters in seemingly innocuous ways, despite the use of cross-validation. We recommend a number of techniques for limiting overhyping, such as lock boxes, blind analyses, pre-registrations, and nested cross-validation. These techniques, are common in other fields that use machine learning, including computer science and physics. Adopting similar safeguards is critical for ensuring the robustness of machine-learning techniques in the neurosciences."
33034769,5.0,"Application of deep learning in detecting neurological disorders from magnetic resonance images: a survey on the detection of Alzheimer's disease, Parkinson's disease and schizophrenia",2020 Oct 9;7(1):11.,"Neuroimaging, in particular magnetic resonance imaging (MRI), has been playing an important role in understanding brain functionalities and its disorders during the last couple of decades. These cutting-edge MRI scans, supported by high-performance computational tools and novel ML techniques, have opened up possibilities to unprecedentedly identify neurological disorders. However, similarities in disease phenotypes make it very difficult to detect such disorders accurately from the acquired neuroimaging data. This article critically examines and compares performances of the existing deep learning (DL)-based methods to detect neurological disorders-focusing on Alzheimer's disease, Parkinson's disease and schizophrenia-from MRI data acquired using different modalities including functional and structural MRI. The comparative performance analysis of various DL architectures across different disorders and imaging modalities suggests that the Convolutional Neural Network outperforms other methods in detecting neurological disorders. Towards the end, a number of current research challenges are indicated and some possible future research directions are provided."
33033576,1.0,Mitochondria under the spotlight: On the implications of mitochondrial dysfunction and its connectivity to neuropsychiatric disorders,2020 Sep 14;18:2535-2546.,"Neuropsychiatric disorders (NPDs) such as bipolar disorder (BD), schizophrenia (SZ) and mood disorder (MD) are hard to manage due to overlapping symptoms and lack of biomarkers. Risk alleles of BD/SZ/MD are emerging, with evidence suggesting mitochondrial (mt) dysfunction as a critical factor for disease onset and progression. Mood stabilizing treatments for these disorders are scarce, revealing the need for biomarker discovery and artificial intelligence approaches to design synthetically accessible novel therapeutics. Here, we show mt involvement in NPDs by associating 245 mt proteins to BD/SZ/MD, with 7 common players in these disease categories. Analysis of over 650 publications suggests that 245 NPD-linked mt proteins are associated with 800 other mt proteins, with mt impairment likely to rewire these interactions. High dosage of mood stabilizers is known to alleviate manic episodes, but which compounds target mt pathways is another gap in the field that we address through mood stabilizer-gene interaction analysis of 37 prescriptions and over-the-counter psychotropic treatments, which we have refined to 15 mood-stabilizing agents. We show 26 of the 245 NPD-linked mt proteins are uniquely or commonly targeted by one or more of these mood stabilizers. Further, induced pluripotent stem cell-derived patient neurons and three-dimensional human brain organoids as reliable BD/SZ/MD models are outlined, along with multiomics methods and machine learning-based decision making tools for biomarker discovery, which remains a bottleneck for precision psychiatry medicine."
33029222,,"Recent advances and future directions for uterine diseases diagnosis, pathogenesis, and management in dairy cows",2020 Aug 11;17(3):e20200063.,"Researchers, veterinarians, and farmers' pursuit of a consistent diagnosis, treatment, and prevention of uterine diseases remains challenging. The diagnosis and treatment of metritis is inconsistent, a concerning situation when considered the global threat of antimicrobial resistance dissemination. Endometritis is an insidious disease absent on routine health programs in many dairy farms and from pharmaceutical therapeutics arsenal in places like the US market. Conversely, a multitude of studies advanced the understanding of how uterine diseases compromise oocyte, follicle, and embryo development, and the uterine environment having long-lasting effects on fertility. The field of uterine disease microbiome also experienced tremendous progress and created opportunities for the development of novel preventives to improve the management of uterine diseases. Activity monitors, biomarkers, genomic selection, and machine learning predictive models are other innovative developments that have been explored in recent years to help mitigate the negative impacts of uterine diseases. Albeit novel tools such as vaccines for metritis, immune modulators, probiotics, genomic selection, and selective antimicrobial therapy are promising, further research is warranted to implement these technologies in a systematic and cost-effective manner."
33028042,1.0,Motion Capture Technology in Industrial Applications: A Systematic Review,2020 Oct 5;20(19):5687.,"The rapid technological advancements of Industry 4.0 have opened up new vectors for novel industrial processes that require advanced sensing solutions for their realization. Motion capture (MoCap) sensors, such as visual cameras and inertial measurement units (IMUs), are frequently adopted in industrial settings to support solutions in robotics, additive manufacturing, teleworking and human safety. This review synthesizes and evaluates studies investigating the use of MoCap technologies in industry-related research. A search was performed in the Embase, Scopus, Web of Science and Google Scholar. Only studies in English, from 2015 onwards, on primary and secondary industrial applications were considered. The quality of the articles was appraised with the AXIS tool. Studies were categorized based on type of used sensors, beneficiary industry sector, and type of application. Study characteristics, key methods and findings were also summarized. In total, 1682 records were identified, and 59 were included in this review. Twenty-one and 38 studies were assessed as being prone to medium and low risks of bias, respectively. Camera-based sensors and IMUs were used in 40% and 70% of the studies, respectively. Construction (30.5%), robotics (15.3%) and automotive (10.2%) were the most researched industry sectors, whilst health and safety (64.4%) and the improvement of industrial processes or products (17%) were the most targeted applications. Inertial sensors were the first choice for industrial MoCap applications. Camera-based MoCap systems performed better in robotic applications, but camera obstructions caused by workers and machinery was the most challenging issue. Advancements in machine learning algorithms have been shown to increase the capabilities of MoCap systems in applications such as activity and fatigue detection as well as tool condition monitoring and object recognition."
33027147,,Artificial intelligence to guide management of acute kidney injury in the ICU: a narrative review,2020 Dec;26(6):563-573.,"Purpose of review:                    Acute kidney injury (AKI) frequently complicates hospital admission, especially in the ICU or after major surgery, and is associated with high morbidity and mortality. The risk of developing AKI depends on the presence of preexisting comorbidities and the cause of the current disease. Besides, many other parameters affect the kidney function, such as the state of other vital organs, the host response, and the initiated treatment. Advancements in the field of informatics have led to the opportunity to store and utilize the patient-related data to train and validate models to detect specific patterns and, as such, predict disease states or outcomes.              Recent findings:                    Machine-learning techniques have also been applied to predict AKI, as well as the patients' outcomes related to their AKI, such as mortality or the need for kidney replacement therapy. Several models have recently been developed, but only a few of them have been validated in external cohorts.              Summary:                    In this article, we provide an overview of the machine-learning prediction models for AKI and its outcomes in critically ill patients and individuals undergoing major surgery. We also discuss the pitfalls and the opportunities related to the implementation of these models in clinical practices."
33024393,1.0,Artificial intelligence in gastric cancer: Application and future perspectives,2020 Sep 28;26(36):5408-5419.,"Gastric cancer is the fourth leading cause of cancer-related mortality across the globe, with a 5-year survival rate of less than 40%. In recent years, several applications of artificial intelligence (AI) have emerged in the gastric cancer field based on its efficient computational power and learning capacities, such as image-based diagnosis and prognosis prediction. AI-assisted diagnosis includes pathology, endoscopy, and computerized tomography, while researchers in the prognosis circle focus on recurrence, metastasis, and survival prediction. In this review, a comprehensive literature search was performed on articles published up to April 2020 from the databases of PubMed, Embase, Web of Science, and the Cochrane Library. Thereby the current status of AI-applications was systematically summarized in gastric cancer. Moreover, future directions that target this field were also analyzed to overcome the risk of overfitting AI models and enhance their accuracy as well as the applicability in clinical practice."
33022947,,"Bone Age Assessment Empowered with Deep Learning: A Survey, Open Research Challenges and Future Directions",2020 Oct 3;10(10):781.,"Deep learning is a quite useful and proliferating technique of machine learning. Various applications, such as medical images analysis, medical images processing, text understanding, and speech recognition, have been using deep learning, and it has been providing rather promising results. Both supervised and unsupervised approaches are being used to extract and learn features as well as for the multi-level representation of pattern recognition and classification. Hence, the way of prediction, recognition, and diagnosis in various domains of healthcare including the abdomen, lung cancer, brain tumor, skeletal bone age assessment, and so on, have been transformed and improved significantly by deep learning. By considering a wide range of deep-learning applications, the main aim of this paper is to present a detailed survey on emerging research of deep-learning models for bone age assessment (e.g., segmentation, prediction, and classification). An enormous number of scientific research publications related to bone age assessment using deep learning are explored, studied, and presented in this survey. Furthermore, the emerging trends of this research domain have been analyzed and discussed. Finally, a critical discussion section on the limitations of deep-learning models has been presented. Open research challenges and future directions in this promising area have been included as well."
33022628,2.0,Electronic skins and machine learning for intelligent soft robots,2020 Apr 22;5(41):eaaz9239.,"Soft robots have garnered interest for real-world applications because of their intrinsic safety embedded at the material level. These robots use deformable materials capable of shape and behavioral changes and allow conformable physical contact for manipulation. Yet, with the introduction of soft and stretchable materials to robotic systems comes a myriad of challenges for sensor integration, including multimodal sensing capable of stretching, embedment of high-resolution but large-area sensor arrays, and sensor fusion with an increasing volume of data. This Review explores the emerging confluence of e-skins and machine learning, with a focus on how roboticists can combine recent developments from the two fields to build autonomous, deployable soft robots, integrated with capabilities for informative touch and proprioception to stand up to the challenges of real-world environments."
33019765,2.0,Review of the State of the Art of Deep Learning for Plant Diseases: A Broad Analysis and Discussion,2020 Oct 1;9(10):1302.,"Deep learning (DL) represents the golden era in the machine learning (ML) domain, and it has gradually become the leading approach in many fields. It is currently playing a vital role in the early detection and classification of plant diseases. The use of ML techniques in this field is viewed as having brought considerable improvement in cultivation productivity sectors, particularly with the recent emergence of DL, which seems to have increased accuracy levels. Recently, many DL architectures have been implemented accompanying visualisation techniques that are essential for determining symptoms and classifying plant diseases. This review investigates and analyses the most recent methods, developed over three years leading up to 2020, for training, augmentation, feature fusion and extraction, recognising and counting crops, and detecting plant diseases, including how these methods can be harnessed to feed deep classifiers and their effects on classifier accuracy."
33015372,11.0,The future of digital health with federated learning,2020 Sep 14;3:119.,"Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing medical data is not fully exploited by ML primarily because it sits in data silos and privacy concerns restrict access to this data. However, without access to sufficient data, ML will be prevented from reaching its full potential and, ultimately, from making the transition from research to clinical practice. This paper considers key factors contributing to this issue, explores how federated learning (FL) may provide a solution for the future of digital health and highlights the challenges and considerations that need to be addressed."
33015010,,Review on the Application of Machine Learning Algorithms in the Sequence Data Mining of DNA,2020 Sep 4;8:1032.,"Deoxyribonucleic acid (DNA) is a biological macromolecule. Its main function is information storage. At present, the advancement of sequencing technology had caused DNA sequence data to grow at an explosive rate, which has also pushed the study of DNA sequences in the wave of big data. Moreover, machine learning is a powerful technique for analyzing largescale data and learns spontaneously to gain knowledge. It has been widely used in DNA sequence data analysis and obtained a lot of research achievements. Firstly, the review introduces the development process of sequencing technology, expounds on the concept of DNA sequence data structure and sequence similarity. Then we analyze the basic process of data mining, summary several major machine learning algorithms, and put forward the challenges faced by machine learning algorithms in the mining of biological sequence data and possible solutions in the future. Then we review four typical applications of machine learning in DNA sequence data: DNA sequence alignment, DNA sequence classification, DNA sequence clustering, and DNA pattern mining. We analyze their corresponding biological application background and significance, and systematically summarized the development and potential problems in the field of DNA sequence data mining in recent years. Finally, we summarize the content of the review and look into the future of some research directions for the next step."
33014031,3.0,EEG-Based Emotion Recognition: A State-of-the-Art Review of Current Trends and Opportunities,2020 Sep 16;2020:8875426.,"Emotions are fundamental for human beings and play an important role in human cognition. Emotion is commonly associated with logical decision making, perception, human interaction, and to a certain extent, human intelligence itself. With the growing interest of the research community towards establishing some meaningful ""emotional"" interactions between humans and computers, the need for reliable and deployable solutions for the identification of human emotional states is required. Recent developments in using electroencephalography (EEG) for emotion recognition have garnered strong interest from the research community as the latest developments in consumer-grade wearable EEG solutions can provide a cheap, portable, and simple solution for identifying emotions. Since the last comprehensive review was conducted back from the years 2009 to 2016, this paper will update on the current progress of emotion recognition using EEG signals from 2016 to 2019. The focus on this state-of-the-art review focuses on the elements of emotion stimuli type and presentation approach, study size, EEG hardware, machine learning classifiers, and classification approach. From this state-of-the-art review, we suggest several future research opportunities including proposing a different approach in presenting the stimuli in the form of virtual reality (VR). To this end, an additional section devoted specifically to reviewing only VR studies within this research domain is presented as the motivation for this proposed new approach using VR as the stimuli presentation device. This review paper is intended to be useful for the research community working on emotion recognition using EEG signals as well as for those who are venturing into this field of research."
33013638,,Intracranial Pressure Monitoring Signals After Traumatic Brain Injury: A Narrative Overview and Conceptual Data Science Framework,2020 Aug 28;11:959.,"Continuous intracranial pressure (ICP) monitoring is a cornerstone of neurocritical care after severe brain injuries such as traumatic brain injury and acts as a biomarker of secondary brain injury. With the rapid development of artificial intelligent (AI) approaches to data analysis, the acquisition, storage, real-time analysis, and interpretation of physiological signal data can bring insights to the field of neurocritical care bioinformatics. We review the existing literature on the quantification and analysis of the ICP waveform and present an integrated framework to incorporate signal processing tools, advanced statistical methods, and machine learning techniques in order to comprehensively understand the ICP signal and its clinical importance. Our goals were to identify the strengths and pitfalls of existing methods for data cleaning, information extraction, and application. In particular, we describe the use of ICP signal analytics to detect intracranial hypertension and to predict both short-term intracranial hypertension and long-term clinical outcome. We provide a well-organized roadmap for future researchers based on existing literature and a computational approach to clinically-relevant biomedical signal data."
33012648,,Effectiveness of Radiofrequency Ablation in the Treatment of Painful Osseous Metastases: A Correlation Meta-Analysis with Machine Learning Cluster Identification,2020 Nov;31(11):1753-1762.,"A systematic review and meta-analysis of pain response after radiofrequency (RF) ablation over time for osseous metastases was conducted in 2019. Analysis used a random-effects model with GOSH plots and meta-regression. Fourteen studies comprising 426 patients, most with recalcitrant pain, were identified. Median pain reduction after RF ablation was 67% over median follow-up of 24 weeks (R2 = -.66, 95% confidence interval -0.76 to -0.55, I2 = 71.24%, fail-safe N = 875) with 44% pain reduction within 1 week. A low-heterogeneity subgroup was identified with median pain reduction after RF ablation of 70% over 12 weeks (R2 = -.75, 95% confidence interval -0.80 to -0.70, I2 = 2.66%, fail-safe N = 910). Addition of cementoplasty after RF ablation did not significantly affect pain scores. Primary tumor type and tumor size did not significantly affect pain scores. A particular, positive association between pain after RF ablation and axial tumors was identified, implying possible increased palliative effects for RF ablation on axial over appendicular lesions. RF ablation is a useful palliative therapy for osseous metastases, particularly in patients with recalcitrant pain."
33010852,,The 21st Annual Feigenbaum Lecture: Beyond Artificial: Echocardiography from Elegant Images to Analytic Intelligence,2020 Oct;33(10):1163-1171.,"Echocardiography has always been a journey from scientific observation to clinical application. Whether in theranostics, understanding the performance of the systemic right ventricle, or uncovering the predictive power of echocardiographic data in congenital heart disease, the author's experiences highlight how echocardiographers at the frontier of scientific inquiry making observations today are inundated with data. It becomes apparent that new clinical applications, if they are to be successful, depend more than ever on effective management of the information we collect. In light of this realization, the 21st Feigenbaum lecture explores analytic intelligence-one path echocardiography might now take on its march from observation to application."
33010735,,Classification of the interictal state with hypsarrhythmia from Zika Virus Congenital Syndrome and of the ictal state from epilepsy in childhood without hypsarrhythmia in EEGs using entropy measures,2020 Nov;126:104014.,"This paper intends to classify the interictal state with hypsarrhythmia in patients with Zika Virus Congenital Syndrome (ZVCS) and of the ictal state in patients with epilepsy in childhood without the presence of hypsarrhythmia. Hypsarrhythmia is a specific interictal chaotic morphology, and the correct distinction between these two EEG states is crucial to improving the cognitive development of these epileptic patients. The proposed approach was assessed using the proprietary database of Casa Ninar, which contains data regarding children from northeastern Brazil born with microcephaly caused by the Zika virus. We also used data from the CHB-MIT database. Fundamental rhythms of the EEG signal δ, θ, α, and β were analyzed, and then decomposed by Discrete Wavelet Transform, in which 45 mother wavelet functions were tested to determine the most appropriate function to represent the EEG signals in the hypsarrhythmia interictal and ictal states. We extracted Shannon, Log Energy, Norm, and Sure entropy measures of the subbands as relevant features, and the combinations among them were applied in the state-of-the-art machine learning methods. The combination of Sure entropy with Shannon entropy, or with Log Energy and Norm, extracted from the δ rhythm, allowed for the best linear separability between the classes in most of the classifiers, obtaining 100% accuracy, sensitivity, and specificity."
33009150,,VR and machine learning: novel pathways in surgical hands-on training,2020 Nov;30(6):817-822.,"Purpose of review:                    Surgical training has dramatically changed over the last decade. It has become not only the way to prepare surgeons for their everyday work, but also a way to certify their skills thus increasing patient safety. This article reviews advances in the use of machine learning and artificial intelligence applied to virtual reality based surgical training over the last 5 years.              Recent findings:                    Eight articles have been published which met the inclusion criteria. This included six articles about the use of machine learning and artificial intelligence for assessment purposes and two articles about the possibility of teaching applications, including one review and one original research article. All the research articles pointed out the importance of machine learning and artificial intelligence for the stratification of trainees, based on their performance on basic tasks or procedures simulated in a virtual reality environment.              Summary:                    Machine learning and artificial intelligence are designed to analyse data and use them to take decisions that typically require human intelligence. Evidence in literature is still scarce about this technology applied to virtual reality and existing manuscripts are mainly focused on its potential to stratify surgical performance and provide synthetic feedbacks about it. In consideration of the exponential growth of computer calculation capabilities, it is possible to expect a parallel increase of research about this topic within the next few years."
33006800,,Metabolic stability studies of lead compounds supported by separation techniques and chemometrics analysis,2021 Jan;44(1):373-386.,"With metabolism being one of the main routes of drug elimination from the body (accounting for removal of around 75% of known drugs), it is crucial to understand and study metabolic stability of drug candidates. Metabolically unstable compounds are uncomfortable to administer (requiring repetitive dosage during therapy), while overly stable drugs increase risk of adverse drug reactions. Additionally, biotransformation reactions can lead to formation of toxic or pharmacologically active metabolites (either less-active than parent drug, or even with different action). There were numerous approaches in estimating metabolic stability, including in vitro, in vivo, in silico, and high-throughput screening to name a few. This review aims at describing separation techniques used in in vitro metabolic stability estimation, as well as chemometric techniques allowing for creation of predictive models which enable high-throughput screening approach for estimation of metabolic stability. With a very low rate of drug approval, it is important to understand in silico methods that aim at supporting classical in vitro approach. Predictive models that allow assessment of certain biological properties of drug candidates allow for cutting not only cost, but also time required to synthesize compounds predicted to be unstable or inactive by in silico models."
33006667,,Recent advances on the machine learning methods in predicting ncRNA-protein interactions,2021 Mar;296(2):243-258.,"Recent transcriptomics and bioinformatics studies have shown that ncRNAs can affect chromosome structure and gene transcription, participate in the epigenetic regulation, and take part in diseases such as tumorigenesis. Biologists have found that most ncRNAs usually work by interacting with the corresponding RNA-binding proteins. Therefore, ncRNA-protein interaction is a very popular study in both the biological and medical fields. However, due to the limitations of manual experiments in the laboratory, machine-learning methods for predicting ncRNA-protein interactions are increasingly favored by the researchers. In this review, we summarize several machine learning predictive models of ncRNA-protein interactions over the past few years, and briefly describe the characteristics of these machine learning models. In order to optimize the performance of machine learning models to better predict ncRNA-protein interactions, we give some promising future computational directions at the end."
33006425,,Machine Learning in Meningioma MRI: Past to Present. A Narrative Review,2020 Oct 2.,"Meningioma is one of the most frequent primary central nervous system tumors. While magnetic resonance imaging (MRI), is the standard radiologic technique for provisional diagnosis and surveillance of meningioma, it nevertheless lacks the prima facie capacity in determining meningioma biological aggressiveness, growth, and recurrence potential. An increasing body of evidence highlights the potential of machine learning and radiomics in improving the consistency and productivity and in providing novel diagnostic, treatment, and prognostic modalities in neuroncology imaging. The aim of the present article is to review the evolution and progress of approaches utilizing machine learning in meningioma MRI-based sementation, diagnosis, grading, and prognosis. We provide a historical perspective on original research on meningioma spanning over two decades and highlight recent studies indicating the feasibility of pertinent approaches, including deep learning in addressing several clinically challenging aspects. We indicate the limitations of previous research designs and resources and propose future directions by highlighting areas of research that remain largely unexplored. LEVEL OF EVIDENCE: 5 TECHNICAL EFFICACY STAGE: 2."
33006018,,How to read and review papers on machine learning and artificial intelligence in radiology: a survival guide to key methodological concepts,2021 Apr;31(4):1819-1830.,"In recent years, there has been a dramatic increase in research papers about machine learning (ML) and artificial intelligence in radiology. With so many papers around, it is of paramount importance to make a proper scientific quality assessment as to their validity, reliability, effectiveness, and clinical applicability. Due to methodological complexity, the papers on ML in radiology are often hard to evaluate, requiring a good understanding of key methodological issues. In this review, we aimed to guide the radiology community about key methodological aspects of ML to improve their academic reading and peer-review experience. Key aspects of ML pipeline were presented within four broad categories: study design, data handling, modelling, and reporting. Sixteen key methodological items and related common pitfalls were reviewed with a fresh perspective: database size, robustness of reference standard, information leakage, feature scaling, reliability of features, high dimensionality, perturbations in feature selection, class balance, bias-variance trade-off, hyperparameter tuning, performance metrics, generalisability, clinical utility, comparison with traditional tools, data sharing, and transparent reporting.Key Points• Machine learning is new and rather complex for the radiology community.• Validity, reliability, effectiveness, and clinical applicability of studies on machine learning can be evaluated with a proper understanding of key methodological concepts about study design, data handling, modelling, and reporting.• Understanding key methodological concepts will provide a better academic reading and peer-review experience for the radiology community."
33005629,1.0,Systems Biology of Gastric Cancer: Perspectives on the Omics-Based Diagnosis and Treatment,2020 Aug 26;7:203.,"Gastric cancer is the fifth most diagnosed cancer in the world, affecting more than a million people and causing nearly 783,000 deaths each year. The prognosis of advanced gastric cancer remains extremely poor despite the use of surgery and adjuvant therapy. Therefore, understanding the mechanism of gastric cancer development, and the discovery of novel diagnostic biomarkers and therapeutics are major goals in gastric cancer research. Here, we review recent progress in application of omics technologies in gastric cancer research, with special focus on the utilization of systems biology approaches to integrate multi-omics data. In addition, the association between gastrointestinal microbiota and gastric cancer are discussed, which may offer insights in exploring the novel microbiota-targeted therapeutics. Finally, the application of data-driven systems biology and machine learning approaches could provide a predictive understanding of gastric cancer, and pave the way to the development of novel biomarkers and rational design of cancer therapeutics."
33004526,2.0,"Artificial intelligence in pulmonary medicine: computer vision, predictive model and COVID-19",2020 Oct 1;29(157):200181.,"Artificial intelligence (AI) is transforming healthcare delivery. The digital revolution in medicine and healthcare information is prompting a staggering growth of data intertwined with elements from many digital sources such as genomics, medical imaging and electronic health records. Such massive growth has sparked the development of an increasing number of AI-based applications that can be deployed in clinical practice. Pulmonary specialists who are familiar with the principles of AI and its applications will be empowered and prepared to seize future practice and research opportunities. The goal of this review is to provide pulmonary specialists and other readers with information pertinent to the use of AI in pulmonary medicine. First, we describe the concept of AI and some of the requisites of machine learning and deep learning. Next, we review some of the literature relevant to the use of computer vision in medical imaging, predictive modelling with machine learning, and the use of AI for battling the novel severe acute respiratory syndrome-coronavirus-2 pandemic. We close our review with a discussion of limitations and challenges pertaining to the further incorporation of AI into clinical pulmonary practice."
33000556,,Part 1: Artificial intelligence technology in surgery,2020 Dec;90(12):2409-2414.,"Artificial intelligence (AI) is one of the disruptive technologies of the fourth Industrial Revolution that is changing our work practices. This technology is in use in highly diverse industries including health care, defence, insurance and e-commerce. This review focuses on the relevance of AI to surgery. AI will aid surgeons with diagnostic decision-making, patient selection for surgery as well as improve patient pre- and post-operative care and management. Ethical considerations of AI with respect to patient rights and data privacy are highlighted. A further challenge is how best to present to national regulators a pragmatic way to assess AI as 'software as a medical device'. This relates to the ramifications for the adoption of AI technology in clinical practice, and its subsequent public funding support and reimbursement. It is evident that AI technology has important applications in surgery in the 21st century. The establishment of a key work programme in this area will be important if surgeons are to fully utilize AI in surgery."
33000054,,Predicting cardiac arrest in the emergency department,2020 Feb 3;1(4):321-326.,"In-hospital cardiac arrest remains a leading cause of death: roughly 300,000 in-hospital cardiac arrests occur each year in the United States, ≈10% of which occur in the emergency department. ED-based cardiac arrest may represent a subset of in-hospital cardiac arrest with a higher proportion of reversible etiologies and a higher potential for neurologically intact survival. Patients presenting to the ED have become increasingly complex, have a high burden of critical illness, and face crowded departments with thinly stretched resources. As a result, patients in the ED are vulnerable to unrecognized clinical deterioration that may lead to ED-based cardiac arrest. Efforts to identify patients who may progress to ED-based cardiac arrest have traditionally been approached through identification of critically ill patients at triage and the identification of patients who unexpectedly deteriorate during their stay in the ED. Interventions to facilitate appropriate triage and resource allocation, as well as earlier identification of patients at risk of deterioration in the ED, could potentially allow for both prevention of cardiac arrest and optimization of outcomes from ED-based cardiac arrest. This review will discuss the epidemiology of ED-based cardiac arrest, as well as commonly used approaches to predict ED-based cardiac arrest and highlight areas that require further research to improve outcomes for this population."
32998213,2.0,Frontiers of Robotic Gastroscopy: A Comprehensive Review of Robotic Gastroscopes and Technologies,2020 Sep 28;12(10):2775.,"Upper gastrointestinal (UGI) tract pathology is common worldwide. With recent advancements in robotics, innovative diagnostic and treatment devices have been developed and several translational attempts made. This review paper aims to provide a highly pictorial critical review of robotic gastroscopes, so that clinicians and researchers can obtain a swift and comprehensive overview of key technologies and challenges. Therefore, the paper presents robotic gastroscopes, either commercial or at a progressed technology readiness level. Among them, we show tethered and wireless gastroscopes, as well as devices aimed for UGI surgery. The technological features of these instruments, as well as their clinical adoption and performance, are described and compared. Although the existing endoscopic devices have thus far provided substantial improvements in the effectiveness of diagnosis and treatment, there are certain aspects that represent unwavering predicaments of the current gastroenterology practice. A detailed list includes difficulties and risks, such as transmission of communicable diseases (e.g., COVID-19) due to the doctor-patient proximity, unchanged learning curves, variable detection rates, procedure-related adverse events, endoscopists' and nurses' burnouts, limited human and/or material resources, and patients' preferences to choose non-invasive options that further interfere with the successful implementation and adoption of routine screening. The combination of robotics and artificial intelligence, as well as remote telehealth endoscopy services, are also discussed, as viable solutions to improve existing platforms for diagnosis and treatment are emerging."
32996518,,Towards development of a novel universal medical diagnostic method: Raman spectroscopy and machine learning,2020 Oct 19;49(20):7428-7453.,"Many problems exist within the myriad of currently employed screening and diagnostic methods. Further, an incredibly wide variety of procedures are used to identify an even greater number of diseases which exist in the world. There is a definite unmet clinical need to improve diagnostic capabilities of these procedures, including improving test sensitivity and specificity, objectivity and definitiveness, and reducing cost and invasiveness of the test, with an interest in replacing multiple diagnostic methods with one powerful tool. There has been a recent surge in the literature which focuses on utilizing Raman spectroscopy in combination with machine learning analyses to improve diagnostic measures for identifying an assortment of diseases, including cancers, viral and bacterial infections, neurodegenerative and autoimmune disorders, and more. This review highlights the work accomplished since 2018 which focuses on using Raman spectroscopy and machine learning to address the need for better screening and medical diagnostics in all areas of disease. A critical evaluation considers both the benefits and obstacles of utilizing the method for universal diagnostics. It is clear based on the evidence provided herein Raman spectroscopy in combination with machine learning provides the first glimmer of hope for the development of an accurate, inexpensive, fast, and non-invasive method for universal medical diagnostics."
32996368,1.0,Exploring the Potential of Artificial Intelligence and Machine Learning to Combat COVID-19 and Existing Opportunities for LMIC: A Scoping Review,Jan-Dec 2020;11:2150132720963634.,"Background:                    In the face of the current time-sensitive COVID-19 pandemic, the limited capacity of healthcare systems resulted in an emerging need to develop newer methods to control the spread of the pandemic. Artificial Intelligence (AI), and Machine Learning (ML) have a vast potential to exponentially optimize health care research. The use of AI-driven tools in LMIC can help in eradicating health inequalities and decrease the burden on health systems.              Methods:                    The literature search for this Scoping review was conducted through the PubMed database using keywords: COVID-19, Artificial Intelligence (AI), Machine Learning (ML), and Low Middle-Income Countries (LMIC). Forty-three articles were identified and screened for eligibility and 13 were included in the final review. All the items of this Scoping review are reported using guidelines for PRISMA extension for scoping reviews (PRISMA-ScR).              Results:                    Results were synthesized and reported under 4 themes. (a) The need of AI during this pandemic: AI can assist to increase the speed and accuracy of identification of cases and through data mining to deal with the health crisis efficiently, (b) Utility of AI in COVID-19 screening, contact tracing, and diagnosis: Efficacy for virus detection can a be increased by deploying the smart city data network using terminal tracking system along-with prediction of future outbreaks, (c) Use of AI in COVID-19 patient monitoring and drug development: A Deep learning system provides valuable information regarding protein structures associated with COVID-19 which could be utilized for vaccine formulation, and (d) AI beyond COVID-19 and opportunities for Low-Middle Income Countries (LMIC): There is a lack of financial, material, and human resources in LMIC, AI can minimize the workload on human labor and help in analyzing vast medical data, potentiating predictive and preventive healthcare.              Conclusion:                    AI-based tools can be a game-changer for diagnosis, treatment, and management of COVID-19 patients with the potential to reshape the future of healthcare in LMIC."
32996149,1.0,CT artifact correction for sparse and truncated projection data using generative adversarial networks,2021 Feb;48(2):615-626.,"Purpose:                    Computed tomography image reconstruction using truncated or sparsely acquired projection data to reduce radiation dose, iodine volume, and patient motion artifacts has been widely investigated. To continue these efforts, we investigated the use of machine learning-based reconstruction techniques using deep convolutional generative adversarial networks (DCGANs) and evaluated its effect using standard imaging metrics.              Methods:                    Ten thousand head computed tomography (CT) scans were collected from the 2019 RSNA Intracranial Hemorrhage Detection and Classification Challenge dataset. Sinograms were simulated and then resampled in both a one-third truncated and one-third sparse manner. DCGANs were tasked with correcting the incomplete projection data, either in the sinogram domain where the full sinogram was recovered by the DCGAN and then reconstructed, or the reconstruction domain where the incomplete data were first reconstructed and the sparse or truncation artifacts were corrected by the DCGAN. Seventy-five hundred images were used for network training and 2500 were withheld for network assessment using mean absolute error (MAE), structural similarity index measure (SSIM), and peak signal-to-noise ratio (PSNR) between results of different correction techniques. Image data from a quality-assurance phantom were also resampled in the two manners and corrected and reconstructed for network performance assessment using line profiles across high-contrast features, the modulation transfer function (MTF), noise power spectrum (NPS), and Hounsfield Unit (HU) linearity analysis.              Results:                    Better agreement with the fully sampled reconstructions were achieved from sparse acquisition corrected in the sinogram domain and the truncated acquisition corrected in the reconstruction domain. MAE, SSIM, and PSNR showed quantitative improvement from the DCGAN correction techniques. HU linearity of the reconstructions was maintained by the correction techniques for the sparse and truncated acquisitions. MTF curves reached the 10% modulation cutoff frequency at 5.86 lp/cm for the truncated corrected reconstruction compared with 2.98 lp/cm for the truncated uncorrected reconstruction, and 5.36 lp/cm for the sparse corrected reconstruction compared with around 2.91 lp/cm for the sparse uncorrected reconstruction. NPS analyses yielded better agreement across a range of frequencies between the resampled corrected phantom and truth reconstructions.              Conclusions:                    We demonstrated the use of DCGANs for CT-image correction from sparse and truncated simulated projection data, while preserving imaging quality of the fully sampled projection data."
32995981,1.0,Enhancement of needle visualization and localization in ultrasound,2021 Jan;16(1):169-178.,"Purpose:                    This scoping review covers needle visualization and localization techniques in ultrasound, where localization-based approaches mostly aim to compute the needle shaft (and tip) location while potentially enhancing its visibility too.              Methods:                    A literature review is conducted on the state-of-the-art techniques, which could be divided into five categories: (1) signal and image processing-based techniques to augment the needle, (2) modifications to the needle and insertion to help with needle-transducer alignment and visibility, (3) changes to ultrasound image formation, (4) motion-based analysis and (5) machine learning.              Results:                    Advantages, limitations and challenges of representative examples in each of the categories are discussed. Evaluation techniques performed in ex vivo, phantom and in vivo studies are discussed and summarized.              Conclusion:                    Greatest limitation of the majority of the literature is that they rely on original visibility of the needle in the static image. Need for additional/improved apparatus is the greatest limitation toward clinical utility in practice.              Significance:                    Ultrasound-guided needle placement is performed in many clinical applications, including biopsies, treatment injections and anesthesia. Despite the wide range and long history of this technique, an ongoing challenge is needle visibility in ultrasound. A robust technique to enhance ultrasonic needle visibility, especially for steeply inserted hand-held needles, and while maintaining clinical utility requirements is needed."
32994889,2.0,Artificial intelligence (AI) and big data in cancer and precision oncology,2020 Aug 28;18:2300-2311.,"Artificial intelligence (AI) and machine learning have significantly influenced many facets of the healthcare sector. Advancement in technology has paved the way for analysis of big datasets in a cost- and time-effective manner. Clinical oncology and research are reaping the benefits of AI. The burden of cancer is a global phenomenon. Efforts to reduce mortality rates requires early diagnosis for effective therapeutic interventions. However, metastatic and recurrent cancers evolve and acquire drug resistance. It is imperative to detect novel biomarkers that induce drug resistance and identify therapeutic targets to enhance treatment regimes. The introduction of the next generation sequencing (NGS) platforms address these demands, has revolutionised the future of precision oncology. NGS offers several clinical applications that are important for risk predictor, early detection of disease, diagnosis by sequencing and medical imaging, accurate prognosis, biomarker identification and identification of therapeutic targets for novel drug discovery. NGS generates large datasets that demand specialised bioinformatics resources to analyse the data that is relevant and clinically significant. Through these applications of AI, cancer diagnostics and prognostic prediction are enhanced with NGS and medical imaging that delivers high resolution images. Regardless of the improvements in technology, AI has some challenges and limitations, and the clinical application of NGS remains to be validated. By continuing to enhance the progression of innovation and technology, the future of AI and precision oncology show great promise."
32994452,1.0,Machine learning prediction in cardiovascular diseases: a meta-analysis,2020 Sep 29;10(1):16057.,"Several machine learning (ML) algorithms have been increasingly utilized for cardiovascular disease prediction. We aim to assess and summarize the overall predictive ability of ML algorithms in cardiovascular diseases. A comprehensive search strategy was designed and executed within the MEDLINE, Embase, and Scopus databases from database inception through March 15, 2019. The primary outcome was a composite of the predictive ability of ML algorithms of coronary artery disease, heart failure, stroke, and cardiac arrhythmias. Of 344 total studies identified, 103 cohorts, with a total of 3,377,318 individuals, met our inclusion criteria. For the prediction of coronary artery disease, boosting algorithms had a pooled area under the curve (AUC) of 0.88 (95% CI 0.84-0.91), and custom-built algorithms had a pooled AUC of 0.93 (95% CI 0.85-0.97). For the prediction of stroke, support vector machine (SVM) algorithms had a pooled AUC of 0.92 (95% CI 0.81-0.97), boosting algorithms had a pooled AUC of 0.91 (95% CI 0.81-0.96), and convolutional neural network (CNN) algorithms had a pooled AUC of 0.90 (95% CI 0.83-0.95). Although inadequate studies for each algorithm for meta-analytic methodology for both heart failure and cardiac arrhythmias because the confidence intervals overlap between different methods, showing no difference, SVM may outperform other algorithms in these areas. The predictive ability of ML algorithms in cardiovascular diseases is promising, particularly SVM and boosting algorithms. However, there is heterogeneity among ML algorithms in terms of multiple parameters. This information may assist clinicians in how to interpret data and implement optimal algorithms for their dataset."
32994368,2.0,"Big data, machine learning and artificial intelligence: a neurologist's guide",2020 Sep 29;21(1):4-11.,"Modern clinical practice requires the integration and interpretation of ever-expanding volumes of clinical data. There is, therefore, an imperative to develop efficient ways to process and understand these large amounts of data. Neurologists work to understand the function of biological neural networks, but artificial neural networks and other forms of machine learning algorithm are likely to be increasingly encountered in clinical practice. As their use increases, clinicians will need to understand the basic principles and common types of algorithm. We aim to provide a coherent introduction to this jargon-heavy subject and equip neurologists with the tools to understand, critically appraise and apply insights from this burgeoning field."
32994289,2.0,The Gut Microbiome and Individual-Specific Responses to Diet,2020 Sep 29;5(5):e00665-20.,"Nutritional content and timing are increasingly appreciated to constitute important human variables collectively impacting all aspects of human physiology and disease. However, person-specific mechanisms driving nutritional impacts on the human host remain incompletely understood, while current dietary recommendations remain empirical and nonpersonalized. Precision nutrition aims to harness individualized bodies of data, including the human gut microbiome, in predicting person-specific physiological responses (such as glycemic responses) to food. With these advances notwithstanding, many unknowns remain, including the long-term efficacy of such interventions in delaying or reversing human metabolic disease, mechanisms driving these dietary effects, and the extent of the contribution of the gut microbiome to these processes. We summarize these conceptual advances, while highlighting challenges and means of addressing them in the next decade of study of precision medicine, toward generation of insights that may help to evolve precision nutrition as an effective future tool in a variety of ""multifactorial"" human disorders."
32993652,5.0,Using machine learning of clinical data to diagnose COVID-19: a systematic review and meta-analysis,2020 Sep 29;20(1):247.,"Background:                    The recent Coronavirus Disease 2019 (COVID-19) pandemic has placed severe stress on healthcare systems worldwide, which is amplified by the critical shortage of COVID-19 tests.              Methods:                    In this study, we propose to generate a more accurate diagnosis model of COVID-19 based on patient symptoms and routine test results by applying machine learning to reanalyzing COVID-19 data from 151 published studies. We aim to investigate correlations between clinical variables, cluster COVID-19 patients into subtypes, and generate a computational classification model for discriminating between COVID-19 patients and influenza patients based on clinical variables alone.              Results:                    We discovered several novel associations between clinical variables, including correlations between being male and having higher levels of serum lymphocytes and neutrophils. We found that COVID-19 patients could be clustered into subtypes based on serum levels of immune cells, gender, and reported symptoms. Finally, we trained an XGBoost model to achieve a sensitivity of 92.5% and a specificity of 97.9% in discriminating COVID-19 patients from influenza patients.              Conclusions:                    We demonstrated that computational methods trained on large clinical datasets could yield ever more accurate COVID-19 diagnostic models to mitigate the impact of lack of testing. We also presented previously unknown COVID-19 clinical variable correlations and clinical subgroups."
32989410,1.0,Leveraging Computational Modeling to Understand Infectious Diseases,2020 Sep 24;1-13.,"Purpose of review:                    Computational and mathematical modeling have become a critical part of understanding in-host infectious disease dynamics and predicting effective treatments. In this review, we discuss recent findings pertaining to the biological mechanisms underlying infectious diseases, including etiology, pathogenesis, and the cellular interactions with infectious agents. We present advances in modeling techniques that have led to fundamental disease discoveries and impacted clinical translation.              Recent findings:                    Combining mechanistic models and machine learning algorithms has led to improvements in the treatment of Shigella and tuberculosis through the development of novel compounds. Modeling of the epidemic dynamics of malaria at the within-host and between-host level has afforded the development of more effective vaccination and antimalarial therapies. Similarly, in-host and host-host models have supported the development of new HIV treatment modalities and an improved understanding of the immune involvement in influenza. In addition, large-scale transmission models of SARS-CoV-2 have furthered the understanding of coronavirus disease and allowed for rapid policy implementations on travel restrictions and contract tracing apps.              Summary:                    Computational modeling is now more than ever at the forefront of infectious disease research due to the COVID-19 pandemic. This review highlights how infectious diseases can be better understood by connecting scientists from medicine and molecular biology with those in computer science and applied mathematics."
32987202,2.0,A comprehensive review of deep learning in colon cancer,2020 Nov;126:104003.,"Deep learning has emerged as a leading machine learning tool in object detection and has attracted attention with its achievements in progressing medical image analysis. Convolutional Neural Networks (CNNs) are the most preferred method of deep learning algorithms for this purpose and they have an essential role in the detection and potential early diagnosis of colon cancer. In this article, we hope to bring a perspective to progress in this area by reviewing deep learning practices for colon cancer analysis. This study first presents an overview of popular deep learning architectures used in colon cancer analysis. After that, all studies related to colon cancer analysis are collected under the field of colon cancer and deep learning, then they are divided into five categories that are detection, classification, segmentation, survival prediction, and inflammatory bowel diseases. Then, the studies collected under each category are summarized in detail and listed. We conclude our work with a summary of recent deep learning practices for colon cancer analysis, a critical discussion of the challenges faced, and suggestions for future research. This study differs from other studies by including 135 recent academic papers, separating colon cancer into five different classes, and providing a comprehensive structure. We hope that this study is beneficial to researchers interested in using deep learning techniques for the diagnosis of colon cancer."
32984921,9.0,Application of artificial intelligence models and optimization algorithms in plant cell and tissue culture,2020 Nov;104(22):9449-9485.,"Artificial intelligence (AI) models and optimization algorithms (OA) are broadly employed in different fields of technology and science and have recently been applied to improve different stages of plant tissue culture. The usefulness of the application of AI-OA has been demonstrated in the prediction and optimization of length and number of microshoots or roots, biomass in plant cell cultures or hairy root culture, and optimization of environmental conditions to achieve maximum productivity and efficiency, as well as classification of microshoots and somatic embryos. Despite its potential, the use of AI and OA in this field has been limited due to complex definition terms and computational algorithms. Therefore, a systematic review to unravel modeling and optimizing methods is important for plant researchers and has been acknowledged in this study. First, the main steps for AI-OA development (from data selection to evaluation of prediction and classification models), as well as several AI models such as artificial neural networks (ANNs), neurofuzzy logic, support vector machines (SVMs), decision trees, random forest (FR), and genetic algorithms (GA), have been represented. Then, the application of AI-OA models in different steps of plant tissue culture has been discussed and highlighted. This review also points out limitations in the application of AI-OA in different plant tissue culture processes and provides a new view for future study objectives. KEY POINTS: • Artificial intelligence models and optimization algorithms can be considered a novel and reliable computational method in plant tissue culture. • This review provides the main steps and concepts for model development. • The application of machine learning algorithms in different steps of plant tissue culture has been discussed and highlighted."
32983950,2.0,Artificial Intelligence and Computational Approaches for Epilepsy,2020 Jun 30;10(1):8-17.,"Studies on treatment of epilepsy have been actively conducted in multiple avenues, but there are limitations in improving its efficacy due to between-subject variability in which treatment outcomes vary from patient to patient. Accordingly, there is a growing interest in precision medicine that provides accurate diagnosis for seizure types and optimal treatment for an individual epilepsy patient. Among these approaches, computational studies making this feasible are rapidly progressing in particular and have been widely applied in epilepsy. These computational studies are being conducted in two main streams: 1) artificial intelligence-based studies implementing computational machines with specific functions, such as automatic diagnosis and prognosis prediction for an individual patient, using machine learning techniques based on large amounts of data obtained from multiple patients and 2) patient-specific modeling-based studies implementing biophysical in-silico platforms to understand pathological mechanisms and derive the optimal treatment for each patient by reproducing the brain network dynamics of the particular patient per se based on individual patient's data. These computational approaches are important as it can integrate multiple types of data acquired from patients and analysis results into a single platform. If these kinds of methods are efficiently operated, it would suggest a novel paradigm for precision medicine."
32983527,1.0,Applications of Machine Learning in Cardiac Electrophysiology,2020 Aug;9(2):71-77.,"Artificial intelligence through machine learning (ML) methods is becoming prevalent throughout the world, with increasing adoption in healthcare. Improvements in technology have allowed early applications of machine learning to assist physician efficiency and diagnostic accuracy. In electrophysiology, ML has applications for use in every stage of patient care. However, its use is still in infancy. This article will introduce the potential of ML, before discussing the concept of big data and its pitfalls. The authors review some common ML methods including supervised and unsupervised learning, then examine applications in cardiac electrophysiology. This will focus on surface electrocardiography, intracardiac mapping and cardiac implantable electronic devices. Finally, the article concludes with an overview of how ML may impact on electrophysiology in the future."
32981888,,The use of artificial intelligence in computed tomography image reconstruction - A literature review,2020 Dec;51(4):671-677.,"Background and purpose:                    The use of AI in the process of CT image reconstruction may improve image quality of resultant images and therefore facilitate low-dose CT examinations.              Methods:                    Articles in this review were gathered from multiple databases (Google Scholar, Ovid and Monash University Library Database). A total of 17 articles regarding AI use in CT image reconstruction was reviewed, including 1 white paper from GE Healthcare.              Results:                    DLR algorithms performed better in terms of noise reduction abilities, and image quality preservation at low doses when compared to other reconstruction techniques.              Conclusion:                    Further research is required to discuss clinical application and diagnostic accuracy of DLR algorithms, but AI is a promising dose-reduction technique with future computational advances."
32980785,,Artificial intelligence in stroke imaging: Current and future perspectives,2021 Jan;69:246-254.,"Artificial intelligence (AI) is a fast-growing research area in computer science that aims to mimic cognitive processes through a number of techniques. Supervised machine learning, a subfield of AI, includes methods that can identify patterns in high-dimensional data using labeled 'ground truth' data and apply these learnt patterns to analyze, interpret, or make predictions on new datasets. Supervised machine learning has become a significant area of interest within the medical community. Radiology and neuroradiology in particular are especially well suited for application of machine learning due to the vast amount of data that is generated. One devastating disease for which neuroimaging plays a significant role in the clinical management is stroke. Within this context, AI techniques can play pivotal roles for image-based diagnosis and management of stroke. This overview focuses on the recent advances of artificial intelligence methods - particularly supervised machine learning and deep learning - with respect to workflow, image acquisition and reconstruction, and image interpretation in patients with acute stroke, while also discussing potential pitfalls and future applications."
32980438,,Multivariate data analysis in cell gene therapy manufacturing,2020 Dec;45:107637.,"The emergence of cell gene therapy (CGT) as a safe and efficacious treatment for numerous severe inherited and acquired human diseases has led to growing interest and investment in new CGT products. The most successful of these have been autologous viral vector-based treatments. The development of viral vector manufacturing processes and ex vivo patient cell processing capabilities is a pressing issue in the advancement of autologous viral vector-based CGT treatments. In viral vector production, scale-up is a critical task due to the limited scalability of traditional laboratory systems and the demand for high volumes of viral vector manufactured in accordance with current good manufacturing practice. Ex vivo cell processing methods require optimisation and automation before they can be scaled out, and several other manufacturing challenges are prevalent such as high levels of raw material and process variability, difficulty characterising complex materials, and a lack of knowledge of critical process parameters and their effect on critical quality attributes of the viral vector and cell drug products. Multivariate data analysis (MVDA) has been leveraged successfully in a variety of applications in the chemical and biochemical industries, including for tasks such as bioprocess monitoring, identification of critical process parameters and assessment of process variability and comparability during process development, scale-up and technology transfer. Henceforth, MVDA is reviewed here as a suitable tool for tackling some of the challenges faced in the development of CGT manufacturing processes. A summary of some key CGT manufacturing challenges is provided along with a review of MVDA applications to mammalian and microbial processes, and an exploration of the potential benefits, requirements and pre-requisites of MVDA applications in the development of CGT manufacturing processes."
32979542,,Artificial intelligence in celiac disease,2020 Oct;125:103996.,"Celiac disease (CD) has been on the rise in the world and a large part of it remains undiagnosed. Novel methods are required to address the gaps in prompt detection and management. Artificial intelligence (AI) has seen an exponential surge in the last decade worldwide. With the advent of big data and powerful computational ability, we now have self-driving cars and smart devices in our daily lives. Huge databases in the form of electronic medical records and images have rendered healthcare a lucrative sector where AI can prove revolutionary. It is being used extensively to overcome the barriers in clinical workflows. From the perspective of a disease, it can be deployed in multiple steps i.e. screening tools, diagnosis, developing novel therapeutic agents, proposing management plans, and defining prognostic indicators, etc. We review the areas where it may augment physicians in the delivery of better healthcare by summarizing current literature on the use of AI in healthcare using CD as a model. We further outline major barriers to its large-scale implementations and prospects from the healthcare point of view."
32978734,,Lake water-level fluctuation forecasting using machine learning models: a systematic review,2020 Dec;27(36):44807-44819.,"Lake water-level fluctuation is a complex and dynamic process, characterized by high stochasticity and nonlinearity, and difficult to model and forecast. In recent years, applications of machine learning (ML) models have yielded substantial progress in forecasting lake water-level fluctuations. This paper presents a comprehensive review of the applications of ML models for modeling water-level dynamics in lakes. Among the many existing ML models, seven popular ML model types are reviewed: (1) artificial neural network (ANN); (2) support vector machine (SVM); (3) artificial neuro-fuzzy inference system (ANFIS); (4) hybrid models, such as hybrid wavelet-artificial neural network (WA-ANN) model, hybrid wavelet-artificial neuro-fuzzy inference system (WA-ANFIS) model, and hybrid wavelet-support vector machine (WA-SVM) model; (5) evolutionary models, such as gene expression programming (GEP) and genetic programming (GP); (6) extreme learning machine (ELM); and (7) deep learning (DL). Model inputs, data split, model performance criteria, and model inter-comparison as well as the associated issues are discussed. The advantages and limitations of the established ML models are also discussed. Some specific directions for future research are also offered. This review provides a new vision for hydrologists and water resources planners for sustainable management of lakes."
32978286,,Machine Learning in Nuclear Medicine: Part 2-Neural Networks and Clinical Aspects,2021 Jan;62(1):22-29.,"This article is the second part in our machine learning series. Part 1 provided a general overview of machine learning in nuclear medicine. Part 2 focuses on neural networks. We start with an example illustrating how neural networks work and a discussion of potential applications. Recognizing that there is a spectrum of applications, we focus on recent publications in the areas of image reconstruction, low-dose PET, disease detection, and models used for diagnosis and outcome prediction. Finally, since the way machine learning algorithms are reported in the literature is extremely variable, we conclude with a call to arms regarding the need for standardized reporting of design and outcome metrics and we propose a basic checklist our community might follow going forward."
32977139,1.0,Data-driven ICU management: Using Big Data and algorithms to improve outcomes,2020 Dec;60:300-304.,"The digitalization of the Intensive Care Unit (ICU) led to an increasing amount of clinical data being collected at the bedside. The term ""Big Data"" can be used to refer to the analysis of these datasets that collect enormous amount of data of different origin and format. Complexity and variety define the value of Big Data. In fact, the retrospective analysis of these datasets allows to generate new knowledge, with consequent potential improvements in the clinical practice. Despite the promising start of Big Data analysis in medical research, which has seen a rising number of peer-reviewed articles, very limited applications have been used in ICU clinical practice. A close future effort should be done to validate the knowledge extracted from clinical Big Data and implement it in the clinic. In this article, we provide an introduction to Big Data in the ICU, from data collection and data analysis, to the main successful examples of prognostic, predictive and classification models based on ICU data. In addition, we focus on the main challenges that these models face to reach the bedside and effectively improve ICU care."
32974930,,Patient generated health data and electronic health record integration in oncologic surgery: A call for artificial intelligence and machine learning,2021 Jan;123(1):52-60.,"In this review, we aim to assess the current state of science in relation to the integration of patient-generated health data (PGHD) and patient-reported outcomes (PROs) into routine clinical care with a focus on surgical oncology populations. We will also describe the critical role of artificial intelligence and machine-learning methodology in the efficient translation of PGHD, PROs, and traditional outcome measures into meaningful patient care models."
32974382,,The Role of Machine Learning in Spine Surgery: The Future Is Now,2020 Aug 21;7:54.,"The recent influx of machine learning centered investigations in the spine surgery literature has led to increased enthusiasm as to the prospect of using artificial intelligence to create clinical decision support tools, optimize postoperative outcomes, and improve technologies used in the operating room. However, the methodology underlying machine learning in spine research is often overlooked as the subject matter is quite novel and may be foreign to practicing spine surgeons. Improper application of machine learning is a significant bioethics challenge, given the potential consequences of over- or underestimating the results of such studies for clinical decision-making processes. Proper peer review of these publications requires a baseline familiarity of the language associated with machine learning, and how it differs from classical statistical analyses. This narrative review first introduces the overall field of machine learning and its role in artificial intelligence, and defines basic terminology. In addition, common modalities for applying machine learning, including classification and regression decision trees, support vector machines, and artificial neural networks are examined in the context of examples gathered from the spine literature. Lastly, the ethical challenges associated with adapting machine learning for research related to patient care, as well as future perspectives on the potential use of machine learning in spine surgery, are discussed specifically."
32973876,,Infrared Spectrometry as a High-Throughput Phenotyping Technology to Predict Complex Traits in Livestock Systems,2020 Aug 20;11:923.,"High-throughput phenotyping technologies are growing in importance in livestock systems due to their ability to generate real-time, non-invasive, and accurate animal-level information. Collecting such individual-level information can generate novel traits and potentially improve animal selection and management decisions in livestock operations. One of the most relevant tools used in the dairy and beef industry to predict complex traits is infrared spectrometry, which is based on the analysis of the interaction between electromagnetic radiation and matter. The infrared electromagnetic radiation spans an enormous range of wavelengths and frequencies known as the electromagnetic spectrum. The spectrum is divided into different regions, with near- and mid-infrared regions being the main spectral regions used in livestock applications. The advantage of using infrared spectrometry includes speed, non-destructive measurement, and great potential for on-line analysis. This paper aims to review the use of mid- and near-infrared spectrometry techniques as tools to predict complex dairy and beef phenotypes, such as milk composition, feed efficiency, methane emission, fertility, energy balance, health status, and meat quality traits. Although several research studies have used these technologies to predict a wide range of phenotypes, most of them are based on Partial Least Squares (PLS) and did not considered other machine learning (ML) techniques to improve prediction quality. Therefore, we will discuss the role of analytical methods employed on spectral data to improve the predictive ability for complex traits in livestock operations. Furthermore, we will discuss different approaches to reduce data dimensionality and the impact of validation strategies on predictive quality."
32972444,1.0,Diagnosis of Rare Diseases: a scoping review of clinical decision support systems,2020 Sep 24;15(1):263.,"Background:                    Rare Diseases (RDs), which are defined as diseases affecting no more than 5 out of 10,000 people, are often severe, chronic and life-threatening. A main problem is the delay in diagnosing RDs. Clinical decision support systems (CDSSs) for RDs are software systems to support clinicians in the diagnosis of patients with RDs. Due to their clinical importance, we conducted a scoping review to determine which CDSSs are available to support the diagnosis of RDs patients, whether the CDSSs are available to be used by clinicians and which functionalities and data are used to provide decision support.              Methods:                    We searched PubMed for CDSSs in RDs published between December 16, 2008 and December 16, 2018. Only English articles, original peer reviewed journals and conference papers describing a clinical prototype or a routine use of CDSSs were included. For data charting, we used the data items ""Objective and background of the publication/project"", ""System or project name"", ""Functionality"", ""Type of clinical data"", ""Rare Diseases covered"", ""Development status"", ""System availability"", ""Data entry and integration"", ""Last software update"" and ""Clinical usage"".              Results:                    The search identified 636 articles. After title and abstracting screening, as well as assessing the eligibility criteria for full-text screening, 22 articles describing 19 different CDSSs were identified. Three types of CDSSs were classified: ""Analysis or comparison of genetic and phenotypic data,"" ""machine learning"" and ""information retrieval"". Twelve of nineteen CDSSs use phenotypic and genetic data, followed by clinical data, literature databases and patient questionnaires. Fourteen of nineteen CDSSs are fully developed systems and therefore publicly available. Data can be entered or uploaded manually in six CDSSs, whereas for four CDSSs no information for data integration was available. Only seven CDSSs allow further ways of data integration. thirteen CDSS do not provide information about clinical usage.              Conclusions:                    Different CDSS for various purposes are available, yet clinicians have to determine which is best for their patient. To allow a more precise usage, future research has to focus on CDSSs RDs data integration, clinical usage and updating clinical knowledge. It remains interesting which of the CDSSs will be used and maintained in the future."
32972036,,An Introduction to Probabilistic Record Linkage with a Focus on Linkage Processing for WTC Registries,2020 Sep 22;17(18):6937.,"Since its post-World War II inception, the science of record linkage has grown exponentially and is used across industrial, governmental, and academic agencies. The academic fields that rely on record linkage are diverse, ranging from history to public health to demography. In this paper, we introduce the different types of data linkage and give a historical context to their development. We then introduce the three types of underlying models for probabilistic record linkage: Fellegi-Sunter-based methods, machine learning methods, and Bayesian methods. Practical considerations, such as data standardization and privacy concerns, are then discussed. Finally, recommendations are given for organizations developing or maintaining record linkage programs, with an emphasis on organizations measuring long-term complications of disasters, such as 9/11."
32971981,3.0,Application of Artificial Intelligence in Early Diagnosis of Spontaneous Preterm Labor and Birth,2020 Sep 22;10(9):733.,"This study reviews the current status and future prospective of knowledge on the use of artificial intelligence for the prediction of spontaneous preterm labor and birth (""preterm birth"" hereafter). The summary of review suggests that different machine learning approaches would be optimal for different types of data regarding the prediction of preterm birth: the artificial neural network, logistic regression and/or the random forest for numeric data; the support vector machine for electrohysterogram data; the recurrent neural network for text data; and the convolutional neural network for image data. The ranges of performance measures were 0.79-0.94 for accuracy, 0.22-0.97 for sensitivity, 0.86-1.00 for specificity, and 0.54-0.83 for the area under the receiver operating characteristic curve. The following maternal variables were reported to be major determinants of preterm birth: delivery and pregestational body mass index, age, parity, predelivery systolic and diastolic blood pressure, twins, below high school graduation, infant sex, prior preterm birth, progesterone medication history, upper gastrointestinal tract symptom, gastroesophageal reflux disease, Helicobacter pylori, urban region, calcium channel blocker medication history, gestational diabetes mellitus, prior cone biopsy, cervical length, myomas and adenomyosis, insurance, marriage, religion, systemic lupus erythematosus, hydroxychloroquine sulfate, and increased cerebrospinal fluid and reduced cortical folding due to impaired brain growth."
32971255,,"A research agenda for ageing in China in the 21st century (2nd edition): Focusing on basic and translational research, long-term care, policy and social networks",2020 Dec;64:101174.,"One of the key issues facing public healthcare is the global trend of an increasingly ageing society which continues to present policy makers and caregivers with formidable healthcare and socio-economic challenges. Ageing is the primary contributor to a broad spectrum of chronic disorders all associated with a lower quality of life in the elderly. In 2019, the Chinese population constituted 18 % of the world population, with 164.5 million Chinese citizens aged 65 and above (65+), and 26 million aged 80 or above (80+). China has become an ageing society, and as it continues to age it will continue to exacerbate the burden borne by current family and public healthcare systems. Major healthcare challenges involved with caring for the elderly in China include the management of chronic non-communicable diseases (CNCDs), physical frailty, neurodegenerative diseases, cardiovascular diseases, with emerging challenges such as providing sufficient dental care, combating the rising prevalence of sexually transmitted diseases among nursing home communities, providing support for increased incidences of immune diseases, and the growing necessity to provide palliative care for the elderly. At the governmental level, it is necessary to make long-term strategic plans to respond to the pressures of an ageing society, especially to establish a nationwide, affordable, annual health check system to facilitate early diagnosis and provide access to affordable treatments. China has begun work on several activities to address these issues including the recent completion of the of the Ten-year Health-Care Reform project, the implementation of the Healthy China 2030 Action Plan, and the opening of the National Clinical Research Center for Geriatric Disorders. There are also societal challenges, namely the shift from an extended family system in which the younger provide home care for their elderly family members, to the current trend in which young people are increasingly migrating towards major cities for work, increasing reliance on nursing homes to compensate, especially following the outcomes of the 'one child policy' and the 'empty-nest elderly' phenomenon. At the individual level, it is important to provide avenues for people to seek and improve their own knowledge of health and disease, to encourage them to seek medical check-ups to prevent/manage illness, and to find ways to promote modifiable health-related behaviors (social activity, exercise, healthy diets, reasonable diet supplements) to enable healthier, happier, longer, and more productive lives in the elderly. Finally, at the technological or treatment level, there is a focus on modern technologies to counteract the negative effects of ageing. Researchers are striving to produce drugs that can mimic the effects of 'exercising more, eating less', while other anti-ageing molecules from molecular gerontologists could help to improve 'healthspan' in the elderly. Machine learning, 'Big Data', and other novel technologies can also be used to monitor disease patterns at the population level and may be used to inform policy design in the future. Collectively, synergies across disciplines on policies, geriatric care, drug development, personal awareness, the use of big data, machine learning and personalized medicine will transform China into a country that enables the most for its elderly, maximizing and celebrating their longevity in the coming decades. This is the 2nd edition of the review paper (Fang EF et al., Ageing Re. Rev. 2015)."
32970997,4.0,Artificial Neural Networks for Neuroscientists: A Primer,2020 Sep 23;107(6):1048-1070.,"Artificial neural networks (ANNs) are essential tools in machine learning that have drawn increasing attention in neuroscience. Besides offering powerful techniques for data analysis, ANNs provide a new approach for neuroscientists to build models for complex behaviors, heterogeneous neural activity, and circuit connectivity, as well as to explore optimization in neural systems, in ways that traditional models are not designed for. In this pedagogical Primer, we introduce ANNs and demonstrate how they have been fruitfully deployed to study neuroscientific questions. We first discuss basic concepts and methods of ANNs. Then, with a focus on bringing this mathematical framework closer to neurobiology, we detail how to customize the analysis, structure, and learning of ANNs to better address a wide range of challenges in brain research. To help readers garner hands-on experience, this Primer is accompanied with tutorial-style code in PyTorch and Jupyter Notebook, covering major topics."
32969051,,Current status and future perspective on artificial intelligence for lower endoscopy,2021 Jan;33(2):273-284.,"The global incidence and mortality rate of colorectal cancer remains high. Colonoscopy is regarded as the gold standard examination for detecting and eradicating neoplastic lesions. However, there are some uncertainties in colonoscopy practice that are related to limitations in human performance. First, approximately one-fourth of colorectal neoplasms are missed on a single colonoscopy. Second, it is still difficult for non-experts to perform adequately regarding optical biopsy. Third, recording of some quality indicators (e.g. cecal intubation, bowel preparation, and withdrawal speed) which are related to adenoma detection rate, is sometimes incomplete. With recent improvements in machine learning techniques and advances in computer performance, artificial intelligence-assisted computer-aided diagnosis is being increasingly utilized by endoscopists. In particular, the emergence of deep-learning, data-driven machine learning techniques have made the development of computer-aided systems easier than that of conventional machine learning techniques, the former currently being considered the standard artificial intelligence engine of computer-aided diagnosis by colonoscopy. To date, computer-aided detection systems seem to have improved the rate of detection of neoplasms. Additionally, computer-aided characterization systems may have the potential to improve diagnostic accuracy in real-time clinical practice. Furthermore, some artificial intelligence-assisted systems that aim to improve the quality of colonoscopy have been reported. The implementation of computer-aided system clinical practice may provide additional benefits such as helping in educational poorly performing endoscopists and supporting real-time clinical decision-making. In this review, we have focused on computer-aided diagnosis during colonoscopy reported by gastroenterologists and discussed its status, limitations, and future prospects."
32968541,1.0,Listening forward: approaching marine biodiversity assessments using acoustic methods,2020 Aug 26;7(8):201287.,"Ecosystems and the communities they support are changing at alarmingly rapid rates. Tracking species diversity is vital to managing these stressed habitats. Yet, quantifying and monitoring biodiversity is often challenging, especially in ocean habitats. Given that many animals make sounds, these cues travel efficiently under water, and emerging technologies are increasingly cost-effective, passive acoustics (a long-standing ocean observation method) is now a potential means of quantifying and monitoring marine biodiversity. Properly applying acoustics for biodiversity assessments is vital. Our goal here is to provide a timely consideration of emerging methods using passive acoustics to measure marine biodiversity. We provide a summary of the brief history of using passive acoustics to assess marine biodiversity and community structure, a critical assessment of the challenges faced, and outline recommended practices and considerations for acoustic biodiversity measurements. We focused on temperate and tropical seas, where much of the acoustic biodiversity work has been conducted. Overall, we suggest a cautious approach to applying current acoustic indices to assess marine biodiversity. Key needs are preliminary data and sampling sufficiently to capture the patterns and variability of a habitat. Yet with new analytical tools including source separation and supervised machine learning, there is substantial promise in marine acoustic diversity assessment methods."
32967993,,Preparing to adapt is key for Olympic curling robots,2020 Sep 23;5(46):eabe2547.,Continued advances in machine learning could enable robots to solve tasks on a human level and adapt to changing conditions.
32967266,1.0,Applications of Genome-Wide Screening and Systems Biology Approaches in Drug Repositioning,2020 Sep 21;12(9):2694.,"Modern drug discovery through de novo drug discovery entails high financial costs, low success rates, and lengthy trial periods. Drug repositioning presents a suitable approach for overcoming these issues by re-evaluating biological targets and modes of action of approved drugs. Coupling high-throughput technologies with genome-wide essentiality screens, network analysis, genome-scale metabolic modeling, and machine learning techniques enables the proposal of new drug-target signatures and uncovers unanticipated modes of action for available drugs. Here, we discuss the current issues associated with drug repositioning in light of curated high-throughput multi-omic databases, genome-wide screening technologies, and their application in systems biology/medicine approaches."
32964109,,Mining genetic and transcriptomic data using machine learning approaches in Parkinson's disease,2020 Sep 9;6:24.,"High-throughput techniques have generated abundant genetic and transcriptomic data of Parkinson's disease (PD) patients but data analysis approaches such as traditional statistical methods have not provided much in the way of insightful integrated analysis or interpretation of the data. As an advanced computational approach, machine learning, which enables people to identify complex patterns and insight from data, has consequently been harnessed to analyze and interpret large, highly complex genetic and transcriptomic data toward a better understanding of PD. In particular, machine learning models have been developed to integrate patient genotype data alone or combined with demographic, clinical, neuroimaging, and other information, for PD outcome study. They have also been used to identify biomarkers of PD based on transcriptomic data, e.g., gene expression profiles from microarrays. This study overviews the relevant literature on using machine learning models for genetic and transcriptomic data analysis in PD, points out remaining challenges, and suggests future directions accordingly. Undoubtedly, the use of machine learning is amplifying PD genetic and transcriptomic achievements for accelerating the study of PD. Existing studies have demonstrated the great potential of machine learning in discovering hidden patterns within genetic or transcriptomic information and thus revealing clues underpinning pathology and pathogenesis. Moving forward, by addressing the remaining challenges, machine learning may advance our ability to precisely diagnose, prognose, and treat PD."
32962932,1.0,Artificial Intelligence in Echocardiography for Anesthesiologists,2021 Jan;35(1):251-261.,"Echocardiography is a unique diagnostic tool for intraoperative monitoring and assessment of patients with cardiovascular diseases. However, there are high levels of interoperator variations in echocardiography interpretations that could lead to inaccurate diagnosis and incorrect treatment. Furthermore, anesthesiologists are faced with the additional challenge to interpret echocardiography and make decisions in a limited timeframe from these complex data. The need for an automated, less operator-dependent process that enhances speed and accuracy of echocardiography analysis is crucial for anesthesiologists. Artificial intelligence is playing an increasingly important role in the medical field and could help anesthesiologists analyze complex echocardiographic data while adding increased accuracy and consistency to interpretation. This review aims to summarize practical use of artificial intelligence in echocardiography and discusses potential limitations and challenges in the future for anesthesiologists."
