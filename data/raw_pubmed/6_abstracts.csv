pmid,title,date,text,citations
32819849,Integration of artificial intelligence into clinical patient management: focus on cardiac imaging,2021 Jan;74(1):72-80.,"Cardiac imaging is a crucial component in the management of patients with heart disease, and as such it influences multiple, inter-related parts of the clinical workflow: physician-patient contact, image acquisition, image pre- and postprocessing, study reporting, diagnostics and outcome predictions, medical interventions, and, finally, knowledge-building through clinical research. With the gradual and ubiquitous infiltration of artificial intelligence into cardiology, it has become clear that, when used appropriately, it will influence and potentially improve-through automation, standardization and data integration-all components of the clinical workflow. This review aims to present a comprehensive view of full integration of artificial intelligence into the standard clinical patient management-with a focus on cardiac imaging, but applicable to all information handling-and to discuss current barriers that remain to be overcome before its widespread implementation and integration.",
32816167,Scalable Signature-Based Molecular Diagnostics Through On-chip Biomarker Profiling Coupled with Machine Learning,2020 Oct;48(10):2377-2399.,"Molecular diagnostics have traditionally relied on discrete biological substances as diagnostic markers. In recent years however, advances in on-chip biomarker screening technologies and data analytics have enabled signature-based diagnostics. Such diagnostics aim to utilize unique combinations of multiple biomarkers or diagnostic 'fingerprints' rather than discrete analyte measurements. This approach has shown to improve both diagnostic accuracy and diagnostic specificity. In this review, signature-based diagnostics enabled by microfluidic and micro-/nano- technologies will be reviewed with a focus on device design and data analysis pipelines and methodologies. With increasing amounts of data available from microfluidic biomarker screening, isolation, and detection platforms, advanced data handling and analytics approaches can be employed. Thus, current data analysis approaches including machine learning and recent advances with image processing, along with potential future directions will be explored. Lastly, the needs and gaps in current literature will be elucidated to inform future efforts towards development of molecular diagnostics and biomarker screening technologies.",2.0
32809857,Applications of Artificial Intelligence in Musculoskeletal Imaging: From the Request to the Report,2021 Feb;72(1):45-59.,"Artificial intelligence (AI) will transform every step in the imaging value chain, including interpretive and noninterpretive components. Radiologists should familiarize themselves with AI developments to become leaders in their clinical implementation. This article explores the impact of AI through the entire imaging cycle of musculoskeletal radiology, from the placement of the requisition to the generation of the report, with an added Canadian perspective. Noninterpretive tasks which may be assisted by AI include the ordering of appropriate imaging tests, automatic exam protocoling, optimized scheduling, shorter magnetic resonance imaging acquisition time, computed tomography imaging with reduced artifact and radiation dose, and new methods of generation and utilization of radiology reports. Applications of AI for image interpretation consist of the determination of bone age, body composition measurements, screening for osteoporosis, identification of fractures, evaluation of segmental spine pathology, detection and temporal monitoring of osseous metastases, diagnosis of primary bone and soft tissue tumors, and grading of osteoarthritis.",
32803154,Artificial Intelligence: A Primer for Breast Imaging Radiologists,2020 Aug;2(4):304-314.,"Artificial intelligence (AI) is a branch of computer science dedicated to developing computer algorithms that emulate intelligent human behavior. Subfields of AI include machine learning and deep learning. Advances in AI technologies have led to techniques that could increase breast cancer detection, improve clinical efficiency in breast imaging practices, and guide decision-making regarding screening and prevention strategies. This article reviews key terminology and concepts, discusses common AI models and methods to validate and evaluate these models, describes emerging AI applications in breast imaging, and outlines challenges and future directions. Familiarity with AI terminology, concepts, methods, and applications is essential for breast imaging radiologists to critically evaluate these emerging technologies, recognize their strengths and limitations, and ultimately ensure optimal patient care.",
32802272,Methods for sequence and structural analysis of B and T cell receptor repertoires,2020 Jul 17;18:2000-2011.,"B cell receptors (BCRs) and T cell receptors (TCRs) make up an essential network of defense molecules that, collectively, can distinguish self from non-self and facilitate destruction of antigen-bearing cells such as pathogens or tumors. The analysis of BCR and TCR repertoires plays an important role in both basic immunology as well as in biotechnology. Because the repertoires are highly diverse, specialized software methods are needed to extract meaningful information from BCR and TCR sequence data. Here, we review recent developments in bioinformatics tools for analysis of BCR and TCR repertoires, with an emphasis on those that incorporate structural features. After describing the recent sequencing technologies for immune receptor repertoires, we survey structural modeling methods for BCR and TCRs, along with methods for clustering such models. We review downstream analyses, including BCR and TCR epitope prediction, antibody-antigen docking and TCR-peptide-MHC Modeling. We also briefly discuss molecular dynamics in this context.",2.0
32802024,Generative Adversarial Network Technologies and Applications in Computer Vision,2020 Aug 1;2020:1459107.,"Computer vision is one of the hottest research fields in deep learning. The emergence of generative adversarial networks (GANs) provides a new method and model for computer vision. The idea of GANs using the game training method is superior to traditional machine learning algorithms in terms of feature learning and image generation. GANs are widely used not only in image generation and style transfer but also in the text, voice, video processing, and other fields. However, there are still some problems with GANs, such as model collapse and uncontrollable training. This paper deeply reviews the theoretical basis of GANs and surveys some recently developed GAN models, in comparison with traditional GAN models. The applications of GANs in computer vision include data enhancement, domain transfer, high-quality sample generation, and image restoration. The latest research progress of GANs in artificial intelligence (AI) based security attack and defense is introduced. The future development of GANs in computer vision is also discussed at the end of the paper with possible applications of AI in computer vision.",1.0
32800297,Supervised Machine Learning: A Brief Primer,2020 Sep;51(5):675-687.,"Machine learning is increasingly used in mental health research and has the potential to advance our understanding of how to characterize, predict, and treat mental disorders and associated adverse health outcomes (e.g., suicidal behavior). Machine learning offers new tools to overcome challenges for which traditional statistical methods are not well-suited. This paper provides an overview of machine learning with a specific focus on supervised learning (i.e., methods that are designed to predict or classify an outcome of interest). Several common supervised learning methods are described, along with applied examples from the published literature. We also provide an overview of supervised learning model building, validation, and performance evaluation. Finally, challenges in creating robust and generalizable machine learning algorithms are discussed.",2.0
32799353,Research challenges and opportunities for using big data in global change biology,2020 Nov;26(11):6040-6061.,"Global change biology has been entering a big data era due to the vast increase in availability of both environmental and biological data. Big data refers to large data volume, complex data sets, and multiple data sources. The recent use of such big data is improving our understanding of interactions between biological systems and global environmental changes. In this review, we first explore how big data has been analyzed to identify the general patterns of biological responses to global changes at scales from gene to ecosystem. After that, we investigate how observational networks and space-based big data have facilitated the discovery of emergent mechanisms and phenomena on the regional and global scales. Then, we evaluate the predictions of terrestrial biosphere under global changes by big modeling data. Finally, we introduce some methods to extract knowledge from big data, such as meta-analysis, machine learning, traceability analysis, and data assimilation. The big data has opened new research opportunities, especially for developing new data-driven theories for improving biological predictions in Earth system models, tracing global change impacts across different organismic levels, and constructing cyberinfrastructure tools to accelerate the pace of model-data integrations. These efforts will uncork the bottleneck of using big data to understand biological responses and adaptations to future global changes.",
32797983,Use of Machine Learning and Artificial Intelligence to Drive Personalized Medicine Approaches for Spine Care,2020 Aug;140:512-518.,"Personalized medicine is a new paradigm of healthcare in which interventions are based on individual patient characteristics rather than on ""one-size-fits-all"" guidelines. As epidemiological datasets continue to burgeon in size and complexity, powerful methods such as statistical machine learning and artificial intelligence (AI) become necessary to interpret and develop prognostic models from underlying data. Through such analysis, machine learning can be used to facilitate personalized medicine via its precise predictions. Additionally, other AI tools, such as natural language processing and computer vision, can play an instrumental part in personalizing the care provided to patients with spine disease. In the present report, we discuss the current strides made in incorporating AI into research on spine disease, especially traumatic spinal cord injury and degenerative spine disease. We describe studies using AI to build accurate prognostic models, extract important information from medical reports via natural language processing, and evaluate functional status in a granular manner using computer vision. Through a case illustration, we have demonstrated how these breakthroughs can facilitate an increased role for more personalized medicine and, thus, change the landscape of spine care.",
32797044,Machine Learning based histology phenotyping to investigate the epidemiologic and genetic basis of adipocyte morphology and cardiometabolic traits,2020 Aug 14;16(8):e1008044.,"Genetic studies have recently highlighted the importance of fat distribution, as well as overall adiposity, in the pathogenesis of obesity-associated diseases. Using a large study (n = 1,288) from 4 independent cohorts, we aimed to investigate the relationship between mean adipocyte area and obesity-related traits, and identify genetic factors associated with adipocyte cell size. To perform the first large-scale study of automatic adipocyte phenotyping using both histological and genetic data, we developed a deep learning-based method, the Adipocyte U-Net, to rapidly derive mean adipocyte area estimates from histology images. We validate our method using three state-of-the-art approaches; CellProfiler, Adiposoft and floating adipocytes fractions, all run blindly on two external cohorts. We observe high concordance between our method and the state-of-the-art approaches (Adipocyte U-net vs. CellProfiler: R2visceral = 0.94, P < 2.2 × 10-16, R2subcutaneous = 0.91, P < 2.2 × 10-16), and faster run times (10,000 images: 6mins vs 3.5hrs). We applied the Adipocyte U-Net to 4 cohorts with histology, genetic, and phenotypic data (total N = 820). After meta-analysis, we found that mean adipocyte area positively correlated with body mass index (BMI) (Psubq = 8.13 × 10-69, βsubq = 0.45; Pvisc = 2.5 × 10-55, βvisc = 0.49; average R2 across cohorts = 0.49) and that adipocytes in subcutaneous depots are larger than their visceral counterparts (Pmeta = 9.8 × 10-7). Lastly, we performed the largest GWAS and subsequent meta-analysis of mean adipocyte area and intra-individual adipocyte variation (N = 820). Despite having twice the number of samples than any similar study, we found no genome-wide significant associations, suggesting that larger sample sizes and a homogenous collection of adipose tissue are likely needed to identify robust genetic associations.",
32793285,A Review on the Challenges in Indian Genomics Research for Variant Identification and Interpretation,2020 Jul 22;11:753.,"Today, genomic data holds great potential to improve healthcare strategies across various dimensions - be it disease prevention, enhanced diagnosis, or optimized treatment. The biggest hurdle faced by the medical and research community in India is the lack of genotype-phenotype correlations for Indians at a population-wide and an individual level. This leads to inefficient translation of genomic information during clinical decision making. Population-wide sequencing projects for Indian genomes help overcome hurdles and enable us to unearth and validate the genetic markers for different health conditions. Machine learning algorithms are essential to analyze huge amounts of genotype data in synergy with gene expression, demographic, clinical, and pathological data. Predictive models developed through these algorithms help in classifying the individuals into different risk groups, so that preventive measures and personalized therapies can be designed. They also help in identifying the impact of each genetic marker with the associated condition, from a clinical perspective. In India, genome sequencing technologies have now become more accessible to the general population. However, information on variants associated with several major diseases is not available in publicly-accessible databases. Creating a centralized database of variants facilitates early detection and mitigation of health risks in individuals. In this article, we discuss the challenges faced by genetic researchers and genomic testing facilities in India, in terms of dearth of public databases, people with knowledge on machine learning algorithms, computational resources and awareness in the medical community in interpreting genetic variants. Potential solutions to enhance genomic research in India, are also discussed.",
32792177,The Pediatric Difficult Airway: Updates and Innovations,2020 Sep;38(3):459-475.,"Children have unique characteristics that make them particularly vulnerable to perioperative adverse events. Skilled airway management is a cornerstone of high-quality anesthetic management. The use of hybrid airway techniques is a critical tool for the pediatric anesthesiologist. Point-of-care ultrasonography has an expanding role in airway management, from preoperative assessment of airway pathology and gastric contents to confirmation of tracheal intubation and identification of the cricothyroid membrane. The exciting fields of 3-dimensional printing, artificial intelligence, and machine learning are areas of innovation that will transform pediatric difficult airway management in years to come.",
32792129,Radiomics and Artificial Intelligence for Renal Mass Characterization,2020 Sep;58(5):995-1008.,"Radiomics allows for high throughput extraction of quantitative data from images. This is an area of active research as groups try to capture and quantify imaging parameters and convert these into descriptive phenotypes of organs or tumors. Texture analysis is one radiomics tool that extracts information about heterogeneity within a given region of interest. This is used with or without associated machine learning classifiers or a deep learning approach is applied to similar types of data. These tools have shown utility in characterizing renal masses, renal cell carcinoma, and assessing response to targeted therapeutic agents in metastatic renal cell carcinoma.",3.0
32785796,"Radiomics in medical imaging-""how-to"" guide and critical reflection",2020 Aug 12;11(1):91.,"Radiomics is a quantitative approach to medical imaging, which aims at enhancing the existing data available to clinicians by means of advanced mathematical analysis. Through mathematical extraction of the spatial distribution of signal intensities and pixel interrelationships, radiomics quantifies textural information by using analysis methods from the field of artificial intelligence. Various studies from different fields in imaging have been published so far, highlighting the potential of radiomics to enhance clinical decision-making. However, the field faces several important challenges, which are mainly caused by the various technical factors influencing the extracted radiomic features.The aim of the present review is twofold: first, we present the typical workflow of a radiomics analysis and deliver a practical ""how-to"" guide for a typical radiomics analysis. Second, we discuss the current limitations of radiomics, suggest potential improvements, and summarize relevant literature on the subject.",10.0
32784652,Practice of Simulation and Life Cycle Assessment in Tribology-A Review,2020 Aug 7;13(16):3489.,"To simulate today's complex tribo-contact scenarios, a methodological breakdown of a complex design problem into simpler sub-problems is essential to achieve acceptable simulation outcomes. This also helps to manage iterative, hierarchical systems within given computational power. In this paper, the authors reviewed recent trends of simulation practices in tribology to model tribo-contact scenario and life cycle assessment (LCA) with the help of simulation. With the advancement of modern computers and computing power, increasing effort has been given towards simulation, which not only saves time and resources but also provides meaningful results. Having said that, like every other technique, simulation has some inherent limitations which need to be considered during practice. Keeping this in mind, the pros and cons of both physical experiments and simulation approaches are reviewed together with their interdependency and how one approach can benefit the other. Various simulation techniques are outlined with a focus on machine learning which will dominate simulation approaches in the future. In addition, simulation of tribo-contacts across different length scales and lubrication conditions is discussed in detail. An extension of the simulation approach, together with experimental data, can lead towards LCA of components which will provide us with a better understanding of the efficient usage of limited resources and conservation of both energy and resources.",1.0
32784445,Computational Methods for Predicting Functions at the mRNA Isoform Level,2020 Aug 8;21(16):5686.,"Multiple mRNA isoforms of the same gene are produced via alternative splicing, a biological mechanism that regulates protein diversity while maintaining genome size. Alternatively spliced mRNA isoforms of the same gene may sometimes have very similar sequence, but they can have significantly diverse effects on cellular function and regulation. The products of alternative splicing have important and diverse functional roles, such as response to environmental stress, regulation of gene expression, human heritable, and plant diseases. The mRNA isoforms of the same gene can have dramatically different functions. Despite the functional importance of mRNA isoforms, very little has been done to annotate their functions. The recent years have however seen the development of several computational methods aimed at predicting mRNA isoform level biological functions. These methods use a wide array of proteo-genomic data to develop machine learning-based mRNA isoform function prediction tools. In this review, we discuss the computational methods developed for predicting the biological function at the individual mRNA isoform level.",1.0
32783626,"Functional cardiac CT-Going beyond Anatomical Evaluation of Coronary Artery Disease with Cine CT, CT-FFR, CT Perfusion and Machine Learning",2020 Sep 1;93(1113):20200349.,"The aim of this review is to provide an overview of different functional cardiac CT techniques which can be used to supplement assessment of the coronary arteries to establish the significance of coronary artery stenoses. We focus on cine-CT, CT-FFR, CT-myocardial perfusion and how developments in machine learning can supplement these techniques.",1.0
32783560,"Machine Learning in Radiomic Renal Mass Characterization: Fundamentals, Applications, Challenges, and Future Directions",2020 Oct;215(4):920-928.,"OBJECTIVE. The purpose of this study is to provide an overview of the traditional machine learning (ML)-based and deep learning-based radiomic approaches, with focus placed on renal mass characterization. CONCLUSION. ML currently has a very low barrier to entry into general medical practice because of the availability of many open-source, free, and easy-to-use toolboxes. Therefore, it should not be surprising to see its related applications in renal mass characterization. A wider picture of the previous works might be beneficial to move this field forward.",
32783147,Big Data Approaches in Heart Failure Research,2020 Oct;17(5):213-224.,"Purpose of review:                    The goal of this review is to summarize the state of big data analyses in the study of heart failure (HF). We discuss the use of big data in the HF space, focusing on ""omics"" and clinical data. We address some limitations of this data, as well as their future potential.              Recent findings:                    Omics are providing insight into plasmal and myocardial molecular profiles in HF patients. The introduction of single cell and spatial technologies is a major advance that will reshape our understanding of cell heterogeneity and function as well as tissue architecture. Clinical data analysis focuses on HF phenotyping and prognostic modeling. Big data approaches are increasingly common in HF research. The use of methods designed for big data, such as machine learning, may help elucidate the biology underlying HF. However, important challenges remain in the translation of this knowledge into improvements in clinical care.",
32781750,Antioxidant Potential of Psychotropic Drugs: From Clinical Evidence to In Vitro and In Vivo Assessment and toward a New Challenge for in Silico Molecular Design,2020 Aug 6;9(8):714.,"Due to high oxygen consumption, the brain is particularly vulnerable to oxidative stress, which is considered an important element in the etiopathogenesis of several mental disorders, including schizophrenia, depression and dependencies. Despite the fact that it is not established yet whether oxidative stress is a cause or a consequence of clinic manifestations, the intake of antioxidant supplements in combination with the psychotropic therapy constitutes a valuable solution in patients' treatment. Anyway, some drugs possess antioxidant capacity themselves and this aspect is discussed in this review, focusing on antipsychotics and antidepressants. In the context of a collection of clinical observations, in vitro and in vivo results are critically reported, often highlighting controversial aspects. Finally, a new challenge is discussed, i.e., the possibility of assessing in silico the antioxidant potential of these drugs, exploiting computational chemistry methodologies and machine learning. Despite the physiological environment being incredibly complex and the detection of meaningful oxidative stress biomarkers being all but an easy task, a rigorous and systematic analysis of the structural and reactivity properties of antioxidant drugs seems to be a promising route to better interpret therapeutic outcomes and provide elements for the rational design of novel drugs.",3.0
32781665,Promoter Architecture and Promoter Engineering in Saccharomyces cerevisiae,2020 Aug 6;10(8):320.,"Promoters play an essential role in the regulation of gene expression for fine-tuning genetic circuits and metabolic pathways in Saccharomyces cerevisiae (S. cerevisiae). However, native promoters in S. cerevisiae have several limitations which hinder their applications in metabolic engineering. These limitations include an inadequate number of well-characterized promoters, poor dynamic range, and insufficient orthogonality to endogenous regulations. Therefore, it is necessary to perform promoter engineering to create synthetic promoters with better properties. Here, we review recent advances related to promoter architecture, promoter engineering and synthetic promoter applications in S. cerevisiae. We also provide a perspective of future directions in this field with an emphasis on the recent advances of machine learning based promoter designs.",3.0
32778984,Challenge-Enabled Machine Learning to Drug-Response Prediction,2020 Aug 10;22(5):106.,"In recent decades, the advancement of computational algorithms and the availability of big data have enabled artificial intelligence (AI) to dramatically improve predictive performance in nearly all research areas. Specifically, machine learning (ML) techniques, a major branch of AI, have been widely used in many tasks of drug discovery and development, including predicting treatment effects, identifying target genes and functional pathways, as well as selecting potential biomarkers. However, in practice, blindly applying ML methods may lead to common pitfalls, including overfitting and lack of generalizability. Therefore, how to improve the robustness and prediction accuracy of ML methods has become a crucial problem for researchers. In this review, we summarize the application of ML models to drug discovery by introducing the top-performing methods developed from large-scale drug-related data challenges in recent years.",
32777930,Artificial Intelligence in plastic surgery: What is it? Where are we now? What is on the horizon?,2020 Oct;102(8):577-580.,"Introduction:                    An increasing quantity of data is required to guide precision medicine and advance future healthcare practices, but current analytical methods often become overwhelmed. Artificial intelligence (AI) provides a promising solution. Plastic surgery is an innovative surgical specialty expected to implement AI into current and future practices. It is important for all plastic surgeons to understand how AI may affect current and future practice, and to recognise its potential limitations.              Methods:                    Peer-reviewed published literature and online content were comprehensively reviewed. We report current applications of AI in plastic surgery and possible future applications based on published literature and continuing scientific studies, and detail its potential limitations and ethical considerations.              Findings:                    Current machine learning models using convolutional neural networks can evaluate breast mammography and differentiate benign and malignant tumours as accurately as specialist doctors, and motion sensor surgical instruments can collate real-time data to advise intraoperative technical adjustments. Centralised big data portals are expected to collate large datasets to accelerate understanding of disease pathogeneses and best practices. Information obtained using computer vision could guide intraoperative surgical decisions in unprecedented detail and semi-autonomous surgical systems guided by AI algorithms may enable improved surgical outcomes in low- and middle-income countries. Surgeons must collaborate with computer scientists to ensure that AI algorithms inform clinically relevant health objectives and are interpretable. Ethical concerns such as systematic biases causing non-representative conclusions for under-represented patient groups, patient confidentiality and the limitations of AI based on the quality of data input suggests that AI will accompany the plastic surgeon, rather than replace them.",
32776259,Neoadjuvant therapy in pancreatic cancer: what is the true oncological benefit?,2020 Nov;405(7):879-887.,"Background:                    Neoadjuvant therapies (neoTx) have revolutionized the treatment of borderline resectable (BR) and locally advanced (LA) pancreatic cancer (PCa) by significantly increasing the rate of R0 resections, which remains the only curative strategy for these patients. However, there is still room for improvement of neoTx in PCa.              Purpose:                    Here, we aimed to critically analyze the benefits of neoTx in LA and BR PCa and its potential use on patients with resectable PCa. We also explored the feasibility of arterial resection (AR) to increase surgical radicality and the incorporation of immunotherapy to optimize neoadjuvant approaches in PCa.              Conclusion:                    For early stage, i.e., resectable, PCa, there is not enough scientific evidence for routinely recommending neoTx. For LA and BR PCa, optimization of neoadjuvant therapy necessitates more sophisticated complex surgical resections, machine learning and radiomic approaches, integration of immunotherapy due to the high antigen load, standardized histopathological assessment, and improved multidisciplinary communication.",
32774791,Limitations and challenges in protein stability prediction upon genome variations: towards future applications in precision medicine,2020 Jul 24;18:1968-1979.,"Protein stability predictions are becoming essential in medicine to develop novel immunotherapeutic agents and for drug discovery. Despite the large number of computational approaches for predicting the protein stability upon mutation, there are still critical unsolved problems: 1) the limited number of thermodynamic measurements for proteins provided by current databases; 2) the large intrinsic variability of ΔΔG values due to different experimental conditions; 3) biases in the development of predictive methods caused by ignoring the anti-symmetry of ΔΔG values between mutant and native protein forms; 4) over-optimistic prediction performance, due to sequence similarity between proteins used in training and test datasets. Here, we review these issues, highlighting new challenges required to improve current tools and to achieve more reliable predictions. In addition, we provide a perspective of how these methods will be beneficial for designing novel precision medicine approaches for several genetic disorders caused by mutations, such as cancer and neurodegenerative diseases.",4.0
32771905,Sequencing enabling design and learning in synthetic biology,2020 Oct;58:54-62.,"The ability to read and quantify nucleic acids such as DNA and RNA using sequencing technologies has revolutionized our understanding of life. With the emergence of synthetic biology, these tools are now being put to work in new ways - enabling de novo biological design. Here, we show how sequencing is supporting the creation of a new wave of biological parts and systems, as well as providing the vast data sets needed for the machine learning of design rules for predictive bioengineering. However, we believe this is only the tip of the iceberg and end by providing an outlook on recent advances that will likely broaden the role of sequencing in synthetic biology and its deployment in real-world environments.",
32771864,Circadian clock effects on cellular proliferation: Insights from theory and experiments,2020 Dec;67:17-26.,"Oscillations of the cellular circadian clock have emerged as an important regulator of many physiological processes, both in health and in disease. One such process, cellular proliferation, is being increasingly recognized to be affected by the circadian clock. Here, we review how a combination of experimental and theoretical work has furthered our understanding of the way circadian clocks couple to the cell cycle and play a role in tissue homeostasis and cancer. Finally, we discuss recently introduced methods for modeling coupling of clocks based on techniques from survival analysis and machine learning and highlight their potential importance for future studies.",2.0
32770165,Digital technologies in the public-health response to COVID-19,2020 Aug;26(8):1183-1192.,"Digital technologies are being harnessed to support the public-health response to COVID-19 worldwide, including population surveillance, case identification, contact tracing and evaluation of interventions on the basis of mobility data and communication with the public. These rapid responses leverage billions of mobile phones, large online datasets, connected devices, relatively low-cost computing resources and advances in machine learning and natural language processing. This Review aims to capture the breadth of digital innovations for the public-health response to COVID-19 worldwide and their limitations, and barriers to their implementation, including legal, ethical and privacy barriers, as well as organizational and workforce barriers. The future of public health is likely to become increasingly digital, and we review the need for the alignment of international strategies for the regulation, evaluation and use of digital technologies to strengthen pandemic management, and future preparedness for COVID-19 and other infectious diseases.",42.0
32768685,From genetics to epigenetics to unravel the etiology of adolescent idiopathic scoliosis,2020 Nov;140:115563.,"Scoliosis is defined as the three-dimensional (3D) structural deformity of the spine with a radiological lateral Cobb angle (a measure of spinal curvature) of ≥10° that can be caused by congenital, developmental or degenerative problems. However, those cases whose etiology is still unknown, and affect healthy children and adolescents during growth, are the commonest form of spinal deformity, known as adolescent idiopathic scoliosis (AIS). In AIS management, early diagnosis and the accurate prediction of curve progression are most important because they can decrease negative long-term effects of AIS treatment, such as unnecessary bracing, frequent exposure to radiation, as well as saving the high costs of AIS treatment. Despite efforts made to identify a method or technique capable of predicting AIS progression, this challenge still remains unresolved. Genetics and epigenetics, and the application of machine learning and artificial intelligence technologies, open up new avenues to not only clarify AIS etiology, but to also identify potential biomarkers that can substantially improve the clinical management of these patients. This review presents the most relevant biomarkers to help explain the etiopathogenesis of AIS and provide new potential biomarkers to be validated in large clinical trials so they can be finally implemented into clinical settings.",
32768446,Clinical concept extraction: A methodology review,2020 Sep;109:103526.,"Background:                    Concept extraction, a subdomain of natural language processing (NLP) with a focus on extracting concepts of interest, has been adopted to computationally extract clinical information from text for a wide range of applications ranging from clinical decision support to care quality improvement.              Objectives:                    In this literature review, we provide a methodology review of clinical concept extraction, aiming to catalog development processes, available methods and tools, and specific considerations when developing clinical concept extraction applications.              Methods:                    Based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines, a literature search was conducted for retrieving EHR-based information extraction articles written in English and published from January 2009 through June 2019 from Ovid MEDLINE In-Process & Other Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science, and the ACM Digital Library.              Results:                    A total of 6,686 publications were retrieved. After title and abstract screening, 228 publications were selected. The methods used for developing clinical concept extraction applications were discussed in this review.",2.0
32767227,Emerging Clinical Technology: Application of Machine Learning to Chronic Pain Assessments Based on Emotional Body Maps,2020 Jul;17(3):774-783.,"Depression and anxiety co-occur with chronic pain, and all three are thought to be caused by dysregulation of shared brain systems related to emotional processing associated with body sensations. Understanding the connection between emotional states, pain, and bodily sensations may help understand chronic pain conditions. We developed a mobile platform for measuring pain, emotions, and associated bodily feelings in chronic pain patients in their daily life conditions. Sixty-five chronic back pain patients reported the intensity of their pain, 11 emotional states, and the corresponding body locations. These variables were used to predict pain 2 weeks later. Applying machine learning, we developed two predictive models of future pain, emphasizing interpretability. One model excluded pain-related features as predictors of future pain, and the other included pain-related predictors. The best predictors of future pain were interactive effects of (a) body maps of fatigue with negative affect and (b) positive affect with past pain. Our findings emphasize the contribution of emotions, especially emotional experience felt in the body, to understanding chronic pain above and beyond the mere tracking of pain levels. The results may contribute to the generation of a novel artificial intelligence framework to help in the development of better diagnostic and therapeutic approaches to chronic pain.",1.0
32767134,Predicting Absenteeism and Temporary Disability Using Machine Learning: a Systematic Review and Analysis,2020 Aug 7;44(9):162.,"The main objective of this paper is to present a systematic analysis and review of the state of the art regarding the prediction of absenteeism and temporary incapacity using machine learning techniques. Moreover, the main contribution of this research is to reveal the most successful prediction models available in the literature. A systematic review of research papers published from 2010 to the present, related to the prediction of temporary disability and absenteeism in available in different research databases, is presented in this paper. The review focuses primarily on scientific databases such as Google Scholar, Science Direct, IEEE Xplore, Web of Science, and ResearchGate. A total of 58 articles were obtained from which, after removing duplicates and applying the search criteria, 18 have been included in the review. In total, 44% of the articles were published in 2019, representing a significant growth in scientific work regarding these indicators. This study also evidenced the interest of several countries. In addition, 56% of the articles were found to base their study on regression methods, 33% in classification, and 11% in grouping. After this systematic review, the efficiency and usefulness of artificial neural networks in predicting absenteeism and temporary incapacity are demonstrated. The studies regarding absenteeism and temporary disability at work are mainly conducted in Brazil and India, which are responsible for 44% of the analyzed papers followed by Saudi Arabia, and Australia which represented 22%. ANNs are the most used method in both classification and regression models representing 83% and 80% of the analyzed works, respectively. Only 10% of the literature use SVM, which is the less used method in regression models. Moreover, Naïve Bayes is the less used method in classification models representing 17%.",
32766229,"Automation, Monitoring, and Standardization of Cell Product Manufacturing",2020 Jul 14;8:811.,"Although regenerative medicine products are at the forefront of scientific research, technological innovation, and clinical translation, their reproducibility and large-scale production are compromised by automation, monitoring, and standardization issues. To overcome these limitations, new technologies at software (e.g., algorithms and artificial intelligence models, combined with imaging software and machine learning techniques) and hardware (e.g., automated liquid handling, automated cell expansion bioreactor systems, automated colony-forming unit counting and characterization units, and scalable cell culture plates) level are under intense investigation. Automation, monitoring and standardization should be considered at the early stages of the developmental cycle of cell products to deliver more robust and effective therapies and treatment plans to the bedside, reducing healthcare expenditure and improving services and patient care.",4.0
32765975,Machine learning: A powerful tool for gene function prediction in plants,2020 Jul 28;8(7):e11376.,"Recent advances in sequencing and informatic technologies have led to a deluge of publicly available genomic data. While it is now relatively easy to sequence, assemble, and identify genic regions in diploid plant genomes, functional annotation of these genes is still a challenge. Over the past decade, there has been a steady increase in studies utilizing machine learning algorithms for various aspects of functional prediction, because these algorithms are able to integrate large amounts of heterogeneous data and detect patterns inconspicuous through rule-based approaches. The goal of this review is to introduce experimental plant biologists to machine learning, by describing how it is currently being used in gene function prediction to gain novel biological insights. In this review, we discuss specific applications of machine learning in identifying structural features in sequenced genomes, predicting interactions between different cellular components, and predicting gene function and organismal phenotypes. Finally, we also propose strategies for stimulating functional discovery using machine learning-based approaches in plants.",3.0
32765399,The Role of Magnetic Resonance Imaging for the Diagnosis of Atypical Parkinsonism,2020 Jul 17;11:665.,"The diagnosis of Parkinson's disease and atypical Parkinsonism remains clinically difficult, especially at the early stage of the disease, since there is a significant overlap of symptoms. Multimodal MRI has significantly improved diagnostic accuracy and understanding of the pathophysiology of Parkinsonian disorders. Structural and quantitative MRI sequences provide biomarkers sensitive to different tissue properties that detect abnormalities specific to each disease and contribute to the diagnosis. Machine learning techniques using these MRI biomarkers can effectively differentiate atypical Parkinsonian syndromes. Such approaches could be implemented in a clinical environment and improve the management of Parkinsonian patients. This review presents different structural and quantitative MRI techniques, their contribution to the differential diagnosis of atypical Parkinsonian disorders and their interest for individual-level diagnosis.",1.0
32763886,Conversational Agents in Health Care: Scoping Review and Conceptual Analysis,2020 Aug 7;22(8):e17158.,"Background:                    Conversational agents, also known as chatbots, are computer programs designed to simulate human text or verbal conversations. They are increasingly used in a range of fields, including health care. By enabling better accessibility, personalization, and efficiency, conversational agents have the potential to improve patient care.              Objective:                    This study aimed to review the current applications, gaps, and challenges in the literature on conversational agents in health care and provide recommendations for their future research, design, and application.              Methods:                    We performed a scoping review. A broad literature search was performed in MEDLINE (Medical Literature Analysis and Retrieval System Online; Ovid), EMBASE (Excerpta Medica database; Ovid), PubMed, Scopus, and Cochrane Central with the search terms ""conversational agents,"" ""conversational AI,"" ""chatbots,"" and associated synonyms. We also searched the gray literature using sources such as the OCLC (Online Computer Library Center) WorldCat database and ResearchGate in April 2019. Reference lists of relevant articles were checked for further articles. Screening and data extraction were performed in parallel by 2 reviewers. The included evidence was analyzed narratively by employing the principles of thematic analysis.              Results:                    The literature search yielded 47 study reports (45 articles and 2 ongoing clinical trials) that matched the inclusion criteria. The identified conversational agents were largely delivered via smartphone apps (n=23) and used free text only as the main input (n=19) and output (n=30) modality. Case studies describing chatbot development (n=18) were the most prevalent, and only 11 randomized controlled trials were identified. The 3 most commonly reported conversational agent applications in the literature were treatment and monitoring, health care service support, and patient education.              Conclusions:                    The literature on conversational agents in health care is largely descriptive and aimed at treatment and monitoring and health service support. It mostly reports on text-based, artificial intelligence-driven, and smartphone app-delivered conversational agents. There is an urgent need for a robust evaluation of diverse health care conversational agents' formats, focusing on their acceptability, safety, and effectiveness.",7.0
32763775,"Prediction on critically ill patients: The role of ""big data""",2020 Dec;60:64-68.,"Accurate outcome prediction in Intensive Care Units (ICUs) would allow for better treatment planning, risk adjustment of study populations, and overall improvements in patient care. In the past, prognostic models have focused on mortality using simple ordinal severity of illness scores which could be tabulated manually by a human. With the improvements in computing power and proliferation of electronic medical records, entirely new approaches have become possible. Here we review the latest advances in outcome prediction, paying close attention to methods which are widely applicable and provide a high-level overview of the challenges the field currently faces.",
32763220,Modern diagnostic technologies for HIV,2020 Aug;7(8):e574-e581.,"Novel diagnostic technologies, including nanotechnology, microfluidics, -omics science, next-generation sequencing, genomics big data, and machine learning, could contribute to meeting the UNAIDS 95-95-95 targets to end the HIV epidemic by 2030. Novel technologies include multiplexed technologies (including biomarker-based point-of-care tests and molecular platform technologies), biomarker-based combination antibody and antigen technologies, dried-blood-spot testing, and self-testing. Although biomarker-based rapid tests, in particular antibody-based tests, have dominated HIV diagnostics since the development of the first HIV test in the mid-1980s, targets such as nucleic acids and genes are now used in nanomedicine, biosensors, microfluidics, and -omics to enable early diagnosis of HIV. These novel technologies show promise as they are associated with ease of use, high diagnostic accuracy, rapid detection, and the ability to detect HIV-specific markers. Additional clinical and implementation research is needed to generate evidence for use of novel technologies and a public health approach will be required to address clinical and operational challenges to optimise their global deployment.",
32762970,EHR Integration of PAP Devices in Sleep Medicine Implementation in the Clinical Setting,2020 Sep;15(3):377-382.,Positive airway pressure (PAP) therapy integration is a component of electronic health record (EHR) sleep medicine optimization. EHR optimization facilitates telehealth in continuous care population health. A coordinated care plan can leverage early telehealth interventions.,
32761550,Machine learning for predicting long-term kidney allograft survival: a scoping review,2021 May;190(2):807-817.,"Supervised machine learning (ML) is a class of algorithms that ""learn"" from existing input-output pairs, which is gaining popularity in pattern recognition for classification and prediction problems. In this scoping review, we examined the use of supervised ML algorithms for the prediction of long-term allograft survival in kidney transplant recipients. Data sources included PubMed, the Cumulative Index to Nursing and Allied Health Literature, and the Institute for Electrical and Electronics Engineers (IEEE) Xplore libraries from inception to November 2019. We screened titles and abstracts and potentially eligible full-text reports to select studies and subsequently abstracted the data. Eleven studies were identified. Decision trees were the most commonly used method (n = 8), followed by artificial neural networks (ANN) (n = 4) and Bayesian belief networks (n = 2). The area under receiver operating curve (AUC) was the most common measure of discrimination (n = 7), followed by sensitivity (n = 5) and specificity (n = 4). Model calibration examining the reliability in risk prediction was performed using either the Pearson r or the Hosmer-Lemeshow test in four studies. One study showed that logistic regression had comparable performance to ANN, while another study demonstrated that ANN performed better in terms of sensitivity, specificity, and accuracy, as compared with a Cox proportional hazards model. We synthesized the evidence related to the comparison of ML techniques with traditional statistical approaches for prediction of long-term allograft survival in patients with a kidney transplant. The methodological and reporting quality of included studies was poor. Our study also demonstrated mixed results in terms of the predictive potential of the models.",
32760624,Artificial Intelligence: Is It Armageddon for Breast Radiologists?,2020 Jun 30;12(6):e8923.,"Artificial Intelligence (AI) has taken radiology by storm, in particular, mammogram interpretation, and we have seen a recent surge in the number of publications on potential uses of AI in breast radiology. Breast cancer exerts a lot of burden on the National Health Service (NHS) and is the second most common cancer in the UK as of 2018. New cases of breast cancer have been on the rise in the past decade, while the survival rate has been improving. The NHS breast cancer screening program led to an improvement in survival rate. The expansion of the screening program led to more mammograms, thereby putting more work on the hands of radiologists, and the issue of double reading further worsens the workload. The introduction of computer-aided detection (CAD) systems to help radiologists was found not to have the expected outcome of improving the performance of readers. Unreliability of CAD systems has led to the explosion of studies and development of applications with the potential use in breast imaging. The purported success recorded with the use of machine learning in breast radiology has led to people postulating ideas that AI will replace breast radiologists. Of course, AI has many applications and potential uses in radiology, but will it replace radiologists? We reviewed many articles on the use of AI in breast radiology to give future radiologists and radiologists full information on this topic. This article focuses on explaining the basic principles and terminology of AI in radiology, potential uses, and limitations of AI in radiology. We have also analysed articles and answered the question of whether AI will replace radiologists.",
32757950,Artificial Intelligence Solutions for Analysis of X-ray Images,2021 Feb;72(1):60-72.,"Artificial intelligence (AI) presents a key opportunity for radiologists to improve quality of care and enhance the value of radiology in patient care and population health. The potential opportunity of AI to aid in triage and interpretation of conventional radiographs (X-ray images) is particularly significant, as radiographs are the most common imaging examinations performed in most radiology departments. Substantial progress has been made in the past few years in the development of AI algorithms for analysis of chest and musculoskeletal (MSK) radiographs, with deep learning now the dominant approach for image analysis. Large public and proprietary image data sets have been compiled and have aided the development of AI algorithms for analysis of radiographs, many of which demonstrate accuracy equivalent to radiologists for specific, focused tasks. This article describes (1) the basis for the development of AI solutions for radiograph analysis, (2) current AI solutions to aid in the triage and interpretation of chest radiographs and MSK radiographs, (3) opportunities for AI to aid in noninterpretive tasks related to radiographs, and (4) considerations for radiology practices selecting AI solutions for radiograph analysis and integrating them into existing IT systems. Although comprehensive AI solutions across modalities have yet to be developed, institutions can begin to select and integrate focused solutions which increase efficiency, increase quality and patient safety, and add value for their patients.",
32754606,Artificial Intelligence in Cutaneous Oncology,2020 Jul 10;7:318.,"Skin cancer, previously known to be a common disease in Western countries, is becoming more common in Asian countries. Skin cancer differs from other carcinomas in that it is visible to our eyes. Although skin biopsy is essential for the diagnosis of skin cancer, decisions regarding whether or not to conduct a biopsy are made by an experienced dermatologist. From this perspective, it is easy to obtain and store photos using a smartphone, and artificial intelligence technologies developed to analyze these photos can represent a useful tool to complement the dermatologist's knowledge. In addition, the universal use of dermoscopy, which allows for non-invasive inspection of the upper dermal level of skin lesions with a usual 10-fold magnification, adds to the image storage and analysis techniques, foreshadowing breakthroughs in skin cancer diagnosis. Current problems include the inaccuracy of the available technology and resulting legal liabilities. This paper presents a comprehensive review of the clinical applications of artificial intelligence and a discussion on how it can be implemented in the field of cutaneous oncology.",
32754171,Systematic Multi-Omics Integration (MOI) Approach in Plant Systems Biology,2020 Jun 26;11:944.,"Across all facets of biology, the rapid progress in high-throughput data generation has enabled us to perform multi-omics systems biology research. Transcriptomics, proteomics, and metabolomics data can answer targeted biological questions regarding the expression of transcripts, proteins, and metabolites, independently, but a systematic multi-omics integration (MOI) can comprehensively assimilate, annotate, and model these large data sets. Previous MOI studies and reviews have detailed its usage and practicality on various organisms including human, animals, microbes, and plants. Plants are especially challenging due to large poorly annotated genomes, multi-organelles, and diverse secondary metabolites. Hence, constructive and methodological guidelines on how to perform MOI for plants are needed, particularly for researchers newly embarking on this topic. In this review, we thoroughly classify multi-omics studies on plants and verify workflows to ensure successful omics integration with accurate data representation. We also propose three levels of MOI, namely element-based (level 1), pathway-based (level 2), and mathematical-based integration (level 3). These MOI levels are described in relation to recent publications and tools, to highlight their practicality and function. The drawbacks and limitations of these MOI are also discussed for future improvement toward more amenable strategies in plant systems biology.",6.0
32750971,Machine Learning Techniques for Ophthalmic Data Processing: A Review,2020 Dec;24(12):3338-3350.,"Machine learning and especially deep learning techniques are dominating medical image and data analysis. This article reviews machine learning approaches proposed for diagnosing ophthalmic diseases during the last four years. Three diseases are addressed in this survey, namely diabetic retinopathy, age-related macular degeneration, and glaucoma. The review covers over 60 publications and 25 public datasets and challenges related to the detection, grading, and lesion segmentation of the three considered diseases. Each section provides a summary of the public datasets and challenges related to each pathology and the current methods that have been applied to the problem. Furthermore, the recent machine learning approaches used for retinal vessels segmentation, and methods of retinal layers and fluid segmentation are reviewed. Two main imaging modalities are considered in this survey, namely color fundus imaging, and optical coherence tomography. Machine learning approaches that use eye measurements and visual field data for glaucoma detection are also included in the survey. Finally, the authors provide their views, expectations and the limitations of the future of these techniques in the clinical practice.",
32749209,Cardiovascular CT and MRI in 2019: Review of Key Articles,2020 Oct;297(1):17-30.,"Cardiac imaging is becoming commonplace throughout radiology practices and is increasingly important in large-cohort prospective cardiovascular trials and in statements and guidelines. In this review, the authors summarize some of the most important imaging findings relevant to clinical practice in the past year. Key coronary CT angiography studies have included rigorous meta-analysis of its diagnostic accuracy, prognostic implications of adverse coronary plaque features, and sex differences. The value of CT for catheter-delivered valve implantation (eg, transcatheter aortic and mitral valve replacements) was further elucidated in large-cohort outcome trials. Hypertrophic cardiomyopathy registries have revealed distinct clinical and MRI phenotypes, highlighting different underlying causes, while others clarified the prognostic usefulness of MRI in hypertrophic cardiomyopathy and Fabry disease. Artificial intelligence and/or machine learning was applied to many aspects of cardiovascular imaging, while evidence of the benefits of both adenosine stress perfusion cardiac MRI and coronary CT angiography-derived fractional flow reserve from real-world trials has increased. Studies on vaping and vascular endothelial function and the whole-body MRI depiction of metabolic syndrome consequences were also noteworthy. Although this review focuses on Radiology articles, key articles from high-impact clinical journals are also included. Although not possible to detail all articles because of space limitations, the authors attempted to highlight those with the most pragmatic and scientific value.",
32745966,COPD phenotypes and machine learning cluster analysis: A systematic review and future research agenda,2020 Sep;171:106093.,"Chronic Obstructive Pulmonary Disease (COPD) is a highly heterogeneous condition projected to become the third leading cause of death worldwide by 2030. To better characterize this condition, clinicians have classified patients sharing certain symptomatic characteristics, such as symptom intensity and history of exacerbations, into distinct phenotypes. In recent years, the growing use of machine learning algorithms, and cluster analysis in particular, has promised to advance this classification through the integration of additional patient characteristics, including comorbidities, biomarkers, and genomic information. This combination would allow researchers to more reliably identify new COPD phenotypes, as well as better characterize existing ones, with the aim of improving diagnosis and developing novel treatments. Here, we systematically review the last decade of research progress, which uses cluster analysis to identify COPD phenotypes. Collectively, we provide a systematized account of the extant evidence, describe the strengths and weaknesses of the main methods used, identify gaps in the literature, and suggest recommendations for future research.",1.0
32740678,Utility of Artificial Intelligence Amidst the COVID 19 Pandemic: A Review,2020 Aug 1;44(9):156.,"The term machine learning refers to a collection of tools used for identifying patterns in data. As opposed to traditional methods of pattern identification, machine learning tools relies on artificial intelligence to map out patters from large amounts of data, can self-improve as and when new data becomes available and is quicker in accomplishing these tasks. This review describes various techniques of machine learning that have been used in the past in the prediction, detection and management of infectious diseases, and how these tools are being brought into the battle against COVID-19. In addition, we also discuss their applications in various stages of the pandemic, the advantages, disadvantages and possible pit falls.",2.0
32740044,Use of artificial intelligence and machine learning for estimating malignancy risk of thyroid nodules,2020 Oct;27(5):345-350.,"Purpose of review:                    Current methods for thyroid nodule risk stratification are subjective, and artificial intelligence algorithms have been used to overcome this shortcoming. In this review, we summarize recent developments in the application of artificial intelligence algorithms for estimating the risks of malignancy in a thyroid nodule.              Recent findings:                    Artificial intelligence have been used to predict malignancy in thyroid nodules using ultrasound images, cytopathology images, and molecular markers. Recent clinical trials have shown that artificial intelligence model's performance matched that of experienced radiologists and pathologists. Explainable artificial intelligence models are being developed to avoid the black box problem. Risk stratification algorithms using artificial intelligence for thyroid nodules are now commercially available in many countries.              Summary:                    Artificial intelligence models could become a useful tool in a thyroidolgist's armamentarium as a decision support tool. Increased adoption of this emerging technology will depend upon increased awareness of the potential benefits and pitfalls in using artificial intelligence.",
32738777,Machine learning in quantitative PET: A review of attenuation correction and low-count image reconstruction methods,2020 Aug;76:294-306.,"The rapid expansion of machine learning is offering a new wave of opportunities for nuclear medicine. This paper reviews applications of machine learning for the study of attenuation correction (AC) and low-count image reconstruction in quantitative positron emission tomography (PET). Specifically, we present the developments of machine learning methodology, ranging from random forest and dictionary learning to the latest convolutional neural network-based architectures. For application in PET attenuation correction, two general strategies are reviewed: 1) generating synthetic CT from MR or non-AC PET for the purposes of PET AC, and 2) direct conversion from non-AC PET to AC PET. For low-count PET reconstruction, recent deep learning-based studies and the potential advantages over conventional machine learning-based methods are presented and discussed. In each application, the proposed methods, study designs and performance of published studies are listed and compared with a brief discussion. Finally, the overall contributions and remaining challenges are summarized.",3.0
32735493,Artificial Intelligence in Lung Cancer: Bridging the Gap Between Computational Power and Clinical Decision-Making,2021 Feb;72(1):86-97.,"Lung cancer remains the most common cause of cancer death worldwide. Recent advances in lung cancer screening, radiotherapy, surgical techniques, and systemic therapy have led to increasing complexity in diagnosis, treatment decision-making, and assessment of recurrence. Artificial intelligence (AI)-based prediction models are being developed to address these issues and may have a future role in screening, diagnosis, treatment selection, and decision-making around salvage therapy. Imaging plays an essential role in all components of lung cancer management and has the potential to play a key role in AI applications. Artificial intelligence has demonstrated value in prognostic biomarker discovery in lung cancer diagnosis, treatment, and response assessment, putting it at the forefront of the next phase of personalized medicine. However, although exploratory studies demonstrate potential utility, there is a need for rigorous validation and standardization before AI can be utilized in clinical decision-making. In this review, we will provide a summary of the current literature implementing AI for outcome prediction in lung cancer. We will describe the anticipated impact of AI on the management of patients with lung cancer and discuss the challenges of clinical implementation of these techniques.",
32735452,Utilizing Artificial Intelligence for Head and Neck Cancer Outcomes Prediction From Imaging,2021 Feb;72(1):73-85.,"Artificial intelligence (AI)-based models have become a growing area of interest in predictive medicine and have the potential to aid physician decision-making to improve patient outcomes. Imaging and radiomics play an increasingly important role in these models. This review summarizes recent developments in the field of radiomics for AI in head and neck cancer. Prediction models for oncologic outcomes, treatment toxicity, and pathological findings have all been created. Exploratory studies are promising; however, validation studies that demonstrate consistency, reproducibility, and prognostic impact remain uncommon. Prospective clinical trials with standardized procedures are required for clinical translation.",
32734172,"Veterinary informatics: forging the future between veterinary medicine, human medicine, and One Health initiatives-a joint paper by the Association for Veterinary Informatics (AVI) and the CTSA One Health Alliance (COHA)",2020 Apr 11;3(2):306-317.,"Objectives:                    This manuscript reviews the current state of veterinary medical electronic health records and the ability to aggregate and analyze large datasets from multiple organizations and clinics. We also review analytical techniques as well as research efforts into veterinary informatics with a focus on applications relevant to human and animal medicine. Our goal is to provide references and context for these resources so that researchers can identify resources of interest and translational opportunities to advance the field.              Methods and results:                    This review covers various methods of veterinary informatics including natural language processing and machine learning techniques in brief and various ongoing and future projects. After detailing techniques and sources of data, we describe some of the challenges and opportunities within veterinary informatics as well as providing reviews of common One Health techniques and specific applications that affect both humans and animals.              Discussion:                    Current limitations in the field of veterinary informatics include limited sources of training data for developing machine learning and artificial intelligence algorithms, siloed data between academic institutions, corporate institutions, and many small private practices, and inconsistent data formats that make many integration problems difficult. Despite those limitations, there have been significant advancements in the field in the last few years and continued development of a few, key, large data resources that are available for interested clinicians and researchers. These real-world use cases and applications show current and significant future potential as veterinary informatics grows in importance. Veterinary informatics can forge new possibilities within veterinary medicine and between veterinary medicine, human medicine, and One Health initiatives.",1.0
32733918,"Allosteric Regulation at the Crossroads of New Technologies: Multiscale Modeling, Networks, and Machine Learning",2020 Jul 9;7:136.,"Allosteric regulation is a common mechanism employed by complex biomolecular systems for regulation of activity and adaptability in the cellular environment, serving as an effective molecular tool for cellular communication. As an intrinsic but elusive property, allostery is a ubiquitous phenomenon where binding or disturbing of a distal site in a protein can functionally control its activity and is considered as the ""second secret of life."" The fundamental biological importance and complexity of these processes require a multi-faceted platform of synergistically integrated approaches for prediction and characterization of allosteric functional states, atomistic reconstruction of allosteric regulatory mechanisms and discovery of allosteric modulators. The unifying theme and overarching goal of allosteric regulation studies in recent years have been integration between emerging experiment and computational approaches and technologies to advance quantitative characterization of allosteric mechanisms in proteins. Despite significant advances, the quantitative characterization and reliable prediction of functional allosteric states, interactions, and mechanisms continue to present highly challenging problems in the field. In this review, we discuss simulation-based multiscale approaches, experiment-informed Markovian models, and network modeling of allostery and information-theoretical approaches that can describe the thermodynamics and hierarchy allosteric states and the molecular basis of allosteric mechanisms. The wealth of structural and functional information along with diversity and complexity of allosteric mechanisms in therapeutically important protein families have provided a well-suited platform for development of data-driven research strategies. Data-centric integration of chemistry, biology and computer science using artificial intelligence technologies has gained a significant momentum and at the forefront of many cross-disciplinary efforts. We discuss new developments in the machine learning field and the emergence of deep learning and deep reinforcement learning applications in modeling of molecular mechanisms and allosteric proteins. The experiment-guided integrated approaches empowered by recent advances in multiscale modeling, network science, and machine learning can lead to more reliable prediction of allosteric regulatory mechanisms and discovery of allosteric modulators for therapeutically important protein targets.",1.0
32733875,Midbrain Dopaminergic Neuron Development at the Single Cell Level: In vivo and in Stem Cells,2020 Jun 25;8:463.,"Parkinson's disease (PD) is a progressive neurodegenerative disorder that predominantly affects dopaminergic (DA) neurons of the substantia nigra. Current treatment options for PD are symptomatic and typically involve the replacement of DA neurotransmission by DA drugs, which relieve the patients of some of their motor symptoms. However, by the time of diagnosis, patients have already lost about 70% of their substantia nigra DA neurons and these drugs offer only temporary relief. Therefore, cell replacement therapy has garnered much interest as a potential treatment option for PD. Early studies using human fetal tissue for transplantation in PD patients provided proof of principle for cell replacement therapy, but they also highlighted the ethical and practical difficulties associated with using human fetal tissue as a cell source. In recent years, advancements in stem cell research have made human pluripotent stem cells (hPSCs) an attractive source of material for cell replacement therapy. Studies on how DA neurons are specified and differentiated in the developing mouse midbrain have allowed us to recapitulate many of the positional and temporal cues needed to generate DA neurons in vitro. However, little is known about the developmental programs that govern human DA neuron development. With the advent of single-cell RNA sequencing (scRNA-seq) and bioinformatics, it has become possible to analyze precious human samples with unprecedented detail and extract valuable high-quality information from large data sets. This technology has allowed the systematic classification of cell types present in the human developing midbrain along with their gene expression patterns. By studying human development in such an unbiased manner, we can begin to elucidate human DA neuron development and determine how much it differs from our knowledge of the rodent brain. Importantly, this molecular description of the function of human cells has become and will increasingly be a reference to define, evaluate, and engineer cell types for PD cell replacement therapy and disease modeling.",
32729531,Artificial intelligence biosensors: Challenges and prospects,2020 Oct 1;165:112412.,"Artificial intelligence (AI) and wearable sensors are two essential fields to realize the goal of tailoring the best precision medicine treatment for individual patients. Integration of these two fields enables better acquisition of patient data and improved design of wearable sensors for monitoring the wearers' health, fitness and their surroundings. Currently, as the Internet of Things (IoT), big data and big health move from concept to implementation, AI-biosensors with appropriate technical characteristics are facing new opportunities and challenges. In this paper, the most advanced progress made in the key phases for future wearable and implantable technology from biosensing, wearable biosensing to AI-biosensing is summarized. Without a doubt, material innovation, biorecognition element, signal acquisition and transportation, data processing and intelligence decision system are the most important parts, which are the main focus of the discussion. The challenges and opportunities of AI-biosensors moving forward toward future medicine devices are also discussed.",5.0
32729465,Nano-enabled sensing approaches for pathogenic bacterial detection,2020 Oct 1;165:112276.,"Infectious diseases caused by pathogenic bacteria, especially antibiotic-resistant bacteria, are one of the biggest threats to global health. To date, bacterial contamination is detected using conventional culturing techniques, which are highly dependent on expert users, limited by the processing time and on-site availability. Hence, real-time and continuous monitoring of pathogen levels is required to obtain valuable information that could assist health agencies in guiding prevention and containment of pathogen-related outbreaks. Nanotechnology-based smart sensors are opening new avenues for early and rapid detection of such pathogens at the patient's point-of-care. Nanomaterials can play an essential role in bacterial sensing owing to their unique optical, magnetic, and electrical properties. Carbon nanoparticles, metallic nanoparticles, metal oxide nanoparticles, and various types of nanocomposites are examples of smart nanomaterials that have drawn intense attention in the field of microbial detection. These approaches, together with the advent of modern technologies and coupled with machine learning and wireless communication, represent the future trend in the diagnosis of infectious diseases. This review provides an overview of the recent advancements in the successful harnessing of different nanoparticles for bacterial detection. In the beginning, we have introduced the fundamental concepts and mechanisms behind the design and strategies of the nanoparticles-based diagnostic platform. Representative research efforts are highlighted for in vitro and in vivo detection of bacteria. A comprehensive discussion is then presented to cover the most commonly adopted techniques for bacterial identification, including some seminal studies to detect bacteria at the single-cell level. Finally, we discuss the current challenges and a prospective outlook on the field, together with the recommended solutions.",4.0
32729254,Machine learning approaches to study glioblastoma: A review of the last decade of applications,2019 Dec;2(6):e1226.,"Background:                    Glioblastoma (GB, formally glioblastoma multiforme) is a malignant type of brain cancer that currently has no cure and is characterized by being highly heterogeneous with high rates of re-incidence and therapy resistance. Thus, it is urgent to characterize the mechanisms of GB pathogenesis to help researchers identify novel therapeutic targets to cure this devastating disease. Recently, a promising approach to identifying novel therapeutic targets is the integration of tumor omics data with clinical information using machine learning (ML) techniques.              Recent findings:                    ML has become a valuable addition to the researcher's toolbox, thanks to its flexibility, multidimensional approach, and a growing community of users. The goal of this review is to introduce basic concepts and applications of ML for studying GB to clinicians and practitioners who are new to data science. ML applications include exploring large data sets, finding new relevant patterns, predicting outcomes, or merely understanding associations of the complex molecular networks presented within the tumor. Here, we review ML applications published between 2008 and 2018 and discuss ML strategies intending to identify new potential therapeutic targets to improve the management and treatment of GB.              Conclusions:                    ML applications to study GB vary in purpose and complexity, with positive results. In GB studies, ML is often used to analyze high-dimensional datasets with prediction or classification as a primary goal. Despite the strengths of ML techniques, they are not fail-safe and methodological issues can occur in GB studies that use them. This is why researchers need to be aware of these issues when planning and appraising studies that apply ML to the study of GB.",
32728877,Artificial intelligence in radiotherapy: a technological review,2020 Aug;14(4):431-449.,"Radiation therapy (RT) is widely used to treat cancer. Technological advances in RT have occurred in the past 30 years. These advances, such as three-dimensional image guidance, intensity modulation, and robotics, created challenges and opportunities for the next breakthrough, in which artificial intelligence (AI) will possibly play important roles. AI will replace certain repetitive and labor-intensive tasks and improve the accuracy and consistency of others, particularly those with increased complexity because of technological advances. The improvement in efficiency and consistency is important to manage the increasing cancer patient burden to the society. Furthermore, AI may provide new functionalities that facilitate satisfactory RT. The functionalities include superior images for real-time intervention and adaptive and personalized RT. AI may effectively synthesize and analyze big data for such purposes. This review describes the RT workflow and identifies areas, including imaging, treatment planning, quality assurance, and outcome prediction, that benefit from AI. This review primarily focuses on deep-learning techniques, although conventional machine-learning techniques are also mentioned.",
32728875,Deep learning in digital pathology image analysis: a survey,2020 Aug;14(4):470-487.,"Deep learning (DL) has achieved state-of-the-art performance in many digital pathology analysis tasks. Traditional methods usually require hand-crafted domain-specific features, and DL methods can learn representations without manually designed features. In terms of feature extraction, DL approaches are less labor intensive compared with conventional machine learning methods. In this paper, we comprehensively summarize recent DL-based image analysis studies in histopathology, including different tasks (e.g., classification, semantic segmentation, detection, and instance segmentation) and various applications (e.g., stain normalization, cell/gland/region structure analysis). DL methods can provide consistent and accurate outcomes. DL is a promising tool to assist pathologists in clinical diagnosis.",1.0
32728829,The Role of Artificial Intelligence in Echocardiography,2020 Jul 30;22(9):99.,"Purpose of review:                    Echocardiography is an indispensable tool in diagnostic cardiology and is fundamental to clinical care. Significant advances in cardiovascular imaging technology paralleled by rapid growth in electronic medical records, miniaturized devices, real-time monitoring, and wearable devices using body sensor network technology have led to the development of complex data.              Recent findings:                    The intricate nature of these data can be overwhelming and exceed the capabilities of current statistical software. Machine learning (ML), a branch of artificial intelligence (AI), can help health care providers navigate through this complex labyrinth of information and unravel hidden discoveries. Furthermore, ML algorithms can help automate several tasks in echocardiography and clinical care. ML can serve as a valuable diagnostic tool for physicians in the field of echocardiography. In addition, it can help expand the capabilities of research and discover alternative pathways in medical management. In this review article, we describe the role of AI and ML in echocardiography.",3.0
32728518,Smart diagnostics devices through artificial intelligence and mechanobiological approaches,2020 Aug;10(8):351.,"The present work illustrates the promising intervention of smart diagnostics devices through artificial intelligence (AI) and mechanobiological approaches in health care practices. The artificial intelligence and mechanobiological approaches in diagnostics widen the scope for point of care techniques for the timely revealing of diseases by understanding the biomechanical properties of the tissue of interest. Smart diagnostic device senses the physical parameters due to change in mechanical, biological, and luidic properties of the cells and to control these changes, supply the necessary drugs immediately using AI techniques. The latest techniques like sweat diagnostics to measure the overall health, Photoplethysmography (PPG) for real-time monitoring of pulse waveform by capturing the reflected signal due to blood pulsation), Micro-electromechanical systems (MEMS) and Nano-electromechanical systems (NEMS) smart devices to detect disease at its early stage, lab-on-chip and organ-on-chip technologies, Ambulatory Circadian Monitoring device (ACM), a wrist-worn device for Parkinson's disease have been discussed. The recent and futuristic smart diagnostics tool/techniques like emotion recognition by applying machine learning algorithms, atomic force microscopy that measures the fibrinogen and erythrocytes binding force, smartphone-based retinal image analyser system, image-based computational modeling for various neurological disorders, cardiovascular diseases, tuberculosis, predicting and preventing of Zika virus, optimal drugs and doses for HIV using AI, etc. have been reviewed. The objective of this review is to examine smart diagnostics devices based on artificial intelligence and mechanobiological approaches, with their medical applications in healthcare. This review determines that smart diagnostics devices have potential applications in healthcare, but more research work will be essential for prospective accomplishments of this technology.",
32728381,Machine learning in oncology: a review,2020 Jun 30;14:1065.,"Machine learning is a set of techniques that promise to greatly enhance our data-processing capability. In the field of oncology, ML presents itself with a wealth of possible applications to the research and the clinical context, such as automated diagnosis and precise treatment modulation. In this paper, we will review the principal applications of ML techniques in oncology and explore in detail how they work. This will allow us to discuss the issues and challenges that ML faces in this field, and ultimately gain a greater understanding of ML techniques and how they can improve oncological research and practice.",
32726074,Leveraging Population Genomics for Individualized Correction of the Hallmarks of Alpha-1 Antitrypsin Deficiency,2020 Jul;7(3):224-246.,"Deep medicine is rapidly moving towards a high-definition approach for therapeutic management of the patient as an individual given the rapid progress of genome sequencing technologies and machine learning algorithms. While considered a monogenic disease, alpha-1 antitrypsin (AAT) deficiency (AATD) patients present with complex and variable phenotypes we refer to as the ""hallmarks of AATD"" that involve distinct molecular mechanisms in the liver, plasma and lung tissues, likely due to both coding and non-coding variation as well as genetic and environmental modifiers in different individuals. Herein, we briefly review the current therapeutic strategies for the management of AATD. To embrace genetic diversity in the management of AATD, we provide an overview of the disease phenotypes of AATD patients harboring different AAT variants. Linking genotypic diversity to phenotypic diversity illustrates the potential for sequence-specific regions of AAT protein fold design to play very different roles during nascent synthesis in the liver and/or function in post-liver plasma and lung environments. We illustrate how to manage diversity with recently developed machine learning (ML) approaches that bridge sequence-to-function-to-structure knowledge gaps based on the principle of spatial covariance (SCV). SCV relationships provide a deep understanding of the genotype to phenotype transformation initiated by AAT variation in the population to address the role of genetic and environmental modifiers in the individual. Embracing the complexity of AATD in the population is critical for risk management and therapeutic intervention to generate a high definition medicine approach for the patient.",
32725781,Cheminformatics in Natural Product-based Drug Discovery,2020 Dec;39(12):e2000171.,"This review seeks to provide a timely survey of the scope and limitations of cheminformatics methods in natural product-based drug discovery. Following an overview of data resources of chemical, biological and structural information on natural products, we discuss, among other aspects, in silico methods for (i) data curation and natural products dereplication, (ii) analysis, visualization, navigation and comparison of the chemical space, (iii) quantification of natural product-likeness, (iv) prediction of the bioactivities (virtual screening, target prediction), ADME and safety profiles (toxicity) of natural products, (v) natural products-inspired de novo design and (vi) prediction of natural products prone to cause interference with biological assays. Among the many methods discussed are rule-based, similarity-based, shape-based, pharmacophore-based and network-based approaches, docking and machine learning methods.",8.0
32722605,"A Comparative Systematic Literature Review on Knee Bone Reports from MRI, X-rays and CT Scans Using Deep Learning and Machine Learning Methodologies",2020 Jul 26;10(8):518.,"The purpose of this research was to provide a ""systematic literature review"" of knee bone reports that are obtained by MRI, CT scans, and X-rays by using deep learning and machine learning techniques by comparing different approaches-to perform a comprehensive study on the deep learning and machine learning methodologies to diagnose knee bone diseases by detecting symptoms from X-ray, CT scan, and MRI images. This study will help those researchers who want to conduct research in the knee bone field. A comparative systematic literature review was conducted for the accomplishment of our work. A total of 32 papers were reviewed in this research. Six papers consist of X-rays of knee bone with deep learning methodologies, five papers cover the MRI of knee bone using deep learning approaches, and another five papers cover CT scans of knee bone with deep learning techniques. Another 16 papers cover the machine learning techniques for evaluating CT scans, X-rays, and MRIs of knee bone. This research compares the deep learning methodologies for CT scan, MRI, and X-ray reports on knee bone, comparing the accuracy of each technique, which can be used for future development. In the future, this research will be enhanced by comparing X-ray, CT-scan, and MRI reports of knee bone with information retrieval and big data techniques. The results show that deep learning techniques are best for X-ray, MRI, and CT scan images of the knee bone to diagnose diseases.",2.0
32721487,High pooled performance of convolutional neural networks in computer-aided diagnosis of GI ulcers and/or hemorrhage on wireless capsule endoscopy images: a systematic review and meta-analysis,2021 Feb;93(2):356-364.e4.,"Background and aims:                    Diagnosis of GI ulcers and/or hemorrhage by wireless capsule endoscopy (WCE) is limited by the physician-dependent, tedious, time-consuming process of image and/ or video classification. Computer-aided diagnosis (CAD) by convolutional neural network (CNN)-based machine learning may help reduce this burden. Our aim was to conduct a meta-analysis and appraise the reported data.              Methods:                    Multiple databases were searched (from inception to November 2019), and studies that reported on the performance of CNN in the diagnosis of GI ulcerations and/or hemorrhage on WCE were selected. A random-effects model was used to calculate the pooled rates. In cases where multiple 2 × 2 contingency tables were provided for different thresholds, we assumed the data tables were independent from each other. Heterogeneity was assessed by I2% and 95% prediction intervals.              Results:                    Nine studies were included in our final analysis that evaluated the performance of CNN-based CAD of GI ulcers and/or hemorrhage by WCE. The pooled accuracy was 95.4% (95% confidence interval [CI], 94.3-96.3), sensitivity was 95.5% (95% CI, 94-96.5), specificity was 95.8% (95% CI, 94.7-96.6), positive predictive value was 95.8% (95% CI, 90.5-98.2), and negative predictive value was 96.8% (95% CI, 94.9-98.1). I2% heterogeneity was negligible except for the pooled positive predictive value.              Conclusions:                    Based on our meta-analysis, CNN-based CAD of GI ulcerations and/or hemorrhage on WCE achieves a high-level performance. The quality of the evidence is robust, and therefore CNN-based CAD has the potential to become the first choice of machine learning to optimize WCE image/video reading.",
32717108,Network-based approaches for understanding gene regulation and function in plants,2020 Oct;104(2):302-317.,Expression reprogramming directed by transcription factors is a primary gene regulation underlying most aspects of the biology of any organism. Our views of how gene regulation is coordinated are dramatically changing thanks to the advent and constant improvement of high-throughput profiling and transcriptional network inference methods: from activities of individual genes to functional interactions across genes. These technical and analytical advances can reveal the topology of transcriptional networks in which hundreds of genes are hierarchically regulated by multiple transcription factors at systems level. Here we review the state of the art of experimental and computational methods used in plant biology research to obtain large-scale datasets and model transcriptional networks. Examples of direct use of these network models and perspectives on their limitations and future directions are also discussed.,1.0
32715371,Detecting Seizures and Epileptiform Abnormalities in Acute Brain Injury,2020 Jul 27;20(9):42.,"Purpose of review:                    Acute brain injury (ABI) is a broad category of pathologies, including traumatic brain injury, and is commonly complicated by seizures. Electroencephalogram (EEG) studies are used to detect seizures or other epileptiform patterns. This review seeks to clarify EEG findings relevant to ABI, explore practical barriers limiting EEG implementation, discuss strategies to leverage EEG monitoring in various clinical settings, and suggest an approach to utilize EEG for triage.              Recent findings:                    Current literature suggests there is an increased morbidity and mortality risk associated with seizures or patterns on the ictal-interictal continuum (IIC) due to ABI. Further, increased use of EEG is associated with better clinical outcomes. However, there are many logistical barriers to successful EEG implementation that prohibit its ubiquitous use. Solutions to these limitations include the use of rapid EEG systems, non-expert EEG analysis, machine learning algorithms, and the incorporation of EEG data into prognostic models.",1.0
32715351,Digital Pharmaceutical Sciences,2020 Jul 26;21(6):206.,"Artificial intelligence (AI) and machine learning, in particular, have gained significant interest in many fields, including pharmaceutical sciences. The enormous growth of data from several sources, the recent advances in various analytical tools, and the continuous developments in machine learning algorithms have resulted in a rapid increase in new machine learning applications in different areas of pharmaceutical sciences. This review summarizes the past, present, and potential future impacts of machine learning technologies on different areas of pharmaceutical sciences, including drug design and discovery, preformulation, and formulation. The machine learning methods commonly used in pharmaceutical sciences are discussed, with a specific emphasis on artificial neural networks due to their capability to model the nonlinear relationships that are commonly encountered in pharmaceutical research. AI and machine learning technologies in common day-to-day pharma needs as well as industrial and regulatory insights are reviewed. Beyond traditional potentials of implementing digital technologies using machine learning in the development of more efficient, fast, and economical solutions in pharmaceutical sciences are also discussed.",4.0
32715331,The automaton as a surgeon: the future of artificial intelligence in emergency and general surgery,2020 Jul 26.,"Background:                    Artificial intelligence (AI) is a field involving computational simulation of human intelligence processes; these applications of deep learning could have implications in the specialty of emergency surgery (ES). ES is a rapidly advancing area, and this review will outline the most recent advances.              Methods:                    A literature search encompassing the uses of AI in surgery was conducted across large databases (Pubmed, OVID, SCOPUS). Two doctors (LR, CH) both collated relevant papers and appraised them. Papers included were published within the last 5 years, and a ""snowball effect"" used to collate further relevant literature.              Results:                    AI has been shown to provide value in predicting surgical outcomes and giving personalised patient risks based on inputted data. Further to this, image recognition technology within AI has showed success in fracture identification and breast cancer diagnosis. Regarding theatre presence, supervised robots have carried out suturing and anastomosis of bowel in controlled environments to a high standard.              Conclusion:                    AI has potential for integration across surgical services, from diagnosis to treatment, and aiding the surgeon in key decision-making for risks per patient. Fully automated surgery may be the future, but at present, AI needs human supervision.",1.0
32713447,The Future of Cardiac Ultrasound in the Neonatal Intensive Care Unit,2020 Sep;47(3):499-513.,"Cardiac ultrasound is increasingly used to guide hemodynamic decision making in the neonatal intensive care unit (NICU). This article focuses on likely future progress in training, accreditation, digital connectivity, miniaturization, and modality development. Many documents have been published internationally to guide cardiac ultrasound training, accreditation, and implementation in the NICU, but challenges remain in providing assessments of hemodynamic status without risking missed structural diagnoses. Advances in simulation training and digital connectivity provide an opportunity to standardize approaches across institutions and continents. Development of machine learning and ultrasound modalities in turn provide huge scope for improving robustness and completeness of assessment.",
32713443,Machine Learning to Support Hemodynamic Intervention in the Neonatal Intensive Care Unit,2020 Sep;47(3):435-448.,"Hemodynamic support in neonatal intensive care is directed at maintaining cardiovascular wellbeing. At present, monitoring of vital signs plays an essential role in augmenting care in a reactive manner. By applying machine learning techniques, a model can be trained to learn patterns in time series data, allowing the detection of adverse outcomes before they become clinically apparent. In this review we provide an overview of the different machine learning techniques that have been used to develop models in hemodynamic care for newborn infants. We focus on their potential benefits, research pitfalls, and challenges related to their implementation in clinical care.",
32713088,"Flying blind, or just flying under the radar? The underappreciated power of de novo methods of mass spectrometric peptide identification",2020 Sep;29(9):1864-1878.,"Mass spectrometry-based proteomics is a popular and powerful method for precise and highly multiplexed protein identification. The most common method of analyzing untargeted proteomics data is called database searching, where the database is simply a collection of protein sequences from the target organism, derived from genome sequencing. Experimental peptide tandem mass spectra are compared to simplified models of theoretical spectra calculated from the translated genomic sequences. However, in several interesting application areas, such as forensics, archaeology, venomics, and others, a genome sequence may not be available, or the correct genome sequence to use is not known. In these cases, de novo peptide identification can play an important role. De novo methods infer peptide sequence directly from the tandem mass spectrum without reference to a sequence database, usually using graph-based or machine learning algorithms. In this review, we provide a basic overview of de novo peptide identification methods and applications, briefly covering de novo algorithms and tools, and focusing in more depth on recent applications from venomics, metaproteomics, forensics, and characterization of antibody drugs.",
32711142,"Pituitary Tumors in the Computational Era, Exploring Novel Approaches to Diagnosis, and Outcome Prediction with Machine Learning",2021 Feb;146:315-321.e1.,"Background:                    Machine learning has emerged as a viable asset in the setting of pituitary surgery. In the past decade, the number of machine learning models developed to aid in the diagnosis of pituitary lesions and predict intraoperative and postoperative complications following transsphenoidal surgery has increased exponentially. As computational processing power continues to increase, big data sets continue to expand, and learning algorithms continue to surpass gold standard predictive tools, machine learning will serve to become an important component in improving patient care and outcomes.              Methods:                    Relevant studies were identified based on a literature search in PubMed and MEDLINE databases, as well as from other sources including reference lists of published articles.              Results:                    Radiomics and artificial neural networks comprise the majority of machine learning-based applications in pituitary surgery. Radiomics serves to quantify specific imaging features, which can then be used to noninvasively identify tumor characteristics and make definitive diagnoses, circumventing presurgical biopsy altogether. Neural networks can be adapted to predict intraoperative changes in visual evoked potentials or cerebral spinal fluid leak. In addition, these algorithms may be combined with others to predict tumor aggressiveness, gross total resection, recurrence and remission, and even total cost burden.              Conclusions:                    The field of machine learning is broad, with radiomics and artificial neural networks comprising 2 commonly used supervised learning methods in pituitary surgery. Given the large heterogeneity of pituitary and sellar lesions, the promise of machine learning lies in its ability to identify relationships and patterns that are otherwise hidden from standard statistical methods. While machine learning has great potential as a clinical adjunct during the surgical preplanning process and in predicting complications and outcomes, challenges moving forward include standardization and validation of these paradigms.",
32709998,Digital health technologies: opportunities and challenges in rheumatology,2020 Sep;16(9):525-535.,"The past decade in rheumatology has seen tremendous innovation in digital health technologies, including the electronic health record, virtual visits, mobile health, wearable technology, digital therapeutics, artificial intelligence and machine learning. The increased availability of these technologies offers opportunities for improving important aspects of rheumatology, including access, outcomes, adherence and research. However, despite its growth in some areas, particularly with non-health-care consumers, digital health technology has not substantially changed the delivery of rheumatology care. This Review discusses key barriers and opportunities to improve application of digital health technologies in rheumatology. Key topics include smart design, voice enablement and the integration of electronic patient-reported outcomes. Smart design involves active engagement with the end users of the technologies, including patients and clinicians through focus groups, user testing sessions and prototype review. Voice enablement using voice assistants could be critical for enabling patients with hand arthritis to effectively use smartphone apps and might facilitate patient engagement with many technologies. Tracking many rheumatic diseases requires frequent monitoring of patient-reported outcomes. Current practice only collects this information sporadically, and rarely between visits. Digital health technology could enable patient-reported outcomes to inform appropriate timing of face-to-face visits and enable improved application of treat-to-target strategies. However, best practice standards for digital health technologies do not yet exist. To achieve the potential of digital health technology in rheumatology, rheumatology professionals will need to be more engaged upstream in the technology design process and provide leadership to effectively incorporate the new tools into clinical care.",3.0
32709958,Refractive surgery beyond 2020,2021 Feb;35(2):362-382.,"Refractive surgery refers to any procedure that corrects or minimizes refractive errors. Today, refractive surgery has evolved beyond the traditional laser refractive surgery, embodied by the popular laser in situ keratomileusis or 'LASIK'. New keratorefractive techniques such as small incision lenticule extraction (SMILE) avoids corneal flap creation and uses a single laser device, while advances in surface ablation techniques have seen a resurgence in its popularity. Presbyopic treatment options have also expanded to include new ablation profiles, intracorneal implants, and phakic intraocular implants. With the improved safety and efficacy of refractive lens exchange, a wider variety of intraocular lens implants with advanced optics provide more options for refractive correction in carefully selected patients. In this review, we also discuss possible developments in refractive surgery beyond 2020, such as preoperative evaluation of refractive patients using machine learning and artificial intelligence, potential use of stromal lenticules harvested from SMILE for presbyopic treatments, and various advances in intraocular lens implants that may provide a closer to 'physiological correction' of refractive errors.",2.0
32708785,"Relevant Applications of Generative Adversarial Networks in Drug Design and Discovery: Molecular De Novo Design, Dimensionality Reduction, and De Novo Peptide and Protein Design",2020 Jul 16;25(14):3250.,"A growing body of evidence now suggests that artificial intelligence and machine learning techniques can serve as an indispensable foundation for the process of drug design and discovery. In light of latest advancements in computing technologies, deep learning algorithms are being created during the development of clinically useful drugs for treatment of a number of diseases. In this review, we focus on the latest developments for three particular arenas in drug design and discovery research using deep learning approaches, such as generative adversarial network (GAN) frameworks. Firstly, we review drug design and discovery studies that leverage various GAN techniques to assess one main application such as molecular de novo design in drug design and discovery. In addition, we describe various GAN models to fulfill the dimension reduction task of single-cell data in the preclinical stage of the drug development pipeline. Furthermore, we depict several studies in de novo peptide and protein design using GAN frameworks. Moreover, we outline the limitations in regard to the previous drug design and discovery studies using GAN models. Finally, we present a discussion of directions and challenges for future research.",2.0
32707839,Biological and Medical Importance of Cellular Heterogeneity Deciphered by Single-Cell RNA Sequencing,2020 Jul 22;9(8):1751.,"The present review discusses recent progress in single-cell RNA sequencing (scRNA-seq), which can describe cellular heterogeneity in various organs, bodily fluids, and pathologies (e.g., cancer and Alzheimer's disease). We outline scRNA-seq techniques that are suitable for investigating cellular heterogeneity that is present in cell populations with very high resolution of the transcriptomic landscape. We summarize scRNA-seq findings and applications of this technology to identify cell types, activity, and other features that are important for the function of different bodily organs. We discuss future directions for scRNA-seq techniques that can link gene expression, protein expression, cellular function, and their roles in pathology. We speculate on how the field could develop beyond its present limitations (e.g., performing scRNA-seq in situ and in vivo). Finally, we discuss the integration of machine learning and artificial intelligence with cutting-edge scRNA-seq technology, which could provide a strong basis for designing precision medicine and targeted therapy in the future.",1.0
32706710,Toward a Taxonomy for Analyzing the Heart Rate as a Physiological Indicator of Posttraumatic Stress Disorder: Systematic Review and Development of a Framework,2020 Jul 22;7(7):e16654.,"Background:                    Posttraumatic stress disorder (PTSD) is a prevalent psychiatric condition that is associated with symptoms such as hyperarousal and overreactions. Treatments for PTSD are limited to medications and in-session therapies. Assessing the way the heart responds to PTSD has shown promise in detecting and understanding the onset of symptoms.              Objective:                    This study aimed to extract statistical and mathematical approaches that researchers can use to analyze heart rate (HR) data to understand PTSD.              Methods:                    A scoping literature review was conducted to extract HR models. A total of 5 databases including Medical Literature Analysis and Retrieval System Online (Medline) OVID, Medline EBSCO, Cumulative Index to Nursing and Allied Health Literature (CINAHL) EBSCO, Excerpta Medica Database (Embase) Ovid, and Google Scholar were searched. Non-English language studies, as well as studies that did not analyze human data, were excluded. A total of 54 studies that met the inclusion criteria were included in this review.              Results:                    We identified 4 categories of models: descriptive time-independent output, descriptive and time-dependent output, predictive and time-independent output, and predictive and time-dependent output. Descriptive and time-independent output models include analysis of variance and first-order exponential; the descriptive time-dependent output model includes a classical time series analysis and mixed regression. Predictive time-independent output models include machine learning methods and analysis of the HR-based fluctuation-dissipation method. Finally, predictive time-dependent output models include the time-variant method and nonlinear dynamic modeling.              Conclusions:                    All of the identified modeling categories have relevance in PTSD, although the modeling selection is dependent on the specific goals of the study. Descriptive models are well-founded for the inference of PTSD. However, there is a need for additional studies in this area that explore a broader set of predictive models and other factors (eg, activity level) that have not been analyzed with descriptive models.",
32706688,Role of Artificial Intelligence in Patient Safety Outcomes: Systematic Literature Review,2020 Jul 24;8(7):e18599.,"Background:                    Artificial intelligence (AI) provides opportunities to identify the health risks of patients and thus influence patient safety outcomes.              Objective:                    The purpose of this systematic literature review was to identify and analyze quantitative studies utilizing or integrating AI to address and report clinical-level patient safety outcomes.              Methods:                    We restricted our search to the PubMed, PubMed Central, and Web of Science databases to retrieve research articles published in English between January 2009 and August 2019. We focused on quantitative studies that reported positive, negative, or intermediate changes in patient safety outcomes using AI apps, specifically those based on machine-learning algorithms and natural language processing. Quantitative studies reporting only AI performance but not its influence on patient safety outcomes were excluded from further review.              Results:                    We identified 53 eligible studies, which were summarized concerning their patient safety subcategories, the most frequently used AI, and reported performance metrics. Recognized safety subcategories were clinical alarms (n=9; mainly based on decision tree models), clinical reports (n=21; based on support vector machine models), and drug safety (n=23; mainly based on decision tree models). Analysis of these 53 studies also identified two essential findings: (1) the lack of a standardized benchmark and (2) heterogeneity in AI reporting.              Conclusions:                    This systematic review indicates that AI-enabled decision support systems, when implemented correctly, can aid in enhancing patient safety by improving error detection, patient stratification, and drug management. Future work is still needed for robust validation of these systems in prospective and real-world clinical environments to understand how well AI can predict safety outcomes in health care settings.",3.0
32706670,Reinforcement Learning for Clinical Decision Support in Critical Care: Comprehensive Review,2020 Jul 20;22(7):e18477.,"Background:                    Decision support systems based on reinforcement learning (RL) have been implemented to facilitate the delivery of personalized care. This paper aimed to provide a comprehensive review of RL applications in the critical care setting.              Objective:                    This review aimed to survey the literature on RL applications for clinical decision support in critical care and to provide insight into the challenges of applying various RL models.              Methods:                    We performed an extensive search of the following databases: PubMed, Google Scholar, Institute of Electrical and Electronics Engineers (IEEE), ScienceDirect, Web of Science, Medical Literature Analysis and Retrieval System Online (MEDLINE), and Excerpta Medica Database (EMBASE). Studies published over the past 10 years (2010-2019) that have applied RL for critical care were included.              Results:                    We included 21 papers and found that RL has been used to optimize the choice of medications, drug dosing, and timing of interventions and to target personalized laboratory values. We further compared and contrasted the design of the RL models and the evaluation metrics for each application.              Conclusions:                    RL has great potential for enhancing decision making in critical care. Challenges regarding RL system design, evaluation metrics, and model choice exist. More importantly, further work is required to validate RL in authentic clinical environments.",
32704420,"Introduction to Machine Learning, Neural Networks, and Deep Learning",2020 Feb 27;9(2):14.,"Purpose:                    To present an overview of current machine learning methods and their use in medical research, focusing on select machine learning techniques, best practices, and deep learning.              Methods:                    A systematic literature search in PubMed was performed for articles pertinent to the topic of artificial intelligence methods used in medicine with an emphasis on ophthalmology.              Results:                    A review of machine learning and deep learning methodology for the audience without an extensive technical computer programming background.              Conclusions:                    Artificial intelligence has a promising future in medicine; however, many challenges remain.              Translational relevance:                    The aim of this review article is to provide the nontechnical readers a layman's explanation of the machine learning methods being used in medicine today. The goal is to provide the reader a better understanding of the potential and challenges of artificial intelligence within the field of medicine.",5.0
32704419,Applications of Artificial Intelligence to Electronic Health Record Data in Ophthalmology,2020 Feb 27;9(2):13.,"Widespread adoption of electronic health records (EHRs) has resulted in the collection of massive amounts of clinical data. In ophthalmology in particular, the volume range of data captured in EHR systems has been growing rapidly. Yet making effective secondary use of this EHR data for improving patient care and facilitating clinical decision-making has remained challenging due to the complexity and heterogeneity of these data. Artificial intelligence (AI) techniques present a promising way to analyze these multimodal data sets. While AI techniques have been extensively applied to imaging data, there are a limited number of studies employing AI techniques with clinical data from the EHR. The objective of this review is to provide an overview of different AI methods applied to EHR data in the field of ophthalmology. This literature review highlights that the secondary use of EHR data has focused on glaucoma, diabetic retinopathy, age-related macular degeneration, and cataracts with the use of AI techniques. These techniques have been used to improve ocular disease diagnosis, risk assessment, and progression prediction. Techniques such as supervised machine learning, deep learning, and natural language processing were most commonly used in the articles reviewed.",2.0
32704411,Artificial Intelligence in Retinopathy of Prematurity Diagnosis,2020 Feb 10;9(2):5.,"Retinopathy of prematurity (ROP) is a leading cause of childhood blindness worldwide. The diagnosis of ROP is subclassified by zone, stage, and plus disease, with each area demonstrating significant intra- and interexpert subjectivity and disagreement. In addition to improved efficiencies for ROP screening, artificial intelligence may lead to automated, quantifiable, and objective diagnosis in ROP. This review focuses on the development of artificial intelligence for automated diagnosis of plus disease in ROP and highlights the clinical and technical challenges of both the development and implementation of artificial intelligence in the real world.",4.0
32702587,The ethics of AI in health care: A mapping review,2020 Sep;260:113172.,"This article presents a mapping review of the literature concerning the ethics of artificial intelligence (AI) in health care. The goal of this review is to summarise current debates and identify open questions for future research. Five literature databases were searched to support the following research question: how can the primary ethical risks presented by AI-health be categorised, and what issues must policymakers, regulators and developers consider in order to be 'ethically mindful? A series of screening stages were carried out-for example, removing articles that focused on digital health in general (e.g. data sharing, data access, data privacy, surveillance/nudging, consent, ownership of health data, evidence of efficacy)-yielding a total of 156 papers that were included in the review. We find that ethical issues can be (a) epistemic, related to misguided, inconclusive or inscrutable evidence; (b) normative, related to unfair outcomes and transformative effectives; or (c) related to traceability. We further find that these ethical issues arise at six levels of abstraction: individual, interpersonal, group, institutional, and societal or sectoral. Finally, we outline a number of considerations for policymakers and regulators, mapping these to existing literature, and categorising each as epistemic, normative or traceability-related and at the relevant level of abstraction. Our goal is to inform policymakers, regulators and developers of what they must consider if they are to enable health and care systems to capitalise on the dual advantage of ethical AI; maximising the opportunities to cut costs, improve care, and improve the efficiency of health and care systems, whilst proactively avoiding the potential harms. We argue that if action is not swiftly taken in this regard, a new 'AI winter' could occur due to chilling effects related to a loss of public trust in the benefits of AI for health care.",3.0
32699250,Causality matters in medical imaging,2020 Jul 22;11(1):3673.,"Causal reasoning can shed new light on the major challenges in machine learning for medical imaging: scarcity of high-quality annotated data and mismatch between the development dataset and the target environment. A causal perspective on these issues allows decisions about data collection, annotation, preprocessing, and learning strategies to be made and scrutinized more transparently, while providing a detailed categorisation of potential biases and mitigation techniques. Along with worked clinical examples, we highlight the importance of establishing the causal relationship between images and their annotations, and offer step-by-step recommendations for future studies.",3.0
32699100,"Endoscopy and central reading in inflammatory bowel disease clinical trials: achievements, challenges and future developments",2021 Feb;70(2):418-426.,"Central reading, that is, independent, off-site, blinded review or reading of imaging endpoints, has been identified as a crucial component in the conduct and analysis of inflammatory bowel disease clinical trials. Central reading is the final step in a workflow that has many parts, all of which can be improved. Furthermore, the best reading algorithm and the most intensive central reader training cannot make up for deficiencies in the acquisition stage (clinical trial endoscopy) or improve on the limitations of the underlying score (outcome instrument). In this review, academic and industry experts review scoring systems, and propose a theoretical framework for central reading that predicts when improvements in statistical power, affecting trial size and chances of success, can be expected: Multireader models can be conceptualised as statistical or non-statistical (social). Important organisational and operational factors, such as training and retraining of readers, optimal bowel preparation for colonoscopy, video quality, optimal or at least acceptable read duration times and other quality control matters, are addressed as well. The theory and practice of central reading and the conduct of endoscopy in clinical trials are interdisciplinary topics that should be of interest to many, regulators, clinical trial experts, gastroenterology societies and those in the academic community who endeavour to develop new scoring systems using traditional and machine learning approaches.",
32697964,"Reinventing radiation therapy with machine learning and imaging bio-markers (radiomics): State-of-the-art, challenges and perspectives",2021 Apr;188:44-60.,"Radiation therapy is a pivotal cancer treatment that has significantly progressed over the last decade due to numerous technological breakthroughs. Imaging is now playing a critical role on deployment of the clinical workflow, both for treatment planning and treatment delivery. Machine-learning analysis of predefined features extracted from medical images, i.e. radiomics, has emerged as a promising clinical tool for a wide range of clinical problems addressing drug development, clinical diagnosis, treatment selection and implementation as well as prognosis. Radiomics denotes a paradigm shift redefining medical images as a quantitative asset for data-driven precision medicine. The adoption of machine-learning in a clinical setting and in particular of radiomics features requires the selection of robust, representative and clinically interpretable biomarkers that are properly evaluated on a representative clinical data set. To be clinically relevant, radiomics must not only improve patients' management with great accuracy but also be reproducible and generalizable. Hence, this review explores the existing literature and exposes its potential technical caveats, such as the lack of quality control, standardization, sufficient sample size, type of data collection, and external validation. Based upon the analysis of 165 original research studies based on PET, CT-scan, and MRI, this review provides an overview of new concepts, and hypotheses generating findings that should be validated. In particular, it describes evolving research trends to enhance several clinical tasks such as prognostication, treatment planning, response assessment, prediction of recurrence/relapse, and prediction of toxicity. Perspectives regarding the implementation of an AI-based radiotherapy workflow are presented.",3.0
32695795,Artificial Intelligence in Cardiac Imaging With Statistical Atlases of Cardiac Anatomy,2020 Jun 30;7:102.,"In many cardiovascular pathologies, the shape and motion of the heart provide important clues to understanding the mechanisms of the disease and how it progresses over time. With the advent of large-scale cardiac data, statistical modeling of cardiac anatomy has become a powerful tool to provide automated, precise quantification of the status of patient-specific heart geometry with respect to reference populations. Powered by supervised or unsupervised machine learning algorithms, statistical cardiac shape analysis can be used to automatically identify and quantify the severity of heart diseases, to provide morphometric indices that are optimally associated with clinical factors, and to evaluate the likelihood of adverse outcomes. Recently, statistical cardiac atlases have been integrated with deep neural networks to enable anatomical consistency of cardiac segmentation, registration, and automated quality control. These combinations have already shown significant improvements in performance and avoid gross anatomical errors that could make the results unusable. This current trend is expected to grow in the near future. Here, we aim to provide a mini review highlighting recent advances in statistical atlasing of cardiac function in the context of artificial intelligence in cardiac imaging.",1.0
32695678,Integrated Multi-Omics Analyses in Oncology: A Review of Machine Learning Methods and Tools,2020 Jun 30;10:1030.,"In recent years, high-throughput sequencing technologies provide unprecedented opportunity to depict cancer samples at multiple molecular levels. The integration and analysis of these multi-omics datasets is a crucial and critical step to gain actionable knowledge in a precision medicine framework. This paper explores recent data-driven methodologies that have been developed and applied to respond major challenges of stratified medicine in oncology, including patients' phenotyping, biomarker discovery, and drug repurposing. We systematically retrieved peer-reviewed journals published from 2014 to 2019, select and thoroughly describe the tools presenting the most promising innovations regarding the integration of heterogeneous data, the machine learning methodologies that successfully tackled the complexity of multi-omics data, and the frameworks to deliver actionable results for clinical practice. The review is organized according to the applied methods: Deep learning, Network-based methods, Clustering, Features Extraction, and Transformation, Factorization. We provide an overview of the tools available in each methodological group and underline the relationship among the different categories. Our analysis revealed how multi-omics datasets could be exploited to drive precision oncology, but also current limitations in the development of multi-omics data integration.",7.0
32694345,Smartphone-Based Fundus Imaging-Where Are We Now?,Jul-Aug 2020;9(4):308-314.,"With the advent of smartphone-based fundus imaging (SBFI), a low-cost alternative to conventional digital fundus photography has become available. SBFI allows for a mobile fundus examination, is applicable both with and without pupil dilation, comes with built-in connectivity and post-processing capabilities, and is relatively easy to master. Furthermore, it is delegable to paramedical staff/technicians and, hence, suitable for telemedicine. Against this background a variety of SBFI applications have become available including screening for diabetic retinopathy, glaucoma, and retinopathy of prematurity and its applications in emergency medicine and pediatrics. In addition, SBFI is convenient for teaching purposes and might serve as a surrogate for direct ophthalmoscopy. First wide-field montage techniques are available and the combination of SBFI with machine learning algorithms for image analyses is promising. In conclusion, SBFI has the potential to make fundus examinations and screenings for patients particularly in low- and middle-income settings more accessible and, therefore, aid tackling the burden of diabetic retinopathy, glaucoma, and retinopathy of prematurity screening. However, image quality for SBFI varies substantially and a reference standard for grading appears prudent. In addition, there is a strong need for comparison of different SBFI approaches in terms of applicability to disease screening and cost-effectiveness.",1.0
32694325,"Spinal Epidural Abscess: Diagnosis, Management, and Outcomes",2020 Nov 1;28(21):e929-e938.,"An infection of the spinal epidural space, spinal epidural abscess (SEA) is a potentially devastating entity that is rising in incidence. Its insidious presentation, variable progression, and potential for precipitous neurologic decline make diagnosis and management of SEA challenging. Prompt diagnosis is key because treatment delay can lead to paralysis or death. Owing to the nonspecific symptoms and signs of SEA, misdiagnosis is alarmingly common. Risk factor assessment to determine the need for definitive MRI reduces diagnostic delays compared with relying on clinical or laboratory findings alone. Although decompression has long been considered the benchmark for SEA, considerable risk associated with spinal surgery is noted in an older cohort with multiple comorbidities. Nonoperative management may represent an alternative in select cases. Failure of nonoperative management is a feared outcome associated with motor deterioration and poor clinical outcomes. Recent studies have identified independent predictors of failure and residual neurologic dysfunction, recurrence, and mortality. Importantly, these studies provide tools that generate probabilities of these outcomes. Future directions of investigation should include external validation of existing algorithms through multi-institutional collaboration, prospective trials, and incorporation of powerful predictive statistics such as machine learning methods.",
32694266,Artificial intelligence for retinopathy of prematurity,2020 Sep;31(5):312-317.,"Purpose of review:                    In this article, we review the current state of artificial intelligence applications in retinopathy of prematurity (ROP) and provide insight on challenges as well as strategies for bringing these algorithms to the bedside.              Recent findings:                    In the past few years, there has been a dramatic shift from machine learning approaches based on feature extraction to 'deep' convolutional neural networks for artificial intelligence applications. Several artificial intelligence for ROP approaches have demonstrated adequate proof-of-concept performance in research studies. The next steps are to determine whether these algorithms are robust to variable clinical and technical parameters in practice. Integration of artificial intelligence into ROP screening and treatment is limited by generalizability of the algorithms to maintain performance on unseen data and integration of artificial intelligence technology into new or existing clinical workflows.              Summary:                    Real-world implementation of artificial intelligence for ROP diagnosis will require massive efforts targeted at developing standards for data acquisition, true external validation, and demonstration of feasibility. We must now focus on ethical, technical, clinical, regulatory, and financial considerations to bring this technology to the infant bedside to realize the promise offered by this technology to reduce preventable blindness from ROP.",
32692273,The recent application of 3D-QSAR and docking studies to novel HIV-protease inhibitor drug discovery,2020 Sep;15(9):1095-1110.,"Introduction:                    Despite the availability of FDA approved inhibitors of HIV protease, numerous efforts are still ongoing to achieve 'near-perfect' drugs devoid of characteristic adverse side effects, toxicities, and mutational resistance. While experimental methods have been plagued with huge consumption of time and resources, there has been an incessant shift towards the use of computational simulations in HIV protease inhibitor drug discovery.              Areas covered:                    Herein, the authors review the numerous applications of 3D-QSAR modeling methods over recent years relative to the design of new HIV protease inhibitors from a series of experimentally derived compounds. Also, the augmentative contributions of molecular docking are discussed.              Expert opinion:                    Efforts to optimize 3D QSAR and molecular docking for HIV-1 drug discovery are ongoing, which could further incorporate inhibitor motions at the active site using molecular dynamics parameters. Also, highly predictive machine learning algorithms such as random forest, K-means, decision trees, linear regression, hierarchical clustering, and Bayesian classifiers could be employed.",
32691219,A machine learning approach for mortality prediction only using non-invasive parameters,2020 Oct;58(10):2195-2238.,"At present, the traditional scoring methods generally utilize laboratory measurements to predict mortality. It results in difficulties of early mortality prediction in the rural areas lack of professional laboratorians and medical laboratory equipment. To improve the efficiency, accuracy, and applicability of mortality prediction in the remote areas, a novel mortality prediction method based on machine learning algorithms is proposed, which only uses non-invasive parameters readily available from ordinary monitors and manual measurement. A new feature selection method based on the Bayes error rate is developed to select valuable features. Based on non-invasive parameters, four machine learning models were trained for early mortality prediction. The subjects contained in this study suffered from general critical diseases including but not limited to cancer, bone fracture, and diarrhea. Comparison tests among five traditional scoring methods and these four machine learning models with and without laboratory measurement variables are performed. Only using the non-invasive parameters, the LightGBM algorithms have an excellent performance with the largest accuracy of 0.797 and AUC of 0.879. There is no apparent difference between the mortality prediction performance with and without laboratory measurement variables for the four machine learning methods. After reducing the number of feature variables to no more than 50, the machine learning models still outperform the traditional scoring systems, with AUC higher than 0.83. The machine learning approaches only using non-invasive parameters achieved an excellent mortality prediction performance and can equal those using extra laboratory measurements, which can be applied in rural areas and remote battlefield for mortality risk evaluation. Graphical abstract.",
32682191,Medical data science in rhinology: Background and implications for clinicians,Nov-Dec 2020;41(6):102627.,"Background:                    An important challenge of big data is using complex information networks to provide useful clinical information. Recently, machine learning, and particularly deep learning, has enabled rapid advances in clinical practice. The application of artificial intelligence (AI) and machine learning (ML) in rhinology is an increasingly relevant topic.              Purpose:                    We review the literature and provide a detailed overview of the recent advances in AI and ML as applied to rhinology. Also, we discuss both the significant benefits of this work as well as the challenges in the implementation and acceptance of these methods for clinical purposes.              Methods:                    We aimed to identify and explain published studies on the use of AI and ML in rhinology based on PubMed, Scopus, and Google searches. The search string ""nasal OR respiratory AND artificial intelligence OR machine learning"" was used. Most of the studies covered areas of paranasal sinuses radiology, including allergic rhinitis, chronic rhinitis, computed tomography scans, and nasal cytology.              Results:                    Cluster analysis and convolutional neural networks (CNNs) were mainly used in studies related to rhinology. AI is increasingly affecting healthcare research, and ML technology has been used in studies of chronic rhinitis and allergic rhinitis, providing some exciting new research modalities.              Conclusion:                    AI is especially useful when there is no conclusive evidence to aid decision making. ML can help doctors make clinical decisions, but it does not entirely replace doctors. However, when critically evaluating studies using this technique, rhinologists must take into account the limitations of its applications and use.",
32679583,Opportunities and challenges in the collection and analysis of digital phenotyping data,2021 Jan;46(1):45-54.,"The broad adoption and use of smartphones has led to fundamentally new opportunities for capturing social, behavioral, and cognitive phenotypes in free-living settings, outside of research laboratories and clinics. Predicated on the use of existing personal devices rather than the introduction of additional instrumentation, smartphone-based digital phenotyping presents us with several opportunities and challenges in data collection and data analysis. These two aspects are strongly coupled, because decisions about what data to collect and how to collect it constrain what statistical analyses can be carried out, now and years later, and therefore ultimately determine what scientific, clinical, and public health questions may be asked and answered. Digital phenotyping combines the excitement of fast-paced technologies, smartphones, cloud computing and machine learning, with deep mathematical and statistical questions, and it does this in the service of a better understanding our own behavior in ways that are objective, scalable, and reproducible. We will discuss some fundamental aspects of collection and analysis of digital phenotyping data, which takes us on a brief tour of several important scientific and technological concepts, from the open-source paradigm to computational complexity, with some unexpected insights provided by fields as varied as zoology and quantum mechanics.",4.0
32676206,Artificial Intelligence (AI) and Cardiovascular Diseases: An Unexpected Alliance,2020 Jun 27;2020:4972346.,"Cardiovascular disease (CVD), despite the significant advances in the diagnosis and treatments, still represents the leading cause of morbidity and mortality worldwide. In order to improve and optimize CVD outcomes, artificial intelligence techniques have the potential to radically change the way we practice cardiology, especially in imaging, offering us novel tools to interpret data and make clinical decisions. AI techniques such as machine learning and deep learning can also improve medical knowledge due to the increase of the volume and complexity of the data, unlocking clinically relevant information. Likewise, the use of emerging communication and information technologies is becoming pivotal to create a pervasive healthcare service through which elderly and chronic disease patients can receive medical care at their home, reducing hospitalizations and improving quality of life. The aim of this review is to describe the contemporary state of artificial intelligence and digital health applied to cardiovascular medicine as well as to provide physicians with their potential not only in cardiac imaging but most of all in clinical practice.",
32674040,Use of artificial intelligence in diagnosis of head and neck precancerous and cancerous lesions: A systematic review,2020 Nov;110:104885.,"This systematic review analyses and describes the application and diagnostic accuracy of Artificial Intelligence (AI) methods used for detection and grading of potentially malignant (pre-cancerous) and cancerous head and neck lesions using whole slide images (WSI) of human tissue slides. Electronic databases MEDLINE via OVID, Scopus and Web of Science were searched between October 2009 - April 2020. Tailored search-strings were developed using database-specific terms. Studies were selected using a strict inclusion criterion following PRISMA Guidelines. Risk of bias assessment was conducted using a tailored QUADAS-2 tool. Out of 315 records, 11 fulfilled the inclusion criteria. AI-based methods were employed for analysis of specific histological features for oral epithelial dysplasia (n = 1), oral submucous fibrosis (n = 5), oral squamous cell carcinoma (n = 4) and oropharyngeal squamous cell carcinoma (n = 1). A combination of heuristics, supervised and unsupervised learning methods were employed, including more than 10 different classification and segmentation techniques. Most studies used uni-centric datasets (range 40-270 images) comprising small sub-images within WSI with accuracy between 79 and 100%. This review provides early evidence to support the potential application of supervised machine learning methods as a diagnostic aid for some oral potentially malignant and malignant lesions; however, there is a paucity of evidence using AI for diagnosis of other head and neck pathologies. Overall, the quality of evidence is low, with most studies showing a high risk of bias which is likely to have overestimated accuracy rates. This review highlights the need for development of state-of-the-art deep learning techniques in future head and neck research.",1.0
