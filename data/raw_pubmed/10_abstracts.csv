pmid,citations,title,date,text
32265157,2.0,Radiomics: A primer for the radiation oncologist,2020 Aug;24(5):403-410.,"Purpose:                    Radiomics are a set of methods used to leverage medical imaging and extract quantitative features that can characterize a patient's phenotype. All modalities can be used with several different software packages. Specific informatics methods can then be used to create meaningful predictive models. In this review, we will explain the major steps of a radiomics analysis pipeline and then present the studies published in the context of radiation therapy.              Methods:                    A literature review was performed on Medline using the search engine PubMed. The search strategy included the search terms ""radiotherapy"", ""radiation oncology"" and ""radiomics"". The search was conducted in July 2019 and reference lists of selected articles were hand searched for relevance to this review.              Results:                    A typical radiomics workflow always includes five steps: imaging and segmenting, data curation and preparation, feature extraction, exploration and selection and finally modeling. In radiation oncology, radiomics studies have been published to explore different clinical outcome in lung (n=5), head and neck (n=5), esophageal (n=3), rectal (n=3), pancreatic (n=2) cancer and brain metastases (n=2). The quality of these retrospective studies is heterogeneous and their results have not been translated to the clinic.              Conclusion:                    Radiomics has a great potential to predict clinical outcome and better personalize treatment. But the field is still young and constantly evolving. Improvement in bias reduction techniques and multicenter studies will hopefully allow more robust and generalizable models."
32258124,1.0,Tabu Search and Machine-Learning Classification of Benign and Malignant Proliferative Breast Lesions,2020 Feb 27;2020:4671349.,Breast cancer is the most diagnosed cancer among women around the world. The development of computer-aided diagnosis tools is essential to help pathologists to accurately interpret and discriminate between malignant and benign tumors. This paper proposes the development of an automated proliferative breast lesion diagnosis based on machine-learning algorithms. We used Tabu search to select the most significant features. The evaluation of the feature is based on the dependency degree of each attribute in the rough set. The categorization of reduced features was built using five machine-learning algorithms. The proposed models were applied to the BIDMC-MGH and Wisconsin Diagnostic Breast Cancer datasets. The performance measures of the used models were evaluated owing to five criteria. The top performing models were AdaBoost and logistic regression. Comparisons with others works prove the efficiency of the proposed method for superior diagnosis of breast cancer against the reviewed classification techniques.
32257670,2.0,Artificial Intelligence: A New Paradigm in Obstetrics and Gynecology Research and Clinical Practice,2020 Feb 28;12(2):e7124.,"Artificial intelligence (AI) is growing exponentially in various fields, including medicine. This paper reviews the pertinent aspects of AI in obstetrics and gynecology (OB/GYN) and how these can be applied to improve patient outcomes and reduce the healthcare costs and workload for clinicians. Herein, we will address current AI uses in OB/GYN, and the use of AI as a tool to interpret fetal heart rate (FHR) and cardiotocography (CTG) to aid in the detection of preterm labor, pregnancy complications, and review discrepancies in its interpretation between clinicians to reduce maternal and infant morbidity and mortality. AI systems can be used as tools to create algorithms identifying asymptomatic women with short cervical length who are at risk of preterm birth. Additionally, the benefits of using the vast data capacity of AI storage can assist in determining the risk factors for preterm labor using multiomics and extensive genomic data. In the field of gynecological surgery, the use of augmented reality helps surgeons detect vital structures, thus decreasing complications, reducing operative time, and helping surgeons in training to practice in a realistic setting. Using three-dimensional (3D) printers can provide materials that mimic real tissues and also helps trainees to practice on a realistic model. Furthermore, 3D imaging allows better depth perception than its two-dimensional (2D) counterpart, allowing the surgeon to create preoperative plans according to tissue depth and dimensions. Although AI has some limitations, this new technology can improve the prognosis and management of patients, reduce healthcare costs, and help OB/GYN practitioners to reduce their workload and increase their efficiency and accuracy by incorporating AI systems into their daily practice. AI has the potential to guide practitioners in decision-making, reaching a diagnosis, and improving case management. It can reduce healthcare costs by decreasing medical errors and providing more dependable predictions. AI systems can accurately provide information on the large array of patients in clinical settings, although more robust data is required."
32257027,3.0,Artificial Intelligence and Machine Learning: A New Disruptive Force in Orthopaedics,2020 Jan 13;54(2):109-122.,"Orthopaedics as a surgical discipline requires a combination of good clinical acumen, good surgical skill, a reasonable physical strength and most of all, good understanding of technology. The last few decades have seen rapid adoption of new technologies into orthopaedic practice, power tools, new implants, CAD-CAM design, 3-D printing, additive manufacturing just to name a few. The new disruption in orthopaedics in the current time and era is undoubtedly the advent of artificial intelligence and robotics. As these technologies take root and innovative applications continue to be incorporated into the main-stream orthopedics, as we know it today, it is imperative to look at and understand the basics of artificial intelligence and what work is being done in the field today. This article takes the form of a loosely structured narrative review and will introduce the reader to key concepts in the field of artificial intelligence as well as some of the directions in application of the same in orthopaedics. Some of the recent work has been summarised and we present our viewpoint at the conclusion as to why we must consider artificial intelligence as a disrupting positive influence on orthopaedic surgery."
32256422,,Neuroprediction and A.I. in Forensic Psychiatry and Criminal Justice: A Neurolaw Perspective,2020 Mar 17;11:220.,"Advances in the use of neuroimaging in combination with A.I., and specifically the use of machine learning techniques, have led to the development of brain-reading technologies which, in the nearby future, could have many applications, such as lie detection, neuromarketing or brain-computer interfaces. Some of these could, in principle, also be used in forensic psychiatry. The application of these methods in forensic psychiatry could, for instance, be helpful to increase the accuracy of risk assessment and to identify possible interventions. This technique could be referred to as 'A.I. neuroprediction,' and involves identifying potential neurocognitive markers for the prediction of recidivism. However, the future implications of this technique and the role of neuroscience and A.I. in violence risk assessment remain to be established. In this paper, we review and analyze the literature concerning the use of brain-reading A.I. for neuroprediction of violence and rearrest to identify possibilities and challenges in the future use of these techniques in the fields of forensic psychiatry and criminal justice, considering legal implications and ethical issues. The analysis suggests that additional research is required on A.I. neuroprediction techniques, and there is still a great need to understand how they can be implemented in risk assessment in the field of forensic psychiatry. Besides the alluring potential of A.I. neuroprediction, we argue that its use in criminal justice and forensic psychiatry should be subjected to thorough harms/benefits analyses not only when these technologies will be fully available, but also while they are being researched and developed."
32255249,2.0,Harnessing data science to advance radiation oncology,2020 Jul;14(7):1514-1528.,"Radiation oncology, a major treatment modality in the care of patients with malignant disease, is a technology- and computer-intensive medical specialty. As such, it should lend itself ideally to data science methods, where computer science, statistics, and clinical knowledge are combined to advance state-of-the-art care. Nevertheless, data science methods in radiation oncology research are still in their infancy and successful applications leading to improved patient care remain scarce. Here, we discuss data interoperability issues within and across organizational boundaries that hamper the introduction of big data and data science techniques in radiation oncology. At the semantic level, creating common underlying models and codification of the data, including the use of data elements with standardized definitions, an ontology, remains a work in progress. Methodological issues in data science and in the use of large population-based health data registries are identified. We show that data science methods and big data cannot replace randomized clinical trials in comparative effectiveness research by reviewing a series of instances where the outcomes of big data analyses and randomized trials are at odds. We also discuss the modern wave of machine learning and artificial intelligence as represented by deep learning and convolutional neural networks. Finally, we identify promising research avenues and remain optimistic that the data sources in radiation oncology can be linked to yield important insights in the near future. We argue that data science will be a valuable complement to, but not a replacement of, the traditional hypothesis-driven translational research chain and the randomized clinical trials that form the backbone of evidence-based medicine."
32253623,4.0,"Machine Learning in Dermatology: Current Applications, Opportunities, and Limitations",2020 Jun;10(3):365-386.,"Machine learning (ML) has the potential to improve the dermatologist's practice from diagnosis to personalized treatment. Recent advancements in access to large datasets (e.g., electronic medical records, image databases, omics), faster computing, and cheaper data storage have encouraged the development of ML algorithms with human-like intelligence in dermatology. This article is an overview of the basics of ML, current applications of ML, and potential limitations and considerations for further development of ML. We have identified five current areas of applications for ML in dermatology: (1) disease classification using clinical images; (2) disease classification using dermatopathology images; (3) assessment of skin diseases using mobile applications and personal monitoring devices; (4) facilitating large-scale epidemiology research; and (5) precision medicine. The purpose of this review is to provide a guide for dermatologists to help demystify the fundamentals of ML and its wide range of applications in order to better evaluate its potential opportunities and challenges."
32253595,2.0,Intelligent Robotics Incorporating Machine Learning Algorithms for Improving Functional Capacity Evaluation and Occupational Rehabilitation,2020 Sep;30(3):362-370.,"Introduction Occupational rehabilitation often involves functional capacity evaluations (FCE) that use simulated work tasks to assess work ability. Currently, there exists no single, streamlined solution to simulate all or a large number of standard work tasks. Such a system would improve FCE and functional rehabilitation through simulating reaching maneuvers and more dexterous functional tasks that are typical of workplace activities. This paper reviews efforts to develop robotic FCE solutions that incorporate machine learning algorithms. Methods We reviewed the literature regarding rehabilitation robotics, with an emphasis on novel techniques incorporating robotics and machine learning into FCE. Results Rehabilitation robotics aims to improve the assessment and rehabilitation of injured workers by providing methods for easily simulating workplace tasks using intelligent robotic systems. Machine learning-based approaches combine the benefits of robotic systems with the expertise and experience of human therapists. These innovations have the potential to improve the quantification of function as well as learn the haptic interactions provided by therapists to assist patients during assessment and rehabilitation. This is done by allowing a robot to learn based on a therapist's motions (""demonstrations"") what the desired workplace activity (""task"") is and how to recreate it for a worker with an injury (""patient""). Through Telerehabilitation and internet connectivity, these robotic assessment techniques can be used over a distance to reach rural and remote locations. Conclusions While the research is in the early stages, robotics with integrated machine learning algorithms have great potential for improving traditional FCE practice."
32251707,10.0,Machine Learning in oncology: A clinical appraisal,2020 Jul 1;481:55-62.,"Machine learning (ML) is a branch of artificial intelligence centered on algorithms which do not need explicit prior programming to function but automatically learn from available data, creating decision models to complete tasks. ML-based tools have numerous promising applications in several fields of medicine. Its use has grown following the increased availability of patient data due to technological advances such as digital health records and high-volume information extraction from medical images. Multiple ML algorithms have been proposed for applications in oncology. For instance, they have been employed for oncological risk assessment, automated segmentation, lesion detection, characterization, grading and staging, prediction of prognosis and therapy response. In the near future, ML could become essential part of every step of oncological screening strategies and patients' management thus leading to precision medicine."
32250986,3.0,Can machine-learning methods really help predict suicide?,2020 Jul;33(4):369-374.,"Purpose of review:                    In recent years there has been interest in the use of machine learning in suicide research in reaction to the failure of traditional statistical methods to produce clinically useful models of future suicide. The current review summarizes recent prediction studies in the suicide literature including those using machine learning approaches to understand what value these novel approaches add.              Recent findings:                    Studies using machine learning to predict suicide deaths report area under the curve that are only modestly greater than, and sensitivities that are equal to, those reported in studies using more conventional predictive methods. Positive predictive value remains around 1% among the cohort studies with a base rate that was not inflated by case-control methodology.              Summary:                    Machine learning or artificial intelligence may afford opportunities in mental health research and in the clinical care of suicidal patients. However, application of such techniques should be carefully considered to avoid repeating the mistakes of existing methodologies. Prediction studies using machine-learning methods have yet to make a major contribution to our understanding of the field and are unproven as clinically useful tools."
32250525,,Propensity score methods in real-world epidemiology: A practical guide for first-time users,2020 Apr;22 Suppl 3:13-20.,"Real-world epidemiology gives us the unique opportunity to observe large numbers of people, and the actions and events that characterize their encounters with healthcare providers. However, the heterogeneity and sheer diversity of the population and healthcare systems makes it impossible for researchers to compare ""like with like"" when attempting to draw causal inferences about interventions and outcomes. The critical issue in epidemiological datasets relates to high risk of bias due to confounders that stem from baseline differences between groups. Propensity score (PS) techniques are statistical approaches that have been used to tackle potential imbalance in the comparison groups. The PS is the estimated probability (based on measured baseline covariates) that the patient receives a particular intervention. Patients that share similar PS will most likely have the same distributions of underlying covariates included in the PS. Implementation of PS methods may achieve better balance of covariates, but there is no consensus on the best way of capturing all relevant confounders for incorporation into the PS model. Should covariates be selected by clinical or epidemiological experts, or would data-driven algorithms (machine learning) offer more efficient and reliable methods of estimating PS and controlling for confounding? The PS can be incorporated into the analysis in different ways, each with its own strengths and limitations, and researchers must choose the best fit for their study objectives. PS methods are particularly advantageous in situations where there are large numbers of measured covariates but relatively few outcome events captured in healthcare administrative databases."
32250332,2.0,Artificial neural networks in neurorehabilitation: A scoping review,2020;46(3):259-269.,"Background:                    Advances in medical technology produce highly complex datasets in neurorehabilitation clinics and research laboratories. Artificial neural networks (ANNs) have been utilized to analyze big and complex datasets in various fields, but the use of ANNs in neurorehabilitation is limited.              Objective:                    To explore the current use of ANNs in neurorehabilitation.              Methods:                    PubMed, CINAHL, and Web of Science were used for the literature search. Studies in the scoping review (1) utilized ANNs, (2) examined populations with neurological conditions, and (3) focused on rehabilitation outcomes. The initial search identified 1,136 articles. A total of 19 articles were included.              Results:                    ANNs were used for prediction of functional outcomes and mortality (n = 11) and classification of motor symptoms and cognitive status (n = 8). Most ANN-based models outperformed regression or other machine learning models (n = 11) and showed accurate performance (n = 6; no comparison with other models) in predicting clinical outcomes and accurately classifying different neurological impairments.              Conclusions:                    This scoping review provides encouraging evidence to use ANNs for clinical decision-making of complex datasets in neurorehabilitation. However, more research is needed to establish the clinical utility of ANNs in diagnosing, monitoring, and rehabilitation of individuals with neurological conditions."
32250086,,Research Progress and Prospect of Machine Learning in Bone Age Assessment,2020 Feb;36(1):91-98.,"Bone age assessment has always been one of the key issues and difficulties in forensic science. With the gradual development of machine learning in many industries, it has been widely introduced to imageology, genomics, oncology, pathology, surgery and other medical research fields in recent years. The reason why the above research fields can be closely combined with machine learning, is because the research subjects of the above branches of medicine belong to the computer vision category. Machine learning provides unique advantages for computer vision research and has made breakthroughs in medical image recognition. Based on the advantages of machine learning in image recognition, it was combined with bone age assessment research, in order to construct a recognition model suitable for forensic skeletal images. This paper reviews the research progress in bone age assessment made by scholars at home and abroad using machine learning technology in recent years."
32250084,,New Opportunities and Challenges for Forensic Medicine in the Era of Artificial Intelligence Technology,2020 Feb;36(1):77-85.,"Traditional forensic identification relies on forensic experts to manually extract information and provide identification opinions based on medicine, biology and other fields of knowledge combined with personal work experience, which is not only time-consuming and require great effort, but also affected by subjective factors that are difficult to overcome. In the era of big data, the booming development of artificial intelligence brings new ideas to forensic medicine. In recent years, forensic researchers at home and abroad have conducted many studies based on artificial intelligence technology, such as face recognition, age and gender identification, DNA analysis, postmortem interval estimation, injury and cause of death identification, showing the feasibility and advantages of using artificial intelligence technology to solve forensic identification problems. As a new means of technology that has adapted to the development of the times, artificial intelligence has brought new vitality to forensic medicine, but at the same time also some new challenges. How to deal with these challenges scientifically and form a new mode of 'artificial intelligence plus forensic medicine' with artificial intelligence and forensic medicine developing collaboratively is a new direction for the development of forensic medicine in the era of big data."
32249351,3.0,Radiomics in gliomas: clinical implications of computational modeling and fractal-based analysis,2020 Jul;62(7):771-790.,"Radiomics is an emerging field that involves extraction and quantification of features from medical images. These data can be mined through computational analysis and models to identify predictive image biomarkers that characterize intra-tumoral dynamics throughout the course of treatment. This is particularly difficult in gliomas, where heterogeneity has been well established at a molecular level as well as visually in conventional imaging. Thus, acquiring clinically useful features remains difficult due to temporal variations in tumor dynamics. Identifying surrogate biomarkers through radiomics may provide a non-invasive means of characterizing biologic activities of gliomas. We present an extensive literature review of radiomics-based analysis, with a particular focus on computational modeling, machine learning, and fractal-based analysis in improving differential diagnosis and predicting clinical outcomes. Novel strategies in extracting quantitative features, segmentation methods, and their clinical applications are producing promising results. Moreover, we provide a detailed summary of the morphometric parameters that have so far been proposed as a means of quantifying imaging characteristics of gliomas. Newly emerging radiomic techniques via machine learning and fractal-based analyses holds considerable potential for improving diagnostic and prognostic accuracy of gliomas. Key points• Radiomic features can be mined through computational analysis to produce quantitative imaging biomarkers that characterize intra-tumoral dynamics throughout the course of treatment.• Surrogate image biomarkers identified through radiomics could enable a non-invasive means of characterizing biologic activities of gliomas.• With novel analytic algorithms, quantification of morphological or sub-regional tumor features to predict survival outcomes is producing promising results.• Quantifying intra-tumoral heterogeneity may improve grading and molecular sub-classifications of gliomas.• Computational fractal-based analysis of gliomas allows geometrical evaluation of tumor irregularities and complexity, leading to novel techniques for tumor segmentation, grading, and therapeutic monitoring."
32249208,3.0,Psychiatric Illnesses as Disorders of Network Dynamics,2020 Jan 16;S2451-9022(20)30019-7.,"This review provides a dynamical systems perspective on mental illness. After a brief introduction to the theory of dynamical systems, we focus on the common assumption in theoretical and computational neuroscience that phenomena at subcellular, cellular, network, cognitive, and even societal levels could be described and explained in terms of dynamical systems theory. As such, dynamical systems theory may also provide a framework for understanding mental illnesses. The review examines a number of core dynamical systems phenomena and relates each of these to aspects of mental illnesses. This provides an outline of how a broad set of phenomena in serious and common mental illnesses and neurological conditions can be understood in dynamical systems terms. It suggests that the dynamical systems level may provide a central, hublike level of convergence that unifies and links multiple biophysical and behavioral phenomena in the sense that diverse biophysical changes can give rise to the same dynamical phenomena and, vice versa, similar changes in dynamics may yield different behavioral symptoms depending on the brain area where these changes manifest. We also briefly outline current methodological approaches for inferring dynamical systems from data such as electroencephalography, functional magnetic resonance imaging, or self-reports, and we discuss the implications of a dynamical view for the diagnosis, prognosis, and treatment of psychiatric conditions. We argue that a consideration of dynamics could play a potentially transformative role in the choice and target of interventions."
32246300,3.0,Myths and facts about artificial intelligence: why machine- and deep-learning will not replace interventional radiologists,2020 Apr 3;37(5):40.,"Artificial intelligence (AI) is revolutionizing healthcare and transforming the clinical practice of physicians across the world. Radiology has a strong affinity for machine learning and is at the forefront of the paradigm shift, as machines compete with humans for cognitive abilities. AI is a computer science simulation of the human mind that utilizes algorithms based on collective human knowledge and the best available evidence to process various forms of inputs and deliver desired outcomes, such as clinical diagnoses and optimal treatment options. Despite the overwhelmingly positive uptake of the technology, warnings have been published about the potential dangers of AI. Concerns have been expressed reflecting opinions that future medicine based on AI will render radiologists irrelevant. Thus, how much of this is based on reality? To answer these questions, it is important to examine the facts, clarify where AI really stands and why many of these speculations are untrue. We aim to debunk the 6 top myths regarding AI in the future of radiologists."
32245523,2.0,Machine learning and clinical epigenetics: a review of challenges for diagnosis and classification,2020 Apr 3;12(1):51.,"Background:                    Machine learning is a sub-field of artificial intelligence, which utilises large data sets to make predictions for future events. Although most algorithms used in machine learning were developed as far back as the 1950s, the advent of big data in combination with dramatically increased computing power has spurred renewed interest in this technology over the last two decades.              Main body:                    Within the medical field, machine learning is promising in the development of assistive clinical tools for detection of e.g. cancers and prediction of disease. Recent advances in deep learning technologies, a sub-discipline of machine learning that requires less user input but more data and processing power, has provided even greater promise in assisting physicians to achieve accurate diagnoses. Within the fields of genetics and its sub-field epigenetics, both prime examples of complex data, machine learning methods are on the rise, as the field of personalised medicine is aiming for treatment of the individual based on their genetic and epigenetic profiles.              Conclusion:                    We now have an ever-growing number of reported epigenetic alterations in disease, and this offers a chance to increase sensitivity and specificity of future diagnostics and therapies. Currently, there are limited studies using machine learning applied to epigenetics. They pertain to a wide variety of disease states and have used mostly supervised machine learning methods."
32244919,2.0,From Bivariate to Multivariate Analysis of Cytometric Data: Overview of Computational Methods and Their Application in Vaccination Studies,2020 Mar 20;8(1):138.,"Flow and mass cytometry are used to quantify the expression of multiple extracellular or intracellular molecules on single cells, allowing the phenotypic and functional characterization of complex cell populations. Multiparametric flow cytometry is particularly suitable for deep analysis of immune responses after vaccination, as it allows to measure the frequency, the phenotype, and the functional features of antigen-specific cells. When many parameters are investigated simultaneously, it is not feasible to analyze all the possible bi-dimensional combinations of marker expression with classical manual analysis and the adoption of advanced automated tools to process and analyze high-dimensional data sets becomes necessary. In recent years, the development of many tools for the automated analysis of multiparametric cytometry data has been reported, with an increasing record of publications starting from 2014. However, the use of these tools has been preferentially restricted to bioinformaticians, while few of them are routinely employed by the biomedical community. Filling the gap between algorithms developers and final users is fundamental for exploiting the advantages of computational tools in the analysis of cytometry data. The potentialities of automated analyses range from the improvement of the data quality in the pre-processing steps up to the unbiased, data-driven examination of complex datasets using a variety of algorithms based on different approaches. In this review, an overview of the automated analysis pipeline is provided, spanning from the pre-processing phase to the automated population analysis. Analysis based on computational tools might overcame both the subjectivity of manual gating and the operator-biased exploration of expected populations. Examples of applications of automated tools that have successfully improved the characterization of different cell populations in vaccination studies are also presented."
32244292,5.0,Applications of Machine Learning Predictive Models in the Chronic Disease Diagnosis,2020 Mar 31;10(2):21.,"This paper reviews applications of machine learning (ML) predictive models in the diagnosis of chronic diseases. Chronic diseases (CDs) are responsible for a major portion of global health costs. Patients who suffer from these diseases need lifelong treatment. Nowadays, predictive models are frequently applied in the diagnosis and forecasting of these diseases. In this study, we reviewed the state-of-the-art approaches that encompass ML models in the primary diagnosis of CD. This analysis covers 453 papers published between 2015 and 2019, and our document search was conducted from PubMed (Medline), and Cumulative Index to Nursing and Allied Health Literature (CINAHL) libraries. Ultimately, 22 studies were selected to present all modeling methods in a precise way that explains CD diagnosis and usage models of individual pathologies with associated strengths and limitations. Our outcomes suggest that there are no standard methods to determine the best approach in real-time clinical practice since each method has its advantages and disadvantages. Among the methods considered, support vector machines (SVM), logistic regression (LR), clustering were the most commonly used. These models are highly applicable in classification, and diagnosis of CD and are expected to become more important in medical practice in the near future."
32244257,5.0,Recent advances in computational methods for measurement of dendritic spines imaged by light microscopy,2020 Jul 30;69(4):196-213.,"Dendritic spines are small protrusions that receive most of the excitatory inputs to the pyramidal neurons in the neocortex and the hippocampus. Excitatory neural circuits in the neocortex and hippocampus are important for experience-dependent changes in brain functions, including postnatal sensory refinement and memory formation. Several lines of evidence indicate that synaptic efficacy is correlated with spine size and structure. Hence, precise and accurate measurement of spine morphology is important for evaluation of neural circuit function and plasticity. Recent advances in light microscopy and image analysis techniques have opened the way toward a full description of spine nanostructure. In addition, large datasets of spine nanostructure can be effectively analyzed using machine learning techniques and other mathematical approaches, and recent advances in super-resolution imaging allow researchers to analyze spine structure at an unprecedented level of precision. This review summarizes computational methods that can effectively identify, segment and quantitate dendritic spines in either 2D or 3D imaging. Nanoscale analysis of spine structure and dynamics, combined with new mathematical approaches, will facilitate our understanding of spine functions in physiological and pathological conditions."
32243801,11.0,How Machine Learning Will Transform Biomedicine,2020 Apr 2;181(1):92-101.,"This Perspective explores the application of machine learning toward improved diagnosis and treatment. We outline a vision for how machine learning can transform three broad areas of biomedicine: clinical diagnostics, precision treatments, and health monitoring, where the goal is to maintain health through a range of diseases and the normal aging process. For each area, early instances of successful machine learning applications are discussed, as well as opportunities and challenges for machine learning. When these challenges are met, machine learning promises a future of rigorous, outcomes-based medicine with detection, diagnosis, and treatment strategies that are continuously adapted to individual and environmental differences."
32240773,4.0,Methods for ChIP-seq analysis: A practical workflow and advanced applications,2021 Mar;187:44-53.,"Chromatin immunoprecipitation followed by sequencing (ChIP-seq) is a central method in epigenomic research. Genome-wide analysis of histone modifications, such as enhancer analysis and genome-wide chromatin state annotation, enables systematic analysis of how the epigenomic landscape contributes to cell identity, development, lineage specification, and disease. In this review, we first present a typical ChIP-seq analysis workflow, from quality assessment to chromatin-state annotation. We focus on practical, rather than theoretical, approaches for biological studies. Next, we outline various advanced ChIP-seq applications and introduce several state-of-the-art methods, including prediction of gene expression level and chromatin loops from epigenome data and data imputation. Finally, we discuss recently developed single-cell ChIP-seq analysis methodologies that elucidate the cellular diversity within complex tissues and cancers."
32240163,6.0,Multiview learning for understanding functional multiomics,2020 Apr 2;16(4):e1007677.,"The molecular mechanisms and functions in complex biological systems currently remain elusive. Recent high-throughput techniques, such as next-generation sequencing, have generated a wide variety of multiomics datasets that enable the identification of biological functions and mechanisms via multiple facets. However, integrating these large-scale multiomics data and discovering functional insights are, nevertheless, challenging tasks. To address these challenges, machine learning has been broadly applied to analyze multiomics. This review introduces multiview learning-an emerging machine learning field-and envisions its potentially powerful applications to multiomics. In particular, multiview learning is more effective than previous integrative methods for learning data's heterogeneity and revealing cross-talk patterns. Although it has been applied to various contexts, such as computer vision and speech recognition, multiview learning has not yet been widely applied to biological data-specifically, multiomics data. Therefore, this paper firstly reviews recent multiview learning methods and unifies them in a framework called multiview empirical risk minimization (MV-ERM). We further discuss the potential applications of each method to multiomics, including genomics, transcriptomics, and epigenomics, in an aim to discover the functional and mechanistic interpretations across omics. Secondly, we explore possible applications to different biological systems, including human diseases (e.g., brain disorders and cancers), plants, and single-cell analysis, and discuss both the benefits and caveats of using multiview learning to discover the molecular mechanisms and functions of these systems."
32239350,2.0,Artificial Intelligence in Hematology: Current Challenges and Opportunities,2020 Jun;15(3):203-210.,"Purpose of review:                    Artificial intelligence (AI), and in particular its subcategory machine learning, is finding an increasing number of applications in medicine, driven in large part by an abundance of data and powerful, accessible tools that have made AI accessible to a larger circle of investigators.              Recent findings:                    AI has been employed in the analysis of hematopathological, radiographic, laboratory, genomic, pharmacological, and chemical data to better inform diagnosis, prognosis, treatment planning, and foundational knowledge related to benign and malignant hematology. As more widespread implementation of clinical AI nears, attention has also turned to the effects this will have on other areas in medicine. AI offers many promising tools to clinicians broadly, and specifically in the practice of hematology. Ongoing research into its various applications will likely result in an increasing utilization of AI by a broader swath of clinicians."
32238826,,Meta-Analysis Based on Nonconvex Regularization,2020 Apr 1;10(1):5755.,"The widespread applications of high-throughput sequencing technology have produced a large number of publicly available gene expression datasets. However, due to the gene expression datasets have the characteristics of small sample size, high dimensionality and high noise, the application of biostatistics and machine learning methods to analyze gene expression data is a challenging task, such as the low reproducibility of important biomarkers in different studies. Meta-analysis is an effective approach to deal with these problems, but the current methods have some limitations. In this paper, we propose the meta-analysis based on three nonconvex regularization methods, which are L1/2 regularization (meta-Half), Minimax Concave Penalty regularization (meta-MCP) and Smoothly Clipped Absolute Deviation regularization (meta-SCAD). The three nonconvex regularization methods are effective approaches for variable selection developed in recent years. Through the hierarchical decomposition of coefficients, our methods not only maintain the flexibility of variable selection and improve the efficiency of selecting important biomarkers, but also summarize and synthesize scientific evidence from multiple studies to consider the relationship between different datasets. We give the efficient algorithms and the theoretical property for our methods. Furthermore, we apply our methods to the simulation data and three publicly available lung cancer gene expression datasets, and compare the performance with state-of-the-art methods. Our methods have good performance in simulation studies, and the analysis results on the three publicly available lung cancer gene expression datasets are clinically meaningful. Our methods can also be extended to other areas where datasets are heterogeneous."
32235273,1.0,Applications of machine learning methods in kidney disease: hope or hype?,2020 May;29(3):319-326.,"Purpose of review:                    The universal adoption of electronic health records, improvement in technology, and the availability of continuous monitoring has generated large quantities of healthcare data. Machine learning is increasingly adopted by nephrology researchers to analyze this data in order to improve the care of their patients.              Recent findings:                    In this review, we provide a broad overview of the different types of machine learning algorithms currently available and how researchers have applied these methods in nephrology research. Current applications have included prediction of acute kidney injury and chronic kidney disease along with progression of kidney disease. Researchers have demonstrated the ability of machine learning to read kidney biopsy samples, identify patient outcomes from unstructured data, and identify subtypes in complex diseases. We end with a discussion on the ethics and potential pitfalls of machine learning.              Summary:                    Machine learning provides researchers with the ability to analyze data that were previously inaccessible. While still burgeoning, several studies show promising results, which will enable researchers to perform larger scale studies and clinicians the ability to provide more personalized care. However, we must ensure that implementation aids providers and does not lead to harm to patients."
32233691,3.0,Thermal ablation of biological tissues in disease treatment: A review of computational models and future directions,2020 Apr 2;39(2):49-88.,"Percutaneous thermal ablation has proven to be an effective modality for treating both benign and malignant tumours in various tissues. Among these modalities, radiofrequency ablation (RFA) is the most promising and widely adopted approach that has been extensively studied in the past decades. Microwave ablation (MWA) is a newly emerging modality that is gaining rapid momentum due to its capability of inducing rapid heating and attaining larger ablation volumes, and its lesser susceptibility to the heat sink effects as compared to RFA. Although the goal of both these therapies is to attain cell death in the target tissue by virtue of heating above 50°C, their underlying mechanism of action and principles greatly differs. Computational modelling is a powerful tool for studying the effect of electromagnetic interactions within the biological tissues and predicting the treatment outcomes during thermal ablative therapies. Such a priori estimation can assist the clinical practitioners during treatment planning with the goal of attaining successful tumour destruction and preservation of the surrounding healthy tissue and critical structures. This review provides current state-of-the-art developments and associated challenges in the computational modelling of thermal ablative techniques, viz., RFA and MWA, as well as touch upon several promising avenues in the modelling of laser ablation, nanoparticles assisted magnetic hyperthermia and non-invasive RFA. The application of RFA in pain relief has been extensively reviewed from modelling point of view. Additionally, future directions have also been provided to improve these models for their successful translation and integration into the hospital work flow."
32232112,,Biomarkers and neuromodulation techniques in substance use disorders,2020 Feb 17;6:4.,"Addictive disorders are a severe health concern. Conventional therapies have just moderate success and the probability of relapse after treatment remains high. Brain stimulation techniques, such as transcranial Direct Current Stimulation (tDCS) and Deep Brain Stimulation (DBS), have been shown to be effective in reducing subjectively rated substance craving. However, there are few objective and measurable parameters that reflect neural mechanisms of addictive disorders and relapse. Key electrophysiological features that characterize substance related changes in neural processing are Event-Related Potentials (ERP). These high temporal resolution measurements of brain activity are able to identify neurocognitive correlates of addictive behaviours. Moreover, ERP have shown utility as biomarkers to predict treatment outcome and relapse probability. A future direction for the treatment of addiction might include neural interfaces able to detect addiction-related neurophysiological parameters and deploy neuromodulation adapted to the identified pathological features in a closed-loop fashion. Such systems may go beyond electrical recording and stimulation to employ sensing and neuromodulation in the pharmacological domain as well as advanced signal analysis and machine learning algorithms. In this review, we describe the state-of-the-art in the treatment of addictive disorders with electrical brain stimulation and its effect on addiction-related neurophysiological markers. We discuss advanced signal processing approaches and multi-modal neural interfaces as building blocks in future bioelectronics systems for treatment of addictive disorders."
32231270,13.0,Memory devices and applications for in-memory computing,2020 Jul;15(7):529-544.,"Traditional von Neumann computing systems involve separate processing and memory units. However, data movement is costly in terms of time and energy and this problem is aggravated by the recent explosive growth in highly data-centric applications related to artificial intelligence. This calls for a radical departure from the traditional systems and one such non-von Neumann computational approach is in-memory computing. Hereby certain computational tasks are performed in place in the memory itself by exploiting the physical attributes of the memory devices. Both charge-based and resistance-based memory devices are being explored for in-memory computing. In this Review, we provide a broad overview of the key computational primitives enabled by these memory devices as well as their applications spanning scientific computing, signal processing, optimization, machine learning, deep learning and stochastic computing."
32229465,11.0,Clinical Text Data in Machine Learning: Systematic Review,2020 Mar 31;8(3):e17984.,"Background:                    Clinical narratives represent the main form of communication within health care, providing a personalized account of patient history and assessments, and offering rich information for clinical decision making. Natural language processing (NLP) has repeatedly demonstrated its feasibility to unlock evidence buried in clinical narratives. Machine learning can facilitate rapid development of NLP tools by leveraging large amounts of text data.              Objective:                    The main aim of this study was to provide systematic evidence on the properties of text data used to train machine learning approaches to clinical NLP. We also investigated the types of NLP tasks that have been supported by machine learning and how they can be applied in clinical practice.              Methods:                    Our methodology was based on the guidelines for performing systematic reviews. In August 2018, we used PubMed, a multifaceted interface, to perform a literature search against MEDLINE. We identified 110 relevant studies and extracted information about text data used to support machine learning, NLP tasks supported, and their clinical applications. The data properties considered included their size, provenance, collection methods, annotation, and any relevant statistics.              Results:                    The majority of datasets used to train machine learning models included only hundreds or thousands of documents. Only 10 studies used tens of thousands of documents, with a handful of studies utilizing more. Relatively small datasets were utilized for training even when much larger datasets were available. The main reason for such poor data utilization is the annotation bottleneck faced by supervised machine learning algorithms. Active learning was explored to iteratively sample a subset of data for manual annotation as a strategy for minimizing the annotation effort while maximizing the predictive performance of the model. Supervised learning was successfully used where clinical codes integrated with free-text notes into electronic health records were utilized as class labels. Similarly, distant supervision was used to utilize an existing knowledge base to automatically annotate raw text. Where manual annotation was unavoidable, crowdsourcing was explored, but it remains unsuitable because of the sensitive nature of data considered. Besides the small volume, training data were typically sourced from a small number of institutions, thus offering no hard evidence about the transferability of machine learning models. The majority of studies focused on text classification. Most commonly, the classification results were used to support phenotyping, prognosis, care improvement, resource management, and surveillance.              Conclusions:                    We identified the data annotation bottleneck as one of the key obstacles to machine learning approaches in clinical NLP. Active learning and distant supervision were explored as a way of saving the annotation efforts. Future research in this field would benefit from alternatives such as data augmentation and transfer learning, or unsupervised learning, which do not require data annotation."
32228387,,Artificial Intelligence in Clinical Neuroscience: Methodological and Ethical Challenges,Apr-Jun 2020;11(2):77-87.,"Clinical neuroscience is increasingly relying on the collection of large volumes of differently structured data and the use of intelligent algorithms for data analytics. In parallel, the ubiquitous collection of unconventional data sources (e.g. mobile health, digital phenotyping, consumer neurotechnology) is increasing the variety of data points. Big data analytics and approaches to Artificial Intelligence (AI) such as advanced machine learning are showing great potential to make sense of these larger and heterogeneous data flows. AI provides great opportunities for making new discoveries about the brain, improving current preventative and diagnostic models in both neurology and psychiatry and developing more effective assistive neurotechnologies. Concurrently, it raises many new methodological and ethical challenges. Given their transformative nature, it is still largely unclear how AI-driven approaches to the study of the human brain will meet adequate standards of scientific validity and affect normative instruments in neuroethics and research ethics. This manuscript provides an overview of current AI-driven approaches to clinical neuroscience and an assessment of the associated key methodological and ethical challenges. In particular, it will discuss what ethical principles are primarily affected by AI approaches to human neuroscience, and what normative safeguards should be enforced in this domain."
32228365,1.0,New Machine Learning Applications to Accelerate Personalized Medicine in Breast Cancer: Rise of the Support Vector Machines,2020 May;24(5):241-246.,"Artificial intelligence, machine learning, health care robots, and algorithms for clinical decision-making are currently being sought after in diverse fields of clinical medicine and bioengineering. The field of personalized medicine stands to benefit from new technologies so as to harness the omics big data, for example, to individualize and accelerate cancer diagnostics and therapeutics in particular. In this overarching context, breast cancer is one of the most common malignancies worldwide with multiple underlying molecular etiologies and each subtype displaying diverse clinical outcomes. Disease stratification for breast cancer is, therefore, vital to its effective and individualized clinical care. The support vector machine (SVM) is a rising machine learning approach that offers robust classification of high-dimensional big data into small numbers of data points (support vectors), achieving differentiation of subgroups in a short amount of time. Considering the rapid timelines required for both diagnosis and treatment of most aggressive cancers, this new machine learning technique has important clinical and public applications and implications for high-throughput data analysis and contextualization. This expert review describes and examines, first, the SVM models employed to forecast breast cancer subtypes using diverse systems science data, including transcriptomics, epigenetics, proteomics, and radiomics, as well as biological pathway, clinical, pathological, and biochemical data. Then, we compare the performance of the present SVM and other diagnostic and therapeutic prediction models across the data types. We conclude by emphasizing that data integration is a critical bottleneck in systems science, cancer research and development, and health care innovation and that SVM and machine learning approaches offer new solutions and ways forward in biomedical, bioengineering, and clinical applications."
32226594,6.0,NanoSolveIT Project: Driving nanoinformatics research to develop innovative and integrated tools for in silico nanosafety assessment,2020 Mar 7;18:583-602.,"Nanotechnology has enabled the discovery of a multitude of novel materials exhibiting unique physicochemical (PChem) properties compared to their bulk analogues. These properties have led to a rapidly increasing range of commercial applications; this, however, may come at a cost, if an association to long-term health and environmental risks is discovered or even just perceived. Many nanomaterials (NMs) have not yet had their potential adverse biological effects fully assessed, due to costs and time constraints associated with the experimental assessment, frequently involving animals. Here, the available NM libraries are analyzed for their suitability for integration with novel nanoinformatics approaches and for the development of NM specific Integrated Approaches to Testing and Assessment (IATA) for human and environmental risk assessment, all within the NanoSolveIT cloud-platform. These established and well-characterized NM libraries (e.g. NanoMILE, NanoSolutions, NANoREG, NanoFASE, caLIBRAte, NanoTEST and the Nanomaterial Registry (>2000 NMs)) contain physicochemical characterization data as well as data for several relevant biological endpoints, assessed in part using harmonized Organisation for Economic Co-operation and Development (OECD) methods and test guidelines. Integration of such extensive NM information sources with the latest nanoinformatics methods will allow NanoSolveIT to model the relationships between NM structure (morphology), properties and their adverse effects and to predict the effects of other NMs for which less data is available. The project specifically addresses the needs of regulatory agencies and industry to effectively and rapidly evaluate the exposure, NM hazard and risk from nanomaterials and nano-enabled products, enabling implementation of computational 'safe-by-design' approaches to facilitate NM commercialization."
32226593,3.0,Exploring 3D chromatin contacts in gene regulation: The evolution of approaches for the identification of functional enhancer-promoter interaction,2020 Feb 28;18:558-570.,"Mechanisms underlying gene regulation are key to understand how multicellular organisms with various cell types develop from the same genetic blueprint. Dynamic interactions between enhancers and genes are revealed to play central roles in controlling gene transcription, but the determinants to link functional enhancer-promoter pairs remain elusive. A major challenge is the lack of reliable approach to detect and verify functional enhancer-promoter interactions (EPIs). In this review, we summarized the current methods for detecting EPIs and described how developing techniques facilitate the identification of EPI through assessing the merits and drawbacks of these methods. We also reviewed recent state-of-art EPI prediction methods in terms of their rationale, data usage and characterization. Furthermore, we briefly discussed the evolved strategies for validating functional EPIs."
32220387,1.0,Artificial Intelligence for Diagnosis of Acute Coronary Syndromes: A Meta-analysis of Machine Learning Approaches,2020 Apr;36(4):577-583.,"Background:                    Machine learning (ML) encompasses a wide variety of methods by which artificial intelligence learns to perform tasks when exposed to data. Although detection of myocardial infarction has been facilitated with introduction of troponins, the diagnosis of acute coronary syndromes (ACS) without myocardial damage (without elevation of serum troponin) remains subjective, and its accuracy remains highly dependent on clinical skills of the health care professionals. Application of a ML algorithm may expedite management of ACS for either early discharge or early initiation of ACS management. We aim to summarize the published studies of ML for diagnosis of ACS.              Methods:                    We searched electronic databases, including PubMed, Embase, and Web of Science from inception up to January 13, 2019, for studies that evaluated ML algorithms for the diagnosis of ACS in patients presenting with chest pain. We then used random-effects bivariate meta-analysis models to summarize the studies.              Results:                    We retained 9 studies that evaluated ML in a total of 6292 patients. The prevalence of ACS in the evaluated cohorts ranged from relatively rare (7%) to common (57%). The pooled sensitivity and specificity were 0.95 and 0.90, respectively. The positive predictive values ranged from 0.64 to 1.0, and the negative predictive values ranged from 0.91 to 1.0. The positive and negative likelihood ratios ranged from 1.6 to 33.0 and 0.01 to 0.13, respectively.              Conclusions:                    The excellent sensitivity, negative likelihood ratio, and negative predictive values suggest that ML may be useful as an initial triage tool for ruling out ACS."
32218708,3.0,Using Artificial Intelligence in Infection Prevention,2020 Mar 19;1-10.,"Purpose of review:                    Artificial intelligence (AI) offers huge potential in infection prevention and control (IPC). We explore its potential IPC benefits in epidemiology, laboratory infection diagnosis, and hand hygiene.              Recent findings:                    AI has the potential to detect transmission events during outbreaks or predict high-risk patients, enabling development of tailored IPC interventions. AI offers opportunities to enhance diagnostics with objective pattern recognition, standardize the diagnosis of infections with IPC implications, and facilitate the dissemination of IPC expertise. AI hand hygiene applications can deliver behavior change, though it requires further evaluation in different clinical settings. However, staff can become dependent on automatic reminders, and performance returns to baseline if feedback is removed.              Summary:                    Advantages for IPC include speed, consistency, and capability of handling infinitely large datasets. However, many challenges remain; improving the availability of high-quality representative datasets and consideration of biases within preexisting databases are important challenges for future developments. AI in itself will not improve IPC; this requires culture and behavior change. Most studies to date assess performance retrospectively so there is a need for prospective evaluation in the real-life, often chaotic, clinical setting. Close collaboration with IPC experts to interpret outputs and ensure clinical relevance is essential."
32217160,6.0,Machine learning for microbial identification and antimicrobial susceptibility testing on MALDI-TOF mass spectra: a systematic review,2020 Oct;26(10):1310-1317.,"Background:                    The matrix assisted laser desorption/ionization and time-of-flight mass spectrometry (MALDI-TOF MS) technology has revolutionized the field of microbiology by facilitating precise and rapid species identification. Recently, machine learning techniques have been leveraged to maximally exploit the information contained in MALDI-TOF MS, with the ultimate goal to refine species identification and streamline antimicrobial resistance determination.              Objectives:                    The aim was to systematically review and evaluate studies employing machine learning for the analysis of MALDI-TOF mass spectra.              Data sources:                    Using PubMed/Medline, Scopus and Web of Science, we searched the existing literature for machine learning-supported applications of MALDI-TOF mass spectra for microbial species and antimicrobial susceptibility identification.              Study eligibility criteria:                    Original research studies using machine learning to exploit MALDI-TOF mass spectra for microbial specie and antimicrobial susceptibility identification were included. Studies focusing on single proteins and peptides, case studies and review articles were excluded.              Methods:                    A systematic review according to the PRISMA guidelines was performed and a quality assessment of the machine learning models conducted.              Results:                    From the 36 studies that met our inclusion criteria, 27 employed machine learning for species identification and nine for antimicrobial susceptibility testing. Support Vector Machines, Genetic Algorithms, Artificial Neural Networks and Quick Classifiers were the most frequently used machine learning algorithms. The quality of the studies ranged between poor and very good. The majority of the studies reported how to interpret the predictors (88.89%) and suggested possible clinical applications of the developed algorithm (100%), but only four studies (11.11%) validated machine learning algorithms on external datasets.              Conclusions:                    A growing number of studies utilize machine learning to optimize the analysis of MALDI-TOF mass spectra. This review, however, demonstrates that there are certain shortcomings of current machine learning-supported approaches that have to be addressed to make them widely available and incorporated them in the clinical routine."
32216134,1.0,Treatment of upper gastrointestinal bleeding in 2020: New techniques and outcomes,2021 Jan;33(1):83-94.,"The clinical outcome of upper gastrointestinal bleeding has improved due to advances in endoscopic therapy and standardized peri-endoscopy care. Apart from validating clinical scores, artificial intelligence-assisted machine learning models may play an important role in risk stratification. While standard endoscopic treatments remain irreplaceable, novel endoscopic modalities have changed the landscape of management. Over-the-scope clips have high success rates as rescue or even first-line treatments in difficult-to-treat cases. Hemostatic powder is safe and easy to use, which can be useful as temporary control with its high immediate hemostatic ability. After endoscopic hemostasis, Doppler endoscopic probe can offer an objective measure to guide the treatment endpoint. In refractory bleeding, angiographic embolization should be considered before salvage surgery. In variceal hemorrhage, banding ligation and glue injection are first-line treatment options. Endoscopic ultrasound-guided therapy is gaining popularity due to its capability of precise localization for treatment targets. A self-expandable metal stent may be considered as an alternative option to balloon tamponade in refractory bleeding. Transjugular intrahepatic portosystemic shunting should be reserved as salvage therapy. In this article, we aim to provide an evidence-based comprehensive review of the major advancements in endoscopic hemostatic techniques and clinical outcomes."
32215849,1.0,The Role and Promise of Artificial Intelligence in Medical Toxicology,2020 Oct;16(4):458-464.,"Artificial intelligence (AI) refers to machines or software that process information and interact with the world as understanding beings. Examples of AI in medicine include the automated reading of chest X-rays and the detection of heart dysrhythmias from wearables. A key promise of AI is its potential to apply logical reasoning at the scale of data too vast for the human mind to comprehend. This scaling up of logical reasoning may allow clinicians to bring the entire breadth of current medical knowledge to bear on each patient in real time. It may also unearth otherwise unreachable knowledge in the attempt to integrate knowledge and research across disciplines. In this review, we discuss two complementary aspects of artificial intelligence: deep learning and knowledge representation. Deep learning recognizes and predicts patterns. Knowledge representation structures and interprets those patterns or predictions. We frame this review around how deep learning and knowledge representation might expand the reach of Poison Control Centers and enhance syndromic surveillance from social media."
32215571,1.0,Generative and discriminative model-based approaches to microscopic image restoration and segmentation,2020 Apr 8;69(2):79-91.,"Image processing is one of the most important applications of recent machine learning (ML) technologies. Convolutional neural networks (CNNs), a popular deep learning-based ML architecture, have been developed for image processing applications. However, the application of ML to microscopic images is limited as microscopic images are often 3D/4D, that is, the image sizes can be very large, and the images may suffer from serious noise generated due to optics. In this review, three types of feature reconstruction applications to microscopic images are discussed, which fully utilize the recent advancements in ML technologies. First, multi-frame super-resolution is introduced, based on the formulation of statistical generative model-based techniques such as Bayesian inference. Second, data-driven image restoration is introduced, based on supervised discriminative model-based ML technique. In this application, CNNs are demonstrated to exhibit preferable restoration performance. Third, image segmentation based on data-driven CNNs is introduced. Image segmentation has become immensely popular in object segmentation based on electron microscopy (EM); therefore, we focus on EM image processing."
32213317,2.0,Image analysis and artificial intelligence in infectious disease diagnostics,2020 Oct;26(10):1318-1323.,"Background:                    Microbiologists are valued for their time-honed skills in image analysis, including identification of pathogens and inflammatory context in Gram stains, ova and parasite preparations, blood smears and histopathologic slides. They also must classify colony growth on a variety of agar plates for triage and assessment. Recent advances in image analysis, in particular application of artificial intelligence (AI), have the potential to automate these processes and support more timely and accurate diagnoses.              Objectives:                    To review current AI-based image analysis as applied to clinical microbiology; and to discuss future trends in the field.              Sources:                    Material sourced for this review included peer-reviewed literature annotated in the PubMed or Google Scholar databases and preprint articles from bioRxiv. Articles describing use of AI for analysis of images used in infectious disease diagnostics were reviewed.              Content:                    We describe application of machine learning towards analysis of different types of microbiologic image data. Specifically, we outline progress in smear and plate interpretation as well as the potential for AI diagnostic applications in the clinical microbiology laboratory.              Implications:                    Combined with automation, we predict that AI algorithms will be used in the future to prescreen and preclassify image data, thereby increasing productivity and enabling more accurate diagnoses through collaboration between the AI and the microbiologist. Once developed, image-based AI analysis is inexpensive and amenable to local and remote diagnostic use."
32211130,3.0,Prediction of the miRNA interactome - Established methods and upcoming perspectives,2020 Mar 5;18:548-557.,"MicroRNAs (miRNAs) are well-studied small noncoding RNAs involved in post-transcriptional gene regulation in a wide range of organisms, including mammals. Their function is mediated by base pairing with their target RNAs. Although many features required for miRNA-mediated repression have been described, the identification of functional interactions is still challenging. In the last two decades, numerous Machine Learning (ML) models have been developed to predict their putative targets. In this review, we summarize the biological knowledge and the experimental data used to develop these ML models. Recently, Deep Neural Network-based models have also emerged in miRNA interaction modeling. We thus outline established and emerging models to give a perspective on the future developments needed to improve the identification of genes directly regulated by miRNAs."
32207586,,The ways of using machine learning in dentistry,2020 Mar;29(3):375-384.,"Innovative computer techniques are starting to be employed not only in academic research, but also in commercial production, finding use in many areas of dentistry. This is conducive to the digitalization of dentistry and its increasing treatment and diagnostic demands. In many areas of dentistry, such as orthodontics and maxillofacial surgery, but also periodontics or prosthetics, only a correct diagnosis ensures the correct treatment plan, which is the only way to restore the patient's health. The diagnosis and treatment plan is based on the specialist's knowledge, but is subject to a large, multi-factorial risk of error. Therefore, the introduction of multiparametric pattern recognition methods (statistics, machine learning and artificial intelligence (AI)) is a great hope for both the physicians and the patients. However, the general use of clinical decision support systems (CDSS) in a dental clinic is not yet realistic and requires work in many aspects - methodical, technological and business. The article presents a review of the latest attempts to apply AI, such as CDSS or genetic algorithms (GAs) in research and clinical dentistry, taking under consideration all of the main dental specialties. Work on the introduction of public CDSS has been continued for years. The article presents the latest achievements in this field, analyzing their real-life application and credibility."
32207266,,Machine Learning Applications in Endocrinology and Metabolism Research: An Overview,2020 Mar;35(1):71-84.,"Machine learning (ML) applications have received extensive attention in endocrinology research during the last decade. This review summarizes the basic concepts of ML and certain research topics in endocrinology and metabolism where ML principles have been actively deployed. Relevant studies are discussed to provide an overview of the methodology, main findings, and limitations of ML, with the goal of stimulating insights into future research directions. Clear, testable study hypotheses stem from unmet clinical needs, and the management of data quality (beyond a focus on quantity alone), open collaboration between clinical experts and ML engineers, the development of interpretable high-performance ML models beyond the black-box nature of some algorithms, and a creative environment are the core prerequisites for the foreseeable changes expected to be brought about by ML and artificial intelligence in the field of endocrinology and metabolism, with actual improvements in clinical practice beyond hype. Of note, endocrinologists will continue to play a central role in these developments as domain experts who can properly generate, refine, analyze, and interpret data with a combination of clinical expertise and scientific rigor."
32205581,1.0,Artificial intelligence driven next-generation renal histomorphometry,2020 May;29(3):265-272.,"Purpose of review:                    Successful integration of artificial intelligence into extant clinical workflows is contingent upon a number of factors including clinician comprehension and interpretation of computer vision. This article discusses how image analysis and machine learning have enabled comprehensive characterization of kidney morphology for development of automated diagnostic and prognostic renal pathology applications.              Recent findings:                    The primordial digital pathology informatics work employed classical image analysis and machine learning to prognosticate renal disease. Although this classical approach demonstrated tremendous potential, subsequent advancements in hardware technology rendered artificial neural networks '(ANNs) the method of choice for machine vision in computational pathology'. Offering rapid and reproducible detection, characterization and classification of kidney morphology, ANNs have facilitated the development of diagnostic and prognostic applications. In addition, modern machine learning with ANNs has revealed novel biomarkers in kidney disease, demonstrating the potential for machine vision to elucidate novel pathologic mechanisms beyond extant clinical knowledge.              Summary:                    Despite the revolutionary developments potentiated by modern machine learning, several challenges remain, including data quality control and curation, image annotation and ontology, integration of multimodal data and interpretation of machine vision or 'opening the black box'. Resolution of these challenges will not only revolutionize diagnostic pathology but also pave the way for precision medicine and integration of artificial intelligence in the process of care."
32204390,,Smart Containers Schedulers for Microservices Provision in Cloud-Fog-IoT Networks. Challenges and Opportunities,2020 Mar 19;20(6):1714.,"Docker containers are the lightweight-virtualization technology prevailing today for the provision of microservices. This work raises and discusses two main challenges in Docker containers' scheduling in cloud-fog-internet of things (IoT) networks. First, the convenience to integrate intelligent containers' schedulers based on soft-computing in the dominant open-source containers' management platforms: Docker Swarm, Google Kubernetes and Apache Mesos. Secondly, the need for specific intelligent containers' schedulers for the different interfaces in cloud-fog-IoT networks: cloud-to-fog, fog-to-IoT and cloud-to-fog. The goal of this work is to support the optimal allocation of microservices provided by the main cloud service providers today and used by millions of users worldwide in applications such as smart health, content delivery networks, smart health, etc. Particularly, the improvement is studied in terms of quality of service (QoS) parameters such as latency, load balance, energy consumption and runtime, based on the analysis of previous works and implementations. Moreover, the scientific-technical impact of smart containers' scheduling in the market is also discussed, showing the possible repercussion of the raised opportunities in the research line."
32201388,5.0,Sport and exercise genomics: the FIMS 2019 consensus statement update,2020 Aug;54(16):969-975.,"Rapid advances in technologies in the field of genomics such as high throughput DNA sequencing, big data processing by machine learning algorithms and gene-editing techniques are expected to make precision medicine and gene-therapy a greater reality. However, this development will raise many important new issues, including ethical, moral, social and privacy issues. The field of exercise genomics has also advanced by incorporating these innovative technologies. There is therefore an urgent need for guiding references for sport and exercise genomics to allow the necessary advancements in this field of sport and exercise medicine, while protecting athletes from any invasion of privacy and misuse of their genomic information. Here, we update a previous consensus and develop a guiding reference for sport and exercise genomics based on a SWOT (Strengths, Weaknesses, Opportunities and Threats) analysis. This SWOT analysis and the developed guiding reference highlight the need for scientists/clinicians to be well-versed in ethics and data protection policy to advance sport and exercise genomics without compromising the privacy of athletes and the efforts of international sports federations. Conducting research based on the present guiding reference will mitigate to a great extent the risks brought about by inappropriate use of genomic information and allow further development of sport and exercise genomics in accordance with best ethical standards and international data protection principles and policies. This guiding reference should regularly be updated on the basis of new information emerging from the area of sport and exercise medicine as well as from the developments and challenges in genomics of health and disease in general in order to best protect the athletes, patients and all other relevant stakeholders."
32201286,1.0,Applications of artificial intelligence in multimodality cardiovascular imaging: A state-of-the-art review,May-Jun 2020;63(3):367-376.,"There has been a tidal wave of recent interest in artificial intelligence (AI), machine learning and deep learning approaches in cardiovascular (CV) medicine. In the era of modern medicine, AI and electronic health records hold the promise to improve the understanding of disease conditions and bring a personalized approach to CV care. The field of CV imaging (CVI), incorporating echocardiography, cardiac computed tomography, cardiac magnetic resonance imaging and nuclear imaging, with sophisticated imaging techniques and high volumes of imaging data, is primed to be at the forefront of the revolution in precision cardiology. This review provides a contemporary overview of the CVI imaging applications of AI, including a critique of the strengths and potential limitations of deep learning approaches."
32201044,7.0,Disentangling Heterogeneity in Alzheimer's Disease and Related Dementias Using Data-Driven Methods,2020 Jul 1;88(1):70-82.,"Brain aging is a complex process that includes atrophy, vascular injury, and a variety of age-associated neurodegenerative pathologies, together determining an individual's course of cognitive decline. While Alzheimer's disease and related dementias contribute to the heterogeneity of brain aging, these conditions themselves are also heterogeneous in their clinical presentation, progression, and pattern of neural injury. We reviewed studies that leveraged data-driven approaches to examining heterogeneity in Alzheimer's disease and related dementias, with a principal focus on neuroimaging studies exploring subtypes of regional neurodegeneration patterns. Over the past decade, the steadily increasing wealth of clinical, neuroimaging, and molecular biomarker information collected within large-scale observational cohort studies has allowed for a richer understanding of the variability of disease expression within the aging and Alzheimer's disease and related dementias continuum. Moreover, the availability of these large-scale datasets has supported the development and increasing application of clustering techniques for studying disease heterogeneity in a data-driven manner. In particular, data-driven studies have led to new discoveries of previously unappreciated disease subtypes characterized by distinct neuroimaging patterns of regional neurodegeneration, which are paralleled by heterogeneous profiles of pathological, clinical, and molecular biomarker characteristics. Incorporating these findings into novel frameworks for more differentiated disease stratification holds great promise for improving individualized diagnosis and prognosis of expected clinical progression, and provides opportunities for development of precision medicine approaches for therapeutic intervention. We conclude with an account of the principal challenges associated with data-driven heterogeneity analyses and outline avenues for future developments in the field."
32197324,17.0,A Review on Applications of Computational Methods in Drug Screening and Design,2020 Mar 18;25(6):1375.,"Drug development is one of the most significant processes in the pharmaceutical industry. Various computational methods have dramatically reduced the time and cost of drug discovery. In this review, we firstly discussed roles of multiscale biomolecular simulations in identifying drug binding sites on the target macromolecule and elucidating drug action mechanisms. Then, virtual screening methods (e.g., molecular docking, pharmacophore modeling, and QSAR) as well as structure- and ligand-based classical/de novo drug design were introduced and discussed. Last, we explored the development of machine learning methods and their applications in aforementioned computational methods to speed up the drug discovery process. Also, several application examples of combining various methods was discussed. A combination of different methods to jointly solve the tough problem at different scales and dimensions will be an inevitable trend in drug screening and design."
32196135,1.0,Progress in Computational and Machine-Learning Methods for Heterogeneous Small-Molecule Activation,2020 Sep;32(35):e1907865.,"The chemical conversion of small molecules such as H2 , H2 O, O2 , N2 , CO2 , and CH4 to energy and chemicals is critical for a sustainable energy future. However, the high chemical stability of these molecules poses grand challenges to the practical implementation of these processes. In this regard, computational approaches such as density functional theory, microkinetic modeling, data science, and machine learning have guided the rational design of catalysts by elucidating mechanistic insights, identifying active sites, and predicting catalytic activity. Here, the theory and methodologies for heterogeneous catalysis and their applications for small-molecule activation are reviewed. An overview of fundamental theory and key computational methods for designing catalysts, including the emerging data science techniques in particular, is given. Applications of these methods for finding efficient heterogeneous catalysts for the activation of the aforementioned small molecules are then surveyed. Finally, promising directions of the computational catalysis field for further outlooks are discussed, focusing on the challenges and opportunities for new methods."
32195886,1.0,Machine Learning and Deep Neural Networks Applications in Computed Tomography for Coronary Artery Disease and Myocardial Perfusion,2020 May;35 Suppl 1:S58-S65.,"During the latest years, artificial intelligence, and especially machine learning (ML), have experienced a growth in popularity due to their versatility and potential in solving complex problems. In fact, ML allows the efficient handling of big volumes of data, allowing to tackle issues that were unfeasible before, especially with deep learning, which utilizes multilayered neural networks. Cardiac computed tomography (CT) is also experiencing a rise in examination numbers, and ML might help handle the increasing derived information. Moreover, cardiac CT presents some fields wherein ML may be pivotal, such as coronary calcium scoring, CT angiography, and perfusion. In particular, the main applications of ML involve image preprocessing and postprocessing, and the development of risk assessment models based on imaging findings. Concerning image preprocessing, ML can help improve image quality by optimizing acquisition protocols or removing artifacts that may hinder image analysis and interpretation. ML in image postprocessing might help perform automatic segmentations and shorten examination processing times, also providing tools for tissue characterization, especially concerning plaques. The development of risk assessment models from ML using data from cardiac CT could aid in the stratification of patients who undergo cardiac CT in different risk classes and better tailor their treatment to individual conditions. While ML is a powerful tool with great potential, applications in the field of cardiac CT are still expanding, and not yet routinely available in clinical practice due to the need for extensive validation. Nevertheless, ML is expected to have a big impact on cardiac CT in the near future."
32195365,7.0,A systematic review of the applications of artificial intelligence and machine learning in autoimmune diseases,2020 Mar 9;3:30.,"Autoimmune diseases are chronic, multifactorial conditions. Through machine learning (ML), a branch of the wider field of artificial intelligence, it is possible to extract patterns within patient data, and exploit these patterns to predict patient outcomes for improved clinical management. Here, we surveyed the use of ML methods to address clinical problems in autoimmune disease. A systematic review was conducted using MEDLINE, embase and computers and applied sciences complete databases. Relevant papers included ""machine learning"" or ""artificial intelligence"" and the autoimmune diseases search term(s) in their title, abstract or key words. Exclusion criteria: studies not written in English, no real human patient data included, publication prior to 2001, studies that were not peer reviewed, non-autoimmune disease comorbidity research and review papers. 169 (of 702) studies met the criteria for inclusion. Support vector machines and random forests were the most popular ML methods used. ML models using data on multiple sclerosis, rheumatoid arthritis and inflammatory bowel disease were most common. A small proportion of studies (7.7% or 13/169) combined different data types in the modelling process. Cross-validation, combined with a separate testing set for more robust model evaluation occurred in 8.3% of papers (14/169). The field may benefit from adopting a best practice of validation, cross-validation and independent testing of ML models. Many models achieved good predictive results in simple scenarios (e.g. classification of cases and controls). Progression to more complex predictive models may be achievable in future through integration of multiple data types."
32193643,,Diagnostic accuracy and potential covariates for machine learning to identify IDH mutations in glioma patients: evidence from a meta-analysis,2020 Aug;30(8):4664-4674.,"Objectives:                    To assess the diagnostic accuracy of machine learning (ML) in predicting isocitrate dehydrogenase (IDH) mutations in patients with glioma and to identify potential covariates that could influence the diagnostic performance of ML.              Methods:                    A systematic search of PubMed, Web of Science, and the Cochrane library up to 1 August 2019 was conducted to collect all the articles investigating the diagnostic performance of ML for prediction of IDH mutation in glioma. The search strategy combined synonyms for 'machine learning', 'glioma', and 'IDH'. Pooled sensitivity, specificity, and their 95% confidence intervals (CIs) were calculated, and the area under the receiver operating characteristic curve (AUC) was obtained.              Results:                    Nine original articles assessing a total of 996 patients with glioma were included. Among these studies, five divided the participants into training and validation sets, while the remaining four studies only had a training set. The AUC of ML for predicting IDH mutation in the training and validation sets was 93% (95% CI 91-95%) and 89% (95% CI 86-92%), respectively. The pooled sensitivity and specificity were, respectively, 87% (95% CI 82-91%) and 88% (95% CI 83-92%) in the training set and 87% (95% CI 76-93%) and 90% (95% CI 72-97%) in the validation set. In subgroup analyses in the training set, the combined use of clinical and imaging features with ML yielded higher sensitivity (90% vs. 83%) and specificity (90% vs. 82%) than the use of imaging features alone. In addition, ML performed better for high-grade gliomas than for low-grade gliomas, and ML that used conventional MRI sequences demonstrated higher specificity for predicting IDH mutation than ML using conventional and advanced MRI sequences.              Conclusions:                    ML demonstrated an excellent diagnostic performance in predicting IDH mutation of glioma. Clinical information, MRI sequences, and glioma grade were the main factors influencing diagnostic specificity.              Key points:                    • Machine learning demonstrated an excellent diagnostic performance for prediction of IDH mutation in glioma (the pooled sensitivity and specificity were 88% and 87%, respectively). • Machine learning that used conventional MRI sequences demonstrated higher specificity in predicting IDH mutation than that based on conventional and advanced MRI sequences (89% vs. 85%). • Integration of clinical and imaging features in machine learning yielded a higher sensitivity (90% vs. 83%) and specificity (90% vs. 82%) than that achieved by using imaging features alone."
32192349,,Biomarkers of neoadjuvant/adjuvant chemotherapy for breast cancer,2020 Jun;9(3):27.,"The improvement of tumor biomarkers prepared for clinical use is a long process. A good biomarker should predict not only prognosis but also the response to therapies. In this review, we describe the biomarkers of neoadjuvant/adjuvant chemotherapy for breast cancer, considering different breast cancer subtypes. In hormone receptor (HR)-positive/human epidermal growth factor 2 (HER2)-negative breast cancers, various genomic markers highly associated with proliferation have been tested. Among them, only two genomic signatures, the 21-gene recurrence score and 70-gene signature, have been reported in prospective randomized clinical trials and met the primary endpoint. However, these genomic markers did not suffice in HER2-positive and triple-negative (TN) breast cancers, which present only classical clinical and pathological information (tumor size, nodal or distant metastatic status) for decision making in the adjuvant setting in daily clinic. Recently, patients with residual invasive cancer after neoadjuvant chemotherapy are at a high-risk of recurrence for metastasis, which, in turn, make these patients best applicants for clinical trials. Two clinical trials have shown improved outcomes with post-operative capecitabine and ado-trastuzumab emtansine treatment in patients with either TN or HER2-positive breast cancer, respectively, who had residual disease after neoadjuvant chemotherapy. Furthermore, tumor-infiltrating lymphocytes (TILs) have been reported to have a predictive value for prognosis and response to chemotherapy from the retrospective analyses. So far, TILs have to not be used to either withhold or prescribe chemotherapy based on the absence of standardized evaluation guidelines and confirmed information. To overcome the low reproducibility of evaluations of TILs, gene signatures or digital image analysis and machine learning algorithms with artificial intelligence may be useful for standardization of assessment for TILs in the future."
32187757,,"Discovering Intermetallics Through Synthesis, Computation, and Data-Driven Analysis",2020 Jul 17;26(40):8689-8697.,"Intermetallics adopt an array of crystal structures, boast diverse chemical compositions, and possess exotic physical properties that have led to a wide range of applications from the biomedical to aerospace industries. Despite a long history of intermetallic synthesis and crystal structure analysis, identifying new intermetallic phases has remained challenging due to the prolonged nature of experimental phase space searching or the need for fortuitous discovery. In this Minireview, new approaches that build on the traditional methods for materials synthesis and characterization are discussed with a specific focus on realizing novel intermetallics. Indeed, advances in the computational modeling of solids using density functional theory in combination with structure prediction algorithms have led to new high-pressure phases, functional intermetallics, and aided experimental efforts. Furthermore, the advent of data-centered methodologies has provided new opportunities to rapidly predict crystal structures, physical properties, and the existence of unknown compounds. Describing the research results for each of these examples in depth while also highlighting the numerous opportunities to merge traditional intermetallic synthesis and characterization with computation and informatics provides insight that is essential to advance the discovery of metal-rich solids."
32185167,1.0,Use of Computational Modeling to Study Joint Degeneration: A Review,2020 Feb 28;8:93.,"Osteoarthritis (OA), a degenerative joint disease, is the most common chronic condition of the joints, which cannot be prevented effectively. Computational modeling of joint degradation allows to estimate the patient-specific progression of OA, which can aid clinicians to estimate the most suitable time window for surgical intervention in osteoarthritic patients. This paper gives an overview of the different approaches used to model different aspects of joint degeneration, thereby focusing mostly on the knee joint. The paper starts by discussing how OA affects the different components of the joint and how these are accounted for in the models. Subsequently, it discusses the different modeling approaches that can be used to answer questions related to OA etiology, progression and treatment. These models are ordered based on their underlying assumptions and technologies: musculoskeletal models, Finite Element models, (gene) regulatory models, multiscale models and data-driven models (artificial intelligence/machine learning). Finally, it is concluded that in the future, efforts should be made to integrate the different modeling techniques into a more robust computational framework that should not only be efficient to predict OA progression but also easily allow a patient's individualized risk assessment as screening tool for use in clinical practice."
32180833,,Latest Advances in Cardiac CT,2020 Feb 26;15:1-7.,"Recent rapid technological advancements in cardiac CT have improved image quality and reduced radiation exposure to patients. Furthermore, key insights from large cohort trials have helped delineate cardiovascular disease risk as a function of overall coronary plaque burden and the morphological appearance of individual plaques. The advent of CT-derived fractional flow reserve promises to establish an anatomical and functional test within one modality. Recent data examining the short-term impact of CT-derived fractional flow reserve on downstream care and clinical outcomes have been published. In addition, machine learning is a concept that is being increasingly applied to diagnostic medicine. Over the coming decade, machine learning will begin to be integrated into cardiac CT, and will potentially make a tangible difference to how this modality evolves. The authors have performed an extensive literature review and comprehensive analysis of the recent advances in cardiac CT. They review how recent advances currently impact on clinical care and potential future directions for this imaging modality."
32175423,2.0,Radiographic assessment of the cup orientation after total hip arthroplasty: a literature review,2020 Feb;8(4):130.,"Optimal acetabular cup orientation is of substantial importance to good long-term function and low complication rates after total hip arthroplasty (THA). The radiographic anteversion (RA) and inclination (RI) angles of the cup are typically studied due to the practicability, simplicity, and ease of interpretation of their measurements. A great number of methods have been developed to date, most of which have been performed on pelvic or hip anteroposterior radiographs. However, there are primarily two influencing factors for these methods: X-ray offset and pelvic rotation. In addition, there are three types of pelvic rotations about the transverse, longitudinal, and anteroposterior axes of the body. Their effects on the RA and RI angles of the cup are interactively correlated with the position and true orientation of the cup. To date, various fitted or analytical models have been established to disclose the correlations between the X-ray offset and pelvic rotation and the RA and RI angles of the cup. Most of these models do not incorporate all the potential influencing parameters. Advanced methods for performing X-ray offset and pelvic rotation corrections are mainly performed on a single pelvic AP radiograph, two synchronized radiographs, or a two-dimensional/three-dimensional (2D-3D) registration system. Some measurement systems, originally developed for evaluating implant migration or wear, could also be used for correcting the X-ray offset and pelvic rotation simultaneously, but some drawbacks still exist with these systems. Above all, the 2D-3D registration technique might be an alternative and powerful tool for accurately measuring cup orientation. In addition to the current methods used for postoperative assessment, navigation systems and augmented reality are also used for the preoperative planning and intraoperative guidance of cup placement. With the continuing development of artificial intelligence and machine learning, these techniques could be incorporated into robot-assisted orthopaedic surgery in the future."
32173518,2.0,Precision health: A pragmatic approach to understanding and addressing key factors in autoimmune diseases,2020 May;19(5):102508.,"The past decade has witnessed a significant paradigm shift in the clinical approach to autoimmune diseases, lead primarily by initiatives in precision medicine, precision health and precision public health initiatives. An understanding and pragmatic implementation of these approaches require an understanding of the drivers, gaps and limitations of precision medicine. Gaining the trust of the public and patients is paramount but understanding that technologies such as artificial intelligences and machine learning still require context that can only be provided by human input or what is called augmented machine learning. The role of genomics, the microbiome and proteomics, such as autoantibody testing, requires continuing refinement through research and pragmatic approaches to their use in applied precision medicine."
32171918,4.0,Machine learning models for drug-target interactions: current knowledge and future directions,2020 Apr;25(4):748-756.,"Predicting the binding affinity between compounds and proteins with reasonable accuracy is crucial in drug discovery. Computational prediction of binding affinity between compounds and targets greatly enhances the probability of finding lead compounds by reducing the number of wet-lab experiments. Machine-learning and deep-learning techniques using ligand-based and target-based approaches have been used to predict binding affinities, thereby saving time and cost in drug discovery efforts. In this review, we discuss about machine-learning and deep-learning models used in virtual screening to improve drug-target interaction (DTI) prediction. We also highlight current knowledge and future directions to guide further development in this field."
32168002,,Recent developments in pediatric retina,2020 May;31(3):155-160.,"Purpose of review:                    Pediatric retina is an exciting, but also challenging field, where patient age and cooperation can limit ease of diagnosis of a broad range of congenital and acquired diseases, inherited retinal degenerations are mostly untreatable and surgical outcomes can be quite different from those for adults. This review aims to highlight some recent advances and trends that are improving our ability to care for children with retinal conditions.              Recent findings:                    Studies have demonstrated the feasibility of multimodal imaging even in nonsedated infants, with portable optical coherence tomography (OCT) and OCT angiography in particular offering structural insights into diverse pediatric retinal conditions. Encouraging long-term outcomes of subretinal voretigene neparvovec-rzyl injection for RPE65 mutation-associated Leber congenital amaurosis have inspired research on the optimization of subretinal gene delivery and gene therapy for other inherited retinal degenerations. In retinopathy of prematurity, machine learning and smartphone-based imaging can facilitate screening, and studies have highlighted favorable outcomes from intravitreal anti-vascular endothelial growth factor (anti-VEGF) injections. A nomogram for pediatric pars plana sclerotomy site placement may improve safety in complex surgeries.              Summary:                    Multimodal imaging, gene therapy, machine learning and surgical innovation have been and will continue to be important to advances in pediatric retina."
32167235,1.0,Deep learning a boon for biophotonics?,2020 Jun;13(6):e201960186.,"This review covers original articles using deep learning in the biophotonic field published in the last years. In these years deep learning, which is a subset of machine learning mostly based on artificial neural network geometries, was applied to a number of biophotonic tasks and has achieved state-of-the-art performances. Therefore, deep learning in the biophotonic field is rapidly growing and it will be utilized in the next years to obtain real-time biophotonic decision-making systems and to analyze biophotonic data in general. In this contribution, we discuss the possibilities of deep learning in the biophotonic field including image classification, segmentation, registration, pseudostaining and resolution enhancement. Additionally, we discuss the potential use of deep learning for spectroscopic data including spectral data preprocessing and spectral classification. We conclude this review by addressing the potential applications and challenges of using deep learning for biophotonic data."
32165361,3.0,Artificial Intelligence in the Management of Intracranial Aneurysms: Current Status and Future Perspectives,2020 Mar;41(3):373-379.,"Intracranial aneurysms with subarachnoid hemorrhage lead to high morbidity and mortality. It is of critical importance to detect aneurysms, identify risk factors of rupture, and predict treatment response of aneurysms to guide clinical interventions. Artificial intelligence has received worldwide attention for its impressive performance in image-based tasks. Artificial intelligence serves as an adjunct to physicians in a series of clinical settings, which substantially improves diagnostic accuracy while reducing physicians' workload. Computer-assisted diagnosis systems of aneurysms based on MRA and CTA using deep learning have been evaluated, and excellent performances have been reported. Artificial intelligence has also been used in automated morphologic calculation, rupture risk stratification, and outcomes prediction with the implementation of machine learning methods, which have exhibited incremental value. This review summarizes current advances of artificial intelligence in the management of aneurysms, including detection and prediction. The challenges and future directions of clinical implementations of artificial intelligence are briefly discussed."
32164862,,General principles of machine learning for brain-computer interfacing,2020;168:311-328.,"Brain-computer interfaces (BCIs) are systems that translate brain activity patterns into commands that can be executed by an artificial device. This enables the possibility of controlling devices such as a prosthetic arm or exoskeleton, a wheelchair, typewriting applications, or games directly by modulating our brain activity. For this purpose, BCI systems rely on signal processing and machine learning algorithms to decode the brain activity. This chapter provides an overview of the main steps required to do such a process, including signal preprocessing, feature extraction and selection, and decoding. Given the large amount of possible methods that can be used for these processes, a comprehensive review of them is beyond the scope of this chapter, and it is focused instead on the general principles that should be taken into account, as well as discussing good practices on how these methods should be applied and evaluated for proper design of reliable BCI systems."
32164861,1.0,Merging brain-computer interface and functional electrical stimulation technologies for movement restoration,2020;168:303-309.,"BCI (brain-computer interface) and functional electrical stimulation (FES) technologies have advanced significantly over the last several decades. Recent efforts have involved the integration of these technologies with the goal of restoring functional movement in paralyzed patients. Implantable BCIs have provided neural recordings with increased spatial resolution and have been combined with sophisticated neural decoding algorithms and increasingly capable FES systems to advance efforts toward this goal. This chapter reviews historical developments that have occurred as the exciting fields of BCI and FES have evolved and now overlapped to allow new breakthroughs in medicine, targeting restoration of movement and lost function in users with disabilities."
32164853,1.0,Monitoring performance of professional and occupational operators,2020;168:199-205.,"The human capacity to simultaneously perform several tasks depends on the quantity and the mode of mentally processing the information imposed by the tasks. Since operational environments are highly dynamic, priorities across tasks will be expected to change as the mission evolves, thus the capability to reallocate the mental resources dynamically depending on such changes is very important. The resources required in very complex situations, such as air traffic management (ATM), can exceed the user's available resources leading to increased workload and performance impairments. In this regard, the availability of information concerning the workload experienced by the operators while dealing with tasks will be fundamental for both warning them when overload conditions are approaching and improving interactions with the system. The idea of our work was to use neurophysiologic data collected from professional air traffic controllers (ATCOs) to provide additional information to standard measures with which to assess the ATCOs' expertise and a machine learning electroencephalography-based index to evaluate their mental workload during the execution of ATC tasks. The results showed that the proposed method was able to track the workload alongside the execution of the realistic ATM scenario, and provide added values to objectively assess the expertise of the ATCOs."
32164200,2.0,Applications of Deep Learning for Dense Scenes Analysis in Agriculture: A Review,2020 Mar 10;20(5):1520.,"Deep Learning (DL) is the state-of-the-art machine learning technology, which shows superior performance in computer vision, bioinformatics, natural language processing, and other areas. Especially as a modern image processing technology, DL has been successfully applied in various tasks, such as object detection, semantic segmentation, and scene analysis. However, with the increase of dense scenes in reality, due to severe occlusions, and small size of objects, the analysis of dense scenes becomes particularly challenging. To overcome these problems, DL recently has been increasingly applied to dense scenes and has begun to be used in dense agricultural scenes. The purpose of this review is to explore the applications of DL for dense scenes analysis in agriculture. In order to better elaborate the topic, we first describe the types of dense scenes in agriculture, as well as the challenges. Next, we introduce various popular deep neural networks used in these dense scenes. Then, the applications of these structures in various agricultural tasks are comprehensively introduced in this review, including recognition and classification, detection, counting and yield estimation. Finally, the surveyed DL applications, limitations and the future work for analysis of dense images in agriculture are summarized."
32162711,2.0,Fracture risk assessment and clinical decision making for patients with metastatic bone disease,2020 Jun;38(6):1175-1190.,"Metastatic breast, prostate, lung, and other cancers often affect bone, causing pain, increasing fracture risk, and decreasing function. Management of metastatic bone disease (MBD) is clinically challenging when there is potential but uncertain risk of pathological fracture. Management of MBD has become a major focus within orthopedic oncology with respect to fracture and impending fracture care. If impending skeletal-related events (SREs), particularly pathologic fracture, could be predicted, increasing evidence suggests that prophylactic surgical treatment improves patient outcomes. However, current fracture risk assessment and radiographic metrics do not have high accuracy and have not been combined with relevant patient survival tools. This review first explores the prevalence, incidence, and morbidity of MBD and associated SREs for different cancer types. Strengths and limitations of current fracture risk scoring systems for spinal stability and long bone fracture are highlighted. More recent computed tomography (CT)-based structural rigidity analysis (CTRA) and finite element (FE) analysis methods offer advantages of increased specificity (true negative rate), but are limited in availability. Other fracture prediction approaches including parametric response mapping and positron emission tomography/computed tomography measures show early promise. Substantial new information to inform clinical decision-making includes measures of survival, clinical benefits, and economic analysis of prophylactic treatment compared to after-fracture stabilization. Areas of future research include use of big data and machine learning to predict SREs, greater access and refinement of CTRA/FE approaches, combination of clinical survival prediction tools with radiographically based fracture risk assessment, and net benefit analysis for fracture risk assessment and prophylactic treatment."
32162398,1.0,Improvement of oral cancer screening quality and reach: The promise of artificial intelligence,2020 Sep;49(8):727-730.,"Oral cancer is easily detectable by physical (self) examination. However, many cases of oral cancer are detected late, which causes unnecessary morbidity and mortality. Screening of high-risk populations seems beneficial, but these populations are commonly located in regions with limited access to health care. The advent of information technology and its modern derivative artificial intelligence (AI) promises to improve oral cancer screening but to date, few efforts have been made to apply these techniques and relatively little research has been conducted to retrieve meaningful information from AI data. In this paper, we discuss the promise of AI to improve the quality and reach of oral cancer screening and its potential effect on improving mortality and unequal access to health care around the world."
32158767,2.0,From Compressed-Sensing to Artificial Intelligence-Based Cardiac MRI Reconstruction,2020 Feb 25;7:17.,"Cardiac magnetic resonance (CMR) imaging is an important tool for the non-invasive assessment of cardiovascular disease. However, CMR suffers from long acquisition times due to the need of obtaining images with high temporal and spatial resolution, different contrasts, and/or whole-heart coverage. In addition, both cardiac and respiratory-induced motion of the heart during the acquisition need to be accounted for, further increasing the scan time. Several undersampling reconstruction techniques have been proposed during the last decades to speed up CMR acquisition. These techniques rely on acquiring less data than needed and estimating the non-acquired data exploiting some sort of prior information. Parallel imaging and compressed sensing undersampling reconstruction techniques have revolutionized the field, enabling 2- to 3-fold scan time accelerations to become standard in clinical practice. Recent scientific advances in CMR reconstruction hinge on the thriving field of artificial intelligence. Machine learning reconstruction approaches have been recently proposed to learn the non-linear optimization process employed in CMR reconstruction. Unlike analytical methods for which the reconstruction problem is explicitly defined into the optimization process, machine learning techniques make use of large data sets to learn the key reconstruction parameters and priors. In particular, deep learning techniques promise to use deep neural networks (DNN) to learn the reconstruction process from existing datasets in advance, providing a fast and efficient reconstruction that can be applied to all newly acquired data. However, before machine learning and DNN can realize their full potentials and enter widespread clinical routine for CMR image reconstruction, there are several technical hurdles that need to be addressed. In this article, we provide an overview of the recent developments in the area of artificial intelligence for CMR image reconstruction. The underlying assumptions of established techniques such as compressed sensing and low-rank reconstruction are briefly summarized, while a greater focus is given to recent advances in dictionary learning and deep learning based CMR reconstruction. In particular, approaches that exploit neural networks as implicit or explicit priors are discussed for 2D dynamic cardiac imaging and 3D whole-heart CMR imaging. Current limitations, challenges, and potential future directions of these techniques are also discussed."
32156226,,A Brief Survey of Machine Learning Methods in Identification of Mitochondria Proteins in Malaria Parasite,2020;26(26):3049-3058.,"The number of human deaths caused by malaria is increasing day-by-day. In fact, the mitochondrial proteins of the malaria parasite play vital roles in the organism. For developing effective drugs and vaccines against infection, it is necessary to accurately identify mitochondrial proteins of the malaria parasite. Although precise details for the mitochondrial proteins can be provided by biochemical experiments, they are expensive and time-consuming. In this review, we summarized the machine learning-based methods for mitochondrial proteins identification in the malaria parasite and compared the construction strategies of these computational methods. Finally, we also discussed the future development of mitochondrial proteins recognition with algorithms."
32155930,,A Survey of Heart Anomaly Detection Using Ambulatory Electrocardiogram (ECG),2020 Mar 6;20(5):1461.,"Cardiovascular diseases (CVDs) are the number one cause of death globally. An estimated 17.9 million people die from CVDs each year, representing 31% of all global deaths. Most cardiac patients require early detection and treatment. Therefore, many products to monitor patient's heart conditions have been introduced on the market. Most of these devices can record a patient's bio-metric signals both in resting and in exercising situations. However, reading the massive amount of raw electrocardiogram (ECG) signals from the sensors is very time-consuming. Automatic anomaly detection for the ECG signals could act as an assistant for doctors to diagnose a cardiac condition. This paper reviews the current state-of-the-art of this technology discusses the pros and cons of the devices and algorithms found in the literature and the possible research directions to develop the next generation of ambulatory monitoring systems."
32154629,2.0,An overview of the first 5 years of the ENIGMA obsessive-compulsive disorder working group: The power of worldwide collaboration,2020 Mar 10.,"Neuroimaging has played an important part in advancing our understanding of the neurobiology of obsessive-compulsive disorder (OCD). At the same time, neuroimaging studies of OCD have had notable limitations, including reliance on relatively small samples. International collaborative efforts to increase statistical power by combining samples from across sites have been bolstered by the ENIGMA consortium; this provides specific technical expertise for conducting multi-site analyses, as well as access to a collaborative community of neuroimaging scientists. In this article, we outline the background to, development of, and initial findings from ENIGMA's OCD working group, which currently consists of 47 samples from 34 institutes in 15 countries on 5 continents, with a total sample of 2,323 OCD patients and 2,325 healthy controls. Initial work has focused on studies of cortical thickness and subcortical volumes, structural connectivity, and brain lateralization in children, adolescents and adults with OCD, also including the study on the commonalities and distinctions across different neurodevelopment disorders. Additional work is ongoing, employing machine learning techniques. Findings to date have contributed to the development of neurobiological models of OCD, have provided an important model of global scientific collaboration, and have had a number of clinical implications. Importantly, our work has shed new light on questions about whether structural and functional alterations found in OCD reflect neurodevelopmental changes, effects of the disease process, or medication impacts. We conclude with a summary of ongoing work by ENIGMA-OCD, and a consideration of future directions for neuroimaging research on OCD within and beyond ENIGMA."
32150991,8.0,The Application of Deep Learning in Cancer Prognosis Prediction,2020 Mar 5;12(3):603.,"Deep learning has been applied to many areas in health care, including imaging diagnosis, digital pathology, prediction of hospital admission, drug design, classification of cancer and stromal cells, doctor assistance, etc. Cancer prognosis is to estimate the fate of cancer, probabilities of cancer recurrence and progression, and to provide survival estimation to the patients. The accuracy of cancer prognosis prediction will greatly benefit clinical management of cancer patients. The improvement of biomedical translational research and the application of advanced statistical analysis and machine learning methods are the driving forces to improve cancer prognosis prediction. Recent years, there is a significant increase of computational power and rapid advancement in the technology of artificial intelligence, particularly in deep learning. In addition, the cost reduction in large scale next-generation sequencing, and the availability of such data through open source databases (e.g., TCGA and GEO databases) offer us opportunities to possibly build more powerful and accurate models to predict cancer prognosis more accurately. In this review, we reviewed the most recent published works that used deep learning to build models for cancer prognosis prediction. Deep learning has been suggested to be a more generic model, requires less data engineering, and achieves more accurate prediction when working with large amounts of data. The application of deep learning in cancer prognosis has been shown to be equivalent or better than current approaches, such as Cox-PH. With the burst of multi-omics data, including genomics data, transcriptomics data and clinical information in cancer studies, we believe that deep learning would potentially improve cancer prognosis."
32143918,,Review of computational methods for the detection and classification of polyps in colonoscopy imaging,2020 Apr;43(4):222-232.,"Computer-aided diagnosis (CAD) is a tool with great potential to help endoscopists in the tasks of detecting and histologically classifying colorectal polyps. In recent years, different technologies have been described and their potential utility has been increasingly evidenced, which has generated great expectations among scientific societies. However, most of these works are retrospective and use images of different quality and characteristics which are analysed off line. This review aims to familiarise gastroenterologists with computational methods and the particularities of endoscopic imaging, which have an impact on image processing analysis. Finally, the publicly available image databases, needed to compare and confirm the results obtained with different methods, are presented."
32141963,,Artificial Intelligence Pertaining to Cardiothoracic Imaging and Patient Care: Beyond Image Interpretation,2020 May;35(3):137-142.,"Artificial intelligence (AI) is a broad field of computational science that includes many subsets. Today the most widely used subset in medical imaging is machine learning (ML). Many articles have focused on the use of ML for pattern recognition to detect and potentially diagnose various pathologies. However, AI algorithm development is now directed toward workflow management. AI can impact patient care at multiple stages of their imaging experience and assist in efficient and effective scheduling, imaging performance, worklist prioritization, image interpretation, and quality assurance. The purpose of this manuscript was to review the potential AI applications in radiology focusing on workflow management and discuss how ML will affect cardiothoracic imaging."
32141423,1.0,Review: Synergy between mechanistic modelling and data-driven models for modern animal production systems in the era of big data,2020 Aug;14(S2):s223-s237.,"Mechanistic models (MMs) have served as causal pathway analysis and 'decision-support' tools within animal production systems for decades. Such models quantitatively define how a biological system works based on causal relationships and use that cumulative biological knowledge to generate predictions and recommendations (in practice) and generate/evaluate hypotheses (in research). Their limitations revolve around obtaining sufficiently accurate inputs, user training and accuracy/precision of predictions on-farm. The new wave in digitalization technologies may negate some of these challenges. New data-driven (DD) modelling methods such as machine learning (ML) and deep learning (DL) examine patterns in data to produce accurate predictions (forecasting, classification of animals, etc.). The deluge of sensor data and new self-learning modelling techniques may address some of the limitations of traditional MM approaches - access to input data (e.g. sensors) and on-farm calibration. However, most of these new methods lack transparency in the reasoning behind predictions, in contrast to MM that have historically been used to translate knowledge into wisdom. The objective of this paper is to propose means to hybridize these two seemingly divergent methodologies to advance the models we use in animal production systems and support movement towards truly knowledge-based precision agriculture. In order to identify potential niches for models in animal production of the future, a cross-species (dairy, swine and poultry) examination of the current state of the art in MM and new DD methodologies (ML, DL analytics) is undertaken. We hypothesize that there are several ways via which synergy may be achieved to advance both our predictive capabilities and system understanding, being: (1) building and utilizing data streams (e.g. intake, rumination behaviour, rumen sensors, activity sensors, environmental sensors, cameras and near IR) to apply MM in real-time and/or with new resolution and capabilities; (2) hybridization of MM and DD approaches where, for example, a ML framework is augmented by MM-generated parameters or predicted outcomes and (3) hybridization of the MM and DD approaches, where biological bounds are placed on parameters within a MM framework, and the DD system parameterizes the MM for individual animals, farms or other such clusters of data. As animal systems modellers, we should expand our toolbox to explore new DD approaches and big data to find opportunities to increase understanding of biological systems, find new patterns in data and move the field towards intelligent, knowledge-based precision agriculture systems."
32141255,2.0,Understanding the Molecular Mechanisms of Asthma through Transcriptomics,2020 May;12(3):399-411.,"The transcriptome represents the complete set of RNA transcripts that are produced by the genome under a specific circumstance or in a specific cell. High-throughput methods, including microarray and bulk RNA sequencing, as well as recent advances in biostatistics based on machine learning approaches provides a quick and effective way of identifying novel genes and pathways related to asthma, which is a heterogeneous disease with diverse pathophysiological mechanisms. In this manuscript, we briefly review how to analyze transcriptome data and then provide a summary of recent transcriptome studies focusing on asthma pathogenesis and asthma drug responses. Studies reviewed here are classified into 2 classes based on the tissues utilized: blood and airway cells."
32140203,,Exploring the computational methods for protein-ligand binding site prediction,2020 Feb 17;18:417-426.,"Proteins participate in various essential processes in vivo via interactions with other molecules. Identifying the residues participating in these interactions not only provides biological insights for protein function studies but also has great significance for drug discoveries. Therefore, predicting protein-ligand binding sites has long been under intense research in the fields of bioinformatics and computer aided drug discovery. In this review, we first introduce the research background of predicting protein-ligand binding sites and then classify the methods into four categories, namely, 3D structure-based, template similarity-based, traditional machine learning-based and deep learning-based methods. We describe representative algorithms in each category and elaborate on machine learning and deep learning-based prediction methods in more detail. Finally, we discuss the trends and challenges of the current research such as molecular dynamics simulation based cryptic binding sites prediction, and highlight prospective directions for the near future."
32140182,11.0,"The greater inflammatory pathway-high clinical potential by innovative predictive, preventive, and personalized medical approach",2019 Dec 10;11(1):1-16.,"Background and limitations:                    Impaired wound healing (WH) and chronic inflammation are hallmarks of non-communicable diseases (NCDs). However, despite WH being a recognized player in NCDs, mainstream therapies focus on (un)targeted damping of the inflammatory response, leaving WH largely unaddressed, owing to three main factors. The first is the complexity of the pathway that links inflammation and wound healing; the second is the dual nature, local and systemic, of WH; and the third is the limited acknowledgement of genetic and contingent causes that disrupt physiologic progression of WH.              Proposed approach:                    Here, in the frame of Predictive, Preventive, and Personalized Medicine (PPPM), we integrate and revisit current literature to offer a novel systemic view on the cues that can impact on the fate (acute or chronic inflammation) of WH, beyond the compartmentalization of medical disciplines and with the support of advanced computational biology.              Conclusions:                    This shall open to a broader understanding of the causes for WH going awry, offering new operational criteria for patients' stratification (prediction and personalization). While this may also offer improved options for targeted prevention, we will envisage new therapeutic strategies to reboot and/or boost WH, to enable its progression across its physiological phases, the first of which is a transient acute inflammatory response versus the chronic low-grade inflammation characteristic of NCDs."
32139886,5.0,Big data in digital healthcare: lessons learnt and recommendations for general practice,2020 Apr;124(4):525-534.,"Big Data will be an integral part of the next generation of technological developments-allowing us to gain new insights from the vast quantities of data being produced by modern life. There is significant potential for the application of Big Data to healthcare, but there are still some impediments to overcome, such as fragmentation, high costs, and questions around data ownership. Envisioning a future role for Big Data within the digital healthcare context means balancing the benefits of improving patient outcomes with the potential pitfalls of increasing physician burnout due to poor implementation leading to added complexity. Oncology, the field where Big Data collection and utilization got a heard start with programs like TCGA and the Cancer Moon Shot, provides an instructive example as we see different perspectives provided by the United States (US), the United Kingdom (UK) and other nations in the implementation of Big Data in patient care with regards to their centralization and regulatory approach to data. By drawing upon global approaches, we propose recommendations for guidelines and regulations of data use in healthcare centering on the creation of a unique global patient ID that can integrate data from a variety of healthcare providers. In addition, we expand upon the topic by discussing potential pitfalls to Big Data such as the lack of diversity in Big Data research, and the security and transparency risks posed by machine learning algorithms."
32138567,1.0,Advances in the use of cell penetrating peptides for respiratory drug delivery,2020 May;17(5):647-664.,"Introduction: Respiratory diseases are leading causes of death in the world, still inhalation therapies are the largest fail in drug development. There is an evident need to develop new therapies. Biomolecules represent apotential therapeutic agent in this regard, however their translation to the clinic is hindered by the lack of tools to efficiently deliver molecules. Cell penetrating peptides (CPPs) have arisen as apotential strategy for intracellular delivery that could theoretically enable the translation of new therapies.Areas covered: In this review, the use of CPPs as astrategy to deliver different molecules (cargoes) to treat lung-relateddiseases will be the focus. Abrief description of these molecules and the innovative methods in designing new CPPs is presented. The delivery of different cargoes (proteins, peptides, poorly soluble drugs and nucleic acids) using CPPs is discussed, focusing on benefits to treat different respiratory diseases like inflammatory disorders, cystic fibrosis and lung cancer.Expert opinion: The advantages of using CPPs to deliver biomolecules and poorly soluble drugs to the lungs is evident. This field has advanced in the past few years toward targeted intracellular delivery, although further studies are needed to fully understand its potential and limitations in vitro and in vivo."
32138284,5.0,Artificial Intelligence in Acute Kidney Injury Risk Prediction,2020 Mar 3;9(3):678.,"Acute kidney injury (AKI) is a frequent complication in hospitalized patients, which is associated with worse short and long-term outcomes. It is crucial to develop methods to identify patients at risk for AKI and to diagnose subclinical AKI in order to improve patient outcomes. The advances in clinical informatics and the increasing availability of electronic medical records have allowed for the development of artificial intelligence predictive models of risk estimation in AKI. In this review, we discussed the progress of AKI risk prediction from risk scores to electronic alerts to machine learning methods."
32135196,,Review and comparative analysis of machine learning-based phage virion protein identification methods,2020 Jun;1868(6):140406.,"Phage virion protein (PVP) identification plays key role in elucidating relationships between phages and hosts. Moreover, PVP identification can facilitate the design of related biochemical entities. Recently, several machine learning approaches have emerged for this purpose and have shown their potential capacities. In this study, the proposed PVP identifiers are systemically reviewed, and the related algorithms and tools are comprehensively analyzed. We summarized the common framework of these PVP identifiers and constructed our own novel identifiers based upon the framework. Furthermore, we focus on a performance comparison of all PVP identifiers by using a training dataset and an independent dataset. Highlighting the pros and cons of these identifiers demonstrates that g-gap DPC (dipeptide composition) features are capable of representing characteristics of PVPs. Moreover, SVM (support vector machine) is proven to be the more effective classifier to distinguish PVPs and non-PVPs."
32133724,5.0,Artificial intelligence in oncology,2020 May;111(5):1452-1460.,"Artificial intelligence (AI) has contributed substantially to the resolution of a variety of biomedical problems, including cancer, over the past decade. Deep learning, a subfield of AI that is highly flexible and supports automatic feature extraction, is increasingly being applied in various areas of both basic and clinical cancer research. In this review, we describe numerous recent examples of the application of AI in oncology, including cases in which deep learning has efficiently solved problems that were previously thought to be unsolvable, and we address obstacles that must be overcome before such application can become more widespread. We also highlight resources and datasets that can help harness the power of AI for cancer research. The development of innovative approaches to and applications of AI will yield important insights in oncology in the coming decade."
32133344,10.0,In silico Strategies to Support Fragment-to-Lead Optimization in Drug Discovery,2020 Feb 18;8:93.,"Fragment-based drug (or lead) discovery (FBDD or FBLD) has developed in the last two decades to become a successful key technology in the pharmaceutical industry for early stage drug discovery and development. The FBDD strategy consists of screening low molecular weight compounds against macromolecular targets (usually proteins) of clinical relevance. These small molecular fragments can bind at one or more sites on the target and act as starting points for the development of lead compounds. In developing the fragments attractive features that can translate into compounds with favorable physical, pharmacokinetics and toxicity (ADMET-absorption, distribution, metabolism, excretion, and toxicity) properties can be integrated. Structure-enabled fragment screening campaigns use a combination of screening by a range of biophysical techniques, such as differential scanning fluorimetry, surface plasmon resonance, and thermophoresis, followed by structural characterization of fragment binding using NMR or X-ray crystallography. Structural characterization is also used in subsequent analysis for growing fragments of selected screening hits. The latest iteration of the FBDD workflow employs a high-throughput methodology of massively parallel screening by X-ray crystallography of individually soaked fragments. In this review we will outline the FBDD strategies and explore a variety of in silico approaches to support the follow-up fragment-to-lead optimization of either: growing, linking, and merging. These fragment expansion strategies include hot spot analysis, druggability prediction, SAR (structure-activity relationships) by catalog methods, application of machine learning/deep learning models for virtual screening and several de novo design methods for proposing synthesizable new compounds. Finally, we will highlight recent case studies in fragment-based drug discovery where in silico methods have successfully contributed to the development of lead compounds."
32132323,,Imaging Brain Mechanisms of Functional Somatic Syndromes: Potential as a Biomarker?,2020 Mar;250(3):137-152.,"When patients present with persistent bodily complaints that cannot be explained by a symptom-linked organic pathology (medically unexplained symptoms), they are diagnosed with 'functional' somatic syndromes (FSS). Despite their prevalence, the management of FSS is notoriously challenging in clinical practice. This may be because FSS are heterogeneous disorders in terms of etiopathogenesis. They include patients with primarily peripheral dysfunction, primarily centrally driven somatic symptoms, and a mix of both. Brain-imaging studies, particularly data-driven pattern recognition methods using machine learning algorithms, could provide brain-based biomarkers for these clinical conditions. In this review, we provide an overview of our brain imaging data on brain-body interactions in one of the most well-known FSS, irritable bowel syndrome (IBS), and discuss the possible development of a brain-based biomarker for FSS. Anticipation of unpredictable pain, which commonly elicits fear in FSS patients, induced increased activity in brain areas associated with hypervigilance during rectal distention and non-distention conditions in IBS. This was coupled with dysfunctional inhibitory influence of the medial prefrontal cortex (mPFC) and pregenual anterior cingulate cortex (pACC) on stress regulation systems, resulting in the activated autonomic nervous system (ANS) and neuroendocrine system stimulated by corticotropin-releasing hormone (CRH). IBS subjects with higher alexithymia, a risk factor for FSS, showed stronger activity in the insula during rectal distention but reduced subjective sensitivity. Reduced top-down regulation of the ANS and CRH system by mPFC and pACC, discordance between the insula response to stimulation and subjective sensation of pain, and stronger threat responses in hypervigilance-related areas may be a candidate brain-based biomarker."
32128929,13.0,Artificial intelligence as the next step towards precision pathology,2020 Jul;288(1):62-81.,"Pathology is the cornerstone of cancer care. The need for accuracy in histopathologic diagnosis of cancer is increasing as personalized cancer therapy requires accurate biomarker assessment. The appearance of digital image analysis holds promise to improve both the volume and precision of histomorphological evaluation. Recently, machine learning, and particularly deep learning, has enabled rapid advances in computational pathology. The integration of machine learning into routine care will be a milestone for the healthcare sector in the next decade, and histopathology is right at the centre of this revolution. Examples of potential high-value machine learning applications include both model-based assessment of routine diagnostic features in pathology, and the ability to extract and identify novel features that provide insights into a disease. Recent groundbreaking results have demonstrated that applications of machine learning methods in pathology significantly improves metastases detection in lymph nodes, Ki67 scoring in breast cancer, Gleason grading in prostate cancer and tumour-infiltrating lymphocyte (TIL) scoring in melanoma. Furthermore, deep learning models have also been demonstrated to be able to predict status of some molecular markers in lung, prostate, gastric and colorectal cancer based on standard HE slides. Moreover, prognostic (survival outcomes) deep neural network models based on digitized HE slides have been demonstrated in several diseases, including lung cancer, melanoma and glioma. In this review, we aim to present and summarize the latest developments in digital image analysis and in the application of artificial intelligence in diagnostic pathology."
32128792,4.0,An Introduction to Machine Learning,2020 Apr;107(4):871-885.,"In the last few years, machine learning (ML) and artificial intelligence have seen a new wave of publicity fueled by the huge and ever-increasing amount of data and computational power as well as the discovery of improved learning algorithms. However, the idea of a computer learning some abstract concept from data and applying them to yet unseen situations is not new and has been around at least since the 1950s. Many of these basic principles are very familiar to the pharmacometrics and clinical pharmacology community. In this paper, we want to introduce the foundational ideas of ML to this community such that readers obtain the essential tools they need to understand publications on the topic. Although we will not go into the very details and theoretical background, we aim to point readers to relevant literature and put applications of ML in molecular biology as well as the fields of pharmacometrics and clinical pharmacology into perspective."
32128436,10.0,Automated assessment of psychiatric disorders using speech: A systematic review,2020 Jan 31;5(1):96-116.,"Objective:                    There are many barriers to accessing mental health assessments including cost and stigma. Even when individuals receive professional care, assessments are intermittent and may be limited partly due to the episodic nature of psychiatric symptoms. Therefore, machine-learning technology using speech samples obtained in the clinic or remotely could one day be a biomarker to improve diagnosis and treatment. To date, reviews have only focused on using acoustic features from speech to detect depression and schizophrenia. Here, we present the first systematic review of studies using speech for automated assessments across a broader range of psychiatric disorders.              Methods:                    We followed the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) guidelines. We included studies from the last 10 years using speech to identify the presence or severity of disorders within the Diagnostic and Statistical Manual of Mental Disorders (DSM-5). For each study, we describe sample size, clinical evaluation method, speech-eliciting tasks, machine learning methodology, performance, and other relevant findings.              Results:                    1395 studies were screened of which 127 studies met the inclusion criteria. The majority of studies were on depression, schizophrenia, and bipolar disorder, and the remaining on post-traumatic stress disorder, anxiety disorders, and eating disorders. 63% of studies built machine learning predictive models, and the remaining 37% performed null-hypothesis testing only. We provide an online database with our search results and synthesize how acoustic features appear in each disorder.              Conclusion:                    Speech processing technology could aid mental health assessments, but there are many obstacles to overcome, especially the need for comprehensive transdiagnostic and longitudinal studies. Given the diverse types of data sets, feature extraction, computational methodologies, and evaluation criteria, we provide guidelines for both acquiring data and building machine learning models with a focus on testing hypotheses, open science, reproducibility, and generalizability.              Level of evidence:                    3a."
32127291,2.0,Data-Driven Approaches to Neuroimaging Analysis to Enhance Psychiatric Diagnosis and Therapy,2020 Aug;5(8):780-790.,"Combining advanced neuroimaging with novel computational methods in network science and machine learning has led to increasingly meaningful descriptions of structure and function in both the normal and the abnormal brain, thereby contributing significantly to our understanding of psychiatric disorders as circuit dysfunctions. Despite its marked potential for psychiatric care, this approach has not yet extended beyond the research setting to any clinically useful applications. Here we review current developments in the study of neuroimaging data using network models and machine learning methods, with a focus on their promise in offering a framework for clinical translation. We discuss 3 potential contributions of these methods to psychiatric care: 1) a better understanding of psychopathology beyond current diagnostic boundaries; 2) individualized prediction of treatment response and prognosis; and 3) formal theories to guide the development of novel interventions. Finally, we highlight current obstacles and sketch a forward-looking perspective of how the application of machine learning and network modeling methods should proceed to accelerate their potential transformation of clinically useful tools."
32127174,,Opportunities for machine learning to improve surgical ward safety,2020 Oct;220(4):905-913.,"Background:                    Delayed recognition of decompensation and failure-to-rescue on surgical wards are major sources of preventable harm. This review assimilates and critically evaluates available evidence and identifies opportunities to improve surgical ward safety.              Data sources:                    Fifty-eight articles from Cochrane Library, EMBASE, and PubMed databases were included.              Conclusions:                    Only 15-20% of patients suffering ward arrest survive. In most cases, subtle signs of instability often occur prior to critical illness and arrest, and underlying pathology is reversible. Coarse risk assessments lead to under-triage of high-risk patients to wards, where surveillance for complications depends on time-consuming manual review of health records, infrequent patient assessments, prediction models that lack accuracy and autonomy, and biased, error-prone decision-making. Streaming electronic heath record data, wearable continuous monitors, and recent advances in deep learning and reinforcement learning can promote efficient and accurate risk assessments, earlier recognition of instability, and better decisions regarding diagnosis and treatment of reversible underlying pathology."
32124415,3.0,Human Papillomavirus Testing in Head and Neck Squamous Cell Carcinoma in 2020: Where Are We Now and Where Are We Going?,2020 Jun;14(2):321-329.,"High risk human papillomavirus (HPV) has transformed head and neck oncology in the past several decades. Now that we have recognized that HPV-positive oropharyngeal squamous cell carcinoma (OPSCC) is a unique cancer type with distinct clinicopathologic features and favorable prognosis, it has become essential to test patients in routine practice. We have progressed greatly in our knowledge of this disease and gone, over the past two to three decades, from doing testing in highly variable amounts and methods to, now, with the help of national and international guidelines and patient staging requirements, to a situation where almost all patients with OPSCC are getting accurate classification through at least p16 immunohistochemistry. However, we are still struggling with how to accurately test specimens from cervical lymph nodes, and, in particular, on fine needle aspiration. In addition, many patients with non-oropharyngeal SCC are getting clinically unnecessary p16 and/or HPV-specific testing. The trends suggest progressive improvement in practices, but many practical questions still remain. On the horizon are myriad non-tissue-based tests, such as HPV serology and plasma DNA, DNA-based testing of fine needle aspirate fluid, computerized analysis of digitized pathology and radiology images, and machine learning from clinical and pathologic features, that may render pathologists largely obsolete for establishing HPV status for our patients' tumors. This review takes a brief look back in time to where we have been, then characterizes current practices in 2020 and lingering questions, and, finally, looks ahead into the possible future of HPV testing in patients with head and neck SCC."
32116995,10.0,PET/MRI Radiomics in Patients With Brain Metastases,2020 Feb 7;11:1.,"Although a variety of imaging modalities are used or currently being investigated for patients with brain tumors including brain metastases, clinical image interpretation to date uses only a fraction of the underlying complex, high-dimensional digital information from routinely acquired imaging data. The growing availability of high-performance computing allows the extraction of quantitative imaging features from medical images that are usually beyond human perception. Using machine learning techniques and advanced statistical methods, subsets of such imaging features are used to generate mathematical models that represent characteristic signatures related to the underlying tumor biology and might be helpful for the assessment of prognosis or treatment response, or the identification of molecular markers. The identification of appropriate, characteristic image features as well as the generation of predictive or prognostic mathematical models is summarized under the term radiomics. This review summarizes the current status of radiomics in patients with brain metastases."
32115658,,Implementing machine learning methods for imaging flow cytometry,2020 Apr 8;69(2):61-68.,"In this review, we focus on the applications of machine learning methods for analyzing image data acquired in imaging flow cytometry technologies. We propose that the analysis approaches can be categorized into two groups based on the type of data, raw imaging signals or features explicitly extracted from images, being analyzed by a trained model. We hope that this categorization is helpful for understanding uniqueness, differences and opportunities when the machine learning-based analysis is implemented in recently developed 'imaging' cell sorters."
32114857,1.0,Advancements in predicting outcomes in patients with glioma: a surgical perspective,2020 Mar;20(3):167-177.,"Introduction: Diffuse glioma is a challenging neurosurgical entity. Although surgery does not provide a cure, it may greatly influence survival, brain function, and quality of life. Surgical treatment is by nature highly personalized and outcome prediction is very complex. To engage and succeed in this balancing act it is important to make best use of the information available to the neurosurgeon.Areas covered: This narrative review provides an update on advancements in predicting outcomes in patients with glioma that are relevant to neurosurgeons.Expert opinion: The classical 'gut feeling' is notoriously unreliable and better prediction strategies for patients with glioma are warranted. There are numerous tools readily available for the neurosurgeon in predicting tumor biology and survival. Predicting extent of resection, functional outcome, and quality of life remains difficult. Although machine-learning approaches are currently not readily available in daily clinical practice, there are several ongoing efforts with the use of big data sets that are likely to create new prediction models and refine the existing models."
32113754,1.0,Symposium review: Dairy Brain-Informing decisions on dairy farms using data analytics,2020 Apr;103(4):3874-3881.,"Management decisions can be informed by near-real-time data streams to improve the economics of the farm and to positively benefit the overall health of a dairy herd or the larger environment. Decision support tools can use data management services and analytics to exploit data streams from farm and other economic, health, and agricultural sources. We will describe a decision support tool that couples data analytics tools to underlying cow, herd, and economic data with an application programming interface. This interface allows the user to interact with a collection of dairy applications without fully exposing the intricacies of the underlying system model and understand the effects of different decisions on outputs of interest. The collection of these applications will form the basis of the Dairy Brain decision support system, which will provide management suggestions to farmers at a single animal or farm level. Dairy operations data will be gathered, cleaned, organized, and disseminated through an agricultural data hub, exploiting newly developed ontologies for integration of multiple data sources. Models of feed efficiency, culling, or other dairy operations (such as large capital expenditures, outsourcing opportunities, and interactions with regulators) form the basis of analytical approaches, operationalized via tools that help secure information and control uncertainties. The applications will be independently generated to provide flexibility, and use tools and modeling approaches from the data science, simulation, machine learning, and optimization disciplines to provide specific recommendations to decision makers. The Dairy Brain is a decision support system that couples data analytics tools with a suite of applications that integrate cow, herd, and economic data to inform management, operational, and animal health improving practices. Research challenges that remain include dealing with increased variability as predictions go from herd or pen level down to individual cow level and choosing the appropriate tool or technique to deal with a specific problem."
32112907,3.0,Imaging of intratumoral heterogeneity in high-grade glioma,2020 May 1;477:97-106.,"High-grade glioma (HGG), and particularly Glioblastoma (GBM), can exhibit pronounced intratumoral heterogeneity that confounds clinical diagnosis and management. While conventional contrast-enhanced MRI lacks the capability to resolve this heterogeneity, advanced MRI techniques and PET imaging offer a spectrum of physiologic and biophysical image features to improve the specificity of imaging diagnoses. Published studies have shown how integrating these advanced techniques can help better define histologically distinct targets for surgical and radiation treatment planning, and help evaluate the regional heterogeneity of tumor recurrence and response assessment following standard adjuvant therapy. Application of texture analysis and machine learning (ML) algorithms has also enabled the emerging field of radiogenomics, which can spatially resolve the regional and genetically distinct subpopulations that coexist within a single GBM tumor. This review focuses on the latest advances in neuro-oncologic imaging and their clinical applications for the assessment of intratumoral heterogeneity."
