pmid,citations,title,date,text
31656552,5.0,A comprehensive survey of error measures for evaluating binary decision making in data science,Sep-Oct 2019;9(5):e1303.,"Binary decision making is a topic of great interest for many fields, including biomedical science, economics, management, politics, medicine, natural science and social science, and much effort has been spent for developing novel computational methods to address problems arising in the aforementioned fields. However, in order to evaluate the effectiveness of any prediction method for binary decision making, the choice of the most appropriate error measures is of paramount importance. Due to the variety of error measures available, the evaluation process of binary decision making can be a complex task. The main objective of this study is to provide a comprehensive survey of error measures for evaluating the outcome of binary decision making applicable to many data-driven fields. This article is categorized under: Fundamental Concepts of Data and Knowledge > Key Design Issues in Data MiningTechnologies > PredictionAlgorithmic Development > Statistics."
31655339,,A quantitative lens on anaerobic life: leveraging the state-of-the-art fluxomics approach to explore clostridial metabolism,2020 Aug;64:47-54.,"Quantitative understanding of clostridial metabolism is of longstanding interest due to the importance of Clostridia as model anaerobes, biotechnology workhorses, and contributors to evolutionary history and ecosystem. Current computational methods such as flux balance analysis-based construction of clostridial metabolism in genome scale provide a fundamental framework for metabolic analysis. However, this method alone is inadequate to characterize cellular metabolic activity. Experiment-driven approaches including isotope tracer-based fluxomics in association with genetic and biochemical methods are needed to gain a more comprehensive understanding. Here we focus on typical examples where these integrated approaches have contributed to the identification of new metabolic pathways and quantification of metabolic fluxes in Clostridia. We also highlight the opportunities and challenges of cutting-edge fluxomics approaches such as machine learning modeling, deuterium tracer approach, and high throughput flux phenotyping in exploring clostridial metabolism with respect to inorganic carbon utilization, redox cofactor interconversion, and other key metabolic features."
31652616,11.0,"Real-Time EMG Based Pattern Recognition Control for Hand Prostheses: A Review on Existing Methods, Challenges and Future Implementation",2019 Oct 22;19(20):4596.,"Upper limb amputation is a condition that significantly restricts the amputees from performing their daily activities. The myoelectric prosthesis, using signals from residual stump muscles, is aimed at restoring the function of such lost limbs seamlessly. Unfortunately, the acquisition and use of such myosignals are cumbersome and complicated. Furthermore, once acquired, it usually requires heavy computational power to turn it into a user control signal. Its transition to a practical prosthesis solution is still being challenged by various factors particularly those related to the fact that each amputee has different mobility, muscle contraction forces, limb positional variations and electrode placements. Thus, a solution that can adapt or otherwise tailor itself to each individual is required for maximum utility across amputees. Modified machine learning schemes for pattern recognition have the potential to significantly reduce the factors (movement of users and contraction of the muscle) affecting the traditional electromyography (EMG)-pattern recognition methods. Although recent developments of intelligent pattern recognition techniques could discriminate multiple degrees of freedom with high-level accuracy, their efficiency level was less accessible and revealed in real-world (amputee) applications. This review paper examined the suitability of upper limb prosthesis (ULP) inventions in the healthcare sector from their technical control perspective. More focus was given to the review of real-world applications and the use of pattern recognition control on amputees. We first reviewed the overall structure of pattern recognition schemes for myo-control prosthetic systems and then discussed their real-time use on amputee upper limbs. Finally, we concluded the paper with a discussion of the existing challenges and future research recommendations."
31651163,1.0,Ab Initio Simulations and Materials Chemistry in the Age of Big Data,2020 Feb 24;60(2):452-459.,"In this perspective, we discuss computational advances in the last decades, both in algorithms as well as in technologies, that enabled the development, widespread use, and maturity of simulation methods for molecular and materials systems. Such advances led to the generation of large amounts of data, which required the creation of several computational databases. Within this scenario, with the democratization of data access, the field now encounters several opportunities for data-driven approaches toward chemical and materials problems. Specifically, machine learning methods for predictions of novel materials or properties are being increasingly used with great success. However, black box usage fails in many instances; several technical details require expert knowledge in order for the predictions to be useful, such as with descriptors and algorithm selection. These approaches represent a direction for further developments, notably allowing advances for both developed and emerging countries with modest computational infrastructures."
31648775,3.0,A review of spatial approaches in road safety,2020 Feb;135:105323.,"Spatial analyses of crashes have been adopted in road safety for decades in order to determine how crashes are affected by neighboring locations, how the influence of parameters varies spatially and which locations warrant interventions more urgently. The aim of the present research is to critically review the existing literature on different spatial approaches through which researchers handle the dimension of space in its various aspects in their studies and analyses. Specifically, the use of different areal unit levels in spatial road safety studies is investigated, different modelling approaches are discussed, and the corresponding study design characteristics are summarized in respective tables including traffic, road environment and area parameters and spatial aggregation approaches. Developments in famous issues in spatial analysis such as the boundary problem, the modifiable areal unit problem and spatial proximity structures are also discussed. Studies focusing on spatially analyzing vulnerable road users are reviewed as well. Regarding spatial models, the application, advantages and disadvantages of various functional/econometric approaches, Bayesian models and machine learning methods are discussed. Based on the reviewed studies, present challenges and future research directions are determined."
31648301,10.0,Key challenges facing data-driven multicellular systems biology,2019 Oct 1;8(10):giz127.,"Increasingly sophisticated experiments, coupled with large-scale computational models, have the potential to systematically test biological hypotheses to drive our understanding of multicellular systems. In this short review, we explore key challenges that must be overcome to achieve robust, repeatable data-driven multicellular systems biology. If these challenges can be solved, we can grow beyond the current state of isolated tools and datasets to a community-driven ecosystem of interoperable data, software utilities, and computational modeling platforms. Progress is within our grasp, but it will take community (and financial) commitment."
31646170,3.0,Statistical methods for dementia risk prediction and recommendations for future work: A systematic review,2019 Oct 8;5:563-569.,"Introduction:                    Numerous dementia risk prediction models have been developed in the past decade. However, methodological limitations of the analytical tools used may hamper their ability to generate reliable dementia risk scores. We aim to review the used methodologies.              Methods:                    We systematically reviewed the literature from March 2014 to September 2018 for publications presenting a dementia risk prediction model. We critically discuss the analytical techniques used in the literature.              Results:                    In total 137 publications were included in the qualitative synthesis. Three techniques were identified as the most commonly used methodologies: machine learning, logistic regression, and Cox regression.              Discussion:                    We identified three major methodological weaknesses: (1) over-reliance on one data source, (2) poor verification of statistical assumptions of Cox and logistic regression, and (3) lack of validation. The use of larger and more diverse data sets is recommended. Assumptions should be tested thoroughly, and actions should be taken if deviations are detected."
31644477,,Machine Learning and Cochlear Implantation-A Structured Review of Opportunities and Challenges,2020 Jan;41(1):e36-e45.,"Objective:                    The use of machine learning technology to automate intellectual processes and boost clinical process efficiency in medicine has exploded in the past 5 years. Machine learning excels in automating pattern recognition and in adapting learned representations to new settings. Moreover, machine learning techniques have the advantage of incorporating complexity and are free from many of the limitations of traditional deterministic approaches. Cochlear implants (CI) are a unique fit for machine learning techniques given the need for optimization of signal processing to fit complex environmental scenarios and individual patients' CI MAPping. However, there are many other opportunities where machine learning may assist in CI beyond signal processing. The objective of this review was to synthesize past applications of machine learning technologies for pediatric and adult CI and describe novel opportunities for research and development.              Data sources:                    The PubMed/MEDLINE, EMBASE, Scopus, and ISI Web of Knowledge databases were mined using a directed search strategy to identify the nexus between CI and artificial intelligence/machine learning literature.              Study selection:                    Non-English language articles, articles without an available abstract or full-text, and nonrelevant articles were manually appraised and excluded. Included articles were evaluated for specific machine learning methodologies, content, and application success.              Data synthesis:                    The database search identified 298 articles. Two hundred fifty-nine articles (86.9%) were excluded based on the available abstract/full-text, language, and relevance. The remaining 39 articles were included in the review analysis. There was a marked increase in year-over-year publications from 2013 to 2018. Applications of machine learning technologies involved speech/signal processing optimization (17; 43.6% of articles), automated evoked potential measurement (6; 15.4%), postoperative performance/efficacy prediction (5; 12.8%), and surgical anatomy location prediction (3; 7.7%), and 2 (5.1%) in each of robotics, electrode placement performance, and biomaterials performance.              Conclusion:                    The relationship between CI and artificial intelligence is strengthening with a recent increase in publications reporting successful applications. Considerable effort has been directed toward augmenting signal processing and automating postoperative MAPping using machine learning algorithms. Other promising applications include augmenting CI surgery mechanics and personalized medicine approaches for boosting CI patient performance. Future opportunities include addressing scalability and the research and clinical communities' acceptance of machine learning algorithms as effective techniques."
31644464,2.0,Current status of functional MRI of osteoarthritis for diagnosis and prognosis,2020 Jan;32(1):102-109.,"Purpose of review:                    Osteoarthritis is a major source of disability, pain and socioeconomic cost worldwide. The epidemiology of the disorder is multifactorial including genetic, biological and biomechanical components, some of them detectable by MRI. This review provides the most recent update on MRI biomarkers which can provide functional information of the joint structures for diagnosis, prognosis and treatment response monitoring in osteoarthritis trials.              Recent findings:                    Compositional or functional MRI can provide clinicians with valuable information on glycosaminoglycan content (chemical exchange saturation transfer, sodium MRI, T1ρ) and collagen organization (T2, T2, apparent diffusion coefficient, magnetization transfer) in joint structures. Other parameters may also provide useful information, such as volumetric measurements of joint structures or advanced image data postprocessing and analysis. Automated tools seem to have a great potential to be included in these efforts providing standardization and acceleration of the image data analysis process.              Summary:                    Functional or compositional MRI has great potential to provide noninvasive imaging biomarkers for osteoarthritis. Osteoarthritis as a whole joint condition needs to be diagnosed in early stages to facilitate selection of patients into clinical trials and/or to measure treatment effectiveness. Advanced evaluation including machine learning, neural networks and multidimensional data analysis allow for wall-to-wall understanding of parameter interactions and their role in clinical evaluation of osteoarthritis."
31641106,9.0,Recommendations and future directions for supervised machine learning in psychiatry,2019 Oct 22;9(1):271.,"Machine learning methods hold promise for personalized care in psychiatry, demonstrating the potential to tailor treatment decisions and stratify patients into clinically meaningful taxonomies. Subsequently, publication counts applying machine learning methods have risen, with different data modalities, mathematically distinct models, and samples of varying size being used to train and test models with the promise of clinical translation. Consequently, and in part due to the preliminary nature of such works, many studies have reported largely varying degrees of accuracy, raising concerns over systematic overestimation and methodological inconsistencies. Furthermore, a lack of procedural evaluation guidelines for non-expert medical professionals and funding bodies leaves many in the field with no means to systematically evaluate the claims, maturity, and clinical readiness of a project. Given the potential of machine learning methods to transform patient care, albeit, contingent on the rigor of employed methods and their dissemination, we deem it necessary to provide a review of current methods, recommendations, and future directions for applied machine learning in psychiatry. In this review we will cover issues of best practice for model training and evaluation, sources of systematic error and overestimation, model explainability vs. trust, the clinical implementation of AI systems, and finally, future directions for our field."
31638733,1.0,Artificial-Intelligence-Driven Organic Synthesis-En Route towards Autonomous Synthesis?,2019 Nov 25;58(48):17114-17116.,AI for chemistry: Automated synthesis can now be performed using an artificial intelligence algorithm to propose the synthetic route and a robotic microfluidic platform to execute the synthesis. This Highlight describes this approach towards small-molecule synthesis and reflects on the significance of this milestone in chemistry.
31635167,9.0,A Review of Force Myography Research and Development,2019 Oct 20;19(20):4557.,"Information about limb movements can be used for monitoring physical activities or for human-machine-interface applications. In recent years, a technique called Force Myography (FMG) has gained ever-increasing traction among researchers to extract such information. FMG uses force sensors to register the variation of muscle stiffness patterns around a limb during different movements. Using machine learning algorithms, researchers are able to predict many different limb activities. This review paper presents state-of-art research and development on FMG technology in the past 20 years. It summarizes the research progress in both the hardware design and the signal processing techniques. It also discusses the challenges that need to be solved before FMG can be used in an everyday scenario. This paper aims to provide new insight into FMG technology and contribute to its advancement."
31634699,8.0,Clinical applications of artificial intelligence in sepsis: A narrative review,2019 Dec;115:103488.,"Many studies have been published on a variety of clinical applications of artificial intelligence (AI) for sepsis, while there is no overview of the literature. The aim of this review is to give an overview of the literature and thereby identify knowledge gaps and prioritize areas with high priority for further research. A literature search was conducted in PubMed from inception to February 2019. Search terms related to AI were combined with terms regarding sepsis. Articles were included when they reported an area under the receiver operator characteristics curve (AUROC) as outcome measure. Fifteen articles on diagnosis of sepsis with AI models were included. The best performing model reached an AUROC of 0.97. There were also seven articles on prognosis, predicting mortality over time with an AUROC of up to 0.895. Finally, there were three articles on assistance of treatment of sepsis, where the use of AI was associated with the lowest mortality rates. Of the articles, twenty-two were judged to be at high risk of bias or had major concerns regarding applicability. This was mostly because predictor variables in these models, such as blood pressure, were also part of the definition of sepsis, which led to overestimation of the performance. We conclude that AI models have great potential for improving early identification of patients who may benefit from administration of antibiotics. Current AI prediction models to diagnose sepsis are at major risks of bias when the diagnosis criteria are part of the predictor variables in the model. Furthermore, generalizability of these models is poor due to overfitting and a lack of standardized protocols for the construction and validation of the models. Until these problems have been resolved, a large gap remains between the creation of an AI algorithm and its implementation in clinical practice."
31633462,4.0,Evolution of Aesthetic Dentistry,2019 Nov;98(12):1294-1304.,"One of the main goals of dental treatment is to mimic teeth and design smiles in a most natural and aesthetic manner, based on the individual and specific needs of the patient. Possibilities to reach that goal have significantly improved over the last decade through new and specific treatment modalities, steadily enhanced and more aesthetic dental materials, and novel techniques and technologies. This article gives an overview of the evolution of aesthetic dentistry over the past 100 y from a historical point of view and highlights advances in the development of dental research and clinical interventions that have contributed the science and art of aesthetic dentistry. Among the most noteworthy advancements over the past decade are the establishment of universal aesthetic rules and guidelines based on the assessment of natural aesthetic parameters, anatomy, and physiognomy; the development of tooth whitening and advanced restorative as well as prosthetic materials and techniques, supported by the pioneering discovery of dental adhesion; the significant progress in orthodontics and periodontal as well as oral and maxillofacial surgery; and, most recently, the implementation of digital technologies in the 3-dimensional planning and realization of truly natural, individual, and aesthetic smiles. In the future, artificial intelligence and machine learning will likely lead to automation of aesthetic evaluation, smile design, and treatment-planning processes."
31632973,19.0,Translational AI and Deep Learning in Diagnostic Pathology,2019 Oct 1;6:185.,"There has been an exponential growth in the application of AI in health and in pathology. This is resulting in the innovation of deep learning technologies that are specifically aimed at cellular imaging and practical applications that could transform diagnostic pathology. This paper reviews the different approaches to deep learning in pathology, the public grand challenges that have driven this innovation and a range of emerging applications in pathology. The translation of AI into clinical practice will require applications to be embedded seamlessly within digital pathology workflows, driving an integrated approach to diagnostics and providing pathologists with new tools that accelerate workflow and improve diagnostic consistency and reduce errors. The clearance of digital pathology for primary diagnosis in the US by some manufacturers provides the platform on which to deliver practical AI. AI and computational pathology will continue to mature as researchers, clinicians, industry, regulatory organizations and patient advocacy groups work together to innovate and deliver new technologies to health care providers: technologies which are better, faster, cheaper, more precise, and safe."
31632915,,AI Meets Exascale Computing: Advancing Cancer Research With Large-Scale High Performance Computing,2019 Oct 2;9:984.,"The application of data science in cancer research has been boosted by major advances in three primary areas: (1) Data: diversity, amount, and availability of biomedical data; (2) Advances in Artificial Intelligence (AI) and Machine Learning (ML) algorithms that enable learning from complex, large-scale data; and (3) Advances in computer architectures allowing unprecedented acceleration of simulation and machine learning algorithms. These advances help build in silico ML models that can provide transformative insights from data including: molecular dynamics simulations, next-generation sequencing, omics, imaging, and unstructured clinical text documents. Unique challenges persist, however, in building ML models related to cancer, including: (1) access, sharing, labeling, and integration of multimodal and multi-institutional data across different cancer types; (2) developing AI models for cancer research capable of scaling on next generation high performance computers; and (3) assessing robustness and reliability in the AI models. In this paper, we review the National Cancer Institute (NCI) -Department of Energy (DOE) collaboration, Joint Design of Advanced Computing Solutions for Cancer (JDACS4C), a multi-institution collaborative effort focused on advancing computing and data technologies to accelerate cancer research on three levels: molecular, cellular, and population. This collaboration integrates various types of generated data, pre-exascale compute resources, and advances in ML models to increase understanding of basic cancer biology, identify promising new treatment options, predict outcomes, and eventually prescribe specialized treatments for patients with cancer."
31632910,10.0,Deep Learning: A Review for the Radiation Oncologist,2019 Oct 1;9:977.,"Introduction: Deep Learning (DL) is a machine learning technique that uses deep neural networks to create a model. The application areas of deep learning in radiation oncology include image segmentation and detection, image phenotyping, and radiomic signature discovery, clinical outcome prediction, image dose quantification, dose-response modeling, radiation adaptation, and image generation. In this review, we explain the methods used in DL and perform a literature review using the Medline database to identify studies using deep learning in radiation oncology. The search was conducted in April 2018, and identified studies published between 1997 and 2018, strongly skewed toward 2015 and later. Methods: A literature review was performed using PubMed/Medline in order to identify important recent publications to be synthesized into a review of the current status of Deep Learning in radiation oncology, directed at a clinically-oriented reader. The search strategy included the search terms ""radiotherapy"" and ""deep learning."" In addition, reference lists of selected articles were hand searched for further potential hits of relevance to this review. The search was conducted in April 2018, and identified studies published between 1997 and 2018, strongly skewed toward 2015 and later. Results: Studies using DL for image segmentation were identified in Brain (n = 2), Head and Neck (n = 3), Lung (n = 6), Abdominal (n = 2), and Pelvic (n = 6) cancers. Use of Deep Learning has also been reported for outcome prediction, such as toxicity modeling (n = 3), treatment response and survival (n = 2), or treatment planning (n = 5). Conclusion: Over the past few years, there has been a significant number of studies assessing the performance of DL techniques in radiation oncology. They demonstrate how DL-based systems can aid clinicians in their daily work, be it by reducing the time required for or the variability in segmentation, or by helping to predict treatment outcomes and toxicities. It still remains to be seen when these techniques will be employed in routine clinical practice."
31629933,5.0,Radiomics in stratification of pancreatic cystic lesions: Machine learning in action,2020 Jan 28;469:228-237.,"Pancreatic cystic lesions (PCLs) are well-known precursors of pancreatic cancer. Their diagnosis can be challenging as their behavior varies from benign to malignant disease. Precise and timely management of malignant pancreatic cysts might prevent transformation to pancreatic cancer. However, the current consensus guidelines, which rely on standard imaging features to predict cyst malignancy potential, are conflicting and unclear. This has led to an increased interest in radiomics, a high-throughput extraction of comprehensible data from standard of care images. Radiomics can be used as a diagnostic and prognostic tool in personalized medicine. It utilizes quantitative image analysis to extract features in conjunction with machine learning and artificial intelligence (AI) methods like support vector machines, random forest, and convolutional neural network for feature selection and classification. Selected features can then serve as imaging biomarkers to predict high-risk PCLs. Radiomics studies conducted heretofore on PCLs have shown promising results. This cost-effective approach would help us to differentiate benign PCLs from malignant ones and potentially guide clinical decision-making leading to better utilization of healthcare resources. In this review, we discuss the process of radiomics, its myriad applications such as diagnosis, prognosis, and prediction of therapy response. We also discuss the outcomes of studies involving radiomic analysis of PCLs and pancreatic cancer, and challenges associated with this novel field along with possible solutions. Although these studies highlight the potential benefit of radiomics in the prevention and optimal treatment of pancreatic cancer, further studies are warranted before incorporating radiomics into the clinical decision support system."
31629922,6.0,Transforming healthcare with big data analytics and artificial intelligence: A systematic mapping study,2019 Dec;100:103311.,"The domain of healthcare has always been flooded with a huge amount of complex data, coming in at a very fast-pace. A vast amount of data is generated in different sectors of healthcare industry: data from hospitals and healthcare providers, medical insurance, medical equipment, life sciences and medical research. With the advancement in technology, there is a huge potential for utilization of this data for transforming healthcare. The application of analytics, machine learning and artificial intelligence over big data enables identification of patterns and correlations and hence provides actionable insights for improving the delivery of healthcare. There have been many contributions to the literature in this topic, but we lack a comprehensive view of the current state of research and application. This paper focuses on assessing the available literature in order to provide the researchers with evidence that enable fostering further development in this area. A systematic mapping study was conducted to identify and analyze research on big data analytics and artificial intelligence in healthcare, in which 2421 articles between 2013 and February 2019 were evaluated. The results of this study will help understand the needs in application of these technologies in healthcare by identifying the areas that require additional research. It will hence provide the researchers and industry experts with a base for future work."
31628551,6.0,The application of artificial neural networks in metabolomics: a historical perspective,2019 Oct 18;15(11):142.,"Background:                    Metabolomics data, with its complex covariance structure, is typically modelled by projection-based machine learning (ML) methods such as partial least squares (PLS) regression, which project data into a latent structure. Biological data are often non-linear, so it is reasonable to hypothesize that metabolomics data may also have a non-linear latent structure, which in turn would be best modelled using non-linear equations. A non-linear ML method with a similar projection equation structure to PLS is artificial neural networks (ANNs). While ANNs were first applied to metabolic profiling data in the 1990s, the lack of community acceptance combined with limitations in computational capacity and the lack of volume of data for robust non-linear model optimisation inhibited their widespread use. Due to recent advances in computational power, modelling improvements, community acceptance, and the more demanding needs for data science, ANNs have made a recent resurgence in interest across research communities, including a small yet growing usage in metabolomics. As metabolomics experiments become more complex and start to be integrated with other omics data, there is potential for ANNs to become a viable alternative to linear projection methods.              Aim of review:                    We aim to first describe ANNs and their structural equivalence to linear projection-based methods, including PLS regression. We then review the historical, current, and future uses of ANNs in the field of metabolomics.              Key scientific concept of review:                    Is metabolomics ready for the return of artificial neural networks?"
31625725,8.0,An Overview of Machine Learning and Big Data for Drug Toxicity Evaluation,2020 Jan 21;33(1):20-37.,"Drug toxicity evaluation is an essential process of drug development as it is reportedly responsible for the attrition of approximately 30% of drug candidates. The rapid increase in the number and types of large toxicology data sets together with the advances in computational methods may be used to improve many steps in drug safety evaluation. The development of in silico models to screen and understand mechanisms of drug toxicity may be particularly beneficial in the early stages of drug development where early toxicity assessment can most reduce expenses and labor time. To facilitate this, machine learning methods have been employed to evaluate drug toxicity but are often limited by small and less diverse data sets. Recent advances in machine learning methods together with the rapid increase in big toxicity data such as molecular descriptors, toxicogenomics, and high-throughput bioactivity data may help alleviate some of the current challenges. In this article, the most common machine learning methods used in toxicity assessment are reviewed together with examples of toxicity studies that have used machine learning methodology. Furthermore, a comprehensive overview of the different types of toxicity tools and data sets available to build in silico toxicity prediction models has been provided to give an overview of the current big toxicity data landscape and highlight opportunities and challenges related to them."
31624739,2.0,Predictive modeling in spine surgery,2019 Sep;7(Suppl 5):S173.,"As the cost of healthcare in the United States increases at an unsustainable rate, health-policy leaders are looking towards innovative ways to maximize value in delivery of care. Incorporating technology, such as artificial intelligence/machine-learning, to assist physicians in decision-making and predicting outcomes, on a real-time basis, is a major topic of discussion. While machine learning is gradually pulling traction in the medical community, it still remains a nascent field in the realm of spine surgery. The current review aims to gather current literature discussing the validity and applicability of machine-learning models in spine surgery."
31623106,12.0,Proteomic Biomarkers for the Detection of Endometrial Cancer,2019 Oct 16;11(10):1572.,"Endometrial cancer is the leading gynaecological malignancy in the western world and its incidence is rising in tandem with the global epidemic of obesity. Early diagnosis is key to improving survival, which at 5 years is less than 20% in advanced disease and over 90% in early-stage disease. As yet, there are no validated biological markers for its early detection. Advances in high-throughput technologies and machine learning techniques now offer unique and promising perspectives for biomarker discovery, especially through the integration of genomic, transcriptomic, proteomic, metabolomic and imaging data. Because the proteome closely mirrors the dynamic state of cells, tissues and organisms, proteomics has great potential to deliver clinically relevant biomarkers for cancer diagnosis. In this review, we present the current progress in endometrial cancer diagnostic biomarker discovery using proteomics. We describe the various mass spectrometry-based approaches and highlight the challenges inherent in biomarker discovery studies. We suggest novel strategies for endometrial cancer detection exploiting biologically important protein biomarkers and set the scene for future directions in endometrial cancer biomarker research."
31622219,1.0,Identifying Cancer Targets Based on Machine Learning Methods via Chou's 5-steps Rule and General Pseudo Components,2019;19(25):2301-2317.,"In recent years, the successful implementation of human genome project has made people realize that genetic, environmental and lifestyle factors should be combined together to study cancer due to the complexity and various forms of the disease. The increasing availability and growth rate of 'big data' derived from various omics, opens a new window for study and therapy of cancer. In this paper, we will introduce the application of machine learning methods in handling cancer big data including the use of artificial neural networks, support vector machines, ensemble learning and naïve Bayes classifiers."
31621574,8.0,Phenotypes of osteoarthritis: current state and future implications,Sep-Oct 2019;37 Suppl 120(5):64-72.,"In the most recent years, an extraordinary research effort has emerged to disentangle osteoarthritis heterogeneity, opening new avenues for progressing with therapeutic development and unravelling the pathogenesis of this complex condition. Several phenotypes and endotypes have been proposed albeit none has been sufficiently validated for clinical or research use as yet. This review discusses the latest advances in OA phenotyping including how new modern statistical strategies based on machine learning and big data can help advance this field of research."
31621015,1.0,A Strength-Weaknesses-Opportunities-Threats (SWOT) Analysis of Cheminformatics in Natural Product Research,2019;110:239-271.,"Cheminformatics-based techniques, such as molecular modeling, docking, virtual screening, and machine learning, are well accepted for their usefulness in drug discovery and development of therapeutically relevant small molecules. Although delayed by several decades, their application in natural product research has led to outstanding findings. Combining information obtained from different sources, i.e., virtual predictions, traditional medicine, structural, biochemical, and biological data, and handling big data effectively will open up new possibilities, but also challenges in the future. Strategies and examples will be presented on how to integrate cheminformatics in pharmacognostic workflows to benefit from these two highly complementary disciplines toward streamlining experimental efforts. While considering their limits and pitfalls and by exploiting their potential, computer-aided strategies should successfully guide future studies and thereby augment our knowledge of bioactive natural lead structures."
31621014,1.0,Open-Access Activity Prediction Tools for Natural Products. Case Study: hERG Blockers,2019;110:177-238.,"Interference with the hERG potassium ion channel may cause cardiac arrhythmia and can even lead to death. Over the last few decades, several drugs, already on the market, and many more investigational drugs in various development stages, have had to be discontinued because of their hERG-associated toxicity. To recognize potential hERG activity in the early stages of drug development, a wide array of computational tools, based on different principles, such as 3D QSAR, 2D and 3D similarity, and machine learning, have been developed and are reviewed in this chapter. The various available prediction tools Similarity Ensemble Approach, SuperPred, SwissTargetPrediction, HitPick, admetSAR, PASSonline, Pred-hERG, and VirtualToxLab™ were used to screen a dataset of known hERG synthetic and natural product actives and inactives to quantify and compare their predictive power. This contribution will allow the reader to evaluate the suitability of these computational methods for their own related projects. There is an unmet need for natural product-specific prediction tools in this field."
31621013,,Cheminformatic Analysis of Natural Product Fragments,2019;110:143-175.,"Fragment-like natural products play a pivotal role in natural product research given their improved synthetic and computational tractability as well as commercial availability compared to more complex natural product structures. A multitude of computational tools have been developed to support the generation, analysis, and application of natural fragments for drug discovery and chemical biology research. In this contribution, the challenges and opportunities in such workflows are discussed and contextualized. Multiple successful applications and validations discussed herein attest to the relevance of natural fragments for drug discovery and the utility of machine learning and data science to support such endeavors."
31621011,,A Toolbox for the Identification of Modes of Action of Natural Products,2019;110:73-97.,"Natural products have long played a leading role as direct source of drugs or as a means to inspire informed molecular design. Indeed, natural products have been biologically prevalidated as protein-binding motifs by millions of years of evolutionary pressure. Despite the tailored architectures, and the ever-growing chemistry toolbox to aid access such privileged structures, identifying the modes of action by which these molecules can be harnessed as therapeutics remains a major bottleneck in discovery chemistry. Herein, an overview of cheminformatics methods applied to the identification of modes of action of natural products is given, and a discussion of successful case studies is provided. A special focus is given to machine learning methods that may help to streamline the development of natural products into drug leads."
31621009,2.0,Cheminformatics Explorations of Natural Products,2019;110:1-35.,"The chemistry of natural products is fascinating and has continuously attracted the attention of the scientific community for many reasons including, but not limited to, biosynthesis pathways, chemical diversity, the source of bioactive compounds and their marked impact on drug discovery. There is a broad range of experimental and computational techniques (molecular modeling and cheminformatics) that have evolved over the years and have assisted the investigation of natural products. Herein, we discuss cheminformatics strategies to explore the chemistry and applications of natural products. Since the potential synergisms between cheminformatics and natural products are vast, we will focus on three major aspects: (1) exploration of the chemical space of natural products to identify bioactive compounds, with emphasis on drug discovery; (2) assessment of the toxicity profile of natural products; and (3) diversity analysis of natural product collections and the design of chemical collections inspired by natural sources."
31620840,4.0,Artificial intelligence applications for pediatric oncology imaging,2019 Oct;49(11):1384-1390.,"Machine learning algorithms can help to improve the accuracy and efficiency of cancer diagnosis, selection of personalized therapies and prediction of long-term outcomes. Artificial intelligence (AI) describes a subset of machine learning that can identify patterns in data and take actions to reach pre-set goals without specific programming. Machine learning tools can help to identify high-risk populations, prescribe personalized screening tests and enrich patient populations that are most likely to benefit from advanced imaging tests. AI algorithms can also help to plan personalized therapies and predict the impact of genomic variations on the sensitivity of normal and tumor tissue to chemotherapy or radiation therapy. The two main bottlenecks for successful AI applications in pediatric oncology imaging to date are the needs for large data sets and appropriate computer and memory power. With appropriate data entry and processing power, deep convolutional neural networks (CNNs) can process large amounts of imaging data, clinical data and medical literature in very short periods of time and thereby accelerate literature reviews, correct diagnoses and personalized treatments. This article provides a focused review of emerging AI applications that are relevant for the pediatric oncology imaging community."
31618951,2.0,A Review of Computational Methods for Cervical Cells Segmentation and Abnormality Classification,2019 Oct 15;20(20):5114.,"Cervical cancer is the one of the most common cancers in women worldwide, affecting around 570,000 new patients each year. Although there have been great improvements over the years, current screening procedures can still suffer from long and tedious workflows and ambiguities. The increasing interest in the development of computer-aided solutions for cervical cancer screening is to aid with these common practical difficulties, which are especially frequent in the low-income countries where most deaths caused by cervical cancer occur. In this review, an overview of the disease and its current screening procedures is firstly introduced. Furthermore, an in-depth analysis of the most relevant computational methods available on the literature for cervical cells analysis is presented. Particularly, this work focuses on topics related to automated quality assessment, segmentation and classification, including an extensive literature review and respective critical discussion. Since the major goal of this timely review is to support the development of new automated tools that can facilitate cervical screening procedures, this work also provides some considerations regarding the next generation of computer-aided diagnosis systems and future research directions."
31617274,3.0,Flexible Piezoelectric Acoustic Sensors and Machine Learning for Speech Processing,2020 Sep;32(35):e1904020.,"Flexible piezoelectric acoustic sensors have been developed to generate multiple sound signals with high sensitivity, shifting the paradigm of future voice technologies. Speech recognition based on advanced acoustic sensors and optimized machine learning software will play an innovative interface for artificial intelligence (AI) services. Collaboration and novel approaches between both smart sensors and speech algorithms should be attempted to realize a hyperconnected society, which can offer personalized services such as biometric authentication, AI secretaries, and home appliances. Here, representative developments in speech recognition are reviewed in terms of flexible piezoelectric materials, self-powered sensors, machine learning algorithms, and speaker recognition."
31614282,4.0,"Visual novelty, curiosity, and intrinsic reward in machine learning and the brain",2019 Oct;58:167-174.,"A strong preference for novelty emerges in infancy and is prevalent across the animal kingdom. When incorporated into reinforcement-based machine learning algorithms, visual novelty can act as an intrinsic reward signal that vastly increases the efficiency of exploration and expedites learning, particularly in situations where external rewards are difficult to obtain. Here we review parallels between recent developments in novelty-driven machine learning algorithms and our understanding of how visual novelty is computed and signaled in the primate brain. We propose that in the visual system, novelty representations are not configured with the principal goal of detecting novel objects, but rather with the broader goal of flexibly generalizing novelty information across different states in the service of driving novelty-based learning."
31613700,3.0,Targeting the Versatile Wnt/β-Catenin Pathway in Cancer Biology and Therapeutics: From Concept to Actionable Strategy,2019 Nov;23(11):517-538.,"This expert review offers a critical synthesis of the latest insights and approaches at targeting the Wnt/β-catenin pathway in various cancers such as colorectal cancer, melanoma, leukemia, and breast and lung cancers. Notably, from organogenesis to cancer, the Wnt/β-catenin signaling displays varied and highly versatile biological functions in animals, with virtually all tissues requiring the Wnt/β-catenin signaling in one way or the other. Aberrant expression of the members of the Wnt/β-catenin has been implicated in many pathological conditions, particularly in human cancers. Mutations in the Wnt/β-catenin pathway genes have been noted in diverse cancers. Biochemical and genetic data support the idea that inhibition of Wnt/β-catenin signaling is beneficial in cancer therapeutics. The interaction of this important pathway with other signaling systems is also noteworthy, but remains as an area for further research and discovery. In addition, formation of different complexes by components of the Wnt/β-catenin pathway and the precise roles of these complexes in the cytoplasmic milieu are yet to be fully elucidated. This article highlights the latest medical technologies in imaging, single-cell omics, use of artificial intelligence (e.g., machine learning techniques), genome sequencing, quantum computing, molecular docking, and computational softwares in modeling interactions between molecules and predicting protein-protein and compound-protein interactions pertinent to the biology and therapeutic value of the Wnt/β-catenin signaling pathway. We discuss these emerging technologies in relationship to what is currently needed to move from concept to actionable strategies in translating the Wnt/β-catenin laboratory discoveries to Wnt-targeted cancer therapies and diagnostics in the clinic."
31611150,5.0,Applications of Artificial Intelligence in Cardiology. The Future is Already Here,2019 Dec;72(12):1065-1075.,"There is currently no other hot topic like the ability of current technology to develop capabilities similar to those of human beings, even in medicine. This ability to simulate the processes of human intelligence with computer systems is known as artificial intelligence (AI). This article aims to clarify the various terms that still sound foreign to us, such as AI, machine learning (ML), deep learning (DL), and big data. It also provides an in-depth description of the concept of AI and its types; the learning techniques and technology used by ML; cardiac imaging analysis with DL; and the contribution of this technological revolution to classical statistics, as well as its current limitations, legal aspects, and initial applications in cardiology. To do this, we conducted a detailed PubMed search on the evolution of original contributions on AI to the various areas of application in cardiology in the last 5 years and identified 673 research articles. We provide 19 detailed examples from distinct areas of cardiology that, by using AI, have shown diagnostic and therapeutic improvements, and which will aid understanding of ML and DL methodology."
31610899,1.0,A survey of adaptive resonance theory neural network models for engineering applications,2019 Dec;120:167-203.,"This survey samples from the ever-growing family of adaptive resonance theory (ART) neural network models used to perform the three primary machine learning modalities, namely, unsupervised, supervised and reinforcement learning. It comprises a representative list from classic to contemporary ART models, thereby painting a general picture of the architectures developed by researchers over the past 30 years. The learning dynamics of these ART models are briefly described, and their distinctive characteristics such as code representation, long-term memory, and corresponding geometric interpretation are discussed. Useful engineering properties of ART (speed, configurability, explainability, parallelization and hardware implementation) are examined along with current challenges. Finally, a compilation of online software libraries is provided. It is expected that this overview will be helpful to new and seasoned ART researchers."
31608730,1.0,Molecular and biomarker-based diagnostics in early sepsis: current challenges and future perspectives,2019 Dec;19(12):1069-1078.,"Introduction: Sepsis, defined as a life-threatening organ dysfunction resulting from dysregulated host response to infection, is still a major challenge for healthcare systems. Early diagnosis is highly needed, yet challenging, due to the non-specificity of clinical symptoms. Rapid and targeted application of therapy strategies is crucial for patient's outcome.Areas covered: Faster and better diagnostics with high accuracy is promised by novel host response biomarkers and a wide variety of direct pathogen identification technologies, which have emerged over the last years. This review will cover both - host response-guided diagnostics and methods for direct pathogen detection. Some of the markers and technologies are already market-ready, others are more likely aspirants. We will discuss them in terms of their performance and benefit for use in clinical diagnostics.Expert opinion: Latest technological advances enable the development of promising diagnostic tests, detecting the host response as well as identifying pathogens without the need of cultivation. However, the syndrome's heterogeneity makes it difficult to develop a universal test suitable for routine use. Moreover, the robustness of the biomarkers and technologies still has to be verified. Combining these technologies and clinical routine parameters with bioinformatic methods (e.g., machine-learning algorithms) may revolutionize sepsis diagnostics."
31607962,1.0,A Comprehensive Review of Computational Methods for Automatic Prediction of Schizophrenia With Insight Into Indigenous Populations,2019 Sep 12;10:659.,"Psychiatrists rely on language and speech behavior as one of the main clues in psychiatric diagnosis. Descriptive psychopathology and phenomenology form the basis of a common language used by psychiatrists to describe abnormal mental states. This conventional technique of clinical observation informed early studies on disturbances of thought form, speech, and language observed in psychosis and schizophrenia. These findings resulted in language models that were used as tools in psychosis research that concerned itself with the links between formal thought disorder and language disturbances observed in schizophrenia. The end result was the development of clinical rating scales measuring severity of disturbances in speech, language, and thought form. However, these linguistic measures do not fully capture the richness of human discourse and are time-consuming and subjective when measured against psychometric rating scales. These linguistic measures have not considered the influence of culture on psychopathology. With recent advances in computational sciences, we have seen a re-emergence of novel research using computing methods to analyze free speech for improving prediction and diagnosis of psychosis. Current studies on automated speech analysis examining for semantic incoherence are carried out based on natural language processing and acoustic analysis, which, in some studies, have been combined with machine learning approaches for classification and prediction purposes."
31606116,5.0,Deep learning based computer-aided diagnosis systems for diabetic retinopathy: A survey,2019 Aug;99:101701.,"Diabetic retinopathy (DR) results in vision loss if not treated early. A computer-aided diagnosis (CAD) system based on retinal fundus images is an efficient and effective method for early DR diagnosis and assisting experts. A computer-aided diagnosis (CAD) system involves various stages like detection, segmentation and classification of lesions in fundus images. Many traditional machine-learning (ML) techniques based on hand-engineered features have been introduced. The recent emergence of deep learning (DL) and its decisive victory over traditional ML methods for various applications motivated the researchers to employ it for DR diagnosis, and many deep-learning-based methods have been introduced. In this paper, we review these methods, highlighting their pros and cons. In addition, we point out the challenges to be addressed in designing and learning about efficient, effective and robust deep-learning algorithms for various problems in DR diagnosis and draw attention to directions for future research."
31606109,7.0,Machine learning and big data: Implications for disease modeling and therapeutic discovery in psychiatry,2019 Aug;99:101704.,"Introduction:                    Machine learning capability holds promise to inform disease models, the discovery and development of novel disease modifying therapeutics and prevention strategies in psychiatry. Herein, we provide an introduction on how machine learning/Artificial Intelligence (AI) may instantiate such capabilities, as well as provide rationale for its application to psychiatry in both research and clinical ecosystems.              Methods:                    Databases PubMed and PsycINFO were searched from 1966 to June 2016 for keywords:Big Data, Machine Learning, Precision Medicine, Artificial Intelligence, Mental Health, Mental Disease, Psychiatry, Data Mining, RDoC, and Research Domain Criteria. Articles selected for review were those that were determined to be aligned with the objective of this particular paper.              Results:                    Results indicate that AI is a viable option to build useful predictors of outcome while offering objective and comparable accuracy metrics, a unique opportunity, particularly in mental health research. The approach has also consistently brought notable insight into disease models through processing the vast amount of already available multi-domain, semi-structured medical data. The opportunity for AI in psychiatry, in addition to disease-model refinement, is in characterizing those at risk, and it is likely also relevant to personalizing and discovering therapeutics.              Conclusions:                    Machine learning currently provides an opportunity to parse disease models in complex, multi-factorial disease states (e.g. mental disorders) and could possibly inform treatment selection with existing therapies and provide bases for domain-based therapeutic discovery."
31605874,5.0,Common themes and emerging trends for the use of technology to support mental health and psychosocial well-being in limited resource settings: A review of the literature,2019 Nov;281:112594.,"There are significant disparities in access to mental health care. With the burgeoning of technologies for health, digital tools have been leveraged within mental health and psychosocial support programming (eMental health). A review of the literature was conducted to understand and identify how eMental health has been used in resource-limited settings in general. PubMed, Ovid Medline and Web of Science were searched. Six-hundred and thirty full-text articles were identified and assessed for eligibility; of those, 67 articles met the inclusion criteria and were analyzed. The most common mental health use cases were for depression (n = 25) and general mental health and well-being (n = 21). Roughly one-third used a website or Internet-enabled intervention (n = 23) and nearly one-third used an SMS intervention (n = 22). Technology was applied to enhance service delivery (n = 32), behavior change communication (n = 26) and data collection (n = 8), and specifically dealt with adherence (n = 7), ecological momentary assessments (n = 7), well-being promotion (n = 5), education (n = 8), telemedicine (n = 28), machine learning (n = 5) and games (n = 2). Emerging trends identified wearables, predictive analytics, robots and virtual reality as promising areas. eMental health interventions that leverage low-tech tools can introduce, strengthen and expand mental health and psychosocial support services and can be a starting point for future, advanced tools."
31603503,1.0,Big data in yeast systems biology,2019 Nov 1;19(7):foz070.,"Systems biology uses computational and mathematical modeling to study complex interactions in a biological system. The yeast Saccharomyces cerevisiae, which has served as both an important model organism and cell factory, has pioneered both the early development of such models and modeling concepts, and the more recent integration of multi-omics big data in these models to elucidate fundamental principles of biology. Here, we review the advancement of big data technologies to gain biological insight in three aspects of yeast systems biology: gene expression dynamics, cellular metabolism and the regulation network between gene expression and metabolism. The role of big data and complementary modeling approaches, including the expansion of genome-scale metabolic models and machine learning methodologies, are discussed as key drivers in the rapid advancement of yeast systems biology."
31603244,3.0,Machine learning techniques for protein function prediction,2020 Mar;88(3):397-413.,"Proteins play important roles in living organisms, and their function is directly linked with their structure. Due to the growing gap between the number of proteins being discovered and their functional characterization (in particular as a result of experimental limitations), reliable prediction of protein function through computational means has become crucial. This paper reviews the machine learning techniques used in the literature, following their evolution from simple algorithms such as logistic regression to more advanced methods like support vector machines and modern deep neural networks. Hyperparameter optimization methods adopted to boost prediction performance are presented. In parallel, the metamorphosis in the features used by these algorithms from classical physicochemical properties and amino acid composition, up to text-derived features from biomedical literature and learned feature representations using autoencoders, together with feature selection and dimensionality reduction techniques, are also reviewed. The success stories in the application of these techniques to both general and specific protein function prediction are discussed."
31602691,8.0,Unsupervised machine learning for exploratory data analysis in imaging mass spectrometry,2020 May;39(3):245-291.,"Imaging mass spectrometry (IMS) is a rapidly advancing molecular imaging modality that can map the spatial distribution of molecules with high chemical specificity. IMS does not require prior tagging of molecular targets and is able to measure a large number of ions concurrently in a single experiment. While this makes it particularly suited for exploratory analysis, the large amount and high-dimensional nature of data generated by IMS techniques make automated computational analysis indispensable. Research into computational methods for IMS data has touched upon different aspects, including spectral preprocessing, data formats, dimensionality reduction, spatial registration, sample classification, differential analysis between IMS experiments, and data-driven fusion methods to extract patterns corroborated by both IMS and other imaging modalities. In this work, we review unsupervised machine learning methods for exploratory analysis of IMS data, with particular focus on (a) factorization, (b) clustering, and (c) manifold learning. To provide a view across the various IMS modalities, we have attempted to include examples from a range of approaches including matrix assisted laser desorption/ionization, desorption electrospray ionization, and secondary ion mass spectrometry-based IMS. This review aims to be an entry point for both (i) analytical chemists and mass spectrometry experts who want to explore computational techniques; and (ii) computer scientists and data mining specialists who want to enter the IMS field. © 2019 The Authors. Mass Spectrometry Reviews published by Wiley Periodicals, Inc. Mass SpecRev 00:1-47, 2019."
31602005,9.0,Recent advances in the detection of base modifications using the Nanopore sequencer,2020 Jan;65(1):25-33.,"DNA and RNA modifications have important functions, including the regulation of gene expression. Existing methods based on short-read sequencing for the detection of modifications show difficulty in determining the modification patterns of single chromosomes or an entire transcript sequence. Furthermore, the kinds of modifications for which detection methods are available are very limited. The Nanopore sequencer is a single-molecule, long-read sequencer that can directly sequence RNA as well as DNA. Moreover, the Nanopore sequencer detects modifications on long DNA and RNA molecules. In this review, we mainly focus on base modification detection in the DNA and RNA of mammals using the Nanopore sequencer. We summarize current studies of modifications using the Nanopore sequencer, detection tools using statistical tests or machine learning, and applications of this technology, such as analyses of open chromatin, DNA replication, and RNA metabolism."
31601480,4.0,Machine Learning and Deep Learning in Medical Imaging: Intelligent Imaging,2019 Dec;50(4):477-487.,"Artificial intelligence (AI) in medical imaging is a potentially disruptive technology. An understanding of the principles and application of radiomics, artificial neural networks, machine learning, and deep learning is an essential foundation to weave design solutions that accommodate ethical and regulatory requirements, and to craft AI-based algorithms that enhance outcomes, quality, and efficiency. Moreover, a more holistic perspective of applications, opportunities, and challenges from a programmatic perspective contributes to ethical and sustainable implementation of AI solutions."
31593701,30.0,Application of Artificial Intelligence to Gastroenterology and Hepatology,2020 Jan;158(1):76-94.e2.,"Since 2010, substantial progress has been made in artificial intelligence (AI) and its application to medicine. AI is explored in gastroenterology for endoscopic analysis of lesions, in detection of cancer, and to facilitate the analysis of inflammatory lesions or gastrointestinal bleeding during wireless capsule endoscopy. AI is also tested to assess liver fibrosis and to differentiate patients with pancreatic cancer from those with pancreatitis. AI might also be used to establish prognoses of patients or predict their response to treatments, based on multiple factors. We review the ways in which AI may help physicians make a diagnosis or establish a prognosis and discuss its limitations, knowing that further randomized controlled studies will be required before the approval of AI techniques by the health authorities."
31593641,1.0,ASK1 and its role in cardiovascular and other disorders: available treatments and future prospects,2019 Oct;16(10):857-870.,"Introduction: Apoptosis signal-regulating kinase 1 (ASK1), also known as MAP3K5, is a member of mitogen-activated protein kinase kinase kinase (MAP3K) family and is well reported as crucial in the regulation of the JNK and P38 pathways. ASK1 is activated in response to a diverse array of stresses such as endoplasmic reticulum stress, lipopolysaccharides, tumor necrosis factor alpha, and reactive oxygen species. The activation of ASK1 induces various stress responses. Areas covered: Considering ASK1 as an important therapeutic drug target, here we have discussed the role of ASK1 in the progression of various diseases. We have also provided an overview of the available inhibitors for ASK1. The success of computational-based approaches toward ASK1 inhibitor design has also been discussed. Expert opinion: A number of reports have outlined the prominent role of ASK1 in the pathogenesis of several diseases. The discovery of novel ASK1 inhibitors would have a wide range of applications in medical science. In-silico techniques have been successfully used in the design of some novel ASK1 inhibitors. The use of machine learning-based approaches in combination with structure-based virtual screening (SBVS) and ligand-based virtual screening (LBVS) will be helpful toward the development of potent ASK1 inhibitors."
31592719,1.0,Implementing Artificial Intelligence and Digital Health in Resource-Limited Settings? Top 10 Lessons We Learned in Congenital Heart Defects and Cardiology,2020 May;24(5):264-277.,"Artificial intelligence (AI) is one of the key drivers of digital health. Digital health and AI applications in medicine and biology are emerging worldwide, not only in resource-rich but also resource-limited regions. AI predates to the mid-20th century, but the current wave of AI builds in part on machine learning (ML), big data, and algorithms that can learn from massive amounts of online user data from patients or healthy persons. There are lessons to be learned from AI applications in different medical specialties and across developed and resource-limited contexts. A case in point is congenital heart defects (CHDs) that continue to plague sub-Saharan Africa, which calls for innovative approaches to improve risk prediction and performance of the available diagnostics. Beyond CHDs, AI in cardiology is a promising context as well. The current suite of digital health applications in CHD and cardiology include complementary technologies such as neural networks, ML, natural language processing and deep learning, not to mention embedded digital sensors. Algorithms that build on these advances are beginning to complement traditional medical expertise while inviting us to redefine the concepts and definitions of expertise in molecular diagnostics and precision medicine. We examine and share here the lessons learned in current attempts to implement AI and digital health in CHD for precision risk prediction and diagnosis in resource-limited settings. These top 10 lessons on AI and digital health summarized in this expert review are relevant broadly beyond CHD in cardiology and medical innovations. As with AI itself that calls for systems approaches to data capture, analysis, and interpretation, both developed and developing countries can usefully learn from their respective experiences as digital health continues to evolve worldwide."
31590664,13.0,Machine learning in cardiovascular magnetic resonance: basic concepts and applications,2019 Oct 7;21(1):61.,"Machine learning (ML) is making a dramatic impact on cardiovascular magnetic resonance (CMR) in many ways. This review seeks to highlight the major areas in CMR where ML, and deep learning in particular, can assist clinicians and engineers in improving imaging efficiency, quality, image analysis and interpretation, as well as patient evaluation. We discuss recent developments in the field of ML relevant to CMR in the areas of image acquisition & reconstruction, image analysis, diagnostic evaluation and derivation of prognostic information. To date, the main impact of ML in CMR has been to significantly reduce the time required for image segmentation and analysis. Accurate and reproducible fully automated quantification of left and right ventricular mass and volume is now available in commercial products. Active research areas include reduction of image acquisition and reconstruction time, improving spatial and temporal resolution, and analysis of perfusion and myocardial mapping. Although large cohort studies are providing valuable data sets for ML training, care must be taken in extending applications to specific patient groups. Since ML algorithms can fail in unpredictable ways, it is important to mitigate this by open source publication of computational processes and datasets. Furthermore, controlled trials are needed to evaluate methods across multiple centers and patient groups."
31588687,,The Role of Protein Engineering in Biomedical Applications of Mammalian Synthetic Biology,2020 Jul;16(27):e1903093.,"Engineered proteins with enhanced or altered functionality, generated for example by mutation or domain fusion, are at the core of nearly all synthetic biology endeavors in the context of precision medicine, also known as personalized medicine. From designer receptors sensing elevated blood markers to effectors rerouting signaling pathways to synthetic transcription factors and the customized therapeutics they regulate, engineered proteins play a crucial role at every step of novel therapeutic approaches using synthetic biology. Here, recent developments in protein engineering aided by advances in directed evolution, de novo design, and machine learning are discussed. Building on clinical successes already achieved with chimeric antigen receptor (CAR-) T cells and other cell-based therapies, these developments are expected to further enhance the capabilities of mammalian synthetic biology in biomedical and other applications."
33693359,1.0,"TGx-DDI, a Transcriptomic Biomarker for Genotoxicity Hazard Assessment of Pharmaceuticals and Environmental Chemicals",2019 Oct 8;2:36.,"Genotoxicity testing is an essential component of the safety assessment paradigm required by regulatory agencies world-wide for analysis of drug candidates, and environmental and industrial chemicals. Current genotoxicity testing batteries feature a high incidence of irrelevant positive findings-particularly for in vitro chromosomal damage (CD) assays. The risk management of compounds with positive in vitro findings is a major challenge and requires complex, time consuming, and costly follow-up strategies including animal testing. Thus, regulators are urgently in need of new testing approaches to meet legislated mandates. Using machine learning, we identified a set of transcripts that responds predictably to DNA-damage in human cells that we refer to as the TGx-DDI biomarker, which was originally referred to as TGx-28.65. We proposed to use this biomarker in conjunction with current genotoxicity testing batteries to differentiate compounds with irrelevant ""false"" positive findings in the in vitro CD assays from true DNA damaging agents (i.e., for de-risking agents that are clastogenic in vitro but not in vivo). We validated the performance of the TGx-DDI biomarker to identify true DNA damaging agents, assessed intra- and inter- laboratory reproducibility, and cross-platform performance. Recently, to augment the application of this biomarker, we developed a high-throughput cell-based genotoxicity testing system using the NanoString nCounter® technology. Here, we review the status of TGx-DDI development, its integration in the genotoxicity testing paradigm, and progress to date in its qualification at the US Food and Drug Administration (FDA) as a drug development tool. If successfully validated and implemented, the TGx-DDI biomarker assay is expected to significantly augment the current strategy for the assessment of genotoxic hazards for drugs and chemicals."
31585696,5.0,Ethics of Artificial Intelligence in Radiology: Summary of the Joint European and North American Multisociety Statement,2019 Nov;16(11):1516-1521.,"This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine. AI has great potential to increase efficiency and accuracy throughout radiology, but it also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice. This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future. The radiology community should start now to develop codes of ethics and practice for AI that promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes."
31584645,5.0,Mining social media for prescription medication abuse monitoring: a review and proposal for a data-centric framework,2020 Feb 1;27(2):315-329.,"Objective:                    Prescription medication (PM) misuse and abuse is a major health problem globally, and a number of recent studies have focused on exploring social media as a resource for monitoring nonmedical PM use. Our objectives are to present a methodological review of social media-based PM abuse or misuse monitoring studies, and to propose a potential generalizable, data-centric processing pipeline for the curation of data from this resource.              Materials and methods:                    We identified studies involving social media, PMs, and misuse or abuse (inclusion criteria) from Medline, Embase, Scopus, Web of Science, and Google Scholar. We categorized studies based on multiple characteristics including but not limited to data size; social media source(s); medications studied; and primary objectives, methods, and findings.              Results:                    A total of 39 studies met our inclusion criteria, with 31 (∼79.5%) published since 2015. Twitter has been the most popular resource, with Reddit and Instagram gaining popularity recently. Early studies focused mostly on manual, qualitative analyses, with a growing trend toward the use of data-centric methods involving natural language processing and machine learning.              Discussion:                    There is a paucity of standardized, data-centric frameworks for curating social media data for task-specific analyses and near real-time surveillance of nonmedical PM use. Many existing studies do not quantify human agreements for manual annotation tasks or take into account the presence of noise in data.              Conclusion:                    The development of reproducible and standardized data-centric frameworks that build on the current state-of-the-art methods in data and text mining may enable effective utilization of social media data for understanding and monitoring nonmedical PM use."
31584379,,Recent Advancement in Predicting Subcellular Localization of Mycobacterial Protein with Machine Learning Methods,2020;16(5):605-619.,"Mycobacterium tuberculosis (MTB) can cause the terrible tuberculosis (TB), which is reported as one of the most dreadful epidemics. Although many biochemical molecular drugs have been developed to cope with this disease, the drug resistance-especially the multidrug-resistant (MDR) and extensively drug-resistance (XDR)-poses a huge threat to the treatment. However, traditional biochemical experimental method to tackle TB is time-consuming and costly. Benefited by the appearance of the enormous genomic and proteomic sequence data, TB can be treated via sequence-based biological computational approach-bioinformatics. Studies on predicting subcellular localization of mycobacterial protein (MBP) with high precision and efficiency may help figure out the biological function of these proteins and then provide useful insights for protein function annotation as well as drug design. In this review, we reported the progress that has been made in computational prediction of subcellular localization of MBP including the following aspects: 1) Construction of benchmark datasets. 2) Methods of feature extraction. 3) Techniques of feature selection. 4) Application of several published prediction algorithms. 5) The published results. 6) The further study on prediction of subcellular localization of MBP."
31584374,2.0,Application of Machine Learning Methods in Predicting Nuclear Receptors and their Families,2020;16(5):594-604.,"Nuclear receptors (NRs) are a superfamily of ligand-dependent transcription factors that are closely related to cell development, differentiation, reproduction, homeostasis, and metabolism. According to the alignments of the conserved domains, NRs are classified and assigned the following seven subfamilies or eight subfamilies: (1) NR1: thyroid hormone like (thyroid hormone, retinoic acid, RAR-related orphan receptor, peroxisome proliferator activated, vitamin D3- like), (2) NR2: HNF4-like (hepatocyte nuclear factor 4, retinoic acid X, tailless-like, COUP-TFlike, USP), (3) NR3: estrogen-like (estrogen, estrogen-related, glucocorticoid-like), (4) NR4: nerve growth factor IB-like (NGFI-B-like), (5) NR5: fushi tarazu-F1 like (fushi tarazu-F1 like), (6) NR6: germ cell nuclear factor like (germ cell nuclear factor), and (7) NR0: knirps like (knirps, knirpsrelated, embryonic gonad protein, ODR7, trithorax) and DAX like (DAX, SHP), or dividing NR0 into (7) NR7: knirps like and (8) NR8: DAX like. Different NRs families have different structural features and functions. Since the function of a NR is closely correlated with which subfamily it belongs to, it is highly desirable to identify NRs and their subfamilies rapidly and effectively. The knowledge acquired is essential for a proper understanding of normal and abnormal cellular mechanisms. With the advent of the post-genomics era, huge amounts of sequence-known proteins have increased explosively. Conventional methods for accurately classifying the family of NRs are experimental means with high cost and low efficiency. Therefore, it has created a greater need for bioinformatics tools to effectively recognize NRs and their subfamilies for the purpose of understanding their biological function. In this review, we summarized the application of machine learning methods in the prediction of NRs from different aspects. We hope that this review will provide a reference for further research on the classification of NRs and their families."
31582102,1.0,Postoperative ward monitoring - Why and what now?,2019 Jun;33(2):229-245.,"The postoperative ward is considered an ideal nursing environment for stable patients transitioning out of the hospital. However, approximately half of all in-hospital cardiorespiratory arrests occur here and are associated with poor outcomes. Current monitoring practices on the hospital ward mandate intermittent vital sign checks. Subtle changes in vital signs often occur at least 8-12 h before an acute event, and continuous monitoring of vital signs would allow for effective therapeutic interventions and potentially avoid an imminent cardiorespiratory arrest event. It seems tempting to apply continuous monitoring to every patient on the ward, but inherent challenges such as artifacts and alarm fatigue need to be considered. This review looks to the future where a continuous, smarter, and portable platform for monitoring of vital signs on the hospital ward will be accompanied with a central monitoring platform and machine learning-based pattern detection solutions to improve safety for hospitalized patients."
31582098,2.0,Predicting hypotension in perioperative and intensive care medicine,2019 Jun;33(2):189-197.,"Blood pressure is the main determinant of organ perfusion. Hypotension is common in patients having surgery and in critically ill patients. The severity and duration of hypotension are associated with hypoperfusion and organ dysfunction. Hypotension is mostly treated reactively after low blood pressure values have already occurred. However, prediction of hypotension before it becomes clinically apparent would allow the clinician to treat hypotension pre-emptively, thereby reducing the severity and duration of hypotension. Hypotension can now be predicted minutes before it actually occurs from the blood pressure waveform using machine-learning algorithms that can be trained to detect subtle changes in cardiovascular dynamics preceding clinically apparent hypotension. However, analyzing the complex cardiovascular system is a challenge because cardiovascular physiology is highly interdependent, works within complicated networks, and is influenced by compensatory mechanisms. Improved hemodynamic data collection and integration will be a key to improve current models and develop new hypotension prediction models."
31580992,6.0,Machine learning applications in systems metabolic engineering,2020 Aug;64:1-9.,"Systems metabolic engineering allows efficient development of high performing microbial strains for the sustainable production of chemicals and materials. In recent years, increasing availability of bio big data, for example, omics data, has led to active application of machine learning techniques across various stages of systems metabolic engineering, including host strain selection, metabolic pathway reconstruction, metabolic flux optimization, and fermentation. In this paper, recent contributions of machine learning approaches to each major step of systems metabolic engineering are discussed. As the use of machine learning in systems metabolic engineering will become more widespread in accordance with the ever-increasing volume of bio big data, future prospects are also provided for the successful applications of machine learning."
31580731,6.0,Micro-nanorobots: important considerations when developing novel drug delivery platforms,2019 Nov;16(11):1259-1275.,"Introduction: There is growing emphasis on the development of bioinspired and biohybrid micro/nanorobots for the targeted drug delivery (TDD). Particularly, stimuli-responsive materials and magnetically triggered systems, identified as the most promising materials and design paradigms. Despite the advances made in fabrication and control, there remains a significant gap in clinical translation. Areas covered: This review discusses the opportunities and challenges about micro/nanorobotics for the TDD as evolutionary evidence in bio-nanotechnology, material science, biohybrid robotics, and many more. Important consideration in context with the material's compatibility/immunogenicity, ethics, and security risk are reported based on the development in artificial intelligence (AI)/machine learning described in literature. The versatility and sophistication of biohybrid components design are being presented, highlighting stimuli-responsive biosystems as smart mechanisms and on-board sensing and control elements. Expert opinion: Focusing on key issues for high controllability at micro- and nano-scale systems in TDD, biohybrid integration strategies, and bioinspired key competences shall be adopted. The promising outlook portraying the commercialization potential and economic viability of micro/nanorobotics will benefit to clinical translation."
31579859,,Delineating conditions and subtypes in chronic pain using neuroimaging,2019 Aug 7;4(4):e768.,"Differentiating subtypes of chronic pain still remains a challenge-both from a subjective and objective point of view. Personalized medicine is the current goal of modern medical care and is limited by the subjective nature of patient self-reporting of symptoms and behavioral evaluation. Physiology-focused techniques such as genome and epigenetic analyses inform the delineation of pain groups; however, except under rare circumstances, they have diluted effects that again, share a common reliance on behavioral evaluation. The application of structural neuroimaging towards distinguishing pain subtypes is a growing field and may inform pain-group classification through the analysis of brain regions showing hypertrophic and atrophic changes in the presence of pain. Analytical techniques such as machine-learning classifiers have the capacity to process large volumes of data and delineate diagnostically relevant information from neuroimaging analysis. The issue of defining a ""brain type"" is an emerging field aimed at interpreting observed brain changes and delineating their clinical identity/significance. In this review, 2 chronic pain conditions (migraine and irritable bowel syndrome) with similar clinical phenotypes are compared in terms of their structural neuroimaging findings. Independent investigations are compared with findings from application of machine-learning algorithms. Findings are discussed in terms of differentiating patient subgroups using neuroimaging data in patients with chronic pain and how they may be applied towards defining a personalized pain signature that helps segregate patient subgroups (eg, migraine with and without aura, with or without nausea; irritable bowel syndrome vs other functional gastrointestinal disorders)."
31579847,8.0,Neuroimaging-based biomarkers for pain: state of the field and current directions,2019 Aug 7;4(4):e751.,"Chronic pain is an endemic problem involving both peripheral and brain pathophysiology. Although biomarkers have revolutionized many areas of medicine, biomarkers for pain have remained controversial and relatively underdeveloped. With the realization that biomarkers can reveal pain-causing mechanisms of disease in brain circuits and in the periphery, this situation is poised to change. In particular, brain pathophysiology may be diagnosable with human brain imaging, particularly when imaging is combined with machine learning techniques designed to identify predictive measures embedded in complex data sets. In this review, we explicate the need for brain-based biomarkers for pain, some of their potential uses, and some of the most popular machine learning approaches that have been brought to bear. Then, we evaluate the current state of pain biomarkers developed with several commonly used methods, including structural magnetic resonance imaging, functional magnetic resonance imaging and electroencephalography. The field is in the early stages of biomarker development, but these complementary methodologies have already produced some encouraging predictive models that must be tested more extensively across laboratories and clinical populations."
31571334,1.0,Effects of oral and oropharyngeal cancer on speech intelligibility using acoustic analysis: Systematic review,2020 Jan;42(1):111-130.,"Background:                    The development of automatic tools based on acoustic analysis allows to overcome the limitations of perceptual assessment for patients with head and neck cancer. The aim of this study is to provide a systematic review of literature describing the effects of oral and oropharyngeal cancer on speech intelligibility using acoustic analysis.              Methods:                    Two databases (PubMed and Embase) were surveyed. The selection process, according to the preferred reporting items for systematic reviews and meta-analyses (PRISMA) statement, led to a final set of 22 articles.              Results:                    Nasalance is studied mainly in oropharyngeal patients. The vowels are mostly studied using formant analysis and vowel space area, the consonants by means of spectral moments with specific parameters according to their phonetic characteristic. Machine learning methods allow classifying ""intelligible"" or ""unintelligible"" speech for T3 or T4 tumors.              Conclusions:                    The development of comprehensive models combining different acoustic measures would allow a better consideration of the functional impact of the speech disorder."
31570887,119.0,ilastik: interactive machine learning for (bio)image analysis,2019 Dec;16(12):1226-1232.,"We present ilastik, an easy-to-use interactive tool that brings machine-learning-based (bio)image analysis to end users without substantial computational expertise. It contains pre-defined workflows for image segmentation, object classification, counting and tracking. Users adapt the workflows to the problem at hand by interactively providing sparse training annotations for a nonlinear classifier. ilastik can process data in up to five dimensions (3D, time and number of channels). Its computational back end runs operations on-demand wherever possible, allowing for interactive prediction on data larger than RAM. Once the classifiers are trained, ilastik workflows can be applied to new data from the command line without further user interaction. We describe all ilastik workflows in detail, including three case studies and a discussion on the expected performance."
31570832,1.0,Looking back and thinking forwards - 15 years of cardiology and cardiovascular research,2019 Nov;16(11):651-660.,"The first issue of Nature Reviews Cardiology was published in November 2004 under the name Nature Clinical Practice Cardiovascular Medicine. To celebrate our 15th anniversary in 2019, we invited six of our Advisory Board members to discuss what they considered the most important advances in their field of cardiovascular research or clinical practice in the past 15 years and what changes they envision for cardiovascular medicine in the next 15 years. Several practice-changing breakthroughs are described, including advances in procedural techniques to treat arrhythmias and hypertension and the development of novel therapeutic strategies to treat heart failure and pulmonary arterial hypertension, as well as those that target risk factors such as inflammation and elevated LDL-cholesterol levels. Furthermore, these key opinion leaders predict that machine learning technology and data derived from wearable devices will pave the way towards the coveted goal of personalized medicine."
31568792,,Investigation of machine learning techniques on proteomics: A comprehensive survey,2019 Dec;149:54-69.,"Proteomics is the extensive investigation of proteins which has empowered the recognizable proof of consistently expanding quantities of protein. Proteins are necessary part of living life form, with numerous capacities. The proteome is the complete arrangement of proteins that are created or altered by a life form or framework of the organism. Proteome fluctuates with time and unambiguous prerequisites, or stresses, that a cell or organism experiences. Proteomics is an interdisciplinary area that has derived from the hereditary data of different genome ventures. Much proteomics information is gathered with the assistance of high throughput techniques, for example, mass spectrometry and microarray. It would regularly take weeks or months to analyze the information and perform examinations by hand. Therefore, scholars and scientific experts are teaming up with computer science researchers and mathematicians to make projects and pipeline to computationally examine the protein information. Utilizing bioinformatics procedures, scientists are prepared to do quicker investigation and protein information storing. The goal of this paper is to brief about the review of machine learning procedures and its application in the field of proteomics."
31567618,7.0,"Recent and Upcoming Technological Developments in Computed Tomography: High Speed, Low Dose, Deep Learning, Multienergy",2020 Jan;55(1):8-19.,"The advent of computed tomography (CT) has revolutionized radiology, and this revolution is still going on. Starting as a pure head scanner, modern CT systems are now able to perform whole-body examinations within a couple of seconds in isotropic resolution, single-rotation whole-organ perfusion, and temporal resolution to fulfill the needs of cardiac CT. Because of the increasing number of CT examinations in all age groups and overall medical-driven radiation exposure, dose reduction remains a hot topic. Although fast gantry rotation, broad detector arrays, and different dual-energy solutions were main topics in the past years, new techniques such as photon counting detectors, powerful x-ray tubes for low-kV scanning, automated image preprocessing, and machine learning algorithms have moved into focus today.The aim of this article is to give an overview of the technical specifications of up-to-date available CT systems and recent hardware and software innovations for CT systems in the near future."
31562965,,Big Data Defined: A Practical Review for Neurosurgeons,2020 Jan;133:e842-e849.,"Background:                    Modern science and healthcare generate vast amounts of data, and, coupled with the increasingly inexpensive and accessible computing, a tremendous opportunity exists to use these data to improve care. A better understanding of data science and its relationship to neurosurgical practice will be increasingly important as we transition into this modern ""big data"" era.              Methods:                    A review of the literature was performed for key articles referencing big data for neurosurgical care or related topics.              Results:                    In the present report, we first defined the nature and scope of data science from a technical perspective. We then discussed its relationship to the modern neurosurgical practice, highlighting key references, which might form a useful introductory reading list.              Conclusions:                    Numerous challenges exist going forward; however, organized neurosurgery has an important role in fostering and facilitating these efforts to merge data science with neurosurgical practice."
31562957,10.0,Computer-aided drug repurposing for cancer therapy: Approaches and opportunities to challenge anticancer targets,2021 Jan;68:59-74.,"Despite huge efforts made in academic and pharmaceutical worldwide research, current anticancer therapies achieve effective treatment in a limited number of neoplasia cases only. Oncology terms such as big killers - to identify tumours with yet a high mortality rate - or undruggable cancer targets, and chemoresistance, represent the current therapeutic debacle of cancer treatments. In addition, metastases, tumour microenvironments, tumour heterogeneity, metabolic adaptations, and immunotherapy resistance are essential features controlling tumour response to therapies, but still, lack effective therapeutics or modulators. In this scenario, where the pharmaceutical productivity and drug efficacy in oncology seem to have reached a plateau, the so-called drug repurposing - i.e. the use of old drugs, already in clinical use, for a different therapeutic indication - is an appealing strategy to improve cancer therapy. Opportunities for drug repurposing are often based on occasional observations or on time-consuming pre-clinical drug screenings that are often not hypothesis-driven. In contrast, in-silico drug repurposing is an emerging, hypothesis-driven approach that takes advantage of the use of big-data. Indeed, the extensive use of -omics technologies, improved data storage, data meaning, machine learning algorithms, and computational modeling all offer unprecedented knowledge of the biological mechanisms of cancers and drugs' modes of action, providing extensive availability for both disease-related data and drugs-related data. This offers the opportunity to generate, with time and cost-effective approaches, computational drug networks to predict, in-silico, the efficacy of approved drugs against relevant cancer targets, as well as to select better responder patients or disease' biomarkers. Here, we will review selected disease-related data together with computational tools to be exploited for the in-silico repurposing of drugs against validated targets in cancer therapies, focusing on the oncogenic signaling pathways activation in cancer. We will discuss how in-silico drug repurposing has the promise to shortly improve our arsenal of anticancer drugs and, likely, overcome certain limitations of modern cancer therapies against old and new therapeutic targets in oncology."
31562756,3.0,Accuracy of Machine Learning Algorithms for the Diagnosis of Autism Spectrum Disorder: Systematic Review and Meta-Analysis of Brain Magnetic Resonance Imaging Studies,2019 Dec 20;6(12):e14108.,"Background:                    In the recent years, machine learning algorithms have been more widely and increasingly applied in biomedical fields. In particular, their application has been drawing more attention in the field of psychiatry, for instance, as diagnostic tests/tools for autism spectrum disorder (ASD). However, given their complexity and potential clinical implications, there is an ongoing need for further research on their accuracy.              Objective:                    This study aimed to perform a systematic review and meta-analysis to summarize the available evidence for the accuracy of machine learning algorithms in diagnosing ASD.              Methods:                    The following databases were searched on November 28, 2018: MEDLINE, EMBASE, CINAHL Complete (with Open Dissertations), PsycINFO, and Institute of Electrical and Electronics Engineers Xplore Digital Library. Studies that used a machine learning algorithm partially or fully for distinguishing individuals with ASD from control subjects and provided accuracy measures were included in our analysis. The bivariate random effects model was applied to the pooled data in a meta-analysis. A subgroup analysis was used to investigate and resolve the source of heterogeneity between studies. True-positive, false-positive, false-negative, and true-negative values from individual studies were used to calculate the pooled sensitivity and specificity values, draw Summary Receiver Operating Characteristics curves, and obtain the area under the curve (AUC) and partial AUC (pAUC).              Results:                    A total of 43 studies were included for the final analysis, of which a meta-analysis was performed on 40 studies (53 samples with 12,128 participants). A structural magnetic resonance imaging (sMRI) subgroup meta-analysis (12 samples with 1776 participants) showed a sensitivity of 0.83 (95% CI 0.76-0.89), a specificity of 0.84 (95% CI 0.74-0.91), and AUC/pAUC of 0.90/0.83. A functional magnetic resonance imaging/deep neural network subgroup meta-analysis (5 samples with 1345 participants) showed a sensitivity of 0.69 (95% CI 0.62-0.75), specificity of 0.66 (95% CI 0.61-0.70), and AUC/pAUC of 0.71/0.67.              Conclusions:                    The accuracy of machine learning algorithms for diagnosis of ASD was considered acceptable by few accuracy measures only in cases of sMRI use; however, given the many limitations indicated in our study, further well-designed studies are warranted to extend the potential use of machine learning algorithms to clinical settings.              Trial registration:                    PROSPERO CRD42018117779; https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=117779."
31557462,20.0,Development and Arealization of the Cerebral Cortex,2019 Sep 25;103(6):980-1004.,"Adult cortical areas consist of specialized cell types and circuits that support unique higher-order cognitive functions. How this regional diversity develops from an initially uniform neuroepithelium has been the subject of decades of seminal research, and emerging technologies, including single-cell transcriptomics, provide a new perspective on area-specific molecular diversity. Here, we review the early developmental processes that underlie cortical arealization, including both cortex intrinsic and extrinsic mechanisms as embodied by the protomap and protocortex hypotheses, respectively. We propose an integrated model of serial homology whereby intrinsic genetic programs and local factors establish early transcriptomic differences between excitatory neurons destined to give rise to broad ""proto-regions,"" and activity-dependent mechanisms lead to progressive refinement and formation of sharp boundaries between functional areas. Finally, we explore the potential of these basic developmental processes to inform our understanding of the emergence of functional neural networks and circuit abnormalities in neurodevelopmental disorders."
31557461,12.0,Engineering a Less Artificial Intelligence,2019 Sep 25;103(6):967-979.,"Despite enormous progress in machine learning, artificial neural networks still lag behind brains in their ability to generalize to new situations. Given identical training data, differences in generalization are caused by many defining features of a learning algorithm, such as network architecture and learning rule. Their joint effect, called ""inductive bias,"" determines how well any learning algorithm-or brain-generalizes: robust generalization needs good inductive biases. Artificial networks use rather nonspecific biases and often latch onto patterns that are only informative about the statistics of the training data but may not generalize to different scenarios. Brains, on the other hand, generalize across comparatively drastic changes in the sensory input all the time. We highlight some shortcomings of state-of-the-art learning algorithms compared to biological brains and discuss several ideas about how neuroscience can guide the quest for better inductive biases by providing useful constraints on representations and network architecture."
31555764,5.0,Applications of Machine Learning Approaches in Emergency Medicine; a Review Article,2019 Jun 3;7(1):34.,"Using artificial intelligence and machine learning techniques in different medical fields, especially emergency medicine is rapidly growing. In this paper, studies conducted in the recent years on using artificial intelligence in emergency medicine have been collected and assessed. These studies belonged to three categories: prediction and detection of disease; prediction of need for admission, discharge and also mortality; and machine learning based triage systems. In each of these categories, the most important studies have been chosen and accuracy and results of the algorithms have been briefly evaluated by mentioning machine learning techniques and used datasets."
31555327,4.0,Current applications of big data and machine learning in cardiology,2019 Aug;16(8):601-607.,"Machine learning (ML) is a software solution with the ability of making predictions without prior explicit programming, aiding in the analysis of large amounts of data. These algorithms can be trained through supervised or unsupervised learning. Cardiology is one of the fields of medicine with the highest interest in its applications. They can facilitate every step of patient care, reducing the margin of error and contributing to precision medicine. In particular, ML has been proposed for cardiac imaging applications such as automated computation of scores, differentiation of prognostic phenotypes, quantification of heart function and segmentation of the heart. These tools have also demonstrated the capability of performing early and accurate detection of anomalies in electrocardiographic exams. ML algorithms can also contribute to cardiovascular risk assessment in different settings and perform predictions of cardiovascular events. Another interesting research avenue in this field is represented by genomic assessment of cardiovascular diseases. Therefore, ML could aid in making earlier diagnosis of disease, develop patient-tailored therapies and identify predictive characteristics in different pathologic conditions, leading to precision cardiology."
31554575,2.0,Cardiovascular models for personalised medicine: Where now and where next?,2019 Oct;72:38-48.,"The aim of this position paper is to provide a brief overview of the current status of cardiovascular modelling and of the processes required and some of the challenges to be addressed to see wider exploitation in both personal health management and clinical practice. In most branches of engineering the concept of the digital twin, informed by extensive and continuous monitoring and coupled with robust data assimilation and simulation techniques, is gaining traction: the Gartner Group listed it as one of the top ten digital trends in 2018. The cardiovascular modelling community is starting to develop a much more systematic approach to the combination of physics, mathematics, control theory, artificial intelligence, machine learning, computer science and advanced engineering methodology, as well as working more closely with the clinical community to better understand and exploit physiological measurements, and indeed to develop jointly better measurement protocols informed by model-based understanding. Developments in physiological modelling, model personalisation, model outcome uncertainty, and the role of models in clinical decision support are addressed and 'where-next' steps and challenges discussed."
31553511,5.0,Autonomous Discovery in the Chemical Sciences Part I: Progress,2020 Dec 14;59(51):22858-22893.,"This two-part Review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this first part, we describe a classification for discoveries of physical matter (molecules, materials, devices), processes, and models and how they are unified as search problems. We then introduce a set of questions and considerations relevant to assessing the extent of autonomy. Finally, we describe many case studies of discoveries accelerated by or resulting from computer assistance and automation from the domains of synthetic chemistry, drug discovery, inorganic chemistry, and materials science. These illustrate how rapid advancements in hardware automation and machine learning continue to transform the nature of experimentation and modeling. Part two reflects on these case studies and identifies a set of open challenges for the field."
31553509,7.0,Autonomous Discovery in the Chemical Sciences Part II: Outlook,2020 Dec 21;59(52):23414-23436.,"This two-part Review examines how automation has contributed to different aspects of discovery in the chemical sciences. In this second part, we reflect on a selection of exemplary studies. It is increasingly important to articulate what the role of automation and computation has been in the scientific process and how that has or has not accelerated discovery. One can argue that even the best automated systems have yet to ""discover"" despite being incredibly useful as laboratory assistants. We must carefully consider how they have been and can be applied to future problems of chemical discovery in order to effectively design and interact with future autonomous platforms. The majority of this Review defines a large set of open research directions, including improving our ability to work with complex data, build empirical models, automate both physical and computational experiments for validation, select experiments, and evaluate whether we are making progress towards the ultimate goal of autonomous discovery. Addressing these practical and methodological challenges will greatly advance the extent to which autonomous systems can make meaningful discoveries."
31552275,9.0,Artificial Intelligence Will Transform Cardiac Imaging-Opportunities and Challenges,2019 Sep 10;6:133.,"Artificial intelligence (AI) using machine learning techniques will change healthcare as we know it. While healthcare AI applications are currently trailing behind popular AI applications, such as personalized web-based advertising, the pace of research and deployment is picking up and about to become disruptive. Overcoming challenges such as patient and public support, transparency over the legal basis for healthcare data use, privacy preservation, technical challenges related to accessing large-scale data from healthcare systems not designed for Big Data analysis, and deployment of AI in routine clinical practice will be crucial. Cardiac imaging and imaging of other body parts is likely to be at the frontier for the development of applications as pattern recognition and machine learning are a significant strength of AI with practical links to image processing. Many opportunities in cardiac imaging exist where AI will impact patients, medical staff, hospitals, commissioners and thus, the entire healthcare system. This perspective article will outline our vision for AI in cardiac imaging with examples of potential applications, challenges and some lessons learnt in recent years."
31551916,2.0,New Approaches to Studying Silent Mesial Temporal Lobe Seizures in Alzheimer's Disease,2019 Sep 4;10:959.,"Silent seizures were discovered in mouse models of Alzheimer's disease over 10 years ago, yet it remains unclear whether these seizures are a salient feature of Alzheimer's disease in humans. Seizures that arise early in the course of Alzheimer's disease most likely originate from the mesial temporal lobe, one of the first structures affected by Alzheimer's disease pathology and one of the most epileptogenic regions of the brain. Several factors greatly limit our ability to identify mesial temporal lobe seizures in patients with Alzheimer's disease, however. First, mesial temporal lobe seizures can be difficult to recognize clinically, as their accompanying symptoms are often subtle or even non-existent. Second, electrical activity arising from the mesial temporal lobe is largely invisible on the scalp electroencephalogram (EEG), the mainstay of diagnosis for epilepsy in this population. In this review, we will describe two new approaches being used to study silent mesial temporal lobe seizures in Alzheimer's disease. We will first describe the methodology and application of foramen ovale electrodes, which captured the first recordings of silent mesial temporal lobe seizures in humans with Alzheimer's disease. We will then describe machine learning approaches being developed to non-invasively identify silent mesial temporal lobe seizures on scalp EEG. Both of these tools have the potential to elucidate the role of silent seizures in humans with Alzheimer's disease, which could have important implications for early diagnosis, prognostication, and development of targeted therapies for this population."
31550922,4.0,Artificial intelligence in healthcare: An essential guide for health leaders,2020 Jan;33(1):10-18.,"Artificial Intelligence (AI) is evolving rapidly in healthcare, and various AI applications have been developed to solve some of the most pressing problems that health organizations currently face. It is crucial for health leaders to understand the state of AI technologies and the ways that such technologies can be used to improve the efficiency, safety, and access of health services, achieving value-based care. This article provides a guide to understand the fundamentals of AI technologies (ie, machine learning, natural language processing, and AI voice assistants) as well as their proper use in healthcare. It also provides practical recommendations to help decision-makers develop an AI strategy that can support their digital healthcare transformation."
33733108,,The Autonomous Mind: The Right to Freedom of Thought in the Twenty-First Century,2019 Sep 26;2:19.,"To lose freedom of thought (FoT) is to lose our dignity, our democracy and our very selves. Accordingly, the right to FoT receives absolute protection under international human rights law. However, this foundational right has been neither significantly developed nor often utilized. The contours of this right urgently need to be defined due to twenty-first century threats to FoT posed by new technologies. As such, this paper draws on law and psychology to consider what the right to FoT should be in the twenty-first century. After discussing contemporary threats to FoT, and recent developments in our understanding of thought that can inform the development of the right, this paper considers three elements of the right; the rights not to reveal one's thoughts, not to be penalized for one's thoughts, and not to have one's thoughts manipulated. The paper then considers, for each element, why it should exist, how the law currently treats it, and challenges that will shape it going forward. The paper concludes that the law should develop the right to FoT with the clear understanding that what this aims to secure is mental autonomy. This process should hence begin by establishing the core mental processes that enable mental autonomy, such as attentional and cognitive agency. The paper argues that the domain of the right to FoT should be extended to include external actions that are arguably constitutive of thought, including internet searches and diaries, hence shielding them with absolute protection. It is stressed that law must protect us from threats to FoT from both states and corporations, with governments needing to act under the positive aspect of the right to ensure societies are structured to facilitate mental autonomy. It is suggested that in order to support mental autonomy, information should be provided in autonomy-supportive contexts and friction introduced into decision making processes to facilitate second-order thought. The need for public debate about how society wishes to balance risk and mental autonomy is highlighted, and the question is raised as to whether the importance attached to thought has changed in our culture. The urgency of defending FoT is re-iterated."
31549948,12.0,Artificial Intelligence for Mammography and Digital Breast Tomosynthesis: Current Concepts and Future Perspectives,2019 Nov;293(2):246-259.,"Although computer-aided diagnosis (CAD) is widely used in mammography, conventional CAD programs that use prompts to indicate potential cancers on the mammograms have not led to an improvement in diagnostic accuracy. Because of the advances in machine learning, especially with use of deep (multilayered) convolutional neural networks, artificial intelligence has undergone a transformation that has improved the quality of the predictions of the models. Recently, such deep learning algorithms have been applied to mammography and digital breast tomosynthesis (DBT). In this review, the authors explain how deep learning works in the context of mammography and DBT and define the important technical challenges. Subsequently, they discuss the current status and future perspectives of artificial intelligence-based clinical applications for mammography, DBT, and radiomics. Available algorithms are advanced and approach the performance of radiologists-especially for cancer detection and risk prediction at mammography. However, clinical validation is largely lacking, and it is not clear how the power of deep learning should be used to optimize practice. Further development of deep learning models is necessary for DBT, and this requires collection of larger databases. It is expected that deep learning will eventually have an important role in DBT, including the generation of synthetic images."
31547800,3.0,Machine learning for discovering missing or wrong protein function annotations : A comparison using updated benchmark datasets,2019 Sep 23;20(1):485.,"Background:                    A massive amount of proteomic data is generated on a daily basis, nonetheless annotating all sequences is costly and often unfeasible. As a countermeasure, machine learning methods have been used to automatically annotate new protein functions. More specifically, many studies have investigated hierarchical multi-label classification (HMC) methods to predict annotations, using the Functional Catalogue (FunCat) or Gene Ontology (GO) label hierarchies. Most of these studies employed benchmark datasets created more than a decade ago, and thus train their models on outdated information. In this work, we provide an updated version of these datasets. By querying recent versions of FunCat and GO yeast annotations, we provide 24 new datasets in total. We compare four HMC methods, providing baseline results for the new datasets. Furthermore, we also evaluate whether the predictive models are able to discover new or wrong annotations, by training them on the old data and evaluating their results against the most recent information.              Results:                    The results demonstrated that the method based on predictive clustering trees, Clus-Ensemble, proposed in 2008, achieved superior results compared to more recent methods on the standard evaluation task. For the discovery of new knowledge, Clus-Ensemble performed better when discovering new annotations in the FunCat taxonomy, whereas hierarchical multi-label classification with genetic algorithm (HMC-GA), a method based on genetic algorithms, was overall superior when detecting annotations that were removed. In the GO datasets, Clus-Ensemble once again had the upper hand when discovering new annotations, HMC-GA performed better for detecting removed annotations. However, in this evaluation, there were less significant differences among the methods.              Conclusions:                    The experiments have showed that protein function prediction is a very challenging task which should be further investigated. We believe that the baseline results associated with the updated datasets provided in this work should be considered as guidelines for future studies, nonetheless the old versions of the datasets should not be disregarded since other tasks in machine learning could benefit from them."
31547220,6.0,Wearable-Based Affect Recognition-A Review,2019 Sep 20;19(19):4079.,"Affect recognition is an interdisciplinary research field bringing together researchers from natural and social sciences. Affect recognition research aims to detect the affective state of a person based on observables, with the goal to, for example, provide reasoning for the person's decision making or to support mental wellbeing (e.g., stress monitoring). Recently, beside of approaches based on audio, visual or text information, solutions relying on wearable sensors as observables, recording mainly physiological and inertial parameters, have received increasing attention. Wearable systems enable an ideal platform for long-term affect recognition applications due to their rich functionality and form factor, while providing valuable insights during everyday life through integrated sensors. However, existing literature surveys lack a comprehensive overview of state-of-the-art research in wearable-based affect recognition. Therefore, the aim of this paper is to provide a broad overview and in-depth understanding of the theoretical background, methods and best practices of wearable affect and stress recognition. Following a summary of different psychological models, we detail the influence of affective states on the human physiology and the sensors commonly employed to measure physiological changes. Then, we outline lab protocols eliciting affective states and provide guidelines for ground truth generation in field studies. We also describe the standard data processing chain and review common approaches related to the preprocessing, feature extraction and classification steps. By providing a comprehensive summary of the state-of-the-art and guidelines to various aspects, we would like to enable other researchers in the field to conduct and evaluate user studies and develop wearable systems."
31546906,7.0,Early Autism Screening: A Comprehensive Review,2019 Sep 19;16(18):3502.,"Autistic spectrum disorder (ASD) refers to a neurodevelopmental condition associated with verbal and nonverbal communication, social interactions, and behavioural complications that is becoming increasingly common in many parts of the globe. Identifying individuals on the spectrum has remained a lengthy process for the past few decades due to the fact that some individuals diagnosed with ASD exhibit exceptional skills in areas such as mathematics, arts, and music among others. To improve the accuracy and reliability of autism diagnoses, many scholars have developed pre-diagnosis screening methods to help identify autistic behaviours at an early stage, speed up the clinical diagnosis referral process, and improve the understanding of ASD for the different stakeholders involved, such as parents, caregivers, teachers, and family members. However, the functionality and reliability of those screening tools vary according to different research studies and some have remained questionable. This study evaluates and critically analyses 37 different ASD screening tools in order to identify possible areas that need to be addressed through further development and innovation. More importantly, different criteria associated with existing screening tools, such as accessibility, the fulfilment of Diagnostic and Statistical Manual of Mental Disorders (DSM-5) specifications, comprehensibility among the target audience, performance (specifically sensitivity, specificity, and accuracy), web and mobile availability, and popularity have been investigated."
31545655,3.0,Using Machine Learning and Natural Language Processing to Review and Classify the Medical Literature on Cancer Susceptibility Genes,2019 Sep;3:1-9.,"Purpose:                    The medical literature relevant to germline genetics is growing exponentially. Clinicians need tools that help to monitor and prioritize the literature to understand the clinical implications of pathogenic genetic variants. We developed and evaluated two machine learning models to classify abstracts as relevant to the penetrance-risk of cancer for germline mutation carriers-or prevalence of germline genetic mutations.              Materials and methods:                    We conducted literature searches in PubMed and retrieved paper titles and abstracts to create an annotated data set for training and evaluating the two machine learning classification models. Our first model is a support vector machine (SVM) which learns a linear decision rule on the basis of the bag-of-ngrams representation of each title and abstract. Our second model is a convolutional neural network (CNN) which learns a complex nonlinear decision rule on the basis of the raw title and abstract. We evaluated the performance of the two models on the classification of papers as relevant to penetrance or prevalence.              Results:                    For penetrance classification, we annotated 3,740 paper titles and abstracts and evaluated the two models using 10-fold cross-validation. The SVM model achieved 88.93% accuracy-percentage of papers that were correctly classified-whereas the CNN model achieved 88.53% accuracy. For prevalence classification, we annotated 3,753 paper titles and abstracts. The SVM model achieved 88.92% accuracy and the CNN model achieved 88.52% accuracy.              Conclusion:                    Our models achieve high accuracy in classifying abstracts as relevant to penetrance or prevalence. By facilitating literature review, this tool could help clinicians and researchers keep abreast of the burgeoning knowledge of gene-cancer associations and keep the knowledge bases for clinical decision support tools up to date."
31545114,1.0,A survey of breast cancer screening techniques: thermography and electrical impedance tomography,2019 Jul;43(5):305-322.,"Breast cancer is a disease that threat many women's life, thus, the early and accurate detection play a key role in reducing the mortality rate. Mammography stands as the reference technique for breast cancer screening; nevertheless, many countries still lack access to mammograms due to economic, social and cultural issues. Last advances in computational tools, infra-red cameras and devices for bio-impedance quantification allowed the development of parallel techniques like, thermography, infra-red imaging and electrical impedance tomography, these being faster, reliable and cheaper. In the last decades, these have been considered as complement procedures for breast cancer diagnosis, where many studies concluded that false positive and false negative rates are greatly reduced. This work aims to review the last breakthroughs about the three above-mentioned techniques describing the benefits of mixing several computational skills to obtain a better global performance. In addition, we provide a comparison between several machine learning techniques applied to breast cancer diagnosis going from logistic regression, decision trees and random forest to artificial, deep and convolutional neural networks. Finally, it is mentioned several recommendations for 3D breast simulations, pre-processing techniques, biomedical devices in the research field, prediction of tumour location and size."
31544714,2.0,Recent Advances and Computational Approaches in Peptide Drug Discovery,2019;25(31):3358-3366.,"Background:                    Drug design and development is a vast field that requires huge investment along with a long duration for providing approval to suitable drug candidates. With the advancement in the field of genomics, the information about druggable targets is being updated at a fast rate which is helpful in finding a cure for various diseases.              Methods:                    There are certain biochemicals as well as physiological advantages of using peptide-based therapeutics. Additionally, the limitations of peptide-based drugs can be overcome by modulating the properties of peptide molecules through various biomolecular engineering techniques. Recent advances in computational approaches have been helpful in studying the effect of peptide drugs on the biomolecular targets. Receptor - ligand-based molecular docking studies have made it easy to screen compatible inhibitors against a target.Furthermore, there are simulation tools available to evaluate stability of complexes at the molecular level. Machine learning methods have added a new edge by enabling accurate prediction of therapeutic peptides.              Results:                    Peptide-based drugs are expected to take over many popular drugs in the near future due to their biosafety, lower off-target binding chances and multifunctional properties.              Conclusion:                    This article summarises the latest developments in the field of peptide-based therapeutics related to their usage, tools, and databases."
31543209,1.0,Research Techniques Made Simple: Feature Selection for Biomarker Discovery,2019 Oct;139(10):2068-2074.e1.,"Molecular biomarkers can be powerful tools for aiding in the efficiency and precision of clinical decision-making. Feature selection methods, machine-learning, and biostatistics have been applied to discover subsets of molecular markers that identify target classes of clinical cases. For example, in the field of dermatology, these approaches have been used to develop predictive models that identify skin diseases, ranging from melanoma to psoriasis, based upon a variety of biomarkers. However, a continuous increase in the variety and size of datasets from which candidate biomarkers can be derived, and limitations in the computational tools used to analyze them, have hindered the interpretability of biomarker discovery studies. In this article, the various methods of feature selection are described along with the important steps needed to properly validate the performance of the selected methods. Limitations and suggestions toward uses of these methods are discussed."
31540192,11.0,Key Topics in Molecular Docking for Drug Design,2019 Sep 15;20(18):4574.,"Molecular docking has been widely employed as a fast and inexpensive technique in the past decades, both in academic and industrial settings. Although this discipline has now had enough time to consolidate, many aspects remain challenging and there is still not a straightforward and accurate route to readily pinpoint true ligands among a set of molecules, nor to identify with precision the correct ligand conformation within the binding pocket of a given target molecule. Nevertheless, new approaches continue to be developed and the volume of published works grows at a rapid pace. In this review, we present an overview of the method and attempt to summarise recent developments regarding four main aspects of molecular docking approaches: (i) the available benchmarking sets, highlighting their advantages and caveats, (ii) the advances in consensus methods, (iii) recent algorithms and applications using fragment-based approaches, and (iv) the use of machine learning algorithms in molecular docking. These recent developments incrementally contribute to an increase in accuracy and are expected, given time, and together with advances in computing power and hardware capability, to eventually accomplish the full potential of this area."
31539636,14.0,Machine learning for clinical decision support in infectious diseases: a narrative review of current applications,2020 May;26(5):584-595.,"Background:                    Machine learning (ML) is a growing field in medicine. This narrative review describes the current body of literature on ML for clinical decision support in infectious diseases (ID).              Objectives:                    We aim to inform clinicians about the use of ML for diagnosis, classification, outcome prediction and antimicrobial management in ID.              Sources:                    References for this review were identified through searches of MEDLINE/PubMed, EMBASE, Google Scholar, biorXiv, ACM Digital Library, arXiV and IEEE Xplore Digital Library up to July 2019.              Content:                    We found 60 unique ML-clinical decision support systems (ML-CDSS) aiming to assist ID clinicians. Overall, 37 (62%) focused on bacterial infections, 10 (17%) on viral infections, nine (15%) on tuberculosis and four (7%) on any kind of infection. Among them, 20 (33%) addressed the diagnosis of infection, 18 (30%) the prediction, early detection or stratification of sepsis, 13 (22%) the prediction of treatment response, four (7%) the prediction of antibiotic resistance, three (5%) the choice of antibiotic regimen and two (3%) the choice of a combination antiretroviral therapy. The ML-CDSS were developed for intensive care units (n = 24, 40%), ID consultation (n = 15, 25%), medical or surgical wards (n = 13, 20%), emergency department (n = 4, 7%), primary care (n = 3, 5%) and antimicrobial stewardship (n = 1, 2%). Fifty-three ML-CDSS (88%) were developed using data from high-income countries and seven (12%) with data from low- and middle-income countries (LMIC). The evaluation of ML-CDSS was limited to measures of performance (e.g. sensitivity, specificity) for 57 ML-CDSS (95%) and included data in clinical practice for three (5%).              Implications:                    Considering comprehensive patient data from socioeconomically diverse healthcare settings, including primary care and LMICs, may improve the ability of ML-CDSS to suggest decisions adapted to various clinical contexts. Currents gaps identified in the evaluation of ML-CDSS must also be addressed in order to know the potential impact of such tools for clinicians and patients."
31538879,,Deep Learning in the Study of Protein-Related Interactions,2020;27(5):359-369.,"Protein-related interaction prediction is critical to understanding life processes, biological functions, and mechanisms of drug action. Experimental methods used to determine proteinrelated interactions have always been costly and inefficient. In recent years, advances in biological and medical technology have provided us with explosive biological and physiological data, and deep learning-based algorithms have shown great promise in extracting features and learning patterns from complex data. At present, deep learning in protein research has emerged. In this review, we provide an introductory overview of the deep neural network theory and its unique properties. Mainly focused on the application of this technology in protein-related interactions prediction over the past five years, including protein-protein interactions prediction, protein-RNA\DNA, Protein- drug interactions prediction, and others. Finally, we discuss some of the challenges that deep learning currently faces."
31537505,1.0,Essential Elements of Natural Language Processing: What the Radiologist Should Know,2020 Jan;27(1):6-12.,"Natural language is ubiquitous in the workflow of medical imaging. Radiologists create and consume free text in their daily work, some of which can be amenable to enhancements through automatic processing. Recent advancements in deep learning and ""artificial intelligence"" have had a significant positive impact on natural language processing (NLP). This article discusses the history of how researchers have extracted data and encoded natural language information for analytical processing, starting from NLP's humble origins in hand-curated, linguistic rules. The evolution of medical NLP including vectorization, word embedding, classification, as well as its use in automated speech recognition, are also explored. Finally, the article will discuss the role of machine learning and neural networks in the context of significant, if incremental, improvements in NLP."
31533522,6.0,An overview and metanalysis of machine and deep learning-based CRISPR gRNA design tools,2020 Jan;17(1):13-22.,"The CRISPR-Cas9 system has become the most promising and versatile tool for genetic manipulation applications. Albeit the technology has been broadly adopted by both academic and pharmaceutic societies, the activity (on-target) and specificity (off-target) of CRISPR-Cas9 are decisive factors for any application of the technology. Several in silico gRNA activity and specificity predicting models and web tools have been developed, making it much more convenient and precise for conducting CRISPR gene editing studies. In this review, we present an overview and comparative analysis of machine and deep learning (MDL)-based algorithms, which are believed to be the most effective and reliable methods for the prediction of CRISPR gRNA on- and off-target activities. As an increasing number of sequence features and characteristics are discovered and are incorporated into the MDL models, the prediction outcome is getting closer to experimental observations. We also introduced the basic principle of CRISPR activity and specificity and summarized the challenges they faced, aiming to facilitate the CRISPR communities to develop more accurate models for applying."
31530047,1.0,A review of medical image detection for cancers in digestive system based on artificial intelligence,2019 Oct;16(10):877-889.,"Introduction: At present, cancer imaging examination relies mainly on manual reading of doctors, which requests a high standard of doctors' professional skills, clinical experience, and concentration. However, the increasing amount of medical imaging data has brought more and more challenges to radiologists. The detection of digestive system cancer (DSC) based on artificial intelligence (AI) can provide a solution for automatic analysis of medical images and assist doctors to achieve high-precision intelligent diagnosis of cancers. Areas covered: The main goal of this paper is to introduce the main research methods of the AI based detection of DSC, and provide relevant reference for researchers. Meantime, it summarizes the main problems existing in these methods, and provides better guidance for future research. Expert commentary: The automatic classification, recognition, and segmentation of DSC can be better realized through the methods of machine learning and deep learning, which minimize the internal information of images that are difficult for humans to discover. In the diagnosis of DSC, the use of AI to assist imaging surgeons can achieve cancer detection rapidly and effectively and save doctors' diagnosis time. These can lay the foundation for better clinical diagnosis, treatment planning and accurate quantitative evaluation of DSC."
31527580,8.0,Machine learning for radiomics-based multimodality and multiparametric modeling,2019 Dec;63(4):323-338.,"Due to the recent developments of both hardware and software technologies, multimodality medical imaging techniques have been increasingly applied in clinical practice and research studies. Previously, the application of multimodality imaging in oncology has been mainly related to combining anatomical and functional imaging to improve diagnostic specificity and/or target definition, such as positron emission tomography/computed tomography (PET/CT) and single-photon emission CT (SPECT)/CT. More recently, the fusion of various images, such as multiparametric magnetic resonance imaging (MRI) sequences, different PET tracer images, PET/MRI, has become more prevalent, which has enabled more comprehensive characterization of the tumor phenotype. In order to take advantage of these valuable multimodal data for clinical decision making using radiomics, we present two ways to implement the multimodal image analysis, namely radiomic (handcrafted feature) based and deep learning (machine learned feature) based methods. Applying advanced machine (deep) learning algorithms across multimodality images have shown better results compared with single modality modeling for prognostic and/or prediction of clinical outcomes. This holds great potentials for providing more personalized treatment for patients and achieve better outcomes."
31526946,1.0,Half a century of computer methods and programs in biomedicine: A bibliometric analysis from 1970 to 2017,2020 Jan;183:105075.,"Background and objective:                    Computer Methods and Programs in Biomedicine (CMPB) is a leading international journal that presents developments about computing methods and their application in biomedical research. The journal published its first issue in 1970. In 2020, the journal celebrates the 50th anniversary. Motivated by this event, this article presents a bibliometric analysis of the publications of the journal during this period (1970-2017).              Methods:                    The objective is to identify the leading trends occurring in the journal by analysing the most cited papers, keywords, authors, institutions and countries. For doing so, the study uses the Web of Science Core Collection database. Additionally, the work presents a graphical mapping of the bibliographic information by using the visualization of similarities (VOS) viewer software. This is done to analyze bibliographic coupling, co-citation and co-occurrence of keywords.              Results:                    CMPB is identified as a leading and core journal for biomedical researchers. The journal is strongly connected to IEEE Transactions on Biomedical Engineering and IEEE Transactions on Medical Imaging. Paper from Wang, Jacques, Zheng (published in 1995) is its most cited document. The top author in this journal is James Geoffrey Chase and the top contributing institution is Uppsala U (Sweden). Most of the papers in CMPB are from the USA followed by the UK and Italy. China and Taiwan are the only Asian countries to appear in the top 10 publishing in CMPB. A keyword co-occurrences analysis revealed strong co-occurrences for classification, picture archiving and communication system (PACS), heart rate variability, survival analysis and simulation. Keywords analysis for the last decade revealed that machine learning for a variety of healthcare problems (including image processing and analysis) dominated other research fields in CMPB.              Conclusions:                    It can be concluded that CMPB is a world-renowned publication outlet for biomedical researchers which has been growing in a number of publications since 1970. The analysis also conclude that the journal is very international with publications from all over the world although today European countries are the most productive ones."
31525565,,Addressing heterogeneity (and homogeneity) in treatment mechanisms in depression and the potential to develop diagnostic and predictive biomarkers,2019;24:101997.,"It has been 10 years since machine learning was first applied to neuroimaging data in psychiatric disorders to identify diagnostic and prognostic markers at the level of the individual. Proof of concept findings in major depression have since been extended in international samples and are beginning to include hundreds of samples from multisite data. Neuroimaging provides the unique capability to detect an acute depressive state in major depression, while we would not expect perfect classification with current diagnostic criteria which are based solely on clinical features. We review developments and the potential impact of heterogeneity, as well as homogeneity, on classification for diagnosis and prediction of clinical outcome. It is likely that there are distinct biotypes which comprise the disorder and which predict clinical outcome. Neuroimaging-based biotypes could aid in identifying the illness in individuals who are unable to recognise their illness and perhaps to identify the treatment resistant form early in the course of the illness. We propose that heterogeneous symptom profiles can arise from a limited number of neural biotypes and that apparently heterogeneous clinical outcomes include a common baseline predictor and common mechanism of treatment. Baseline predictors of clinical outcome reflect factors which indicate the general likelihood of response as well as those which are selective for a particular form of treatment. Irrespective of the mechanism, the capacity for response will moderate the outcome, which includes inherent models of interpersonal relationships that could be associated with genetic risk load and represented by patterns of functional and structural neural correlates as a predictive biomarker. We propose that methods which directly address heterogeneity are essential and that a synergistic combination could bring together data-driven inductive and symptom-based deductive approaches. Through this iterative process, major depression can develop from being syndrome characterized by a collection of symptoms to a disease with an identifiable pathophysiology."
31523704,23.0,Artificial Intelligence and Machine Learning in Pathology: The Present Landscape of Supervised Methods,2019 Sep 3;6:2374289519873088.,"Increased interest in the opportunities provided by artificial intelligence and machine learning has spawned a new field of health-care research. The new tools under development are targeting many aspects of medical practice, including changes to the practice of pathology and laboratory medicine. Optimal design in these powerful tools requires cross-disciplinary literacy, including basic knowledge and understanding of critical concepts that have traditionally been unfamiliar to pathologists and laboratorians. This review provides definitions and basic knowledge of machine learning categories (supervised, unsupervised, and reinforcement learning), introduces the underlying concept of the bias-variance trade-off as an important foundation in supervised machine learning, and discusses approaches to the supervised machine learning study design along with an overview and description of common supervised machine learning algorithms (linear regression, logistic regression, Naive Bayes, k-nearest neighbor, support vector machine, random forest, convolutional neural networks)."
