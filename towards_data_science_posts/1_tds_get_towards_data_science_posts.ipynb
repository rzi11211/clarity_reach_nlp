{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards Data Science Blog Posts: Get Blog Posts\n",
    "### *Use requests library and BeautifulSoup to scrape posts from TowardsDataScience.com*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries\n",
    "\n",
    "import pandas as pd\n",
    "import requests \n",
    "import numpy as np\n",
    "from time import sleep \n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save url as a variable\n",
    "url = 'https://towardsdatascience.com/archive/2021/3/3'\n",
    "\n",
    "#check status\n",
    "res = requests.get(url)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code adapted from https://hackernoon.com/how-to-scrape-a-medium-publication-a-python-tutorial-for-beginners-o8u3t69\n",
    "stories_data = []\n",
    "\n",
    "#iterate through each month, determine the number of days in each month\n",
    "for month in range(1, 5):\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        n_days = 31\n",
    "    elif month in [4, 6, 9, 11]:\n",
    "        n_days = 30\n",
    "    else:\n",
    "        n_days = 28\n",
    "    \n",
    "    #iterate through the appropriate nunber of days in each month\n",
    "    for day in range(1, n_days + 1):\n",
    "\n",
    "        month, day = str(month), str(day)\n",
    "\n",
    "        if len(month) == 1:\n",
    "            month = f'0{month}'\n",
    "        if len(day) == 1:\n",
    "            day = f'0{day}'\n",
    "        \n",
    "        #build the date and url for each day\n",
    "        date = f'{month}/{day}/2021'\n",
    "        url = f'https://towardsdatascience.com/archive/2021/{month}/{day}'\n",
    "\n",
    "        #scrape the content on that day's archive page and save as a BeautifulSoup object\n",
    "        page  = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        stories = soup.find_all('div', class_='streamItem streamItem--postPreview js-streamItem')\n",
    "        \n",
    "        #sleep so as not to overwhelm the server\n",
    "        sleep(np.random.randint(1, 15))\n",
    "        \n",
    "        #for each post\n",
    "        for story in stories:\n",
    "            each_story = []\n",
    "            \n",
    "            #grab the author URL\n",
    "            author_box = story.find('div', class_='postMetaInline u-floatLeft u-sm-maxWidthFullWidth')\n",
    "            author_url = author_box.find('a')['href']\n",
    "\n",
    "            #get the reading time, if applicable\n",
    "            try:\n",
    "                reading_time = author_box.find('span', class_='readingTime')['title']\n",
    "                reading_time = reading_time.split()[0]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            #get the title and subtitle\n",
    "            title = story.find('h3').text if story.find('h3') else '-'\n",
    "            subtitle = story.find('h4').text if story.find('h4') else '-'\n",
    "            \n",
    "            sleep(np.random.randint(1, 15))\n",
    "\n",
    "            #save claps, if present\n",
    "            if story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                           ' js-multirecommendCountButton u-disablePointerEvents'):\n",
    "\n",
    "                claps = story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                                    ' js-multirecommendCountButton u-disablePointerEvents').text\n",
    "            else:\n",
    "                claps = 0\n",
    "            \n",
    "            #save responses, if present\n",
    "            if story.find('a', class_='button button--chromeless u-baseColor--buttonNormal'):\n",
    "                responses = story.find('a', class_='button button--chromeless u-baseColor--buttonNormal').text\n",
    "                responses = responses.split()[0]\n",
    "            else:\n",
    "                responses = '0 responses'\n",
    "            \n",
    "            #save the post's URL\n",
    "            story_url = story.find('a', class_='button button--smaller button--chromeless u-baseColor--buttonNormal')[\n",
    "                'href']\n",
    "            \n",
    "            #scrape the content for each post and save as a BeautifulSoup object\n",
    "\n",
    "            story_page = requests.get(story_url)\n",
    "            story_soup = BeautifulSoup(story_page.text, 'html.parser')\n",
    "\n",
    "            #grab all section and paragraph info\n",
    "            sections = story_soup.find_all('section')\n",
    "            story_paragraphs = []\n",
    "            section_titles = []\n",
    "            \n",
    "            for section in sections:\n",
    "                paragraphs = section.find_all('p')\n",
    "                for paragraph in paragraphs:\n",
    "                    story_paragraphs.append(paragraph.text)\n",
    "\n",
    "                subs = section.find_all('h1')\n",
    "                for sub in subs:\n",
    "                    section_titles.append(sub.text)\n",
    "\n",
    "            number_sections = len(section_titles)\n",
    "            number_paragraphs = len(story_paragraphs)\n",
    "            \n",
    "            #append to the list\n",
    "            each_story.append(date)\n",
    "            each_story.append(title)\n",
    "            each_story.append(subtitle)\n",
    "            each_story.append(claps)\n",
    "            each_story.append(responses)\n",
    "            each_story.append(author_url)\n",
    "            each_story.append(story_url)\n",
    "            each_story.append(reading_time)\n",
    "            each_story.append(number_sections)\n",
    "            each_story.append(section_titles)\n",
    "            each_story.append(number_paragraphs)\n",
    "            each_story.append(story_paragraphs)\n",
    "            stories_data.append(each_story)\n",
    "    \n",
    "    #set up column headers for df\n",
    "    columns = ['date', 'title', 'subtitle', 'claps', 'responses', \n",
    "           'author_url', 'story_url', 'reading_time (mins)', \n",
    "           'number_sections', 'section_titles', 'number_paragraphs', 'paragraphs']\n",
    "    #save as a dataframe\n",
    "    df = pd.DataFrame(stories_data, columns=columns)\n",
    "    df.to_csv(f'../data/2021_{month}.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some 2020 stories\n",
    "stories_data = []\n",
    "\n",
    "for month in range(10, 13):\n",
    "    if month in [1, 3, 5, 7, 8, 10, 12]:\n",
    "        n_days = 31\n",
    "    elif month in [4, 6, 9, 11]:\n",
    "        n_days = 30\n",
    "    else:\n",
    "        n_days = 28\n",
    "\n",
    "    for day in range(1, n_days + 1):\n",
    "\n",
    "        month, day = str(month), str(day)\n",
    "\n",
    "        if len(month) == 1:\n",
    "            month = f'0{month}'\n",
    "        if len(day) == 1:\n",
    "            day = f'0{day}'\n",
    "\n",
    "        date = f'{month}/{day}/2020'\n",
    "        url = f'https://towardsdatascience.com/archive/2020/{month}/{day}'\n",
    "\n",
    "        page  = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        stories = soup.find_all('div', class_='streamItem streamItem--postPreview js-streamItem')\n",
    "        \n",
    "        sleep(np.random.randint(1, 15))\n",
    "        \n",
    "        for story in stories:\n",
    "            each_story = []\n",
    "\n",
    "            author_box = story.find('div', class_='postMetaInline u-floatLeft u-sm-maxWidthFullWidth')\n",
    "            author_url = author_box.find('a')['href']\n",
    "\n",
    "            try:\n",
    "                reading_time = author_box.find('span', class_='readingTime')['title']\n",
    "                reading_time = reading_time.split()[0]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            title = story.find('h3').text if story.find('h3') else '-'\n",
    "            subtitle = story.find('h4').text if story.find('h4') else '-'\n",
    "            \n",
    "            sleep(np.random.randint(1, 15))\n",
    "\n",
    "            if story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                           ' js-multirecommendCountButton u-disablePointerEvents'):\n",
    "\n",
    "                claps = story.find('button', class_='button button--chromeless u-baseColor--buttonNormal'\n",
    "                                                    ' js-multirecommendCountButton u-disablePointerEvents').text\n",
    "            else:\n",
    "                claps = 0\n",
    "\n",
    "            if story.find('a', class_='button button--chromeless u-baseColor--buttonNormal'):\n",
    "                responses = story.find('a', class_='button button--chromeless u-baseColor--buttonNormal').text\n",
    "                responses = responses.split()[0]\n",
    "            else:\n",
    "                responses = '0 responses'\n",
    "\n",
    "            story_url = story.find('a', class_='button button--smaller button--chromeless u-baseColor--buttonNormal')[\n",
    "                'href']\n",
    "            \n",
    "            story_page = requests.get(story_url)\n",
    "            story_soup = BeautifulSoup(story_page.text, 'html.parser')\n",
    "\n",
    "            sections = story_soup.find_all('section')\n",
    "            story_paragraphs = []\n",
    "            section_titles = []\n",
    "            \n",
    "            for section in sections:\n",
    "                paragraphs = section.find_all('p')\n",
    "                for paragraph in paragraphs:\n",
    "                    story_paragraphs.append(paragraph.text)\n",
    "\n",
    "                subs = section.find_all('h1')\n",
    "                for sub in subs:\n",
    "                    section_titles.append(sub.text)\n",
    "\n",
    "            number_sections = len(section_titles)\n",
    "            number_paragraphs = len(story_paragraphs)\n",
    "            \n",
    "            each_story.append(date)\n",
    "            each_story.append(title)\n",
    "            each_story.append(subtitle)\n",
    "            each_story.append(claps)\n",
    "            each_story.append(responses)\n",
    "            each_story.append(author_url)\n",
    "            each_story.append(story_url)\n",
    "            each_story.append(reading_time)\n",
    "            each_story.append(number_sections)\n",
    "            each_story.append(section_titles)\n",
    "            each_story.append(number_paragraphs)\n",
    "            each_story.append(story_paragraphs)\n",
    "            stories_data.append(each_story)\n",
    "            \n",
    "    columns = ['date', 'title', 'subtitle', 'claps', 'responses', \n",
    "           'author_url', 'story_url', 'reading_time (mins)', \n",
    "           'number_sections', 'section_titles', 'number_paragraphs', 'paragraphs']\n",
    "\n",
    "    df = pd.DataFrame(stories_data, columns=columns)\n",
    "    df.to_csv(f'../data/2020_{month}.csv', sep='\\t', index=False)\n",
    "    df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
