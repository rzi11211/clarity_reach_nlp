{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a35499cd-8ce6-41f4-9f25-1a75bfcea826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "#modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d27416d-2f7d-4d55-a806-3e3db69ca72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =  '../data/vectorized_jargon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24897dab-53e6-467f-9c9d-474235bcb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77de176b-387e-4fae-9360-ed17214a26ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claps</th>\n",
       "      <th>text</th>\n",
       "      <th>A/B testing</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>action</th>\n",
       "      <th>activation function</th>\n",
       "      <th>active learning</th>\n",
       "      <th>AdaGrad</th>\n",
       "      <th>agent</th>\n",
       "      <th>agglomerative clustering</th>\n",
       "      <th>...</th>\n",
       "      <th>user matrix</th>\n",
       "      <th>validation</th>\n",
       "      <th>validation set</th>\n",
       "      <th>vanishing gradient problem</th>\n",
       "      <th>Wasserstein loss</th>\n",
       "      <th>weight</th>\n",
       "      <th>Weighted Alternating Least Squares (WALS)</th>\n",
       "      <th>wide model</th>\n",
       "      <th>width</th>\n",
       "      <th>total_jargon_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>398</td>\n",
       "      <td>python builtin database — here’s use utilize b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>build deploy dashboard python google sheets vu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360</td>\n",
       "      <td>magic python context managers getting started ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>generating image segmentation masks — easy way...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301</td>\n",
       "      <td>top 5 machine learning certifications opinion ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   claps                                               text  A/B testing  \\\n",
       "0    398  python builtin database — here’s use utilize b...            0   \n",
       "1    203  build deploy dashboard python google sheets vu...            0   \n",
       "2    360  magic python context managers getting started ...            0   \n",
       "3     88  generating image segmentation masks — easy way...            0   \n",
       "4    301  top 5 machine learning certifications opinion ...            0   \n",
       "\n",
       "   accuracy  action  activation function  active learning  AdaGrad  agent  \\\n",
       "0         0       2                    0                0        0      0   \n",
       "1         0       5                    0                0        0      0   \n",
       "2         0       2                    0                0        0      0   \n",
       "3         0       0                    0                0        0      0   \n",
       "4         0       0                    0                0        0      0   \n",
       "\n",
       "   agglomerative clustering  ...  user matrix  validation  validation set  \\\n",
       "0                         0  ...            0           0               0   \n",
       "1                         0  ...            0           0               0   \n",
       "2                         0  ...            0           0               0   \n",
       "3                         0  ...            0           0               0   \n",
       "4                         0  ...            0           0               0   \n",
       "\n",
       "   vanishing gradient problem  Wasserstein loss  weight  \\\n",
       "0                           0                 0       2   \n",
       "1                           0                 0       0   \n",
       "2                           0                 0       0   \n",
       "3                           0                 0       0   \n",
       "4                           0                 0       0   \n",
       "\n",
       "   Weighted Alternating Least Squares (WALS)  wide model  width  \\\n",
       "0                                          0           0      0   \n",
       "1                                          0           0      0   \n",
       "2                                          0           0      0   \n",
       "3                                          0           0      1   \n",
       "4                                          0           0      0   \n",
       "\n",
       "   total_jargon_count  \n",
       "0                  11  \n",
       "1                  12  \n",
       "2                  45  \n",
       "3                  10  \n",
       "4                  46  \n",
       "\n",
       "[5 rows x 415 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69b5d49-1028-4d7e-9c71-0345d5f14ae0",
   "metadata": {},
   "source": [
    "### Modeling Attempt I: Claps as Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0d1ce-3b8e-48ad-ac02-ed98f0ad7047",
   "metadata": {},
   "source": [
    "#### Remove Columns Not Needed For Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7c85033-f627-4430-8c4a-d1002c27e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3abd344-70d6-43cc-a9f7-9e323e071f9e",
   "metadata": {},
   "source": [
    "#### Transform the Target into a Binary Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a860d8e9-1990-450a-9596-cc30ff31f1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.012762167029"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#establish a threshold for 'high engagement' of mean plus one standard deviation\n",
    "thresh = df['claps'].mean() + df['claps'].std()\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ce9753d-d0ba-46e3-a321-e8ff6f763f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1168"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many posts meet that criterion\n",
    "(df['claps'] >= thresh).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42bafcbe-1eb0-4eae-97d7-fd764aca9c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "claps = [1 if clap >= thresh else 0 for clap in df['claps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a303f79c-8470-4f28-826f-42739c96c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['claps'] = claps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7076bfbb-c6b1-42d6-9102-43c237fe4983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.872252\n",
       "1    0.127748\n",
       "Name: claps, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['claps'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c4a7e-4466-4e6a-9892-f3ec08419155",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dacc387-1c20-49d3-8449-509ea420fe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm no nulls \n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85ae1c4b-607d-42fe-90d6-0a0e9f11295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='claps')\n",
    "y = df['claps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ca8f4c9-2233-4c1e-8e47-5bcf9476b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,\n",
    "                                                 y,\n",
    "                                                 test_size=.2,\n",
    "                                                  stratify=y,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2addc33d-0830-4c71-8042-1d23084b81c1",
   "metadata": {},
   "source": [
    "#### Run Through Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "829b8b1a-a600-4a79-8cd8-c55ec5e5e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    SVC(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for model_obj in model_list:\n",
    "    #instantiate each model \n",
    "    model = model_obj\n",
    "   \n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train) \n",
    "  \n",
    "    #create a dictionary with scores and evaluation metrics for each model\n",
    "    results_dict = {}    \n",
    "    results_dict['model_name'] = str(model_obj)\n",
    "    results_dict['train_score'] = model.score(X_train, y_train)\n",
    "    results_dict['test_score'] = model.score(X_test, y_test)\n",
    "    results_dict['cv_score'] = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "    results_dict['precision_score'] = precision_score(y_test, model.predict(X_test))\n",
    "    results_dict['train_f1_score'] = f1_score(y_train, model.predict(X_train))  \n",
    "    results_dict['test_f1_score'] = f1_score(y_test, model.predict(X_test))  \n",
    "    \n",
    "    #add the dictionary to the list\n",
    "    results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe32dc2b-8fb4-4be3-85a0-54ce00f7d521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.872983</td>\n",
       "      <td>0.869328</td>\n",
       "      <td>0.869428</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.033299</td>\n",
       "      <td>0.008299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.998769</td>\n",
       "      <td>0.791689</td>\n",
       "      <td>0.789993</td>\n",
       "      <td>0.164384</td>\n",
       "      <td>0.995159</td>\n",
       "      <td>0.158940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>0.974706</td>\n",
       "      <td>0.870421</td>\n",
       "      <td>0.864642</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.890338</td>\n",
       "      <td>0.055777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.998633</td>\n",
       "      <td>0.874248</td>\n",
       "      <td>0.872573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994618</td>\n",
       "      <td>0.033613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.874214</td>\n",
       "      <td>0.870421</td>\n",
       "      <td>0.868609</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.053498</td>\n",
       "      <td>0.016598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.872710</td>\n",
       "      <td>0.872061</td>\n",
       "      <td>0.872300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006403</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB()</td>\n",
       "      <td>0.854389</td>\n",
       "      <td>0.839256</td>\n",
       "      <td>0.848784</td>\n",
       "      <td>0.134146</td>\n",
       "      <td>0.136253</td>\n",
       "      <td>0.069620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  train_score  test_score  cv_score  \\\n",
       "0      LogisticRegression()     0.872983    0.869328  0.869428   \n",
       "1  DecisionTreeClassifier()     0.998769    0.791689  0.789993   \n",
       "2       BaggingClassifier()     0.974706    0.870421  0.864642   \n",
       "3  RandomForestClassifier()     0.998633    0.874248  0.872573   \n",
       "4      AdaBoostClassifier()     0.874214    0.870421  0.868609   \n",
       "5                     SVC()     0.872710    0.872061  0.872300   \n",
       "6             BernoulliNB()     0.854389    0.839256  0.848784   \n",
       "\n",
       "   precision_score  train_f1_score  test_f1_score  \n",
       "0         0.142857        0.033299       0.008299  \n",
       "1         0.164384        0.995159       0.158940  \n",
       "2         0.411765        0.890338       0.055777  \n",
       "3         1.000000        0.994618       0.033613  \n",
       "4         0.285714        0.053498       0.016598  \n",
       "5         0.000000        0.006403       0.000000  \n",
       "6         0.134146        0.136253       0.069620  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f85f4c-1dd0-4f87-8178-155c7d53a609",
   "metadata": {},
   "source": [
    "None of these models are better than baseline at predicting whether a post will get an above-average number of claps or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd6921c-9931-4e84-9ad6-9a54701d65e7",
   "metadata": {},
   "source": [
    "### Modeling Attempt II: Log of Claps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "917b7703-5172-48ee-9d02-3a42f57a52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the file back in\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521fb979-4912-46c1-8ab3-db05f6891679",
   "metadata": {},
   "source": [
    "#### Transform Claps into Log Claps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59387a8e-c01b-4b33-9eec-e7b413551c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_claps'] = np.log(df['claps'])\n",
    "df = df[np.isfinite(df['log_claps'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ebcc0a-c148-4a34-b2af-c6cf8b02b591",
   "metadata": {},
   "source": [
    "#### Remove Columns Not Needed For Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3860cef5-fd5c-4c78-a942-af88e04de4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['claps', 'text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f021bbb-5818-4c48-a8a8-6eb4a7df99dd",
   "metadata": {},
   "source": [
    "#### Transform the Target into a Binary Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4ef9b8a-6243-42b8-8799-b1715a227447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.105927127864417"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#establish a threshold for 'high engagement' of mean plus one standard deviation\n",
    "thresh = df['log_claps'].mean() + df['log_claps'].std()\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3e79bac-a059-4085-bc36-d59aebc59569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1433"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many posts meet that criterion\n",
    "(df['log_claps'] >= thresh).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fec2442-36f1-4c34-b51e-519d3e8f843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_claps = [1 if clap >= thresh else 0 for clap in df['log_claps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "888234b9-70f5-4796-8694-075e8c5fb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_claps'] = log_claps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "474cd1cc-7a2e-467d-8172-204bb44ebed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.84225\n",
       "1    0.15775\n",
       "Name: log_claps, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['log_claps'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd760d-87ef-40e0-9ba7-6112a98ae4f6",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bb1143c-9b64-418b-9c27-e556442135ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm no nulls \n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d3afc94-052b-4c12-be61-aed7223b941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='log_claps')\n",
    "y = df['log_claps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eddc4b9a-9ed1-40de-859a-c182358402fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,\n",
    "                                                 y,\n",
    "                                                 test_size=.2,\n",
    "                                                  stratify=y,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b8073-5b7b-4d4e-8324-fdb54fd23003",
   "metadata": {},
   "source": [
    "#### Run Through Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5875370b-4751-41ce-baf1-0be770e660e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    SVC(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for model_obj in model_list:\n",
    "    #instantiate each model \n",
    "    model = model_obj\n",
    "   \n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train) \n",
    "  \n",
    "    #create a dictionary with scores and evaluation metrics for each model\n",
    "    results_dict = {}    \n",
    "    results_dict['model_name'] = str(model_obj)\n",
    "    results_dict['train_score'] = model.score(X_train, y_train)\n",
    "    results_dict['test_score'] = model.score(X_test, y_test)\n",
    "    results_dict['cv_score'] = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "    results_dict['precision_score'] = precision_score(y_test, model.predict(X_test))\n",
    "    results_dict['train_f1_score'] = f1_score(y_train, model.predict(X_train))  \n",
    "    results_dict['test_f1_score'] = f1_score(y_test, model.predict(X_test))  \n",
    "    \n",
    "    #add the dictionary to the list\n",
    "    results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "33025ec4-1e2b-4907-bb28-043dbea1bb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.842851</td>\n",
       "      <td>0.842598</td>\n",
       "      <td>0.838448</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.041946</td>\n",
       "      <td>0.020548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.998624</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.743911</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.995618</td>\n",
       "      <td>0.170778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>0.973854</td>\n",
       "      <td>0.832691</td>\n",
       "      <td>0.834594</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.909782</td>\n",
       "      <td>0.044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.998624</td>\n",
       "      <td>0.841497</td>\n",
       "      <td>0.842026</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.995626</td>\n",
       "      <td>0.006897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.844090</td>\n",
       "      <td>0.840947</td>\n",
       "      <td>0.837897</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.051883</td>\n",
       "      <td>0.033445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.842576</td>\n",
       "      <td>0.842047</td>\n",
       "      <td>0.842301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB()</td>\n",
       "      <td>0.832943</td>\n",
       "      <td>0.819483</td>\n",
       "      <td>0.821797</td>\n",
       "      <td>0.211268</td>\n",
       "      <td>0.108664</td>\n",
       "      <td>0.083799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  train_score  test_score  cv_score  \\\n",
       "0      LogisticRegression()     0.842851    0.842598  0.838448   \n",
       "1  DecisionTreeClassifier()     0.998624    0.759494  0.743911   \n",
       "2       BaggingClassifier()     0.973854    0.832691  0.834594   \n",
       "3  RandomForestClassifier()     0.998624    0.841497  0.842026   \n",
       "4      AdaBoostClassifier()     0.844090    0.840947  0.837897   \n",
       "5                     SVC()     0.842576    0.842047  0.842301   \n",
       "6             BernoulliNB()     0.832943    0.819483  0.821797   \n",
       "\n",
       "   precision_score  train_f1_score  test_f1_score  \n",
       "0         0.600000        0.041946       0.020548  \n",
       "1         0.187500        0.995618       0.170778  \n",
       "2         0.225806        0.909782       0.044025  \n",
       "3         0.333333        0.995626       0.006897  \n",
       "4         0.416667        0.051883       0.033445  \n",
       "5         0.000000        0.003484       0.000000  \n",
       "6         0.211268        0.108664       0.083799  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d54ba-2499-4381-9c14-f6bda2b3bcb9",
   "metadata": {},
   "source": [
    "None of these models are better than baseline at predicting whether a post will get an above-average number of claps or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8429eeaa-5010-4643-ac2c-e2a5bbedcee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
