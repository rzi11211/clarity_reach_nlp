{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5040863-63b1-442e-af34-afe012485456",
   "metadata": {},
   "source": [
    "# Modeling: Bag of Words Classification Model\n",
    "### *LogClaps as Target*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35499cd-8ce6-41f4-9f25-1a75bfcea826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#nlp\n",
    "import nltk\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f23a4f-4531-43b8-b420-1789d14d62dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d27416d-2f7d-4d55-a806-3e3db69ca72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =  'data/nlp_nltk_stemmed_preproc_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24897dab-53e6-467f-9c9d-474235bcb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename).drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77de176b-387e-4fae-9360-ed17214a26ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_claps</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.907755</td>\n",
       "      <td>['7', 'recommend', 'skill', 'learn', '2021', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.192362</td>\n",
       "      <td>['ultim', 'guid', 'ace', 'code', 'interview', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.934474</td>\n",
       "      <td>['shakespear', 'versu', 'eminem—', 'who’', 'be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.068904</td>\n",
       "      <td>['custom', 'segment', 'onlin', 'retail', 'deta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.890349</td>\n",
       "      <td>['implement', 'visualttransform', 'pytorch', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log_claps                                               text\n",
       "0   6.907755  ['7', 'recommend', 'skill', 'learn', '2021', '...\n",
       "1   6.192362  ['ultim', 'guid', 'ace', 'code', 'interview', ...\n",
       "2   4.934474  ['shakespear', 'versu', 'eminem—', 'who’', 'be...\n",
       "3   5.068904  ['custom', 'segment', 'onlin', 'retail', 'deta...\n",
       "4   4.890349  ['implement', 'visualttransform', 'pytorch', '..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f021bbb-5818-4c48-a8a8-6eb4a7df99dd",
   "metadata": {},
   "source": [
    "#### Transform the Target into a Binary Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee677d3-6fc1-4238-bc68-8c93fc07fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num infinite: 62\n",
      "Num null: 0\n",
      "Shape is (9804, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num infinite: {len(df['log_claps']) - np.isfinite(df['log_claps']).sum()}\")\n",
    "print(f\"Num null: {df['log_claps'].isnull().sum()}\")\n",
    "print(f'Shape is {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7704eae-c983-45a7-be9f-b34b830ba9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove inf and nan values\n",
    "\n",
    "df = df[np.isfinite(df['log_claps'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ef9b8a-6243-42b8-8799-b1715a227447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.258180875814285"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#establish a threshold for 'high engagement' of mean plus one standard deviation\n",
    "thresh = df['log_claps'].mean() + df['log_claps'].std()\n",
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3e79bac-a059-4085-bc36-d59aebc59569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1492"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many posts meet that criterion\n",
    "(df['log_claps'] >= thresh).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fec2442-36f1-4c34-b51e-519d3e8f843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_claps = [1 if clap >= thresh else 0 for clap in df['log_claps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d09449-5f1a-41e6-8bac-4edb2baa424c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9742"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(log_claps).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888234b9-70f5-4796-8694-075e8c5fb0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_claps'] = log_claps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "474cd1cc-7a2e-467d-8172-204bb44ebed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.846849\n",
       "1    0.153151\n",
       "Name: log_claps, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['log_claps'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd760d-87ef-40e0-9ba7-6112a98ae4f6",
   "metadata": {},
   "source": [
    "#### Classification Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb1143c-9b64-418b-9c27-e556442135ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_claps    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d3afc94-052b-4c12-be61-aed7223b941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['log_claps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eddc4b9a-9ed1-40de-859a-c182358402fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,\n",
    "                                                 y,\n",
    "                                                 test_size=.2,\n",
    "                                                  stratify=y,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b8073-5b7b-4d4e-8324-fdb54fd23003",
   "metadata": {},
   "source": [
    "#### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccbfdaaa-aaec-4338-8ce3-3fa0c818eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(min_df=5, max_df=.98, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1ea39f5-74d8-4b4c-8e7e-46f1334c5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cvec = cvec.fit_transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9dcd63-20ec-4394-a654-f08a8b986144",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    SVC(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for model_obj in model_list:\n",
    "    #instantiate each model \n",
    "    model = model_obj\n",
    "   \n",
    "    #fit the model\n",
    "    model.fit(X_train_cvec, y_train) \n",
    "  \n",
    "    #create a dictionary with scores and evaluation metrics for each model\n",
    "    results_dict = {}    \n",
    "    results_dict['model_name'] = str(model_obj)\n",
    "    results_dict['train_score'] = model.score(X_train_cvec, y_train)\n",
    "    results_dict['test_score'] = model.score(X_test_cvec, y_test)\n",
    "    results_dict['cv_score'] = cross_val_score(model, X_train_cvec, y_train, cv = 5).mean()\n",
    "    results_dict['precision_score'] = precision_score(y_test, model.predict(X_test_cvec))\n",
    "    results_dict['train_f1_score'] = f1_score(y_train, model.predict(X_train_cvec))  \n",
    "    results_dict['test_f1_score'] = f1_score(y_test, model.predict(X_test_cvec))  \n",
    "    \n",
    "    #add the dictionary to the list\n",
    "    results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33025ec4-1e2b-4907-bb28-043dbea1bb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830682</td>\n",
       "      <td>0.827408</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786044</td>\n",
       "      <td>0.783652</td>\n",
       "      <td>0.286738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>0.978314</td>\n",
       "      <td>0.855823</td>\n",
       "      <td>0.853073</td>\n",
       "      <td>0.616438</td>\n",
       "      <td>0.923840</td>\n",
       "      <td>0.242588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856850</td>\n",
       "      <td>0.854869</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.146789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.864622</td>\n",
       "      <td>0.841970</td>\n",
       "      <td>0.840882</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.336060</td>\n",
       "      <td>0.259615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.885153</td>\n",
       "      <td>0.851206</td>\n",
       "      <td>0.847556</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.400536</td>\n",
       "      <td>0.058442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB()</td>\n",
       "      <td>0.896574</td>\n",
       "      <td>0.812211</td>\n",
       "      <td>0.806620</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.282353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  train_score  test_score  cv_score  \\\n",
       "0      LogisticRegression()     1.000000    0.830682  0.827408   \n",
       "1  DecisionTreeClassifier()     1.000000    0.786044  0.783652   \n",
       "2       BaggingClassifier()     0.978314    0.855823  0.853073   \n",
       "3  RandomForestClassifier()     1.000000    0.856850  0.854869   \n",
       "4      AdaBoostClassifier()     0.864622    0.841970  0.840882   \n",
       "5                     SVC()     0.885153    0.851206  0.847556   \n",
       "6             BernoulliNB()     0.896574    0.812211  0.806620   \n",
       "\n",
       "   precision_score  train_f1_score  test_f1_score  \n",
       "0         0.423077        1.000000       0.347826  \n",
       "1         0.286738        1.000000       0.277296  \n",
       "2         0.616438        0.923840       0.242588  \n",
       "3         0.827586        1.000000       0.146789  \n",
       "4         0.457627        0.336060       0.259615  \n",
       "5         0.900000        0.400536       0.058442  \n",
       "6         0.339623        0.651685       0.282353  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_results = pd.DataFrame(results_list)\n",
    "cvec_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e14ff1-dae3-49e1-8b88-6d7328a74940",
   "metadata": {},
   "source": [
    "With a baseline accuracy of 84.6%, this model is not predictive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343e1d6-f32e-4c31-b651-d21f8570534a",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a604d7-33f1-464f-829c-f50d4dd76423",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(min_df=5, max_df=.98, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0607c80e-846f-4cc4-8e12-6b3234f31295",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tvec = tvec.fit_transform(X_train)\n",
    "X_test_tvec = tvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f070026-c6e4-4807-8bf5-b71bdbde7bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    LogisticRegression(),\n",
    "    DecisionTreeClassifier(),\n",
    "    BaggingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    SVC(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for model_obj in model_list:\n",
    "    #instantiate each model \n",
    "    model = model_obj\n",
    "   \n",
    "    #fit the model\n",
    "    model.fit(X_train_tvec, y_train) \n",
    "  \n",
    "    #create a dictionary with scores and evaluation metrics for each model\n",
    "    results_dict = {}    \n",
    "    results_dict['model_name'] = str(model_obj)\n",
    "    results_dict['train_score'] = model.score(X_train_tvec, y_train)\n",
    "    results_dict['test_score'] = model.score(X_test_tvec, y_test)\n",
    "    results_dict['cv_score'] = cross_val_score(model, X_train_tvec, y_train, cv = 5).mean()\n",
    "    results_dict['precision_score'] = precision_score(y_test, model.predict(X_test_tvec))\n",
    "    results_dict['train_f1_score'] = f1_score(y_train, model.predict(X_train_tvec))  \n",
    "    results_dict['test_f1_score'] = f1_score(y_test, model.predict(X_test_tvec))  \n",
    "    \n",
    "    #add the dictionary to the list\n",
    "    results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8328f02-2173-471d-adb0-4d72ef78c748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.860516</td>\n",
       "      <td>0.849153</td>\n",
       "      <td>0.849609</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.169595</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.779887</td>\n",
       "      <td>0.785834</td>\n",
       "      <td>0.276451</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.274112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>0.977929</td>\n",
       "      <td>0.863007</td>\n",
       "      <td>0.854355</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.922383</td>\n",
       "      <td>0.247887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857363</td>\n",
       "      <td>0.855254</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.859489</td>\n",
       "      <td>0.841970</td>\n",
       "      <td>0.837931</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.304762</td>\n",
       "      <td>0.237624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.926986</td>\n",
       "      <td>0.852745</td>\n",
       "      <td>0.851020</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.687534</td>\n",
       "      <td>0.094637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB()</td>\n",
       "      <td>0.896574</td>\n",
       "      <td>0.812211</td>\n",
       "      <td>0.806620</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.282353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model_name  train_score  test_score  cv_score  \\\n",
       "0      LogisticRegression()     0.860516    0.849153  0.849609   \n",
       "1  DecisionTreeClassifier()     1.000000    0.779887  0.785834   \n",
       "2       BaggingClassifier()     0.977929    0.863007  0.854355   \n",
       "3  RandomForestClassifier()     1.000000    0.857363  0.855254   \n",
       "4      AdaBoostClassifier()     0.859489    0.841970  0.837931   \n",
       "5                     SVC()     0.926986    0.852745  0.851020   \n",
       "6             BernoulliNB()     0.896574    0.812211  0.806620   \n",
       "\n",
       "   precision_score  train_f1_score  test_f1_score  \n",
       "0         0.583333        0.169595       0.086957  \n",
       "1         0.276451        1.000000       0.274112  \n",
       "2         0.771930        0.922383       0.247887  \n",
       "3         0.833333        1.000000       0.152439  \n",
       "4         0.452830        0.304762       0.237624  \n",
       "5         0.789474        0.687534       0.094637  \n",
       "6         0.339623        0.651685       0.282353  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec_results = pd.DataFrame(results_list)\n",
    "tvec_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5f3aea-9701-462c-a9cf-8d4e517b35a9",
   "metadata": {},
   "source": [
    "With a baseline accuracy of 84.6%, this model is not predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7ca43-29f2-4e43-897e-19dab8f44854",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
