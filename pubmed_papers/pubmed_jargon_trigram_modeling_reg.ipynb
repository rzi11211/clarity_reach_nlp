{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a35499cd-8ce6-41f4-9f25-1a75bfcea826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, chi2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d27416d-2f7d-4d55-a806-3e3db69ca72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =  '../data/pubmed_vectorized_jargon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54f0a901-f2a2-45e8-b9d7-85283837767f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename).set_index('pmid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9e6bee5-c231-4225-a460-2fe899a4f3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations</th>\n",
       "      <th>fulltext</th>\n",
       "      <th>A/B testing</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>action</th>\n",
       "      <th>activation function</th>\n",
       "      <th>active learning</th>\n",
       "      <th>AdaGrad</th>\n",
       "      <th>agent</th>\n",
       "      <th>agglomerative clustering</th>\n",
       "      <th>...</th>\n",
       "      <th>user matrix</th>\n",
       "      <th>validation</th>\n",
       "      <th>validation set</th>\n",
       "      <th>vanishing gradient problem</th>\n",
       "      <th>Wasserstein loss</th>\n",
       "      <th>weight</th>\n",
       "      <th>Weighted Alternating Least Squares (WALS)</th>\n",
       "      <th>wide model</th>\n",
       "      <th>width</th>\n",
       "      <th>total_jargon_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pmid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22627698</th>\n",
       "      <td>35</td>\n",
       "      <td>extracting biological information computationa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22952238</th>\n",
       "      <td>4</td>\n",
       "      <td>uncovering transcription factor modules using ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22944687</th>\n",
       "      <td>19</td>\n",
       "      <td>understanding substrate specificity convention...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22075226</th>\n",
       "      <td>12</td>\n",
       "      <td>membrane protein structural bioinformatics des...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23012584</th>\n",
       "      <td>10</td>\n",
       "      <td>future medical diagnostics: large digitized da...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 415 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          citations                                           fulltext  \\\n",
       "pmid                                                                     \n",
       "22627698         35  extracting biological information computationa...   \n",
       "22952238          4  uncovering transcription factor modules using ...   \n",
       "22944687         19  understanding substrate specificity convention...   \n",
       "22075226         12  membrane protein structural bioinformatics des...   \n",
       "23012584         10  future medical diagnostics: large digitized da...   \n",
       "\n",
       "          A/B testing  accuracy  action  activation function  active learning  \\\n",
       "pmid                                                                            \n",
       "22627698            0         0       1                    0                0   \n",
       "22952238            0         0       1                    0                0   \n",
       "22944687            0         1       1                    0                0   \n",
       "22075226            0         0       0                    0                0   \n",
       "23012584            0         0       0                    0                0   \n",
       "\n",
       "          AdaGrad  agent  agglomerative clustering  ...  user matrix  \\\n",
       "pmid                                                ...                \n",
       "22627698        0      0                         0  ...            0   \n",
       "22952238        0      0                         0  ...            0   \n",
       "22944687        0      0                         0  ...            0   \n",
       "22075226        0      0                         0  ...            0   \n",
       "23012584        0      0                         0  ...            0   \n",
       "\n",
       "          validation  validation set  vanishing gradient problem  \\\n",
       "pmid                                                               \n",
       "22627698           1               0                           0   \n",
       "22952238           0               0                           0   \n",
       "22944687           0               0                           0   \n",
       "22075226           0               0                           0   \n",
       "23012584           0               0                           0   \n",
       "\n",
       "          Wasserstein loss  weight  Weighted Alternating Least Squares (WALS)  \\\n",
       "pmid                                                                            \n",
       "22627698                 0       0                                          0   \n",
       "22952238                 0       0                                          0   \n",
       "22944687                 0       0                                          0   \n",
       "22075226                 0       0                                          0   \n",
       "23012584                 0       0                                          0   \n",
       "\n",
       "          wide model  width  total_jargon_count  \n",
       "pmid                                             \n",
       "22627698           0      0                  11  \n",
       "22952238           0      0                   3  \n",
       "22944687           0      0                   7  \n",
       "22075226           0      0                   2  \n",
       "23012584           0      0                   1  \n",
       "\n",
       "[5 rows x 415 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a2eaa6fd-54c4-4bad-9d1a-e56adcb84855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "citations                                    0\n",
       "fulltext                                     0\n",
       "A/B testing                                  0\n",
       "accuracy                                     0\n",
       "action                                       0\n",
       "                                            ..\n",
       "weight                                       0\n",
       "Weighted Alternating Least Squares (WALS)    0\n",
       "wide model                                   0\n",
       "width                                        0\n",
       "total_jargon_count                           0\n",
       "Length: 415, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d3afc94-052b-4c12-be61-aed7223b941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['citations', 'fulltext'])\n",
    "y = df['citations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3508560e-dc8c-4406-ae83-c4c38a9efefa",
   "metadata": {},
   "source": [
    "#### Look at Phrase Frequency in the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdd4d04b-f5e7-4922-b173-0c35494453b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot top occurring words/phrases\n",
    "\n",
    "#remove the total count for the plot\n",
    "jargon_X = X.drop(columns='total_jargon_count')\n",
    "plt.figure(figsize = (10,10))\n",
    "jargon_X.sum().sort_values(ascending = False).head(20).plot(kind='barh');\n",
    "figurefont = {'fontname' : 'Futura'}\n",
    "plt.xticks(**figurefont, fontsize = 14);\n",
    "plt.yticks(**figurefont, fontsize = 14);\n",
    "plt.savefig('../figures/pubmed_top_occurring_jargon.jpg',  bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e477c4-6eb1-43f9-95e7-7ea198a240df",
   "metadata": {},
   "source": [
    "### Modeling Attempt I: Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8839de-c3ae-498f-a4e2-923b17cdc43d",
   "metadata": {},
   "source": [
    "#### StatsModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95d5758f-9e0f-4a43-83bb-c96e8c165137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2809, 100)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = SelectKBest(chi2, k=100).fit_transform(X, y)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f3e54c3-3326-424f-bfae-2fdd0585b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm = sm.add_constant(X_new, prepend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7addf719-ea0a-42bb-8c95-0e1bcc579f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split \n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm=train_test_split(X_sm,\n",
    "                                                 y,\n",
    "                                                 test_size=.2,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0fe05bb3-3359-47af-a456-d099a0dae2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>citations</td>    <th>  R-squared:         </th> <td>   0.097</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.054</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.293</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 10 May 2021</td> <th>  Prob (F-statistic):</th> <td>2.40e-11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:19:49</td>     <th>  Log-Likelihood:    </th> <td> -9029.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2247</td>      <th>  AIC:               </th> <td>1.826e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2146</td>      <th>  BIC:               </th> <td>1.884e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   100</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    8.1756</td> <td>    0.598</td> <td>   13.681</td> <td> 0.000</td> <td>    7.004</td> <td>    9.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    2.3686</td> <td>    0.949</td> <td>    2.496</td> <td> 0.013</td> <td>    0.508</td> <td>    4.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    3.4544</td> <td>    0.777</td> <td>    4.444</td> <td> 0.000</td> <td>    1.930</td> <td>    4.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    9.4013</td> <td>   10.037</td> <td>    0.937</td> <td> 0.349</td> <td>  -10.282</td> <td>   29.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    7.4660</td> <td>    4.793</td> <td>    1.558</td> <td> 0.119</td> <td>   -1.934</td> <td>   16.866</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    3.4395</td> <td>    1.195</td> <td>    2.878</td> <td> 0.004</td> <td>    1.096</td> <td>    5.783</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.9298</td> <td>    0.793</td> <td>    3.697</td> <td> 0.000</td> <td>    1.376</td> <td>    4.484</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    4.9210</td> <td>    2.394</td> <td>    2.055</td> <td> 0.040</td> <td>    0.226</td> <td>    9.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    1.7643</td> <td>    3.633</td> <td>    0.486</td> <td> 0.627</td> <td>   -5.360</td> <td>    8.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.0102</td> <td>    7.341</td> <td>    0.001</td> <td> 0.999</td> <td>  -14.386</td> <td>   14.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    3.5731</td> <td>    1.627</td> <td>    2.196</td> <td> 0.028</td> <td>    0.382</td> <td>    6.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   57.7275</td> <td>   15.607</td> <td>    3.699</td> <td> 0.000</td> <td>   27.120</td> <td>   88.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    4.1696</td> <td>    0.794</td> <td>    5.253</td> <td> 0.000</td> <td>    2.613</td> <td>    5.726</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    3.3999</td> <td>    1.308</td> <td>    2.600</td> <td> 0.009</td> <td>    0.835</td> <td>    5.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    2.3185</td> <td>    2.287</td> <td>    1.014</td> <td> 0.311</td> <td>   -2.167</td> <td>    6.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    6.1956</td> <td>    2.935</td> <td>    2.111</td> <td> 0.035</td> <td>    0.441</td> <td>   11.950</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    3.2183</td> <td>    1.104</td> <td>    2.916</td> <td> 0.004</td> <td>    1.054</td> <td>    5.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    3.6321</td> <td>    1.013</td> <td>    3.584</td> <td> 0.000</td> <td>    1.645</td> <td>    5.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    4.6962</td> <td>    1.304</td> <td>    3.602</td> <td> 0.000</td> <td>    2.140</td> <td>    7.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>    5.4823</td> <td>    1.724</td> <td>    3.179</td> <td> 0.001</td> <td>    2.101</td> <td>    8.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>    7.5599</td> <td>    2.002</td> <td>    3.775</td> <td> 0.000</td> <td>    3.633</td> <td>   11.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>    2.8749</td> <td>    0.935</td> <td>    3.076</td> <td> 0.002</td> <td>    1.042</td> <td>    4.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   23.5968</td> <td>    8.166</td> <td>    2.890</td> <td> 0.004</td> <td>    7.584</td> <td>   39.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>   10.9336</td> <td>    2.662</td> <td>    4.108</td> <td> 0.000</td> <td>    5.714</td> <td>   16.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>   18.2985</td> <td>    6.561</td> <td>    2.789</td> <td> 0.005</td> <td>    5.432</td> <td>   31.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    3.0396</td> <td>    1.581</td> <td>    1.922</td> <td> 0.055</td> <td>   -0.061</td> <td>    6.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    3.5000</td> <td>    0.927</td> <td>    3.774</td> <td> 0.000</td> <td>    1.681</td> <td>    5.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>    4.4379</td> <td>    2.506</td> <td>    1.771</td> <td> 0.077</td> <td>   -0.477</td> <td>    9.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>  -12.6866</td> <td>   14.476</td> <td>   -0.876</td> <td> 0.381</td> <td>  -41.075</td> <td>   15.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    2.0654</td> <td>    1.111</td> <td>    1.859</td> <td> 0.063</td> <td>   -0.113</td> <td>    4.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    4.4300</td> <td>    0.842</td> <td>    5.263</td> <td> 0.000</td> <td>    2.779</td> <td>    6.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>    5.3436</td> <td>    1.999</td> <td>    2.673</td> <td> 0.008</td> <td>    1.424</td> <td>    9.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>   32.9450</td> <td>   10.082</td> <td>    3.268</td> <td> 0.001</td> <td>   13.174</td> <td>   52.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   10.8561</td> <td>    2.614</td> <td>    4.153</td> <td> 0.000</td> <td>    5.729</td> <td>   15.983</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    1.0647</td> <td>    3.892</td> <td>    0.274</td> <td> 0.784</td> <td>   -6.568</td> <td>    8.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    5.0806</td> <td>    3.580</td> <td>    1.419</td> <td> 0.156</td> <td>   -1.941</td> <td>   12.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>    3.5391</td> <td>    0.828</td> <td>    4.274</td> <td> 0.000</td> <td>    1.915</td> <td>    5.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>   10.1316</td> <td>    3.472</td> <td>    2.918</td> <td> 0.004</td> <td>    3.324</td> <td>   16.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    5.9213</td> <td>    3.352</td> <td>    1.767</td> <td> 0.077</td> <td>   -0.651</td> <td>   12.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>   37.7750</td> <td>   13.911</td> <td>    2.715</td> <td> 0.007</td> <td>   10.494</td> <td>   65.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.2054</td> <td>    5.481</td> <td>    0.037</td> <td> 0.970</td> <td>  -10.543</td> <td>   10.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    5.7812</td> <td>    1.632</td> <td>    3.541</td> <td> 0.000</td> <td>    2.580</td> <td>    8.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>    1.7500</td> <td>    2.498</td> <td>    0.701</td> <td> 0.484</td> <td>   -3.148</td> <td>    6.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>    3.8664</td> <td>    1.579</td> <td>    2.449</td> <td> 0.014</td> <td>    0.770</td> <td>    6.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>   10.7464</td> <td>    7.738</td> <td>    1.389</td> <td> 0.165</td> <td>   -4.428</td> <td>   25.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>    2.7084</td> <td>    1.532</td> <td>    1.768</td> <td> 0.077</td> <td>   -0.295</td> <td>    5.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    3.3695</td> <td>    1.258</td> <td>    2.679</td> <td> 0.007</td> <td>    0.903</td> <td>    5.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    2.8775</td> <td>    3.687</td> <td>    0.780</td> <td> 0.435</td> <td>   -4.353</td> <td>   10.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>    9.1220</td> <td>    3.648</td> <td>    2.501</td> <td> 0.012</td> <td>    1.969</td> <td>   16.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    4.7204</td> <td>    2.915</td> <td>    1.619</td> <td> 0.106</td> <td>   -0.997</td> <td>   10.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    2.4609</td> <td>    2.593</td> <td>    0.949</td> <td> 0.343</td> <td>   -2.624</td> <td>    7.546</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>    3.9170</td> <td>    0.748</td> <td>    5.234</td> <td> 0.000</td> <td>    2.449</td> <td>    5.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>    5.2454</td> <td>    3.137</td> <td>    1.672</td> <td> 0.095</td> <td>   -0.907</td> <td>   11.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>    2.3919</td> <td>    1.062</td> <td>    2.251</td> <td> 0.024</td> <td>    0.308</td> <td>    4.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>    3.3237</td> <td>    0.741</td> <td>    4.486</td> <td> 0.000</td> <td>    1.871</td> <td>    4.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    6.6156</td> <td>    5.501</td> <td>    1.203</td> <td> 0.229</td> <td>   -4.172</td> <td>   17.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>    4.0957</td> <td>    0.979</td> <td>    4.184</td> <td> 0.000</td> <td>    2.176</td> <td>    6.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>    2.8153</td> <td>    1.076</td> <td>    2.616</td> <td> 0.009</td> <td>    0.704</td> <td>    4.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>    3.4362</td> <td>    1.330</td> <td>    2.584</td> <td> 0.010</td> <td>    0.828</td> <td>    6.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>   14.9447</td> <td>    6.332</td> <td>    2.360</td> <td> 0.018</td> <td>    2.527</td> <td>   27.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>    3.6024</td> <td>    1.064</td> <td>    3.385</td> <td> 0.001</td> <td>    1.515</td> <td>    5.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>   -1.6888</td> <td>    6.970</td> <td>   -0.242</td> <td> 0.809</td> <td>  -15.357</td> <td>   11.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>   11.6170</td> <td>    3.340</td> <td>    3.478</td> <td> 0.001</td> <td>    5.067</td> <td>   18.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>    2.1874</td> <td>    1.163</td> <td>    1.881</td> <td> 0.060</td> <td>   -0.094</td> <td>    4.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>    7.4847</td> <td>    7.267</td> <td>    1.030</td> <td> 0.303</td> <td>   -6.767</td> <td>   21.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>    3.1343</td> <td>    0.919</td> <td>    3.411</td> <td> 0.001</td> <td>    1.332</td> <td>    4.937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>    4.6656</td> <td>    1.535</td> <td>    3.040</td> <td> 0.002</td> <td>    1.656</td> <td>    7.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>    6.3902</td> <td>    1.922</td> <td>    3.325</td> <td> 0.001</td> <td>    2.621</td> <td>   10.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>    6.8471</td> <td>    3.647</td> <td>    1.877</td> <td> 0.061</td> <td>   -0.305</td> <td>   14.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>    4.0994</td> <td>    0.850</td> <td>    4.822</td> <td> 0.000</td> <td>    2.432</td> <td>    5.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>    3.8890</td> <td>    0.755</td> <td>    5.150</td> <td> 0.000</td> <td>    2.408</td> <td>    5.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>    1.7748</td> <td>    1.861</td> <td>    0.954</td> <td> 0.340</td> <td>   -1.874</td> <td>    5.424</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>    4.4148</td> <td>    1.907</td> <td>    2.315</td> <td> 0.021</td> <td>    0.675</td> <td>    8.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>    2.5067</td> <td>    3.624</td> <td>    0.692</td> <td> 0.489</td> <td>   -4.599</td> <td>    9.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>    6.7952</td> <td>    3.614</td> <td>    1.880</td> <td> 0.060</td> <td>   -0.292</td> <td>   13.882</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>    3.9985</td> <td>    1.977</td> <td>    2.022</td> <td> 0.043</td> <td>    0.121</td> <td>    7.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>    3.5366</td> <td>    2.235</td> <td>    1.583</td> <td> 0.114</td> <td>   -0.846</td> <td>    7.919</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>    3.0774</td> <td>    1.127</td> <td>    2.730</td> <td> 0.006</td> <td>    0.867</td> <td>    5.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>    1.8412</td> <td>    3.358</td> <td>    0.548</td> <td> 0.584</td> <td>   -4.745</td> <td>    8.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>    4.3230</td> <td>    2.256</td> <td>    1.916</td> <td> 0.055</td> <td>   -0.101</td> <td>    8.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>    4.7297</td> <td>    1.216</td> <td>    3.889</td> <td> 0.000</td> <td>    2.345</td> <td>    7.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>    4.2220</td> <td>    5.462</td> <td>    0.773</td> <td> 0.440</td> <td>   -6.489</td> <td>   14.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>    9.1372</td> <td>    8.581</td> <td>    1.065</td> <td> 0.287</td> <td>   -7.690</td> <td>   25.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>    6.7048</td> <td>    7.345</td> <td>    0.913</td> <td> 0.361</td> <td>   -7.700</td> <td>   21.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>    4.4626</td> <td>    0.861</td> <td>    5.183</td> <td> 0.000</td> <td>    2.774</td> <td>    6.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>   -2.8553</td> <td>   13.798</td> <td>   -0.207</td> <td> 0.836</td> <td>  -29.915</td> <td>   24.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>    5.5648</td> <td>    1.179</td> <td>    4.718</td> <td> 0.000</td> <td>    3.252</td> <td>    7.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>    4.6458</td> <td>    1.496</td> <td>    3.105</td> <td> 0.002</td> <td>    1.712</td> <td>    7.580</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>    3.5974</td> <td>    0.808</td> <td>    4.452</td> <td> 0.000</td> <td>    2.013</td> <td>    5.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>    1.6173</td> <td>    6.341</td> <td>    0.255</td> <td> 0.799</td> <td>  -10.817</td> <td>   14.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>    6.9715</td> <td>    6.359</td> <td>    1.096</td> <td> 0.273</td> <td>   -5.498</td> <td>   19.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>    3.9531</td> <td>    0.925</td> <td>    4.274</td> <td> 0.000</td> <td>    2.139</td> <td>    5.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>   -2.8676</td> <td>    5.144</td> <td>   -0.557</td> <td> 0.577</td> <td>  -12.956</td> <td>    7.221</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>   11.2752</td> <td>    5.056</td> <td>    2.230</td> <td> 0.026</td> <td>    1.361</td> <td>   21.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>   13.6881</td> <td>    2.996</td> <td>    4.568</td> <td> 0.000</td> <td>    7.812</td> <td>   19.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>   10.9774</td> <td>   14.405</td> <td>    0.762</td> <td> 0.446</td> <td>  -17.272</td> <td>   39.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    2.7574</td> <td>    0.998</td> <td>    2.763</td> <td> 0.006</td> <td>    0.801</td> <td>    4.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>   10.3106</td> <td>    6.607</td> <td>    1.561</td> <td> 0.119</td> <td>   -2.646</td> <td>   23.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>    2.8457</td> <td>    2.373</td> <td>    1.199</td> <td> 0.231</td> <td>   -1.809</td> <td>    7.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>    0.5141</td> <td>    7.011</td> <td>    0.073</td> <td> 0.942</td> <td>  -13.235</td> <td>   14.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>   -3.6047</td> <td>    0.714</td> <td>   -5.051</td> <td> 0.000</td> <td>   -5.004</td> <td>   -2.205</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1481.326</td> <th>  Durbin-Watson:     </th> <td>   2.062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>17172.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.036</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>15.106</td>  <th>  Cond. No.          </th> <td>    539.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              citations   R-squared:                       0.097\n",
       "Model:                            OLS   Adj. R-squared:                  0.054\n",
       "Method:                 Least Squares   F-statistic:                     2.293\n",
       "Date:                Mon, 10 May 2021   Prob (F-statistic):           2.40e-11\n",
       "Time:                        11:19:49   Log-Likelihood:                -9029.1\n",
       "No. Observations:                2247   AIC:                         1.826e+04\n",
       "Df Residuals:                    2146   BIC:                         1.884e+04\n",
       "Df Model:                         100                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          8.1756      0.598     13.681      0.000       7.004       9.347\n",
       "x1             2.3686      0.949      2.496      0.013       0.508       4.229\n",
       "x2             3.4544      0.777      4.444      0.000       1.930       4.979\n",
       "x3             9.4013     10.037      0.937      0.349     -10.282      29.085\n",
       "x4             7.4660      4.793      1.558      0.119      -1.934      16.866\n",
       "x5             3.4395      1.195      2.878      0.004       1.096       5.783\n",
       "x6             2.9298      0.793      3.697      0.000       1.376       4.484\n",
       "x7             4.9210      2.394      2.055      0.040       0.226       9.616\n",
       "x8             1.7643      3.633      0.486      0.627      -5.360       8.889\n",
       "x9             0.0102      7.341      0.001      0.999     -14.386      14.407\n",
       "x10            3.5731      1.627      2.196      0.028       0.382       6.764\n",
       "x11           57.7275     15.607      3.699      0.000      27.120      88.335\n",
       "x12            4.1696      0.794      5.253      0.000       2.613       5.726\n",
       "x13            3.3999      1.308      2.600      0.009       0.835       5.965\n",
       "x14            2.3185      2.287      1.014      0.311      -2.167       6.804\n",
       "x15            6.1956      2.935      2.111      0.035       0.441      11.950\n",
       "x16            3.2183      1.104      2.916      0.004       1.054       5.383\n",
       "x17            3.6321      1.013      3.584      0.000       1.645       5.619\n",
       "x18            4.6962      1.304      3.602      0.000       2.140       7.253\n",
       "x19            5.4823      1.724      3.179      0.001       2.101       8.864\n",
       "x20            7.5599      2.002      3.775      0.000       3.633      11.487\n",
       "x21            2.8749      0.935      3.076      0.002       1.042       4.708\n",
       "x22           23.5968      8.166      2.890      0.004       7.584      39.610\n",
       "x23           10.9336      2.662      4.108      0.000       5.714      16.153\n",
       "x24           18.2985      6.561      2.789      0.005       5.432      31.165\n",
       "x25            3.0396      1.581      1.922      0.055      -0.061       6.141\n",
       "x26            3.5000      0.927      3.774      0.000       1.681       5.319\n",
       "x27            4.4379      2.506      1.771      0.077      -0.477       9.353\n",
       "x28          -12.6866     14.476     -0.876      0.381     -41.075      15.702\n",
       "x29            2.0654      1.111      1.859      0.063      -0.113       4.244\n",
       "x30            4.4300      0.842      5.263      0.000       2.779       6.081\n",
       "x31            5.3436      1.999      2.673      0.008       1.424       9.264\n",
       "x32           32.9450     10.082      3.268      0.001      13.174      52.717\n",
       "x33           10.8561      2.614      4.153      0.000       5.729      15.983\n",
       "x34            1.0647      3.892      0.274      0.784      -6.568       8.697\n",
       "x35            5.0806      3.580      1.419      0.156      -1.941      12.102\n",
       "x36            3.5391      0.828      4.274      0.000       1.915       5.163\n",
       "x37           10.1316      3.472      2.918      0.004       3.324      16.940\n",
       "x38            5.9213      3.352      1.767      0.077      -0.651      12.494\n",
       "x39           37.7750     13.911      2.715      0.007      10.494      65.056\n",
       "x40            0.2054      5.481      0.037      0.970     -10.543      10.954\n",
       "x41            5.7812      1.632      3.541      0.000       2.580       8.982\n",
       "x42            1.7500      2.498      0.701      0.484      -3.148       6.648\n",
       "x43            3.8664      1.579      2.449      0.014       0.770       6.963\n",
       "x44           10.7464      7.738      1.389      0.165      -4.428      25.920\n",
       "x45            2.7084      1.532      1.768      0.077      -0.295       5.712\n",
       "x46            3.3695      1.258      2.679      0.007       0.903       5.836\n",
       "x47            2.8775      3.687      0.780      0.435      -4.353      10.107\n",
       "x48            9.1220      3.648      2.501      0.012       1.969      16.275\n",
       "x49            4.7204      2.915      1.619      0.106      -0.997      10.438\n",
       "x50            2.4609      2.593      0.949      0.343      -2.624       7.546\n",
       "x51            3.9170      0.748      5.234      0.000       2.449       5.385\n",
       "x52            5.2454      3.137      1.672      0.095      -0.907      11.398\n",
       "x53            2.3919      1.062      2.251      0.024       0.308       4.475\n",
       "x54            3.3237      0.741      4.486      0.000       1.871       4.777\n",
       "x55            6.6156      5.501      1.203      0.229      -4.172      17.403\n",
       "x56            4.0957      0.979      4.184      0.000       2.176       6.015\n",
       "x57            2.8153      1.076      2.616      0.009       0.704       4.926\n",
       "x58            3.4362      1.330      2.584      0.010       0.828       6.044\n",
       "x59           14.9447      6.332      2.360      0.018       2.527      27.362\n",
       "x60            3.6024      1.064      3.385      0.001       1.515       5.689\n",
       "x61           -1.6888      6.970     -0.242      0.809     -15.357      11.979\n",
       "x62           11.6170      3.340      3.478      0.001       5.067      18.167\n",
       "x63            2.1874      1.163      1.881      0.060      -0.094       4.468\n",
       "x64            7.4847      7.267      1.030      0.303      -6.767      21.736\n",
       "x65            3.1343      0.919      3.411      0.001       1.332       4.937\n",
       "x66            4.6656      1.535      3.040      0.002       1.656       7.675\n",
       "x67            6.3902      1.922      3.325      0.001       2.621      10.159\n",
       "x68            6.8471      3.647      1.877      0.061      -0.305      14.000\n",
       "x69            4.0994      0.850      4.822      0.000       2.432       5.766\n",
       "x70            3.8890      0.755      5.150      0.000       2.408       5.370\n",
       "x71            1.7748      1.861      0.954      0.340      -1.874       5.424\n",
       "x72            4.4148      1.907      2.315      0.021       0.675       8.155\n",
       "x73            2.5067      3.624      0.692      0.489      -4.599       9.613\n",
       "x74            6.7952      3.614      1.880      0.060      -0.292      13.882\n",
       "x75            3.9985      1.977      2.022      0.043       0.121       7.876\n",
       "x76            3.5366      2.235      1.583      0.114      -0.846       7.919\n",
       "x77            3.0774      1.127      2.730      0.006       0.867       5.288\n",
       "x78            1.8412      3.358      0.548      0.584      -4.745       8.427\n",
       "x79            4.3230      2.256      1.916      0.055      -0.101       8.747\n",
       "x80            4.7297      1.216      3.889      0.000       2.345       7.115\n",
       "x81            4.2220      5.462      0.773      0.440      -6.489      14.933\n",
       "x82            9.1372      8.581      1.065      0.287      -7.690      25.964\n",
       "x83            6.7048      7.345      0.913      0.361      -7.700      21.109\n",
       "x84            4.4626      0.861      5.183      0.000       2.774       6.151\n",
       "x85           -2.8553     13.798     -0.207      0.836     -29.915      24.204\n",
       "x86            5.5648      1.179      4.718      0.000       3.252       7.878\n",
       "x87            4.6458      1.496      3.105      0.002       1.712       7.580\n",
       "x88            3.5974      0.808      4.452      0.000       2.013       5.182\n",
       "x89            1.6173      6.341      0.255      0.799     -10.817      14.052\n",
       "x90            6.9715      6.359      1.096      0.273      -5.498      19.441\n",
       "x91            3.9531      0.925      4.274      0.000       2.139       5.767\n",
       "x92           -2.8676      5.144     -0.557      0.577     -12.956       7.221\n",
       "x93           11.2752      5.056      2.230      0.026       1.361      21.190\n",
       "x94           13.6881      2.996      4.568      0.000       7.812      19.564\n",
       "x95           10.9774     14.405      0.762      0.446     -17.272      39.227\n",
       "x96            2.7574      0.998      2.763      0.006       0.801       4.714\n",
       "x97           10.3106      6.607      1.561      0.119      -2.646      23.267\n",
       "x98            2.8457      2.373      1.199      0.231      -1.809       7.500\n",
       "x99            0.5141      7.011      0.073      0.942     -13.235      14.263\n",
       "x100          -3.6047      0.714     -5.051      0.000      -5.004      -2.205\n",
       "==============================================================================\n",
       "Omnibus:                     1481.326   Durbin-Watson:                   2.062\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17172.965\n",
       "Skew:                           3.036   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.106   Cond. No.                         539.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = sm.OLS(y_train_sm, X_train_sm).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c82d7-0d63-4d61-a100-27f2e72840b6",
   "metadata": {},
   "source": [
    "#### sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a37c5e4-206b-49ac-8b43-8e63aba1dff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split \n",
    "X_train, X_test, y_train, y_test=train_test_split(X,\n",
    "                                                 y,\n",
    "                                                 test_size=.2,\n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83e74369-5feb-4710-8c6c-9e8e64bf2cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0943a734-b672-4a59-a494-2c0d4e8d02be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1001694881137769 -6.580819492417445e+19 -4.5225530269651395e+19\n"
     ]
    }
   ],
   "source": [
    "train_score = linreg.score(X_train, y_train)\n",
    "test_score = linreg.score(X_test, y_test)\n",
    "cv_score = cross_val_score(linreg, X_train, y_train).mean()\n",
    "print(train_score, test_score, cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb3329cc-de5f-4acf-9e4c-0889a4055481",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "Z_train = sc.fit_transform(X_train)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa762b3f-334d-4937-8c3c-e3e1613c61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a list of Lasso alphas to check.\n",
    "l_alphas = np.linspace(-3,0, 100)\n",
    "\n",
    "# Cross-validate over our list of Lasso alphas.\n",
    "lasso_cv = LassoCV(alphas=l_alphas, cv=5, max_iter=5_000)\n",
    "\n",
    "# Fit model using best lasso alpha!\n",
    "lasso_cv.fit(Z_train, y_train)\n",
    "\n",
    "train_score = lasso_cv.score(Z_train, y_train)\n",
    "test_score = lasso_cv.score(Z_test, y_test)\n",
    "cv_score = cross_val_score(lasso_cv, Z_train, y_train).mean()\n",
    "print(train_score, test_score, cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5875370b-4751-41ce-baf1-0be770e660e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    BaggingRegressor(),\n",
    "    RandomForestRegressor(),\n",
    "    AdaBoostRegressor(),\n",
    "    SVR(),\n",
    "    MLPRegressor()\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for model_obj in model_list:\n",
    "    #instantiate each model \n",
    "    model = model_obj\n",
    "   \n",
    "    #fit the model\n",
    "    model.fit(X_train, y_train) \n",
    "  \n",
    "    #create a dictionary with scores and evaluation metrics for each model\n",
    "    results_dict = {}    \n",
    "    results_dict['model_name'] = str(model_obj)\n",
    "    results_dict['train_score'] = model.score(X_train, y_train)\n",
    "    results_dict['test_score'] = model.score(X_test, y_test)\n",
    "    results_dict['cv_score'] = cross_val_score(model, X_train, y_train, cv = 5).mean()\n",
    "    results_dict['train_RMSE'] = np.sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
    "    results_dict['test_RMSE'] = np.sqrt(mean_squared_error(y_test, model.predict(X_test))) \n",
    "    \n",
    "    #add the dictionary to the list\n",
    "    results_list.append(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33025ec4-1e2b-4907-bb28-043dbea1bb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv_score</th>\n",
       "      <th>train_RMSE</th>\n",
       "      <th>test_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.107889</td>\n",
       "      <td>-3.854745e+18</td>\n",
       "      <td>-8.554226e+19</td>\n",
       "      <td>13.633553</td>\n",
       "      <td>3.364617e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>0.903520</td>\n",
       "      <td>-5.681028e-01</td>\n",
       "      <td>-1.006465e+00</td>\n",
       "      <td>4.483517</td>\n",
       "      <td>2.145977e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BaggingRegressor()</td>\n",
       "      <td>0.726274</td>\n",
       "      <td>-1.223815e-01</td>\n",
       "      <td>-2.296880e-01</td>\n",
       "      <td>7.551918</td>\n",
       "      <td>1.815549e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor()</td>\n",
       "      <td>0.769043</td>\n",
       "      <td>-7.729565e-02</td>\n",
       "      <td>-1.617014e-01</td>\n",
       "      <td>6.936890</td>\n",
       "      <td>1.778710e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostRegressor()</td>\n",
       "      <td>-0.263098</td>\n",
       "      <td>-2.319613e-01</td>\n",
       "      <td>-5.518553e-01</td>\n",
       "      <td>16.222514</td>\n",
       "      <td>1.902113e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>-0.120087</td>\n",
       "      <td>-1.505261e-01</td>\n",
       "      <td>-1.359134e-01</td>\n",
       "      <td>15.276555</td>\n",
       "      <td>1.838171e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name  train_score    test_score      cv_score  \\\n",
       "0       LinearRegression()     0.107889 -3.854745e+18 -8.554226e+19   \n",
       "1  DecisionTreeRegressor()     0.903520 -5.681028e-01 -1.006465e+00   \n",
       "2       BaggingRegressor()     0.726274 -1.223815e-01 -2.296880e-01   \n",
       "3  RandomForestRegressor()     0.769043 -7.729565e-02 -1.617014e-01   \n",
       "4      AdaBoostRegressor()    -0.263098 -2.319613e-01 -5.518553e-01   \n",
       "5                    SVR()    -0.120087 -1.505261e-01 -1.359134e-01   \n",
       "\n",
       "   train_RMSE     test_RMSE  \n",
       "0   13.633553  3.364617e+10  \n",
       "1    4.483517  2.145977e+01  \n",
       "2    7.551918  1.815549e+01  \n",
       "3    6.936890  1.778710e+01  \n",
       "4   16.222514  1.902113e+01  \n",
       "5   15.276555  1.838171e+01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results_list)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a19e061-dbab-4139-9790-d239580ecf9b",
   "metadata": {},
   "source": [
    "These are very poor results. None of these words account for the variance in the target variable. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
